{"title": "Secure Randomness, Consensus, and Threshold Signatures. Eleftherios Kokoris-Kogias†", "content": "Asynchronous Distributed Key Generation for Computationally-\nSecure Randomness, Consensus, and Threshold Signatures.\nEleftherios Kokoris-Kogias†\nFaceook Novi & IST Austria\nlefteris2k@gmail.comDahlia Malkhi\nFaceook Novi\ndahliamalkhi@gmail.comAlexander Spiegelman\nFaceook Novi\nsasha.spiegelman@gmail.com\nABSTRACT\nIn this paper, we present the first Asynchronous Distributed Key\nGeneration (ADKG) algorithm which is also the first distributed\nkey generation algorithm that can generate cryptographic keys\nwith a dual (f,2f+1)−threshold (where fis the number of faulty\nparties). As a result, using our ADKG we remove the trusted setup\nassumption that the most scalable consensus algorithms make. In\nordertocreateaDKGwithadual (f,2f+1)−thresholdwefirst\nanswer in the affirmative the open question posed by Cachin et\nal. [7] on how to create an Asynchronous Verifiable Secret Sharing\n(AVSS) protocol with a reconstruction threshold of f+1<k≤\n2f+1, which is of independent interest. Our High-threshold-AVSS\n(HAVSS) uses an asymmetric bivariate polynomial to encode the\nsecret. This enables the reconstruction of the secret only if a set\nofknodescontributewhileallowinganhonestnodethatdidnot\nparticipate in the sharing phase to recover his share with the help\noff+1 honest parties.\nOncewehaveHAVSSwecanuseittobootstrapscalablepartially\nsynchronousconsensusprotocols,butthequestiononhowtogeta\nDKGinasynchronyremainsasweneedawaytoproducecommon\nrandomness. The solution comes from a novel Eventually Perfect\nCommon Coin (EPCC) abstraction that enables the generation of a\ncommoncoinfrom nconcurrentHAVSSinvocations.EPCC’skey\nproperty is thatit is eventually reliable, asit might fail toagree at\nmostftimes(evenifinvokedapolynomialnumberoftimes).Using\nEPCCweimplementan EventuallyEfficientAsynchronousBinary\nAgreement (EEABA)which isoptimalwhenthe EPCCagreesand\nprotects safety when EPCC fails.\nFinally, using EEABA we construct the first ADKG which has\nthe same overhead and expected runtime as the best partially-synchronous DKG (\nO(n4)words,O(f)rounds). As a corollary of\nour ADKG, we can also create the first Validated Asynchronous\nByzantineAgreement(VABA)that doesnot need atrusted dealer\nto setup threshold signatures of degree n−f. Our VABA has an\noverheadofexpected O(n2)wordsand O(1)timeperinstance,after\nan initial O(n4)words and O(f)time bootstrap via ADKG.\n∗Corresponding Author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\nand/or a fee. Request permissions from permissions@acm.org.\nCCS ’20, November 9–13, 2020, Virtual Event, USA\n© 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7089-9/20/11...$15.00\nhttps://doi.org/10.1145/3372297.3423364CCS CONCEPTS\n•Securityandprivacy →Distributedsystemssecurity ;Cryp-\ntography; Security protocols; •Computing methodologies →\nDistributed algorithms.\nKEYWORDS\nasynchornous verifiable secret sharing; consensus; randomness;\nmultipartycomputation;byzantinefault-tolerance;blockchain;thresh-\nold sharing; distributed key generation; binary agreement\nACM Reference Format:\nEleftheriosKokoris-Kogias,DahliaMalkhi,andAlexanderSpiegelman.2020.\nAsynchronous Distributed Key Generation for Computationally- Secure\nRandomness,Consensus,andThresholdSignatures..In Proceedingsofthe\n2020ACMSIGSACConferenceonComputerandCommunicationsSecurity\n(CCS ’20), November 9–13, 2020, Virtual Event, USA. ACM, New York, NY,\nUSA, 17 pages. https://doi.org/10.1145/3372297.3423364\n1 INTRODUCTION\nA common assumption made by many modern Byzantine fault\ntolerantdistributedalgorithmsistheexistenceofatrusteddealer\nthat generates and distributes cryptographic keys at the beginning\nof every execution. For example, efficient asynchronous Byzantine\nagreement protocols [ 1,3,9,17,29] use a shared coin scheme to\nproduce randomness [ 34], efficient state machine replication proto-\ncols [20,35] use a threshold signature scheme to reduce commu-\nnicationcomplexity,andefficientsecuremultipartycomputation\nprotocols [ 22,23] use threshold encryption [ 26] to reduce the com-\nmunicationcomplexityforsharingsecretinputs.Alltheseschemes\nrequire a trusted dealer, which is a single point of failure and a\npotential weakness for secure decentralized systems.\nItisthereforenaturaltoaskunderwhatnetworkassumptions\nand at what cost the requirement of a trusted dealer can be sub-\nstituted with a distributed key generation (DKG) protocol. A DKG\nprotocolallowsagroupofpartiestodistributeprivatesharesofa\ncryptographic key and later use them to compute a common value\nsuchthatanadversarycontrollingathresholdofthepartiescan-\nnotpredictthevalue.Thereby,thisvaluecanbeusedtoproduce\nunpredictable randomness or as a “private” key.\nIn synchronous communication settings, a DKG protocol can be\nrealizedvia acombinationof twobuildingblocks,secret sharing\nandconsensus[ 32](orabroadcastchannelsuchasablockchain[ 2,\n18]). In a nutshell, all parties simultaneously choose and share a\nsecret and then use a Byzantine agreement instance for each secret\nin order to agree if it should be part of the key. The key is the\nsum of all valid secrets and the share of each party is the sumof the corresponding shares. To the best of our knowledge, no\nasynchronousDKG(ADKG)protocolhasbeenpreviouslyproposed.\nWe focus on protocols with n=3f+1 parties that assume no*\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1751trusted setup except for public key infrastructure (PKI). We further\nexplore protocols that support threshold recovery of 2 f+1, which\nis required by efficient Byzantine agreement algorithms that use\nthreshold signatures to reduce the size of the messages from linear\nin the number of parties to constant [1, 20, 35].\nAnaiveapproachforADKGistoapplytheideasin[ 32]tothe\nasynchronoussettings.For example,itispossible tousetheAVSS\nscheme of Cachin et al [ 7] andnindependent parallel instances of\na binary agreement protocol1like [4,6]. However, the resulting\nalgorithm has three drawbacks: First, the secret sharing in [ 7] has\nareconstructionthresholdof f+1andthustheresultingADKG\ncannothavethedesired2 f+1threshold.Second,running nbinary\nagreements does not guarantee a successful protocol execution,\nsincetheycanallterminatewith0whichmeansthatthekeywill\ninclude no secrets. Finally, even if we could guarantee that morethan\nfinstances terminate successfully2, the resulting protocol\nwouldbeinefficientwithacommunicationcomplexityof O(n5loдn).\nInthispaperwepresentthefirstADKGprotocolwitharecovery\nthreshold of 2 f+1 and low communication cost. Formally, the\nmain theorem we prove in this paper is following:\nTheorem 1.1. There exists a protocol among nparties that solves\nAsynchronousDistributedKeyGeneration(ADKG)withreconstruc-\ntion threshold k≤n−fand is secure against an adaptive adversary\nthat controls up to f<n/3parties, with expected O(n4)communica-\ntion complexity and expected O(f)running time.\nIn a nutshell, our protocol follows the idea of concurrently shar-\ningnsecretsandthenagreewhichtoconsiderforthekey.However,\ninstead of using a costly Byzantine agreement instance for each\nsecret,weusethesecretsasthedrivingrandomnesssourcetobuild\nan efficient common coin which in turn we use for an efficient\nByzantine agreement. In particular, we observe that to build a com-\nmon coin from the secrets we can use a slightly weaker agreement\nnotion which is not subject to the FLP impossibility result. To this\nend,wefirstimprovetheasynchronoussecretsharingschemein[ 7]\ntosupport2 f+1reconstructionthreshold.Then,werelyonthe\ncompletenesspropertyofoursecretsharingschemeandguarantee\nthat eventually all honest parties get shares for the same secrets.\nAs a result, we know that all parties eventually agree on the set of\nsecrets and ,hence, could use it for a shared coin. Unfortunately,the parties do not know when this happens (in contrast to the\nagreement problem) and cannot ever terminate.\nTocircumventthisnon-terminationproblem,ourideaistolet\nthe parties optimistically think that every received share is the last\none (i.e., all correct AVSS instance have terminated and all other\ninstancesarefaulty)andtrytoterminate.Eachtimeanewshare\nis received by n−fparties, they generate new key shares and\ninitiate a shared coin protocol (produce a threshold signature and\nhashittogetunpredictablerandomness).Thissharedcoinflipis\nin turn used in some efficient binary agreement protocol (these\nkeysreplacetheonesproducedbythetrusteddealer).Iftheparties\nhappento agreeon thekey (theirsets ofshares correspond tothe\nsamesecrets),thentheByzantineagreementprotocolterminates\nsuccessfully.Otherwise,somepartiesreceivedsharesthatothers\nhave not yet received and they will try again to terminate when\n1Each instance agrees on whether an AVSS secret is correctly shared.\n2So that the adversary does not know all the secrets that are included in the key.the next (additional) secret is recoverable by all honest parties.\nWecallourcoin EventuallyPerfectCommonCoin(EPCC) andthe\nresultingByzantineagreement EventuallyEfficientAsynchronous\nBinaryAgreement(EE-ABA) ,becauseeventually(afteratmost f\nfailed tries) the protocols converge to the optimal solutions.\nFinally, once we have an EE-ABA, we run ninstances that share\nthe same EPCC and use it in order to decide on the final set of\nshares,whichterminatestheADKGprotocol.Inordertoguaranteethat the final key is unpredictable, the parties refrain from voting 0\ninthebinaryagreementinstancesthattheyconsiderfaultyuntil\nthey witness f+1 binary agreements terminating with 1 (which is\nguaranteedtohappenduetothestrongterminationoftheHAVSS).Nextweexplainthealgorithmsinmoredetailandprovethatparties\ncannot disagree on the set of shares more than ftimes.\n1.1 Technical contribution\nWe break the ADKG construction in a bottom-up manner, starting\nwithabuildingblock(Section3)wecall High-thresholdAsynchro-\nnousVerifiableSecretSharing (HAVSS).HAVSSisanextensionof\nCachin et al. [ 7] AVSS protocol that answers in the affirmative the\nopenquestiontheyposedontheexistenceofanAVSSprotocolthathasareconstructionthresholdof\nf+1<k≤2f+1.Toachievethis,\nwe separate the reconstruction threshold(which we increase to k)\nfromtherecoverythreshold(whichisstill f+1).Inordertoencode\nthischange,weusean asymmetric bivariatepolynomialwhereeach\ndimension plays a different role (recovery, reconstruction) and we\ndefend againstan adaptiveadversary with areliable broadcast step\nbefore terminating the sharing. More formally HAVSS satisfies the\nfollowing lemma.\nLemma 1.2. There exists a protocol among nparties that solves\nAsynchronous Verifiable Secret Sharing (AVSS) for reconstructionthreshold\nf+1<k≤n−f, with no trusted setup, and is secure\nagainst an adaptive adversary that controls up to f<n/3parties,\nwithO(n3)word communication.\nThe“secretsauce”: Thesecond(intermediate)buildingblockis\ntheweakDistributedKeyGeneration (Section4).Itbuildsontopof n\nparallel HAVSS invocations and uses the fact that all honest nodes\neventuallyterminateallcorrectHAVSStodeliverapredictionon\nwhattheDKGshouldoutput.ThewDKGisweakerthanconsensus\nbecause it refrains from outputting a final decision. Instead, it acts\nasaneventuallyperfectagreementdetector.AnyprotocolthatusesthewDKGgetstheguaranteethateventuallyallpartieswilloutput\nthe same key, but the specific time when the detector becomes\nperfectcannotbedetermined.OnekeypropertyofwDKGisthat\neverypredictionisasupersetofallpriorpredictions,hencethere\ncan only be a limited, totally-ordered number of predictions.\nOurthirdbuildingblock(Section5)iscalled EventuallyPerfect\nCommonCoin (EPCC).ItreliesonthewDKGtodetectthepoints\nof agreement and on adaptively secure deterministic thresholdsignatures [\n28] to produce the randomness. The key property of\nthe EPCC is that the adversary can only force it to disagree a finite\n(f)numberoftimes.Thishappensbecauseapointofdisagreement\noccurs only if f+1 honest parties are slower than the rest and\nthe adversary brings them up to speed after they have invoked the\nEPCC but before they deliver the result. Due to the way the wDKG\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1752is constructed this can happen for at most fdifferent keys and for\neach candidate key it may happen at most once.\nOncewehavetheEPCCwecanusetheprotocolofMoustefaoui\netal.[29]tocreateourfourthbuildingblock:anefficientAsynchro-\nnous Binary Agreement protocol that does not assume a trusted\nsetup(Section6.1).Wecallit EventuallyEfficientABA(EEABA) asit\nmight have ffailed runs before converging, but once it converges\nit is optimal (with communication complexity of O(n2)and con-\nstantexpectedroundcomplexity).FormallyEEABAachievesthe\nfollowing:\nLemma 1.3. There exists a protocol among nparties that solves\nAsynchronousBinaryAgreement(ABA)withoutatrusteddealerin\nthe authenticated setting and is secure against an adaptive adversary\nthat controls up to f<n/3parties, with O(n4)one-shot ( O(n2)\namortized)wordcommunicationandexpected O(f)one-shot( O(1)\namortized) running time.\nFinally, in Section 6.2 we invoke nconcurrent and correlated\nEEABAs(oneforeveryHAVSS)toagreeonthesetofsharesthat\nconstruct the key and complete the ADKG protocol (Theorem 1).\nCorollaries. Since solving DKG implies a solution for consensus\n(if the secret value is public then it can be used as the consensus\ndecision), a corollary of our main theorem is:\nCorollary1.4. Thereexistsaprotocolamong npartiesthatsolves\nValidated Asynchronous Byzantine Agreement without a trusted\ndealer in the authenticated setting and is secure against an adap-tive adversary that controls up to\nf<n/3parties, with expected\nO(n4)word communication and expected O(f)running time.\nAndthroughthecombinationofourADKGwiththeoptimalval-\nidated asynchronous Byzantine agreement (VABA) of [ 1] a second\ncorollary is:\nCorollary1.5. Thereexistsaprotocolamong npartiesthatsolves\nValidated Asynchronous Byzantine Agreement without a trusteddealer in the authenticated setting and is secure against an adap-tive adversary that controls up to\nf<n/3parties, with expected\nO(n2)amortizedwordcommunicationandexpectedconstantamor-\ntized running time.\nContributions. In summary our contributions are:\n•Weanswertheopenproblemofahigh-thresholdAVSSposedbyCachinetal.[\n7]affirmatively.HAVSSincombinationwith\nHybrid-DKG[ 24]removesthesetuprequirementofefficient\npartially synchronous consensus protocols [20, 35].\n•WeintroduceanovelEPCCconstructionthatdisagreesat\nmostftimes but can be used polynomially many times.\n•UsingourEPCCinsidetheprotocolofMoustefauoietal.[ 29]\nwecreateEEABAprotocolthatneedsnotrustedsetup.EE-\nABA is optimal if amortized. It terminates in O(f)one-shot\n(O(1)amortized)expectedroundsandhas O(n4)forone-shot,\n(O(n2)amortized) word complexity.\n•UsingnparallelinvocationofBinaryAgreement(allsharing\nthesameEPCC),weconstructacomputationally-secure,effi-\ncient, leaderless ADKG. Once the ADKG terminates, we can\nusetheresultingkeyasaperfectcommoncoinandasthekey\nused in the threshold signature scheme, which are the build-\ning blocks of VABA. The ADKG has O(n4)word complexityandterminatesinanexpected O(f)rounds.Hence,thecom-\nbination of ADKG and VABA results in the first trustless\nVABA solution, which is also optimal if amortized.\n1.2 Related work\nConsensusisoneofthemostwellstudieddistributedsystemsprob-\nlem, first introduced by Pease et al [ 31], which has become once\nagainrelevantduetotheinterestinblockchainprotocols[ 25,27].\nTheproblemcanbestatedinformallyas:howtoensurethataset\nof distributed processes achieve agreement on a value despite a\nfractionoftheprocessesbeingfaulty.Fromatheoreticalpointof\nview, the relevance of the consensus problem derives from several\notherdistributedsystemsproblemsbeingreducibleorequivalent\nto it. Examples are atomic broadcast [ 21], or state machine replica-\ntion[33].Algorithmsthatsolveconsensusvarymuchdependingon\nthe system model. This paper considers a message-passing setting\nfor systems that may experience Byzantine (or arbitrary) faults in\nasynchronous settings (i.e., without timing assumptions).\nIn this paper, we focus on 3 interconnected variants: Asyn-\nchronous Binary Agreement (ABA), Distributed Key Generation\n(DKG),andValidatedAsynchronousByzantineAgreement(VABA).\nFurthremore, we survey Asynchronous Secure Multiparty Compu-\ntation(AMPC)thatcouldprovideagenericsolutiontoourproblem.\nABA:.The first optimally resilient ( f<n/3) ABA was intro-\nduced by Bracha [ 6]. It is based on locally drawn random coins\nused to defend against a network controlling adversary. As the\nprotocoluseslocalrandomizationitcanonlyterminatewhenall\ncorrect processes happen to propose the same (0 or 1) value which\nhas an expected O(2n)number of rounds with every round costing\nO(n3)messages. Canetti and Rabin [ 11] where the first to propose\nanABAthathaspolynomialtotalcommunicationcomplexity,how-\never, the protocol is far from practically efficient with a cost of\nO(n8loдn)bits. Advancements in the information-theoretic secure\nmodel have lowered the cost down to O(n6)[4].\nIn order to reduce the communication complexity, Cachin et\nal[9]demonstratedhowtoachieveconsensusagainstacomputationally-\nboundedadversaryusingcryptography.Tryingtoachievethis,how-\never, introduced a new assumption of a trusted dealer that dealsa perfect common-coin. Mostefaoui et al. [\n29] slightly weakened\nthe assumption of Cachin et al. by assuming a weak common-coin.\nNevertheless, it remains an open problem on how to get such a\ncoinefficiently.Thisisthecoreofourwork,webuildaneventually\nperfect common coin without the need of a trusted dealer. Ourcoin is also in the computationally-bounded adversary and falls\nin-between the weak coin and the perfect coin and as a result, can\npower Mostefaoui’s protocol.\nDKG:.Adistributedkeygenerationisaprotocolthatisexecuted\noncebyasetofpartiesinordertoachieveconsensusonashared\nsecretkey.Thecoreideaisthateachpartyusessecretsharingto\ndispersesomesecretvalueandthenthepartiesreachconsensuson\nwhichsecretvalueshavebeencorrectlyshared.Intheend,these\nvaluesarecombinedandthefinalresultisathresholdprivate-public\nkey-pair that can be used for efficient ABA [ 9] and VABA [ 1]. The\nfirst DKG was proposed by Pedersen [ 32] and is fully synchronous.\nGennaroetal.[ 19]showedthatPedersen’sschemeissecureifused\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1753forthreshold signatures,but does notproduce uniformlyrandom\nkeys. Hence they also proposed a scheme that produces such keys,\nwhich is not of interest to our protocols. Later, Kate et al. [ 24]\nrealized that synchronous protocols are not suitable for large scale\ndeploymentovertheInternetandproposedapartially-synchronous\nDKG instead. Their protocol has a worst-case O(n4)bit complexity\nand produces keys with a threshold of k=f+1.\nOurcontributiontotheDKGspaceistwo-fold.First,weshow\nhow to generate keys with threshold reconstruction k=2f+1,\nwhich as we already mentioned can be used to power scalable\npartially synchronous BFT protocols [ 20,35]. Second, we create\nthefirstasynchronousDKGwith O(n4)wordcomplexitymakingit\npractical to generate distributed keys with no timing assumptions.\nVABA:.The VABA problem was introduced by Cachin et al. [ 8]\nwhichgeneralizesABA,byallowinganyexternallyvalidvalueto\nbeeligibleforconsensus.Inthismodel,Abrahametal.[ 1]havepro-\nvidedanoptimalsolution( f<n/3)forVABAthathasanexpected\ncomplexity of O(n2)messages and terminates with probability 1\nin an expected constant number of rounds. Both these protocols\nassume a perfect-coin, hence require a trusted setup. Our contri-bution in this model is also two-fold. First we show how we can\nimplement a VABA protocol with no trusted setup and second we\nshow how to bootstrap the more efficient protocols [ 1,8] with our\nADKG in order to get an optimal VABA if we amortize the cost of\nthe ADKG over O(n2)runs.\nSecure Multiparty Computation: On a first glance our protocol\ncan be categorised as a special case of Asynchronous Secure Multi-\nparty Computation [ 5], however with further inspection it actually\nprovides a foundation for increasing the efficiency [ 5,14,15,22,\n23,30]andremovingthetrustedsetupassumption[ 14,22,23]of\nexisting multiparty computation protocols.\nMore specifically, existing MPC protocols assume access to a\nByzantineAgreementblackbox whichtheyneed toreachagree-\nmentontheinputsbydeployingnparallelBAs.HoweverthisblackboxdeploymentofBAleadstoinefficienciesleadingtoanexpected\nO(n5loдn)worldcomplexityinthecryptographicallysecuresetting.\nUsing our protocol which opens the black boxes and reuses the\ncommon coin, we can agree on the same inputs in only O(n4).\nFurthermore, MPC protocols either assume a trusted setup of\nthresholdsignaturesandthresholdencryption[ 14,22,23]oremploy\naspecialtypeofAVSScalledACSS[ 5],whichguaranteesthatall\nhonestparties (insteadof f+1)get ashare.Our HAVSS provides\nthesameguarantees,makingitacryptographicallysecureACSS\nprotocol. Choudry and Patra [ 13] have created a framework where\nan MPC protocol can be constructed using BA and ACSS, as a\nresultifwepluginourHAVSSandcoupleitwitherror-corrected\nreliable broadcast [ 10] we could get the most efficient AMPC with\ncomplexityof O(n3loдn)permultiplicationgate.Thisimprovement\ncomes at the cost of sacrificing unconditional security since the\nstateofthearthasan O(n5loдn)cost3.However,themostnatural\nuseofADKG wouldbetobootstrapthe thresholdencryptionandthreshold signingprotocols of[\n23] andthen runat O(n2)cost per\nmultiplication gate. If the AMPC protocol has more than O(n2)\ngates, then we can get an amortized cost of O(n2)per gate.\n3Concurrent non peer-reviewed works claims reduction to O(n4loдn)[12]In summary, this paper provides practical improvements on\nthe foundation protocols of AMPC which could result through\ncompositiontopracticallyefficientproto cols.However,weleave\nthe actual secure implementation and proofs to future work.\n2 MODEL AND DEFINITIONS\nIn order to reason about distributed algorithms in cryptographicsettings we adopt the model defined in [\n9]. For space limitation\nandbetterreadabilitywedefinehereasimplifiedversionandthe\nfullformalmodelcanbefoundin[ 1,8,9]andinAppendixA.We\nconsider an asynchronous message passing system consisting of a\nsetΠofnparties and an adaptive adversary. The adversary may\ncontrol up to f<n/3 parties during an execution. An adaptive\nadversaryisnotrestrictedtochoosewhichpartiestocorruptatthe\nbeginningofanexecution,butisfreetocorrupt(upto f)parties\nonthefly.Notethatonceapartyiscorrupted,itremainscorrupted,andwecallitfaulty.Apartythatisnevercorruptediscalled honest.\nCommunication. Weassumeasynchronousauthenticatedlinks\ncontrolled by the adversary, that is, the adversary can see all mes-\nsages and decide when and what messages to deliver but cannot\ndeliver a message from an honest party that was not generated by\nit.Inordertobeabletousecryptographictoolsinasynchronous\nsettings,themodeldefinedin[ 1,8,9]restrictstheadversarytoper-\nform no more than a polynomial in the security parameter number\nof computation steps during the time a message between two hon-\nest parties is sent and delivered. For completeness, in Appendix A,\nwe give the formal definition of the assumption on message deliv-\nery and the termination requirement in asynchronous protocols\nwithcomputationallyboundedadversaries.Ho wever,inor dertobe\nable to focus on the distributed computing aspect of our work, we\nassumethroughoutthepaperperfectcryptographictools,standard\ndelivery assumptions and termination requirement. That is, weassume every message between two honest parties is eventually\ndelivered.\nComplexity. Following[ 1],ourbasiccommunicationunitis word,\nwhich maycontain a constant number of valuesof somedomain V\nandcryptographicsignatures.Wedefinethetotal communication\ncostof our protocol to be the number of words sent among honest\nparties. One word is a signature that is linear in the size of the\nsecurity parameter.\nCryptographicAbstractions. Giventhatourprotocolsusecryp-\ntographic constructions as black boxes, we assume perfect cryp-\ntographictoolsandpresentsimplifiededucationalexamplesthat\nuse the multiplicative notation and simple computationally hiding\ncommitments.Furthermore,inordertostillhaveacorrectproto-\ncolweemploytheDiffie-HellmanBasedThresholdCoin-Tossing\nSchemeofCachinetal.[ 9].Thiswaythereadercanfocusonthe\ndistributed aspect of the protocol which is the novelty. However,\nin order to be adaptively-secure, the actual implementation of our\nconsensusalgorithmrequirespairing-basedthresholdcryptogra-\nphy, as shown by Libert et al. [ 28]. More specifically, Libert et al.\nrunsaclassicsynchronousDKG[ 32],butwecaninsteaduseour\nADKG (Section 6.2) to terminate their protocol in asynchrony and\ngenerate the consistent secret shares.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1754Diffie-Hellman Based Coin. In order to follow our protocols, we\nneedtopresentthecoin-tossingprotocolofCachinetal.[ 9].We\nwork with a group Gof large prime order q. At a high level, the\nvalue of a coin Cis obtained by first hashing Cto obtain ¯д∈G,\nthenraising ¯дtoasecretexponent x0∈Zqtoobtain ¯д0∈G,and\nfinally hashing ¯д0to obtain the value F(C)∈{0,1}.\nIn this paper, we distributively generate the secret exponent x0\nsuch that before the coin-toss is invoked every party Piholds a\nsharexiofx0. The party uses this share to generate a share of\nthecoinF(C)whichis ¯дxi.Forourpurposeweabstracttheinner\nworkings of the coin by exposing four functions:\ngenerate-share( xi,C),itusesthepartialkey xitogenerateacoin-\nshare for coin C.\nverify-share( C,m,σ)verifies that σis a valid share of party Pm.\ngenerate-coin( C,[σi])generates a coin given a threshold of valid\nshares of C.\nverify-coin( C,σP),verifiesthatthegivenvalue σPcorrespondto\nvalid coin for C.\n3 HIGH-THRESHOLD ASYNCHRONOUS\nVERIFIABLE SECRET SHARING\nExistingAVSS[ 7,11]schemesprovideareconstructionthreshold\nupton−2fshares.Intuitivelythisisbecauseatthesharingstep\ntheparticipatingnodescanonlywaitfor n−freadymessagefrom\nnodes, where readyconfirms that a node has verified its share. As\na result in the reconstruction phase, there can be up to f(corrupt)\nnodes who participated at the sharing but do not participate in\nthe reconstruction, hence for the reconstruction to succeed the\nrecovery threshold should be n−f−f=n−2f.\nIn this section we present our HAVSS scheme that requires a\nhighthresholdofupto n−fsharesforthesecretreconstruction.\nOurschemeisanextensionoftheAVSSschemebyCachinetal.[ 7],\nwhere the dealer uses an asymmetric bivariate polynomial instead\nof a symmetric one. The key idea is that one dimension of the\nasymmetric bivariate polynomial has an order of fand is used for\nshares recovery, while the other dimension has an order of 2 fand\nis used for the secret reconstruction.\n3.1 Definition\nOur protocolfalls inthe classof dual-threshold sharing [9],which\nare protocols that allow the reconstruction threshold of a secretto be more than\nf+1. Although in the original AVSS [ 7] paper\nthe authors introduce the notion of a dual-threshold secret shar-ing scheme with reconstruction threshold up to\nn−f, the AVSS\ndescribedonlyworksforreconstructionthreshold n−2f.Inthis\nwork, we solve the open problem posed by the authors on creating\nan(n,k,f)dual-threshold AVSS where f+1<k≤n−f. This\nis an important challenge since an (f,n−f)-AVSS can power4\nefficient Byzantine agreement [ 1,35] and efficient MPC [ 22,23]\nwhich currently require a trusted dealer during setup.\nWefollowthedefinitionsofCachinetal[ 7]andmodifythemfor\nHAVSS:Aprotocolwithatag ID.dtoshareasecret s∈Zqconsists\nof asharingstage and a reconstruction stage as follows.\n4Coupled with a suitable DKG [24]Sharingstage. Thesharingstagestartswhenthepartyinitializes\nthe protocol. In this case, we say the party initializes a sharing\nID.d. There is a special party Pd, called a dealer, which is activated\nadditionally on an input message of the form (ID.d,in,share,s).I f\nthisoccurs,wesay PdsharessusingID.damongthegroup.Aparty\nis said to complete the sharing ID.dwhen it generates an output of\nthe form (ID.d,out,shared). Anhonest but slow partymight not\ncompletethesharingifthedealerismalicious.Inthiscase,itcan\nstill recover its share of the secret from the rest of the parties that\nmanaged to terminate the sharing. Such a party is said to indirectly\ncomplete the sharing ID.d.\nReconstruction stage. After a party has completed the sharing, it\nmay be activated on a message (ID.d,in,reconstruct) . In this case,\nwesaytheparty startsthereconstructionfor ID.d.Attheendofthe\nreconstruction stage,every partyshould outputthe sharedsecret.\nA partyPiterminates the reconstruction stage by generating an\noutput of the form (ID.d,out,reconstructed ,zi). In this case, we\nsayPireconstructs ziforID.d.This terminates the protocol.\nFurthermore,theprotocolshouldsatisfythefollowingproperties\nfor our threat model, except with negligible probability:\nH(i) : Liveness. If the adversary initializes all honest parties on\nsharingID.d,deliversallassociatedmessages,andthedealer\nPdis honest throughout the sharing stage, then all honest\nparties complete the sharing. Moreover, if all honest parties\nsubsequently start the reconstruction for ID.d, then every\nhonest party Pireconstructs some ziforID.d.\nH(ii) : Agreement. Provided the adversary initializes all honest\npartiesonsharing ID.danddeliversallassociatedmessages,\nthefollowingholds:Ifsomehonestpartycompletestheshar-\ningID.d, then all honest parties will complete the sharing\nofID.d.\nH(iii) : Correctness. Oncekhonest parties have completed the\nsharing of ID.d, there exists a fixed value zsuch that the\nfollowing holds:\n(1)If the dealer has shared (ID.d,in,share,s)and is honest\nthroughout the sharing stage then z=s.\n(2) If an honest party Pireconstruct ziforID.dthenzi=z.\nH(iv) : Privacy. If an honest dealer shared (ID.d,in,share,s)and\nlessthank−fhonestpartieshavestartedthereconstruction\nforID.d, thenthe adversary hasno advantage when trying\nto guess the value s.\n3.2 Implementation\nThe key mechanism of HAVSS (see Figure 1) is the use of an asym-\nmetric bi-variate polynomial (k−1,f). The first dimension is used\nto protect the secret, which is reconstructed if kshares are com-\nbined, whereas the second dimension is used to enable recovery of\nthesharesofthesecretfromanygroupof f+1honestparticipants.\nLetpandqbe two large primes satisfying q|(p−1), andq>n.\nLetGdenoteamultiplicativesubgroupoforder qofZpandletд\nbe a generators of G.\n(1)Thedealercomputesaone-dimensionalsharingofthesecret\nand uses the second dimension of the bi-variate polynomial\ntosharethesecret-shares.Thisisachievedbychoosingaran-\ndombivariatepolynomial u∈Zq[x,y]wherethedimension\n[x]isofdegree t=k−1andthedimension [y]isofdegree f\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1755Figure 1: Intuition of HAVSS. Pjreceives row y∗.jwhich is\nused to compute the recovery polynomial bj(y)and column\nyj.∗whichisusedtocomputethesharepolynomial aj(x)and\nrecover its share Sj=aj(0). If a malicious dealer does not\nsendPmits share, Pmcan still complete indirectly the shar-\ning. This is possible because Pj, that completes the sharing\ndirectly, will send Pma message with ym.j. Since there are\nf+1available parties that should have shares in column m\nandcompletethesharingdirectly, Pmwillgetenoughpoints\nto recover aj(x), hence recover Sm=am(0). As a result, even-\ntuallykparties will have shares Si, compute locally u(0,x)\nand recover the secret s=u(0,0).\nwithu(0,0)=sanditcommitsto u(x,y)=/summationtext.1t,f\nj,l=0ujlxjylby\ncomputing a commitment matrix C={Cjl}withCjl=дujl\nforj∈[0,t],l∈[0,f]. The dealer sends each party Pia\nmessagecontainingthecommitmentmatrix Caswellasa\nrecovery polynomial ai(y):=u(i,y)of orderfand ashare\npolynomial bi(x):=u(x,i)of ordert.\n(2)When the parties receive the sendmessage from the dealer,\nthey echothepointsinwhichtheirshareandrecoverypoly-\nnomial overlap with each other. To this effect, Pisends an\nechomessage containing C,ai(j),bi(j)to every party Pj.\n(3)Uponreceiving kechomessagesthatagreeon Candcontain\nvalidpoints,everyparty Piinterpolatesitsownshareand\nrecovery polynomials ¯aiand¯bifrom the receiving points\nandverifiesthattheyarethesameastheonesreceivedby\nthe dealer. Then Pisends a readymessage containing C.\n(4)Once the party receives a total of n−freadymessages that\nagreeonC,itcompletes thesharing.Itsshareofthesecretis\nsi=¯ai(0).Inordertoguaranteethattherestoftheparties\nalso complete the sharing, it sends the set of n−fready\nmessages(forthepartiesthatsendthe readymessageand\nwillfinishwith shared)aswellas bi(j)toeveryparty Pj(for\nthe ones that are slow and will finish indirectly).\n(5)A party that has not sent a readymessage yet, needs to\nconsider the possibility that it is in the slow set. Hence, if\nit receives f+1 consistent sharedmessages, it interpolates\nsi=¯ai(0)and finishes the sharing indirectly.\nAs a result, during reconstruction, every honest node eventually\nhas a correct share of the secret. Hence eventually kpoints that\nare consistent with Cbecome public. Once Pireceives them all, he\ncan interpolate u(0,y)and recover s=u(0,0). The protocol hascommunication complexity of O(n4), however, it can be optimized\ntoO(n3)as shown in [7].\n3.3 Protocols\nAlgorithm 1 and 2. In the protocol description, the following predi-\ncates are used:\nverify-poly(C ,i,a,b), wherea,bare polynomials of degree fandt\nrespectively, i.e.,\na(y)=f/summationdisplay.1\nl=0alylandb(x)=t/summationdisplay.1\nj=0bjxj\nThis predicate verifies that the given polynomials are share and\nrecoverypolynomialsfor PiconsistentwithC;itistrueifandonly\nifforl∈[0,f],itholdsдal=/producttext.1f\nj=0(Cjl)ijandforj∈[0,t],itholds\nдbl=/producttext.1t\nl=0(Cjl)il.\nverify-point(C ,i,m,α,β), verifies that the given values α,βcor-\nrespond to points f(m,i),f(i,m), respectively, committed to C,\nwhichPisupposedly receives from Pm; it is true if and only if\nдα=/producttext.1f,t\nj,l=0(Cjl)mjilandдβ=/producttext.1f,t\nj,l=0(Cjl)ijml.\nverify-share(C ,m,σ)verifies that σis a valid share of Pmwith\nrespecttoC; it is true if and only if дσ=/producttext.1t\nj=0(Cj0)mj.\nverify-shared(C ,SiдC)verifies the set of signatures SiдC.\nThe parties may need to interpolate a polynomial aof degree\nforapolynomial bofdegree t.Thiscanbedoneusingstandard\nLagrange interpolation, we abbreviate this by saying a party inter-\npolatesa.\nIn the protocol description the variables e,f, andrcount the\nnumberof echo,sharedandreadymessages.Theyareinstantiated\nseparately only for values of Cthat have actually been received in\nincoming messages.\nAnalysis. ProofsfortheHAVSSpropertiesmostlyfollowfrom[ 7]\nand for space limitation deferred to Appendix B.\n3.4 HAVSS for Bootstrap of Hotstuff/SBFT\nAlthoughthispaperfocusesonfullyasynchronousprotocols,ad-\nvancementsinpartiallysynchronousprotocols[ 20,35]haveshown\nthattheabilitytogeneratedistributivelyan (f,2f+1)-thresholdkey\nisausefulprimitive.HAVSSisthefirstprotocolthatcanpowersuch\nefficient DKGs, for example, if we combine HAVSS with Hybrid-\nDKG [24] we can securely bootstrap Hotstuff and SBFT without\nintroducing any new assumptions.\n4 WEAK DISTRIBUTED KEY GENERATION\nThissectiondescribesanasynchronousprotocolfordetectingagree-\nment on the generation of (up to) f+1candidate shared keys\nwithoutatrustedsetup,whichweuseforbuildingtheeventually\nperfectcoininthenextsection.ThekeyideaofwDKGisthatthe\nprotocol never terminates (e.g., never commits to a specific key).\nInstead,eachpartyoutputsafinitesequenceofcandidatekeys,and\neven though there is no explicit termination (otherwise, we would\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1756Algorithm 1 Protocol HAVSSfor party Piand tagID.d(sharing\nstage)\n1:uponinitialization do\n2: success←false\n3:for allCdo\n4: eC←0;rC←0\n5: AC←∅;BC←∅SiдC←∅\n6:upon receiving “ID.d,in,share,s”do ⊿onlyPd\n7:choose a random asymmetric bivariate polynomials uof\ndegree (t, f) with u(0,0)=u00=s, i.e.,\nu(x,y)=t,f/summationdisplay.1\nj,l=0ujlxjyl\n8:C←{Cjl}, whereCjl=дujlforj∈[0,t]andl∈[0,f]\n9:forj∈[1,n]do\n10: aj(y)←u(j,y);bj(x)←u(x,j)\n11: send “ID.d,send,C,aj,bj”t oPj\n12:upon receiving “ID.d,send,C,a,b”f r o mPdfor the first time do\n13:ifverify−poly(C,i,a,b)then\n14: forj∈[1,n]dosend “ID.d,echo,C,a(j),b(j)”t oPj\n15:upon receiving “ID.d,echo,C,α,β”f r o mPmfor the first time do\n16:ifverify−point(C,i,m,α,β)then\n17: AC←AC/uniontext.1{(m,α)};BC←BC/uniontext.1{(m,β)}\n18: eC←eC+1\n19: ifeC=kthen\n20: interpolate ¯a,¯bfromBC,AC, respectively\n21: forj∈[1,n]dosend“ID.d,ready,C,¯a(j),¯b(j),siдi”to\nPj\n22:upon receiving “ID.d,ready,C,α,β,siдm”f r o mPmfor the first\ntimedo\n23:ifverify−point(C,i,m,α,β)then\n24: SiдC←SiдC/uniontext.1{(m,siдm)}\n25: rC←rC+1\n26: ifrC=n−fandeC≥kthen\n27: ¯C←C;si←¯a(0);success←true\n28: forj∈[1,n]dosend“ID.d,shared,C,SiдC,¯b(j)”toPj\n29: output(ID.d,out,shared)\n30:upon receiving “ID.d,shared,C,Siдm\nC,β”f r o mPmfor the first\ntimedo\n31:ifverify−shared(C,Siдm\nC)then\n32: ifeC≥kthen ⊿Can fully terminate\n33: ¯C←C;si←¯a(0);success←true\n34: forj∈[1,n]dosend“ID.d,shared,C,SiдC,¯b(j)”toPj\n35: output(ID.d,out,shared)\n36: else if verify−point(C,i,m,β)then ⊿Can only recover\nshare\n37: BC←BC/uniontext.1{(m,β)}\n38: rC←rC+1\n39: ifrC=f+1then\n40: ¯C←C\n41: interpolate ¯afromBC,\n42: si←¯a(0)\n43: output(ID.d,out,shared)Algorithm 2 Protocol HAVSSfor party Piand tagID.d(recon-\nstruction stage)\n1:upon receiving “ID.d,in,reconstruct” do\n2:c←0;S←∅\n3:forj∈[1,n]dosend “ID.d,reconstruct-share ,si\"t oPj\n4:upon receiving “ID.d,reconstruct-share ,σ”f r o mPmdo\n5:ifverify−share(¯C,m,σ)then\n6: S←S/uniontext.1{(m,σ)};c←c+1\n7: ifc=kthen\n8: interpolate a0fromS\n9: output(ID.d,out,reconstructed ,a0(0))\n10: halt\ncontradictthe FLP[ 16]impossibility ofasynchronousagreement),\nwe guarantee that eventually all honest parties stop outputting\nnewcandidatekeysandthelastcandidatekeyoutputbyallhon-\nest parties is the same. Moreover, to bound the complexity of an\nhigher-levelprotocolthatusesourweakdistributedkeygeneration\n(wDKG), we guarantee that no honest party outputs more than\nf+1 keys.\n4.1 Definition\nA weak Distributed Key Generation is a helper protocol that is\nimplementedontopof nHAVSSinstanceswhereeachparty Piacts\nasthedealerofHAVSSinstance i.Wedenotethesharethatparty\nPireceivesinHAVSSinstance jbysj\ni,anddefinea prediction ofa\ncandidatedistributedkeytobeasetofshares.DuringawDKGeach\npartyPimightoutputasequenceofpredictions,andwesaythatan\noutputpredictionPultimate islastifPidoesnotoutputaprediction\nafterPultimate.Foreachparty Pi,thereisaone-to-onemapping\nbetweenasetofHAVSSdealersandthepredictionsinducedbythe\nHAVSSinstancesofthesedealers.Thatis,givenaset Sofparties,\ntheprediction sharesi(S)/defines{sj\ni|Pj∈S},andgivenaprediction P\nofPi,source(P)/defines{Pj|sj\ni∈P}. Note that source(shares i(S))=S.\nWesaythattwopredictions P1,P2ofdifferentpartiesare matching\nifsource(P 1)=source(P 2).\nThe wDKG protocol provides the following properties.\nW(i): Inclusion. Forevery prediction Panhonest partyoutputs,\n|source(P)| ≥ 2f+1.\nW(ii): Containment. For each honest party Pi, predictions are\nordered by strict containment. This means that for any two\npredictions output by Piin timesk<j:Pk⊂Pj.\nW(iii): Eventual Agreement. Everyhonestpartyeventuallyout-\nputs an ultimate prediction, and all ultimate predictions are\nmatching.\nW(iv): Privacy. If no honest party reveals its private share for a\nprediction pthen the adversary can neither compute the\nprediction pnorthesharedsecrets.Thisisequivalenttothe\nHAVSS privacy property defined before.\n4.2 Technical Overview\nThe wDKG protocol uses ninstances of HAVSS as sub-protocols.\nEachparty PiinvokesHAVSSinstance ID.iasadealerandpartic-\nipates in the sharing phases of all HAVSS instances as a receiver.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1757Upon initialization, each party Piinstantiates its HAVSS with a\nrandomsecretandcollects n−fsharesfromdifferentHAVSSin-\nstances(includingitsown)intoaprediction H.Notethatsince n−f\ninstances have honest leaders, then all honest parties eventually\ncollectn−fshares.Then,itstartstheeventualagreementphase\nbybroadcastinga candidate-key messagethatincludes source(H).\nLater,anytime PideliversanotherHAVSSshare,itinsertstheshare\nintoHandbroadcaststhenew source(H)inanother candidate-key\nmessage.\nWhenaparty pireceives2 f+1candidate-key messageswith\nthesamesource(setofparties) S,it(1)waitsuntil H⊇sharesi(S)\norin otherwords until pigetsallthe HAVSS sharesfrominstances\nwith parties from Sacting as dealers; and then (2) outputs the\nprediction sharesi(S)provided it did not output a prediction P/npropersubset\nsharesi(S)beforetomakesurepartiesoutputincreasingpredictions\nby containment. Note that by the containment property and since\npredictions by honest parties consists of at least 2 f+1 shares, we\nget that each party outputs at most f+1 predictions.\nAlthough the above protocol has an efficient ( O(n4))as we will\nseelater)wordcomplexity,itneedsonefurthercheckinorderto\navoid exponential computation andstorage. The challenge is that\nevery time a party receives a new candidate-key it needs to search\nits local memory to increase the counter of how many matching\nsource(H)it has received. Honest parties broadcast up to f+1\ncandidate-key messages,butaByzantinepartymightbroadcastan\nexponentialnumberofsuchmessages,causingthelocalmemory\nandthecostofsearchingittobecomeexponential.Therefore,in\norder to avoid this attack we ignore candidate-key messages from\nparties that do not satisfy containment (i.e., a party piignores a\ncandidate-key messagewithsourceset Sfromparty pjifitprevi-\nously received from pjacandidate-key message with source set\nS/prime/npropersubsetS). The pseudocode appears in Algorithm 3.\nAlgorithm 3 Protocol wDKGfor party Pi\n1:uponinitialization do\n2:for every j∈{1,...,n}do\n3: Sj←{ } ⊿The source (set of parties) pireceived from pj\n4:H←{ } ⊿The set of HAVSS shares pioutputs\n5:SP←{ } ⊿The source set of the current prediction\n6:C[:]←0 ⊿A counter for every possible source\n7:selectrandomri\n8:invoke(i,in,share,ri)⊿Every party starts an HAVSS as a dealer\n9:upon(ID.j,out,shared)do\n10:H←H∪{sj\ni}\n11:if|H|≥n−fthen\n12: send “candidate-key ,source(H)” to all parties\n13:upon receiving “candidate-key ,S” from party pjdo⊿Handle these\nmessages one after the other\n14:ifS⊃Sj∪SPthen\n15: Sj←S\n16: C[S]←C[S]+1\n17: ifC[S]=n−fthen\n18: SP←S\n19: waituntilH⊇shares i(S)\n20: output(out,key,shares i(S))4.3 Analysis\nInthisSectionweprovethattheprotocolinFigure3implements\nwDKG. The first two proofs follow directly from the code. For the\neventual agreement we first need to show that no honest party\nwill get stuck at a prediction that is not the best possible. Then we\nshowthatpartieswillkeepdeliveringpredictionsthatincludemore\nsharesuntiltheydeliverapredictionwiththemaximumnumberof\nshares(allthesharesthatweregeneratedbygooddealers).Since\nno party gets stuck at a suboptimal prediction and there exists amaximum prediction, all parties will eventually deliver that pre-diction and stop delivering anything new, hence they eventually\nagree.Ofcoursethepartieswillnotbeawarethattheprediction\nthey delivered is the maximum, which is the reason they cannot\nexplicitly terminate. Specifically, we prove the following lemmas:\n4.3.1 Correctness proof. In this section we prove that the protocol\nin Figure 3 implements wDKG, i.e., satisfies containment, inclusion,\nand eventual agreement :\nLemma 4.1. The protocol inAlgorithm 3 satisfies W(ii) (Contain-\nment).\nProof.Byline14,honestpartiesignore“ candidate-key ,S”mes-\nsages when S/npropersupersetSP. By the code, SPstores the source set of the last\nprediction. The lemma follows from the fact that candidate-key\nmessages never handled in parallel.\n/square\nLemma 4.2. The protocol in Algorithm 3 satisfies W(i) (Inclusion).\nProof.LetPbeapredictionsomehonestparty Pioutputs.By\nline17,Pigetsatleast n−f“candidate-key ,source(P)”messages.\nThus,atleastonehonestpartysendsa“ candidate-key ,source(P)”\nmessage. Therefore, by line 11, |source(P)| =|P|≥n−f.\n/square\nLemma 4.3. An honest party is never stuck.\nProof.The only possible place for an honest party to stuck\nis in Line 19. Consider an honest party Pithat gets to Line 19\nand waits until its H⊇sharesi(S)whereSis the source set it\nreceived in the candidate-key message. By Line 17, Pigetsn−f\n“candidate-key ,S” messages, and thus at least one honest party Pj\nsent “ candidate-key ,S” message. By the code, Pjdelivers a share\nfor every HAVSS instance in S. Thus, by property H(ii), Piwill\neventually deliver a share for every HAVSS instance in Sas well.\nMeaningthateventually H⊇sharesi(S),andthus Piwilleventually\nend the waiting in Line 19.\n/square\nLemma 4.4. The protocol in Algorithm 3 satisfies W(iii) (Eventual\nAgreement).\nProof.Note that the size of His bounded by n, so for every\nhonestpartythere isapointafterwhich Hisneverchanging and\nincludesallHAVSSsharesitwilleverdeliver.ByH(ii),allhonest\nparties will eventually reach the same source(H), which we denote\nbySH.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1758We now show that an honest party Pidoes not ignore a\n“candidate-key ,SH” message from an honest party Pj. In other\nwords, theif statement in Line14 is always truewhen Pjreceives\nsuch message. We need to show two conditions:\n•First,SH⊃Sj. Since by the code, Pjonly sends the\n“candidate-key/prime/primewithsource(H), we get by the definition of\nSHthatPjnever sends “ candidate-key ,S/prime” message with\nS/prime/notsubseteqlSH.\n•Second,SH⊃SP. Assume by a way of contradiction that at\nsomepoint PisetsSP←S/primes.t.S/prime/notsubseteqlSH.Bythecode, Pigets\n“candidate-key ,S/prime”messagefromatleastonehonestparty\nPk. Therefore, the source(H)of partyPjwas equal to S/primeat\nsome point. A contradiction to the definition of SH.\nBypropertyH(i),andsincewehaveatleast n−fhonestparties,\nwe get that |SH|≥n−f. Thus, by the code, all honest parties will\neventually send “ candidate-key ,SH” message to all other honest\nparties. Therefore, by Lemma 4.3 and from the above, every honest\npartyPiwilleventuallyprocess n−f“candidate-key ,SH”message,\npass the if statement in Line 17, and output sharesi(SH).\nIt is left to show that no honest party will ever output a pre-\ndiction after sharesi(SH). Assume by a way of contradiction that\nsome party PioutputsS/primeafter it outputs sharesi(SH). By property\nW(ii) (Containment), S/prime⊃SH. Thus, by definition of SH,S/primecon-\ntains a party that acts as a dealer in a HAVSS instance in which\nnohonestpartydeliversashare.Therefore,nohonestpartyever\nsends a “ candidate-key ,S/prime” message. Hence, Pinever get n−f\n“candidate-key ,S/prime”messages,andthusbythecodeneveroutput S/prime.\nA contradiction.\n/square\nLemma 4.5. The protocol in Algorithm 3 satisfiesW(iv) (Privacy).\nProof.FollowsdirectlyfromtheW(i)(inclusion)andH(iv)(pri-\nvacy).\n/square\nComplexity. Bythecode,eachpartysendsatmost f+1candidate-\nkeymessages,eachofwhichofsize O(n),toallotherparties.There-\nfore, the bit complexity of each party is O(n3)words, and the total\nbit complexity is O(n4)words.\n5 FROM WEAK DKG TO EVENTUALLY\nPERFECT COMMON COIN\nIn this section, we use wDKG as the backbone of an eventually-\nperfectcommoncoin(EPCC),whichisaperfect-commoncointhat\nfails a finite number of times (at most fin our case). As a result,\nwecanuseitasaperfect-coinaslongaswemakesuretohandle\nthe small number of disagreements.\n5.1 Definition\nTheEPCCisalong-livedtask,whichcanbeinvokedmanytimes\nbyeachpartyvia coin-toss(sq) invocation.Eachinvocationisasso-\nciatedwithauniquesequencenumber sqandreturnsavalue v.W e\nassume well-formed executions in which honest parties block any\nsubsequent EPCC invocations until the invoked EPCC returns a\nvalue. This is crucial for the Eventual Agreement property because\ndisagreement on the EPCC output in one instance must advance atleast one wDKG key toward the following instance. For notational\nconvenience,weassumethatifapartyinvokes coin-toss(sq) and\nlater invoke coin-toss(sq’), then sq/prime>sq.\nAn EPCC implementation must satisfy the following properties:\nE(i): Unpredictability. For every sq, the probability that the ad-\nversarypredictsthereturnvalueof coin-toss(sq) invocation\nbyanhonestpartybeforeatleastonehonestpartyinvoke\ncoin-toss(sq) isatmost1 /2+ϵ(k),whereϵ(k)isanegligible\nfunction.\nE(ii): Termination: Ifn−fhonest parties invoke coin-toss(sq) ,\nthen all coin-toss(sq) invocations by honest parties eventu-\nally return.\nE(iii): Eventual Agreement: There are at most fsequence num-\nberssqforwhichtwoinvocationsof coin-toss(sq) byhonest\nparties return different coins.\n5.2 Technical Overview\nOurEPCCprotocolisbuiltontopof nHAVSSinstancesandusesthe\nwDKGalgorithmasasub-protocol.RecallthatthewDKGalgorithm\noutputs a sequence of at most f+1 predictions (sets of HAVSS\nshares)P1,...,Pl. Whenever, the wDKG sub-protocol outputs a\npredictionPiwe use it to derive a tuple /angbracketleftKPi,VPi/angbracketright, whereKPiis\nthekey, andVPiis the abit vector indicating the HAVSS instances\nincluded in source(P i)(see get-keybelow). The /angbracketleftK,V/angbracketrightvariables\nstorethelastderivedkey,andthebitvector,respectively,andare\nupdated whenever the wDKG outputs a new prediction.\nUpona coin-toss(sq) invocationbyanhonestparty Pi,itentersa\nprotocol to construct a common coin. The protocol loops using the\noutputsfromwDKGuntilforsomekey K,Pisucceedsincollecting\nn−fshares corresponding to Kand the sequence number sq.\nMore specifically, each party Piuses the latest key K,Voutput\nfromwDKGandthesequencenumber sqtogenerateitsshareof\nthecommon-coin,andsendsa coin-share messagewiththeshare\ntogether with the bit vector Vto all other parties. Whenever the\nwDKGoutputsanewprediction, Piupdatesthe /angbracketleftK,V/angbracketrightvariables,\nand broadcasts a new share.\nAcoin-toss(sq) invocationbyanhonestparty Pireturnswhen\nitcollects2 f+1coin-share messagesfromdifferentpartieswith\nvalidcoin-sharesandthesamebitvector V/prime.Notethat V/primecanbe\ndifferent from any bit vector party Pipreviously sent in a coin-\nsharemessage. To validate the coin-shares, Pineeds to generate a\ncommitment Cv/primethatisassociatedtothebitvector V/primebycombin-\ning all the commitments of HAVSS instances included in V/prime(see\nget-commitment below). Note that in order to be able to do it, Pi\nfirstneedstocompletethesharingphasesofallHAVSSinstances\nincludedin V/prime.Then,after Pisuccessfullyverifiesthe2 f+1signa-\ntures(see verify-share below),itusesthemtoproduceacoin(see\ngenerate-coin below), sends it in a coinmessage together with the\nbit vector to all other parties, and outputs it.\nUponreceivinga coinmessage, Pifirstchecksthatthebitvector\nincludes at least 2 f+1 ones in order make sure randomness from\nhonest parties were included in the associated key generations.Next,\nPigenerates a commitment associated with the bit vector\nand then uses it to verify the coin (see verify-coin below). If the\nverification passes, Piforwards the coinmessage to all parties and\noutput the coin.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1759Note that since EPCC is a long lived object some honest parties\nmay complete a coin-toss(sq) for some sqbefore another honest\npartyinvoked coin-toss(sq) .Tohandlethis,honestpartiesmaintain\ntwomaps SandCoinsthatmaptuplesofbit-vectorsand sqtoset\nof coin-shares and coins, respectively. These maps are updated\nevery time a share-coin or coin message is received regardless ifthere is a\ncoin-toss(sq) operation in progress. In addition, when\nacoin-toss(sq) operation invoked by an honest party Pi, it first\nchecks these maps to see if it already received enough messages\nto return a coin. The pseudocode is given below (Algorithm 4) andthe omitted proofs are given in Appendix C. In the pseudocode we\nuse the following functions:\nget-key(P) getsapredictionoutput PfromawDKGsub-protocol,\nand outputs /angbracketleftKP,VP/angbracketrightthat are computed as follows:\nKP=/summationdisplay.1\ns∈Psand ∀pi∈source(P) ,VP[i]=1\nInotherwords, KPisthesumofallsharesin PandVPindicatesthe\nHAVSS instances these shares came from.get-commitment( V\nP)gets a bit vector that was generated from a\npredictionP, and returns a commitment CPthat is used to verify\nsignatures associated with KP(share and coin). In order to be able\nto compute CP, parties first have to complete the sharing phases\nof all the HAVSS instance indicated by VPin order to get their\ncommitment, and then multiply them to get CP. More specifically,\n∀i∈{1,...,n},ifVP[i]=1,then wait for commitment Ci\nfromP/prime\nisHAVSS instance\nCP=n/productdisplay.1\ni=1VP[i]Ci\nIn Algorithm 4, an invocation of get-commitment can block\nforeverifsendbyabadpartythatliesaboutwhatHAVSSinstances\nhave terminated. We do not need to handle this as we only care to\nreturn one random value of a sq. To this end, we handle all events\nconcurrently and abort all outstanding procedures associated with\nsqafter we output a coin for sq.\nNotethatforeveryprediction Panhonestpartygetsfromthe\nwDKGprotocol,thebitvector VPdefinesauniqueprivate Ki\nPfor\neveryparty Pi,andauniqueglobalcommitment CP.Together,they\nform the setup required for the Diffie-Hellman based threshold\ncoin-tossing scheme that is given in [ 9], which yields a common\ncoin flip for each sqinput. In our educational example, we use\nPedersen [ 32] DKG, which does not produce uniformly random\nkeys[19],butasshownbyLibertetal.[ 28]itissufficientforthe\nadaptivelysecurethresholdsignatures,whichwewilluseforthe\nreal-worlddeployment.Henceweassumethatthekeygenerated\nby the DKG is sufficiently random for our proofs and only focuson proving that it remains unpredictable and private. Below we\nbrieflydescribethefunctionalitythisschemeprovides,andmore\ndetails and formal proofs can be found in [ 9]. Note that the wDKG\nmightoutputdifferentsequencesofpredictionswheninvokedby\ndifferent parties, so the challenge that we overcome in Algorithm 4\nis how to eventually agree on the same key.generate-share( CP,KP,sq)usesthekey KPderivedfromprediction\nPtosignthesequencenumber sqinordertogenerateasharefora\ncoin defined by CPandsq.\nverify-share( CP,sq,j,σ), verifies that the given value σis a valid\ncoin share from Pjfor the coin defined by CPandsq.\ngenerate-coin( CP,Σ,sq)uses a set Σof 2f+1 valid shares defined\nbyCPandsqin order to generates the coin.\nverify-coin( CP,σ,sq), verifies that the given value σis a valid coin\ndefined by CPandsq.\n5.3 Analysis\n5.3.1 Correctness proof. Inthissectionweshow unpredictability,\ntermination, and eventual agreement of our EPCC. The first two\npropertiescaneasilybededucedfromthecode.Foreventualagree-\nment we first need to show that (due to WDKG’s containment\nproperty)ifapartyusesacertainsetofshares V1toproduceran-\ndomness then it will only use supersets of V1in future invocations.\nThis creates a total ordering of predictions. The second part of the\nproof relies on the well-formed nature of EPCC and shows that\nifdifferentsetsofshareswhereusedtogeneraterandomnessfor\na certain invocation sqthen only the largest set of shares will be\nusedforanysubsequentinvocation.Giventhattherecanonlybe\nf+1differentvalidandtotallyorderedsets,theadversarycanonly\ncausethe generation ofinconsistentrandomnessat most ftimes.\nSpecifically, we prove in Appendix C the following Lemmas:\nLemma5.1. Ifavalidcoinforsome sqisgenerated,thenatleast\n2f+1validshare-coinsassociatedwithsomebitvector Vforsqwere\npreviously generated, f+1of which by honest parties.\nLemma 5.2. The protocol in Algorithm 4 satisfies E(i) (Unpre-\ndictability).\nLemma5.3. Forevery sq,ifaninvocationof coin-toss(sq) byan\nhonest party Pireturns, then all coin-toss(sq) invocations by honest\nparties eventually return.\nLemma5.4. TheprotocolinAlgorithm4satisfiesE(ii)(Termina-\ntion).\nLemma5.5. Ifanhonestpartygeneratesashare-coinassociated\nwithV, then it will never generate a share-coin associated with V/prime/notsuperseteql\nV.\nLemma5.6. Ifforsome sq,tw o coin-toss(sq) invocationsbytwo\nhonest parties return different valid coins ρ1/nequalρ2, then there are\ntwo bit vectors V1,V2s.t. (1)V1⊂V2; and (2) f+1honest parties\ngeneratedvalidshare-coinsassociatedwith V1forsqandf+1honest\nparties generated valid share-coins associated with V2forsq.\nLemma 5.7. For every 1≤k≤f+1, if there are ksequence\nnumbers sqfor which two invocations of coin-toss(sq) by honest\nparties output different coins, then there is a bit vector Vof size at\nleast2f+1+ksuch that f+1honest parties generated valid share-\ncoins associated with V.\nLemma5.8. TheprotocolinAlgorithm4satisfiesE(iii)(Eventual\nAgreement).\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1760Algorithm 4 Protocol EPCCfor party Pi. All events must be han-\ndled in parallel per sq. Upon first output message for sqall other\ninvocations are aborted.\n1:uponinitialization do\n2:invoke wDKG\n3:K←⊥;V←⊥ ⊿last derived key and bit vector, respectively\n4:currentSQ ←⊥ ⊿⊥indicates that there is not coin-toss in\nprogress\n5:S[:]←{} ⊿A mapping from tuples of bit vector and sq to sets of\nshares\n6:Coins[:]←⊥⊿A mapping from tuples of bit vector and sq to coins\n7:upon(out,key,P)do ⊿prediction output form the wDKG\nsub-protocol\n8:/angbracketleftK,V/angbracketright← get-key(P)\n9:ifcurrentSQ /nequal⊥then\n10: BroadcastShare()\n11:upon coin-toss(sq) do\n12:currentSQ ←sq⊿Avoid races during concurrent invocations\n13:if∃V/primes.t.Coins[/angbracketleftV/prime,sq/angbracketright]/nequal⊥then ⊿Already saw the coin\n14: ForwardCoinAndReturn( V/prime,sq)\n15:if∃V/primes.t.|S[/angbracketleftV/prime,sq/angbracketright]| ≥2f+1then ⊿Enough shares\n16: BroadcastCoinAndReturn( V/prime,sq)\n17:ifV/nequal⊥then\n18: BroadcastShare()\n19:uponreceiving “coin-share ,sq,σ,Vj”messagefromparty Pjforthe\nfirst time do\n20:C←get-commitment( Vj)\n21:ifverify-share( C,sq,j,σ)∧/summationtext.1n\nk=1Vj[k]≥2f+1then\n22: S[/angbracketleftVj,sq/angbracketright]←S[/angbracketleftVj,sq/angbracketright]∪ {σ}\n23: ifsq=currentSQ ∧|S[/angbracketleftVj,sq/angbracketright]| ≥2f+1then\n24: BroadcastCoinAndReturn( Vj,sq)\n25:upon receiving “coin,sq,ρ,Vj”messagefromparty Pjforthefirst\ntimedo\n26:C←get-commitment( Vj)\n27:ifverify-coin( C,ρ,sq)∧/summationtext.1nk=1Vj[k]≥2f+1then\n28: Coins[/angbracketleftVj,sq/angbracketright]←ρ\n29: ifsq=currentSQ then\n30: ForwardCoinAndReturn( Vj,sq)\n31:procedure BroadcastShare()\n32:C←get-commitment( V)\n33:σ←generate-share( C,K,currentSQ )\n34:send “coin-share ,currentSQ ,σ,V” to all parties\n35:procedure BroadcastCoinAndReturn( V/prime,sq)\n36:C←get-commitment( V/prime)\n37:ρ←generate-coin( C,S[/angbracketleftV/prime,sq/angbracketright],sq)\n38:send “coin ,sq,ρ,V/prime” to all parties\n39:currentSQ ←⊥\n40:output(out,coin,sq,ρ)\n41:procedure ForwardCoinAndReturn( V/prime,sq)\n42:send “coin ,sq,Coins[/angbracketleftV/prime,sq/angbracketright],V/prime” to all parties\n43:currentSQ ←⊥\n44:output(out,coin,sq,Coins[/angbracketleftV/prime,sq/angbracketright])5.3.2 Complexity. ByW(i)andW(ii),eachpartyoutputsatmost\nf+1predictionsfromthewDKGsub-protocol.Foreachpredictions,\neach party sends at most a constant number of words and O(n)\nsized bit-vector to every party. Hence the worst-case complexity of\na consistent coin flipping is O( n4)b i t s+O ( n3) words.\n6 ACHIEVING CONSENSUS\n6.1 Eventually Efficient Asynchronous Binary\nAgreement\nOncewehaveourEPCC,wecanuseitinanyBinaryAgreement\nprotocol that uses a weak coin [ 6,29]. The most efficient asynchro-\nnous BA solution is from Moustefaoui’s et al [ 29] and has O( n2) bit\ncomplexity5.\nSinceourcoinhasatmost fbadflips,whenweplugitin[ 29]\nwe knowthat ifwe invoke ninstances ofABA insuccession with\nthe same coin, then the overall number of bad flips remains fin\nthe entire succession. Hence, the overall complexity remains O(n3)\nbit complexity and expected O(f)rounds. We refer to an ABA that\nhas this succession property as eventually efficient ABA (EEABA).\nWe refrain from reintroducing the full protocol as we only need\nto plug in our coin-toss(sq) and make sure that a party which has\nalready seen a safe value continues to coin-toss(sq) in order for\nEPCCtobelive,butignorestheoutputofEPCC(asitalreadyknows\nthe safe value). The total bit complexity of our EEABA has two\nparts.First,thereistheneededHAVSSforEPCCtowork,whichhas\natotalO(n4)words (nconcurrentinstancesofHAVSS).Then,we\ncan start running the ABA of [ 29] which (as mentioned above) has\nanoverallcomplexityremains O(n3)bitcomplexityandexpected\nO(f)rounds. Hence the total complexity of EEABA is O(n4)bit\ncomplexity and expected O(f)rounds. Nevertheless, if we run this\nprotocolfor(O( n2))sequentialdecisionsitwillamortizeto O(n2)\ncommunication complexity and O(1)termination because the coin\nwill be perfect for most of the EEABA instances (at most ffailures\ndue to asynchrony) which means that the n2−finstances will\nterminateinanexpectednumberof2rounds.Hence,wecanget\nthe ABA with the properties defined in Lemma 1.3.\n6.2 Asynchronous Distributed Key Generation\nWe build our ADKG protocol on top of EEABA by explicitly termi-\nnatingthewDKGandagreeingonwhatHAVSSinstancescontribute\nto the scheme. We can achieve this by extending the Asynchronous\nCommonSubset(ACS) protocolintroducedbyBen-oretal[ 5].Inan\nACSprotocol, nprocessorshavesomeinitialvalueandtheyneed\nto agree on a subset of values to be adopted. Our Asynchronous\nDistributed Key Generation is similar, with the added restriction\nthat the values we agree on need to remain private (secret-shared),\nhence parties output the same set of parties source(v) and maintain\na private shares set vlocally. For simplicity, we do not deal in this\nsectionwiththespecificdetailsofhowtoagenerateasecret-key,\npublic-key, andthe commitmentsfor verification,which isfairly\nstraightforward after we agree on the set of HAVSS instances.\n6.2.1 Definition. Moreformally,anAsynchronousDistributedKey\nGeneration protocol is a one-shot consensus variant. Each party\n5They do not give an implementation for their weak coin assumption, but instead use\nan external oracle.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1761Algorithm 5 Protocol ADKGfor party Pi\n1:uponinitialization do\n2:I←Π ⊿A set of parties, initially all\n3:K←{ }⊿ThesetofHAVSSsharesthatcorrespondsthetheagreed\ninstances\n4:c←0⊿A counter for the number of ABAs in which Pidecided\n5:selectrandomri\n6:invoke(i,in,share,ri)⊿Every party starts an HAVSS as a dealer\n7:upon(ID.j,out,shared)do⊿The sharing phase of Pj’s HAVSS\ncompleted\n8:ifPj∈Ithen\n9: invokeABA.jwith 1\n10: I←I\\{Pj} ⊿Remove instances already voted on\n11:upon(ABA.j,deliver,1)do\n12:K←K∪{sj\ni}⊿This might block until the HAVSS delivers, but it\nwill eventually terminate.\n13:c←c+1\n14:ifc=n−fthen\n15: for allPl∈Ido\n16: invokeABA.lwith 0\n17: I←I\\{Pl} ⊿Remove instances already voted on\n18:ifc=nthen\n19: outputK\n20:upon(ABA.j,deliver,0)do\n21:c←c+1\n22:ifc=nthen\n23: outputK\nis initialized with an ID.iof the HAVSS instanceit should act as a\ndealer,aswellasthefull IDvectoroftheHAVSSinstancesitshould\nbeapartof.Foreveryparty pi,theprotocoloutputsaprivateset\nof shares vis.t. the following is satisfied except with negligible\nprobability:\nA(i): Validity. If an honest party outputs a set of shares v, then\n|v|≥n−fandvincludes only valid shares.\nA(ii): Agreement. Foreverytwohonestparties Pi,Pj,ifPiandPj\noutput sets of shares viandvj, respectively, then source(vi)\n=source(vj).\nA(iii): Liveness. Ifn−fcorrectpartiesstartdealingsharesand\ntheadversarydeliversallmessages,thenallcorrectparties\noutput a set of shares.\nA(iv): Privacy. Ifanhonestparty pioutputsasetofshares viand\nnohonestpartyhasrevealeditsoutputsharesandthesecret\nit shared, then the adversary cannot compute the sum of\nsecrets shared by parties in source(vi).\n6.2.2 Technical Overview. WefollowtheACSsolutionofBen-Or\net al [5], which consists of starting nparallel reliable broadcasts,\nonefor eachpartytoact asthesender, whereforeach broadcast\ninstance,theyuseasingleABAtoagreewhetheritsvalueshouldbe\nincludedintheset.Intheirprotocol,partiesinvokewith1(success)\nevery ABA that corresponds to a reliable broadcast instance in\nwhich they deliver a value, and refraining from invoking with 0\nany ABA instance until n−fABA instances have decided 1. Then,theyinvokewith0 allotherABAinstanceandterminatethe ACS\nprotocol once they decided in all ABA instances.\nOur ADKG protocol is similar but instead of reliable broadcasts,\nweusesHAVSSinstances.Bytheagreementandlivenessproperties\nof the HAVSS, eventually there are n−fABA instances which all\nhonestpartiesinvokewith1andthuseventually n−finstances\nagree on 1 (all honest parties decide 1). Note that the properties of\nthebinaryABA guaranteethatifallhonest partiesinvokeitwith\n1, thenthey all eventuallydecide 1 (same for0). This protocolhas\nanexpectedrunningtimeof O(loд(n)).AdditionallyEEABAhasan\nexpectedrunningtimeof O(1)whenthenetworkissynchronized\nandanexpectedrunningtimeof O(f)whentheadversaryismanip-\nulating the message ordering hence the full ADKG protocol has an\nexpected O(loдn)running timewithout anetwork leveladversary\nandanO(f+loдn)=O(f)runningtimeunderasynchrony.Ona\nhigh-level the ADKG works as follows:\nWhen a party is initialized for ADKG it also initializes nparallel\nABA instances of Section 6.1 s.t. ABA.jwill be used to decide if\nHAVSSID.jterminated successfully (all honest parties delivered a\nsharethatcorrespondstothesamesecret),andproceedsasfollows:\n(1)Once player Pidelivers an HAVSS share for Pj’s instance he\ninputs 1 in ABA.j.\n(2)OncePidecides 1 in n-fABA instances, it inputs 0 in every\nABA instance it have not invoked yet.\n(3)WhenPidecidesinall nABAinstances, pioutputsthesubset\nKof shares that corresponds to ABA instance in which it\ndecided 1.\nA detailed description of the protocol is given in Algorithm 5\nand the proof is given in Appendix D.\nAnalysis. Thecostof nparallelinstances(whereeachinstance\ncostsaworstcaseof O(n3)andhasanexpected O(n)runningtime)\nisO(n4)thesameastheHAVSSstep.OncetheADKGterminatesthe\nsystemcanusethestrongcommon-coingeneratedtorunVABA[ 1]\nand amortize the costs to O(n2). We know that validity, agreement\nandlivenessholdfromACS.Privacyholdsfrom inclusion andpri-\nvacyof the wDKG. With this we prove our main Theorem.\n7 CONCLUSION\nIn this paper, we show a protocol that implements the first asyn-\nchronous Distributed Key Generation protocol. To achieve this we\nshowhowtogetthefirstAVSSprotocolthatsupportsthresholds\nf+1<k≤2f+1, the first Eventually Efficient ABA which does\nnotneed atrustedsetupand canalsobe amortizedtotheoptimal\ncostifrun O(n2)timesinsequence,andthefirstVABAthatdoes\nnot require a trusted setup.\nACKNOWLEDGEMENTS\nWe would like to thank Ittai Abraham for the discussions and guid-\nance during the initial conception of the project, especially forHAVSS. Furthermore, we would like to thank the anonymous re-\nviewersforpointingouttherelevanceofthisworktoMPCproto-\ncols.\nREFERENCES\n[1]IttaiAbraham,DahliaMalkhi,andAlexanderSpiegelman.Asymptoticallyoptimal\nvalidated asynchronous byzantine agreement. In Proceedings of the 2019 ACM\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1762Symposium on Principles of Distributed Computing, pages 337–346, 2019.\n[2]AbhinavAggarwal,MahnushMovahedi,JaredSaia,andMahdiZamani. Boot-\nstrapping public blockchains without a trusted setup. In Proceedings of the 2019\nACM Symposium on Principles of Distributed Computing, pages 366–368, 2019.\n[3]GeorgiaAvarikioti,EleftheriosKokorisKogias,andRogerWattenhofer. Brick:\nAsynchronous state channels. arXiv preprint arXiv:1905.11360, 2019.\n[4]Laasya Bangalore, Ashish Choudhury, and Arpita Patra. Almost-surely terminat-\ningasynchronousbyzantineagreementrevisited. In Proceedingsofthe2018ACM\nSymposium on Principles of Distributed Computing, pages 295–304. ACM, 2018.\n[5]MichaelBen-Or,BoazKelmer,andTalRabin. Asynchronoussecurecomputations\nwith optimal resilience. In Proceedings of the thirteenth annual ACM symposium\non Principles of distributed computing, pages 183–192. ACM, 1994.\n[6]Gabriel Bracha. An asynchronous [(n-1)/3]-resilient consensus protocol. In Pro-\nceedingsofthethirdannualACMsymposiumonPrinciplesofdistributedcomputing,\npages 154–162. ACM, 1984.\n[7]Christian Cachin, Klaus Kursawe, Anna Lysyanskaya, and Reto Strobl. Asyn-\nchronousverifiablesecretsharingandproactivecryptosystems. In Proceedingsof\nthe 9th ACM conference on Computer and communications security , pages 88–97.\nACM, 2002.\n[8]ChristianCachin,KlausKursawe,FrankPetzold,andVictorShoup. Secureand\nefficient asynchronous broadcast protocols. In Annual International Cryptology\nConference, pages 524–541. Springer, 2001.\n[9]Christian Cachin, Klaus Kursawe, and Victor Shoup. Random oracles in con-\nstantinople:Practicalasynchronousbyzantineagreementusingcryptography.\nJournal of Cryptology, 18(3):219–246, 2005.\n[10]Christian Cachin and Stefano Tessaro. Asynchronous verifiable informationdispersal. In 24th IEEE Symposium on Reliable Distributed Systems (SRDS’05),\npages 191–201. IEEE, 2005.\n[11]RanCanettiandTalRabin. Fastasynchronousbyzantineagreementwithoptimal\nresilience. In STOC, volume 93, pages 42–51. Citeseer, 1993.\n[12]AshishChoudhury. Optimally-resilientunconditionally-secureasynchronous\nmulti-party computation revisited. Cryptology ePrint Archive, Report 2020/906,\n2020. https://eprint.iacr.org/2020/906.\n[13]AshishChoudhuryandArpitaPatra. Anefficientframeworkforuncondition-\nally secure multiparty computation. IEEE Transactions on Information Theory,\n63(1):428–468, 2016.\n[14]Ran Cohen. Asynchronous securemultiparty computation inconstant time. In\nPublic-Key Cryptography–PKC 2016, pages 183–207. Springer, 2016.\n[15]Sandro Coretti, Juan Garay, Martin Hirt, and Vassilis Zikas. Constant-round\nasynchronous multi-party computation based on one-way functions. In Interna-\ntional Conference on theTheory and Applicationof Cryptology andInformation\nSecurity, pages 998–1021. Springer, 2016.\n[16]Michael J. Fischer, Nancy A. Lynch, and Michael S. Paterson. Impossibility of\ndistributed consensus with one faulty process. JACM, 1985.\n[17]Bryan Ford, Philipp Jovanovic, and Ewa Syta. Que sera consensus: Simple\nasynchronous agreement with private coins and threshold logical clocks. arXiv\npreprint arXiv:2003.02291, 2020.\n[18]Juan A Garay, Aggelos Kiayias, Nikos Leonardos, and Giorgos Panagiotakos.\nBootstrapping the blockchain, with applications to consensus and fast pki setup.\nInIACR International Workshop on Public Key Cryptography, pages 465–495.\nSpringer, 2018.\n[19]Rosario Gennaro, Stanisław Jarecki, Hugo Krawczyk, and Tal Rabin. Secure\ndistributed key generation for discrete-log based cryptosystems. In International\nConference on the Theory and Applications of Cryptographic Techniques, pages\n295–310. Springer, 1999.\n[20]GuyGolanGueta,IttaiAbraham,ShellyGrossman,DahliaMalkhi,BennyPinkas,\nMichaelReiter,Dragos-AdrianSeredinschi,OrrTamir,andAlinTomescu. Sbft:\nascalableanddecentralizedtrustinfrastructure. In 201949thAnnualIEEE/IFIP\ninternationalconferenceondependablesystemsandnetworks(DSN),pages568–580.\nIEEE, 2019.\n[21]Vassos Hadzilacos and Sam Toueg. A modular approach to fault-tolerant broad-\ncasts and related problems. Technical report, Cornell University, 1994.\n[22]MartinHirt,JesperBuusNielsen,andBartoszPrzydatek.Cryptographicasynchro-\nnousmulti-partycomputationwithoptimalresilience. In AnnualInternational\nConference on the Theory and Applications of Cryptographic Techniques, pages\n322–340. Springer, 2005.\n[23]MartinHirt,JesperBuusNielsen,andBartoszPrzydatek. Asynchronousmulti-\nparty computation with quadratic communication. In International Colloquium\non Automata, Languages, and Programming, pages 473–485. Springer, 2008.\n[24]AniketKate,YizhouHuang,andIanGoldberg. Distributedkeygenerationinthe\nwild.IACR Cryptology ePrint Archive, 2012:377, 2012.\n[25]EleftheriosKokorisKogias,PhilippJovanovic,NicolasGailly,IsmailKhoffi,LinusGasser,andBryanFord. Enhancingbitcoinsecurityandperformancewithstrongconsistencyviacollectivesigning. In 25th\n{usenix}securitysymposium( {usenix}\nsecurity 16), pages 279–296, 2016.\n[26]Eleftherios Kokoris-Kogias, Enis Ceyhun Alp, Sandra Deepthy Siby, NicolasGailly, Linus Gasser, Philipp Jovanovic, Ewa Syta, and Bryan Ford. Calypso:\nAuditablesharingofprivatedataoverblockchains. IACRCryptol.ePrintArch.,Tech. Rep, 209:2018, 2018.\n[27]Eleftherios Kokoris-Kogias, Philipp Jovanovic, Linus Gasser, Nicolas Gailly, Ewa\nSyta, and Bryan Ford. Omniledger: A secure, scale-out, decentralized ledger via\nsharding. In 2018IEEESymposiumonSecurityandPrivacy(SP),pages583–598.\nIEEE, 2018.\n[28]BenoîtLibert,MarcJoye,andMotiYung. Bornandraiseddistributively:Fully\ndistributed non-interactive adaptively-secure threshold signatures with short\nshares.Theoretical Computer Science, 645:1–24, 2016.\n[29]Achour Mostéfaoui, Hamouma Moumen, and Michel Raynal. Signature-free\nasynchronousbinarybyzantineconsensuswitht<n/3,o(n2)messages,ando(1)\nexpected time. Journal of the ACM (JACM), 62(4):31, 2015.\n[30]Arpita Patra, Ashish Choudhary, and C Pandu Rangan. Efficient statistical\nasynchronous verifiable secret sharing with optimal resilience. In International\nConference on Information Theoretic Security, pages 74–92. Springer, 2009.\n[31]Marshall Pease, Robert Shostak, and Leslie Lamport. Reaching agreement in the\npresence of faults. Journal of the ACM (JACM), 27(2):228–234, 1980.\n[32]TorbenPrydsPedersen. Athresholdcryptosystemwithoutatrustedparty. In\nWorkshopontheTheoryandApplicationofofCryptographicTechniques,pages\n522–526. Springer, 1991.\n[33]Fred BSchneider. Implementingfault-tolerant services using thestate machine\napproach: A tutorial. ACM Computing Surveys (CSUR), 22(4):299–319, 1990.\n[34]Ewa Syta, Philipp Jovanovic,Eleftherios KokorisKogias, NicolasGailly,Linus\nGasser, IsmailKhoffi, MichaelJ Fischer,and BryanFord. Scalablebias-resistant\ndistributedrandomness. In 2017IEEESymposiumonSecurityandPrivacy(SP),\npages 444–460. Ieee, 2017.\n[35]Maofan Yin,Dahlia Malkhi, Michael KReiter, Guy Golan Gueta,and Ittai Abra-\nham. Hotstuff:Bftconsensuswithlinearityandresponsiveness. In Proceedingsof\nthe 2019 ACM Symposium on Principles of Distributed Computing, pages 347–356,\n2019.\nA FULL COMPUTATIONAL MODEL\nFollowing[ 1,8,9],weusestandardmoderncryptographicassump-\ntions and definitions. We model the computations made by all\nsystemcomponentsasprobabilisticTuringmachines,andbound\nthe number of computational basic steps allowed by the adversary\nbyapolynomialina securityparameterk.Afunction ϵ(k)isneg-\nligibleinkif for allc>0 there exists a k0s.t.ϵ(k)<1/kcfor all\nk>k0. A computational problem is called infeasible if any poly-\nnomialtimeprobabilisticalgorithmsolvesitonlywithnegligible\nprobability. Note that by the definition of infeasible problems, the\nprobability tosolve at leastone such problemout of apolynomial\ninknumberofproblemsisnegligible.Intuitively,thismeansthat\nforanyprotocol Pthatusesapolynomialin knumberofinfeasible\nproblems, if Pis correct provided that the adversary does not solve\noneofitsinfeasibleproblems,thentheprotocoliscorrectexcept\nwith negligible probability. We assume that the number of parties\nnis bounded by a polynomial in k.\nCommunication. Weassumeasynchronouslinkscontrolledby\ntheadversary,thatis,theadversarycanseeallmessagesanddecide\nwhen and what messages to deliver. In order to fit the communi-\ncation model with the computational assumptions, we restrict the\nadversarytoperformnomorethanapolynomialin knumberof\ncomputationsteps betweenthetime amessage mfroman honest\npartypiis sent to an honest party pjand the time mis delivered\nbypj6. In addition, for simplicity, we assume that messages are\nauthenticated inasensethatifanhonestparty pireceivesames-\nsagemindicating that mwas sent by an honest party pj, thenm\nwas indeed generated by pjand sent to piat some prior time. This\nassumptionisreasonablesinceitcanbeeasily implementedwith\nstandard symmetric-key cryptographic techniques in our model.\n6Notethatalthoughthisrestrictiongivessomeupperboundonthecommunication\nin terms of the adversary localspeed, the model is still asynchronous since speeds of\ndifferent parties are completely unrelated.\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1763Termination. Notethatthetraditionaldefinitionoftheliveness\npropertyindistributedsystem,whichrequiresthatallcorrect(hon-\nest)parties eventually terminateprovidedthatallmessagesbetween\ncorrect(honest)partieseventuallyarrive,doesnotmakesensein\nthis model. This is because the traditional definition allows the\nfollowing:\n•Unbounded delivery time between honest parties, whichpotentially gives the adversary unbounded time to solve\ninfeasible problems.\n•Unboundedrunsthatpotentiallymayconsistofanunboundednumber of infeasible problems, and thus the probability that\nthe adversary manages to solve one is not negligible.\nFollowing Cachin et al. [ 8,9], we address the first concern by re-\nstricting the number of computation steps the adversary makes\nduringmessagetransmissionamonghonestparties.Soaslongas\nthetotalnumberofmessagesintheprotocolispolynomialin k,the\nerrorprobabilityremainsnegligible.Todealwiththesecondcon-\ncern, we do not use a standard liveness property in this paper, but\ninstead we reason about the total number of messages required for\nallhonestpartiestoterminate.Weadoptthefollowingdefinition\nfrom [8, 9]:\nDefinition A.1 (Uniformly Bounded Statistic). LetXbe a random\nvariable. We say that Xisprobabilistically uniformly bounded if\nthere exist a fixed polynomial T(k)and a fixed negligible functions\nδ(l)andϵ(k)such that for all l,k≥0,\nPr[X>lT(k)] ≤δ(l)+ϵ(k)\nWith the above definition Cachin et al. [ 8,9] define a progress\nproperty that makes sense in the cryptographic settings:\n•Efficiency: The number of messages generated by the honest\nparties is probabilistically uniformly bounded\nTheefficiencypropertyimpliesthattheprobabilityoftheadversary\ntosolveaninfeasibleproblemisnegligible,whichmakesitpossible\nto reason about the correctness of the primitives’ properties. How-\never, note that this property can be trivially satisfied by a protocol\nthatneverterminatesbutalsoneversendsanymessages.Therefore,\ninorderforaprimitivetobemeaningfulinthismodel,Cachinet\nal. [8, 9] require another property:\n•Termination :Ifallmessagessentbyhonestpartieshavebeen\ndelivered, then all honest parties terminated.\nB HAVSS PROOFS\nLemma B.1. The protocol in Algorithms 1 and 2 satisfy H(i) (Live-\nness).\nProof.Ifthedealer pdishonest,itfollowsdirectlybyinspection\nof the protocol that all honest parties complete the sharing ID.d,\nprovided all parties initialize the sharing ID.dand the adversary\ndelivers all associated messages.\n/square\nLemmaB.2. TheprotocolinAlgorithms1and2satisfyH(ii)(Agree-\nment).\nProof.We show that if some honest party picompletes the\nsharingof ID.d,thenallhonestpartieswillcompletethesharingofID.d, provided all parties initialize the sharing ID.dand the\nadversary delivers all associated messages. Consider two cases:\n•First,picompletes the sharing directly (line 29 or line 35 in\nAlgorithm1).Thenithasreceived n−fvalid readymessages\nthat agree on some ¯Cfrom a set of at least n−fpartiesS.\nSince we have at most fByzantine parties, we get that S\ncontains at least n−2fhonest parties who have witnessed\nkvalid echomessages and thus each such party will also\ncompletethesharinguponreceptionof n−freadymessages.\nBy the algorithm in step 4 (line 28 or 34), after receiving\nn−f(signed) valid readymessages, pisends them to all\notherparties. Therefore,every honestparty in Seventually\nreceivesn−fvalid readymessages and thus eventually\noutputsshared.Itislefttoshowthathonestpartiesnotin\nSwillterminateaswell.Considersuchparty pjthatnever\nsent a readymessage. We already showed that eventually\nf+1honestpartiesin Soutputshared,whichmeansthat\nthey had a correct b(j)polynomial and they will eventually\nsent a sharedmessage with a valid point to pj. Therefore,\npjeventually gets at least f+1 consistent shared messages,\nrecoversitsshareinstep5andterminatesaswell(line36-43).\n•Second,picompletethesharingindirectly(line36-43).Then\nweknowthat pigetsatleast f+1consistent sharedmessages,\nmeaning that pigets at least one such message from an\nhonestparty pj.Bystep4, pjwaspartofSandterminated\n(line 29 or 35). Therefore, by the first case, we get that all\nhonest eventually output shared.\n/square\nLemmaB.3. Supposeanhonestparty Pisendsa sharedmessage\ncontaining Ciand a distinct honest party Pjsends a sharedmessage\ncontaining Cj. ThenCi=Cj.\nProof.We prove the lemma by contradiction. Suppose Ci/nequalCj.\nPioutputs the sharedforCionly if it has received at least n−f\nreadymessagesfor Ciorverified SiдCthatcontains n−fsigned\nreadymessages for Ci.Pjoutputs the sharedforCjonly if it has\nreceived at least n−freadymessage for Cjor verified SiдCthat\ncontainstheon n−fsigned readymessagesfor Cj.Fromthe n−f\nreadymessages for Ciat leastn−2fare generated by honest\nparties. From the n−freadymessages for Cjat leastn−2fare\ngenerated by honest parties. Since there are at most fmalicious\npartiesand n>3fthisis onlypossibleif anhonestparty signed\ntwocontradicting readymessages.Acontradictiontothecodeof\nthe protocol.\n/square\nLemmaB.4. TheprotocolinAlgorithms1and2satisfyH(iii)(Cor-\nrectness).\nProof.LetJbetheindexsetofthe khonestpartiesthathave\ncompleted the sharing and let sjbe the shares of J.T op r o v et h e\nfirstpart,supposethedealerhasshared sandishonestthroughout\nthe sharing stage. Towards a contradiction assume z/nequals.\nBecause the dealer is honest, it is easy to see that every echo\nmessage sent from an honest PitoPjcontainsC,u(i,j),u(j,i),as\ncomputed by the dealer. Furthermore, if the parties in Jcomputed\ntheir shares only from these echo messages, then sj=aj(0)=\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1764u(j,0). But since z/nequals, at least one honest party Picomputed a\npolynomial ai(y)/nequalu(i,y); this must be because Piaccepted an\nechoorreadymessagefromsomecorrupted Pmcontaining am/nequal\nu(m,i). SincePihas evaluated verify-point to true, we have дa=/producttext.1f\nj=0(Cjl)ijOntheotherhand,thedealerhassentpolynomials am\ntoPmsatisfying дam=/producttext.1f\nj=0(¯Cjl)ij. However, from Lemma B.3\nandthefactthatthedealerishonestweknowthat ¯C=C.Hence\nPmknows an am/nequalasuch that дa=дam, however this is a\ncollisiontothecommitmentschemewhichshouldbehard(binding\ncommitment). A contradiction.\nTo prove the second part, assume by a way of contradiction that\ntwodistincthonestparties PiandPjreconstructvalues ziandzj\nsuch that zi/nequalzj. This means that they have received two distinct\nsetsSi=(l,s(i)\nl)Sj=(l,s(j)\nl))and ofkshares each, which are valid\nwithrespecttotheuniquecommitmentmatrix CusedbyPiandPj\n(the uniqueness of Cfollows from Lemma B.3). According to the\nprotocol, ziandzjareinterpolatedfromthesets Si,Sjrespectively.\nSincethesharesinarevalid,itiseasytoseethat дzi=C00=дzj,\nhowever the commitment scheme is binding. A contradiction.\n/square\nLemma B.5. The protocol in Algorithms 1 and 2 satisfy H(iV) (Pri-\nvacy).\nProof.Ifthedealer pdishonest,itfollowsdirectlybyinspec-\ntion of the protocol that the dealer generated a polynomial with\ndegree(t,f)thennosetof fsharescanreconstructit.Furthermore,\nby inspection of the code, no honest party reveals its shares and\npolynomials to any unauthorized party. Finally, the lemma follows\nfromthehidingpropertyofthecommitmentscheme.Thatis,the\nadversary is unable to recover a share or points on the polynomial\nby looking atC.\n/square\nC EPCC PROOFS\nLemma5.1. Ifavalidcoinforsome sqisgenerated,thenatleast\n2f+1validshare-coinsassociatedwithsomebitvector Vforsqwere\npreviously generated, f+1of which by honest parties.\nProof.Bythecode, Pieithergets2 f+1share-coinmessages\nwith correct shares associated with some bit vector Vandsqor\ngetsacoinmessagewithvalidcoinassociatedwithsomebitvector\nVandsq.Inthe secondcase,bythe generate-coin andverify-coin\nfunctions,weknowthatatleast2 f+1validshare-coinsassociated\nwithVandsqare needed to produce the valid coin. In addition,\nnote that by the code, Piignores bit vectors that include less than\n2f+1ones.Therefore,weonlyneedtoshowthattheadversary\ncannotproducemorethan fvalidshare-coinsassociatedwith sq\nand some bit vector Vthat includes at least 2 f+1 ones (before\nhonest parties do it).\nBy the H(iv) property of HAVSS (privacy ), the adversary cannot\nlearn the shares of honest parties that were delivered in HAVSS\ninstanceswithhonestdealers.Since Vincludesatleast2 f+1ones,\nwe get that the associated keys of honest parties include shares\nfromHAVSSinstanceswithhonestdealers.Therefore,theadversary\ncannot learn the keys of honest parties that are associated with V,and thus cannot produce more than fvalid share-coins associated\nwithV.\n/square\nLemma 5.2. The protocol in Algorithm 4 satisfies E(i) (Unpre-\ndictability).\nProof.First, due to W(i) (Inclusion), we know that any valid\nshared private-key has contribution of at least f+1 honest parties\nwho never reveal them, hence the adversary does not know the\nshared private-key.\nSecond, consider an honest party Piwho’s coin-toss(sq) invoca-\ntionreturnsacoin ρ.ByLemma5.1,atleast f+1share-coinsfor sq\nwerepreviouslygenerated.Bythecode,anhonestpartydoesnot\ngenerate a share-coin for sqbefore coin-toss(sq) is invoked. There-\nfore, the adversary can neither know the private-key nor predict ρ\nbefore at least one honest party invokes coin-toss(sq).\n/square\nLemma5.3. Forevery sq,ifaninvocationof coin-toss(sq) byan\nhonest party Pireturns, then all coin-toss(sq) invocations by honest\nparties eventually return.\nProof.Assume by a way of contradiction that some invocation\nofcoin-toss(sq) byanhonestparty Pjneverreturns.Bythecode,\nbeforePireturns, it forwards the coin to all other parties in a\ncoinmessage,and thusall otherhonest partieseventually getthis\nmessages. In addition, since Piis honest, we know that the coin is\nvalidandassociatedwithabitvectorthatincludesatleast2 f+1\nones. Therefore, Pjwill eventually get this coin, successfully verify\nit and return it. A contradiction.\n/square\nLemma5.4. TheprotocolinAlgorithm4satisfiesE(ii)(Termina-\ntion).\nProof.Assume by a way of contradiction that some invocation\nofcoin-toss(sq) byanhonestparty Pjneverreturns.ByLemma5.3,\nwe get that no invocation of coin-toss(sq) by an honest party re-\nturns.BytheW(iii)(EventualAgreement)propertyofthewDKG\nsub-protocol, every party Pieventually outputs an ultimate pre-\ndictionandneveroutputsapredictionagain.Moreover,byW(iii),\nwe also know that all the ultimate predictions of honest parties\narematching,meaningthattheyareassociatedwiththesamebit\nvectorV/prime. In addition, by property W(i), we get that V/primeincludes at\nleast 2f+1 ones.\nTherefore,bythecode,allhonestpartieseventuallygenerateand\nsend to all other parties a valid coin-share for sqthat is associated\nwithV/prime. Hence,Pjwill eventually get 2 f+1 valid coin shares for\nsqthat are associated with a valid bit vector (includes 2 f+1 ones),\nand thus eventually generate a coin and return. A contradiction.\n/square\nLemma5.5. Ifanhonestpartygeneratesashare-coinassociated\nwithV, then it will never generate a share-coin associated with V/prime/notsuperseteql\nV.\nProof.By the code, at any point during the EPCC algorithm,\nan honest party generates share-coins that are associated with the\nbitvectorthatwereproduced(via get-key)fromthelastprediction\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1765itreceivedfromthewDKGsub-protocol.BypropertyW(ii)(Con-\ntainment) of the wDKG sub-protocol, we know that predictions\noutputted from the wDKG are related by containment, and thus\nthe lemma follows.\n/square\nLemma5.6. Ifforsome sq,tw o coin-toss(sq) invocationsbytwo\nhonest parties return different valid coins ρ1/nequalρ2, then there are\ntwo bit vectors V1,V2s.t. (1)V1⊂V2; and (2) f+1honest parties\ngeneratedvalidshare-coinsassociatedwith V1forsqandf+1honest\nparties generated valid share-coins associated with V2forsq.\nProof.ByLemma5.1, ρ1impliesthatatleast2 f+1validshare-\ncoins associated with some bit vector V1forsqwere previously\ngenerated, f+1 of which by honest parties; and ρ2implies that at\nleast 2f+1 valid share-coins associated with some bit vector V2\nforsqwere previously generated, f+1 of which by honest parties.\nTherefore,thereisatleast1honestparty Pithatgeneratedashare-\ncoin forsqthat is associated with V1and another share-coin for sq\nthatisassociatedwith V2.Sinceρ1/nequalρ2,wegetbyH(iii)(HAVSS\ncorrectness)that V1/nequalV2.Therefore,byLemma5.5, V1andV2are\nrelated by containment.\n/square\nLemma 5.7. For every 1≤k≤f+1, if there are ksequence\nnumbers sqfor which two invocations of coin-toss(sq) by honest\nparties output different coins, then there is a bit vector Vof size at\nleast2f+1+ksuch that f+1honest parties generated valid share-\ncoins associated with V.\nProof. We prove by induction on k.\nBase:we show that if there is one sqfor which two invocations\nofcoin-toss(sq) by honest parties output different coins then there\nis some vector Vof size at least 2 f+2 such that f+1 honest\nparties generated valid share-coins associated with V. By the code,\nhonestpartiesonlygenerateshare-coinsthatareassociatedwith\nbit vectors that were produced from wDKG prediction outputs.\nThus,bypropertyW(i)(Inclusion)ofwDKG,honestpartiesonly\ngenerate share-coins that are associated with bit vectors of sizeat lest 2\nf+1. Therefore, the base case follows from Lemma 5.6.\nStep:Assume the lemma holds for some 1 ≤k≤f, we show\nthat the lemma holds for k+1. First note that sine k≤f,w e\nget that the total number number of crytpographic signatures is\npolynomialinthesecurityparameter,andthusallpreviouslemmas\nhold except with negligible probability. Let sqkandskk+1be the\nkthand(k+1)thsequence numbers for which two invocations of\ncoin-toss by honest parties output different coins, respectively. By\nthewell-formednatureofEPCCweareguaranteedthatanyhonest\nparty invokes coin-toss( sqk+1)only after coin-toss( sqk)returns.\nBytheinductionassumption,thereisabitvector Vkofsizeatleast\n2f+1+ksuchthat f+1honestpartiesgeneratedvalidshare-coins\nassociatedwith Vkbeforetheir coin-toss( sqk)invocationreturns.\nSo by Lemma 5.5 and by well-formance, there are f+1 honest\nparties that do generate share-coins associated with bit vectors\nwithlessthan2 f+1+kentriesfor skk+1.ByLemma5.1,weneed\n2f+1validsharesinordertogenerateavalidcoinfor skk+1.Thus,\nsince every bad party can generate at most one valid share-coin,\nweget thatonly coinsthat areassociatedwith bitvectors ofsize atleast2f+1+kcan begenerated for skk+1. Therefore,the lemma\nfollows from lemma 5.6.\n/square\nLemma5.8. TheprotocolinAlgorithm4satisfiesE(iii)(Eventual\nAgreement).\nProof.Assumebyawayofcontradictionthatthereare f+1\nsequence numbers sqfor which two invocations of coin-toss(sq)\nby honest parties return different coins. By Lemma 5.7, then there\nis a bit vector Vof size at least 3 f+2 such that f+1 honest\nparties generated valid share-coins associated with V. Since the\nnumberofpartiesis(andthusHAVSS)instancesis3 f+1,wegeta\ncontradiction to the bit vector definition.\n/square\nD ADKG PROOFS\nLemma D.1. All honest parties decide 1in at least n−fABA\ninstances.\nProof. Consider two case:\n•First, there is an honest party that inputs 0 in some ABAinstance. By the code, it decides 1 in at least\nn−fABA\ninstances. Therefore, by the ABA Agreement property all\nhonest parties decide 1 in at least n−fABA instances.\n•Second, no honest party invoke an ABA with 0. By the H(i)\n(Liveness)propertyofHAVSS,thereare n−fHAVSSinstance\nforwhichallhonestpartiesdeliverashare,andthusinput\n1 in the corresponding ABA instances. Therefore, by the\nValidityandTerminationpropertiesallhonestpartiesdecide\n1 in these n−fABA instances.\n/square\nLemma D.2. The protocol in Algorithm 5 satisfies A(i) (Validity).\nProof.Consider a party pithat outputs a set of shares v.B y\nthe code, since pioutputs a value, it outputs a decision in all ABA\ninstances. Moreover, vincludes all the shares of HAVSS for which\nthecorrespondingABAdecides1.Thus,weneedtoprovethat pi\ndecides1inatleast n−fABAinstances.TheLemmafollowsfrom\nLemma D.1.\n/square\nLemma D.3. The protocol in Algorithm 5 satisfies A(ii) (Agree-\nment).\nProof.By the code, parties include all the shares of HAVSS\ninstances for which they output 1 in the corresponding ABA in-stances. Therefore, the lemma follows from the ABA Agreement\nproperty.\n/square\nLemma D.4. IfABA.joutputs 1, then all honest parties eventually\ndeliver a share for the HAVSS instance for which pjis the dealer.\nProof.BytheABAvalidity,atleastonehonestpartyinput1to\nABA.j. Thereforethere isat leastone honestparty who deliversa\nsharefortheHAVSSinstanceforwhich pjisthedealer.TheLemma\nfollows from the Agreement (Hii) property of HAVSS.\n/square\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1766Lemma D.5. The protocol in Algorithm 5 satisfies A(iii) (Liveness).\nProof.ByLemmaD.4,allpartiesoutputprovidedtheydecidein\nalltheABAinstances.Thus,weneed toprovethatallABAinstance\neventually terminate. Therefore, by the termination property of\nABA,weonlyneedtoprovethatallhonestpartyinvokeallABA\ninstances.Thus,bythecode,weneedtoprovethatatleast n−f\nABA instance decide 1. The Lemma follows from Lemma D.1.\n/squareLemma D.6. The protocol in Algorithm 5 satisfies A(iv) (Privacy).\nProof.Consider an honest party pithat outputs a set of shares\nvi. By the Validity property, |vi|≥n−f, and thus source(vi)\ncontains at least 1 honest party. The lemma follows from H(iV)\n(Privacy) of HAVSS.\n/square\nSession 6A: Signatures\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1767"}
{"title": "CapSpeaker: Injecting Voices to Microphones via Capacitors Xiaoyu Ji", "content": "CapSpeaker: Injecting Voices to Microphones via Capacitors\nXiaoyu Ji\nUSSLab, Zhejiang University\nxji@zju.edu.cnJuchuan Zhang\nUSSLab, Zhejiang University\njuchuanzhang@zju.edu.cnShui Jiang\nUSSLab, Zhejiang University\n3180104945@zju.edu.cn\nJishen Li\nUSSLab, Zhejiang University\n3180105960@zju.edu.cnWenyuan Xu∗\nUSSLab, Zhejiang University\nxuwenyuan@zju.edu.cn\nABSTRACT\nVoiceassistantscanbemanipulatedbyvariousmaliciousvoicecom-\nmands, yet existing attacks require a nearby speaker to play the\nattackcommands.Inthispaper,weshowthatevenwhennospeak-\ners are available, we can play malicious commands by utilizing the\ncapacitors inside electronic devices, i.e., we convert capacitors into\nspeakers and call it CapSpeaker . Essentially, capacitors can emit\nacoustic noises due to the inverse piezoelectric effect, i.e., vary-\ning the voltage across a capacitor can make it vibrate and thusemit acoustic noises. Forcing capacitors to play malicious voicecommandsischallengingbecause(1)thefrequencyresponsesof\ncapacitors as speakers have poor performance in the range of audi-\nblevoices,and(2)wehavenodirectcontroloverthevoltageacross\ncapacitorstomanipulatetheiremittingsounds.Toovercomethe\nchallenges, we use a PWM-based modulation scheme to embed the\nmaliciousaudioontoahigh-frequencycarrier,e.g.,above20kHz,\nand we create malware that can induce the right voltage across the\ncapacitors such that CapSpeaker plays the chosen malicious com-\nmands. We conducted extensive experiments with 2 LED lamps (a\nmodifiedoneandacommercialone)and5victimdevices(iPhone4s,\niPad mini 5, Huawei Nova 5i, etc.). Evaluation results demonstrate\nthat CapSpeaker isfeasibleatadistanceupto10.5cm,triggering\na smartphone to receive voice commands, e.g., “open the door”.\nCCS CONCEPTS\n•Securityandprivacy →Embeddedsystemssecurity ;Malicious\ndesign modifications ; Mobile platform security.\nKEYWORDS\nIoT security, ASR security, malicious voice commands, capacitor\nsounds, voice injection\nACM Reference Format:\nXiaoyu Ji, Juchuan Zhang, Shui Jiang, Jishen Li, and Wenyuan Xu. 2021.\nCapSpeaker:InjectingVoicestoMicrophonesviaCapacitors.In Proceedings\nof the 2021 ACM SIGSAC Conference on Computer and Communications\n∗Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n© 2021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3485389\nMalware\nOpen the door.\nInaudible Voice \nCommand\nExecute the Voice \nCommand“Open the door”\nLamp\nCapacitors\nFigure 1: Attack scenario of CapSpeaker . The malware inside\nan LEDlamp can manipulatethe voltage acrossthe built-in\nMLC capacitors of the LED lamp to produce malicious voice\ncommands, which can further trigger a voice assistant to\nexecute the commands such as “open the door”.\nSecurity(CCS’21),November15–19,2021,VirtualEvent,RepublicofKorea.\nACM,NewYork,NY,USA,15pages.https://doi.org/10.1145/3460120.3485389\n1 INTRODUCTION\nCapacitorsareubiquitousandindispensablecomponentsinelec-\ntronicdevicessincetheyareusedforvoltagestabilization,filtering,\netc [55]. Particularly, Multi-layer Ceramic (MLC) capacitors [ 46]\nare dominant due to their high energy density and low cost, and\nthenumberofMLCcapacitorsconsumedperyearisreportedtobe\napproximatelyonetrillion(1012)pieces[38].MLCcapacitorsare\nknowntocreateannoyingbutbenignhigh-pitchednoises,yetno\none has been reported to produce voices via such capacitors, to the\nbestofourknowledge.Inthispaper,weinvestigatethefeasibility\nofutilizingcommodityelectronicdeviceswithbuilt-incapacitors\ntoinjectmaliciousvoicecommandsintovoiceassistants,suchas\nApple Siri [ 11], Xiaomi Art Speaker [ 14], and potentially allowing\nan attacker to open the door sneakily.\nUnlikeexistingworkthatinjectsmaliciousvoicecommandsinto\nvoice assistants via a loudspeaker [ 19,49,50,62,63], we propose\nCapSpeaker thatcaninjectvoicecommandsbyconvertinganelec-\ntronicdevice(e.g.,alamp)thatarenotdesignedtoproducevoice\nintoaspeaker.Onequestionis“Howcanacapacitorproducevoices? ”\nTheunderlyingphysicsprincipleshowsthatcapacitorscanemit\nacoustic noises due to the inverse piezoelectric effect of ceramic\nmaterials [ 54], i.e., the voltage across a capacitor causes the capaci-\ntortovibrateatthesamefrequencyas thevoltagesignal.Thus,a\ncapacitor can produce sounds in a similar way as a speaker, i.e., by\nconverting currents into an acoustic signal.\nTo produce malicious voice commands, we envision that during\nthe manufacturing phase an attacker can install the malware in an\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1915\nLEDlamp,asshowninFig.1.Theprogramcanbeamodifiedversion\nofanormalapplication,e.g.,asimplebrightnesscontrolapplication,\nwithabilitiestoinducethe‘right’voltageacrosscapacitorsinside\nthe lamp circuits and to make the capacitors produce malicious\nvoices with “open the door” embedded. As a result, CapSpeaker\ncan opportunistically trigger the nearby voice assistants inside a\nsmartphone to execute an unexpected command1.\nPromising yet challenging, the design of CapSpeaker faces two\nchallenges.1)Howtoplayhumanvoices?Thefrequencyofhuman\nvoices is mainly below 4 kHz [ 40], but the capacitors’ frequency\nresponse2below 4 kHz is too low to produce voices. The peak\nfrequencyresponseofcapacitorsrangesbetween10kHzand90kHz,\nwithin which capacitors can produce a loud sound but is out of\nthemainhumanvoicerange.2)Howtocontinuouslycontrolthe\nvoltageacrosscapacitorstoproducethedesiredvoices?Commercial\ndevices are typically well packaged and have no access control\ninterfaces to interact with a capacitor.\nToaddresstheabovechallenges,wefirstperformexperiments\nand simulations to analyze the factors that determine the strength\nof produced sounds. The experiments involve MLC capacitors con-nected with a switch controlled by a signal generator, whereby we\nhavecontroloverthefrequencyandtheamplitudeofthevoltage\nacross the capacitor. We found that the sound strength and thefrequency of the MLC capacitor are directly determined by the\namplitudeandthefrequencyofvoltagechangeacrossthecapacitor\nbut are almost unaffected by the capacitance or the capacitor pack-\nagingtype.OursimulationofMLCcapacitorssolderedonaprintedcircuitboard(PCB)withCOMSOL[\n3]showsthatthePCBsizesand\nmaterials,capacitorpositions,andnumberswillaffecttheproduced\nsound strength as well. Thus, given an electronic device, attackers\nshallbeabletoproducedesiredvoicewithcarefullycraftedvoltage\nsignals.\nToinjecthumanvoicesby CapSpeaker despitethelowfrequency\nresponsebelow4kHz,wemodulatethemaliciousvoicecommands\non a carrier of a high-frequency band, e.g., ≥20 kHz, where the\ncapacitorshavethepeakfrequencyresponseandproducealoud\nvoice.Thebenefitofsuchasolutionisthat CapSpeaker canproduce\ninaudible voice commands, but the challenge is to have the victim\ndevicedemodulatethevoiceandextracttheembeddedcommand.\nByutilizing thenonlinearityofthe microphone[ 63],we envision\nthat the modulated commands can be demodulated and extracted.\nTomaketheattackfeasible,thecarrierfrequencyhastobecarefully\nchosen by balancing the trade-off between the frequency response\nof the capacitors and the peak nonlinearity of the microphone,\nand we model the selection of carrier frequency as an optimizationproblem.Unabletodirectlychangethevoltageacrosscapacitors,wedesignaprogram-levelcontrolmechanismtoindirectlymanipulate\nthevoltages,i.e.,werelyonhigh-levelprogramminginstructions\ntocontroltheperipheralloadofadevice.Additionally,wefound\nit is impossible to modulate the voltage levels continuously viaamplitude modulation due to hardware constraints, we employ\npulse width modulation (PWM) to control the average voltage and\nthusthestrengthofthevoicescontinuously.Thus,wemanageto\n1Demo video is available at https://github.com/USSLab/CapSpeaker.\n2The quantitative measure of the output in response to a given input frequency.producethemaliciousvoicecommandsbysimplyrunningmalware\non an electronic device.\nTo evaluate thepractical performance withvarious factors, we\nimplemented and evaluated CapSpeaker with extensive experi-\nments by utilizing both a modified and a commercial LED lamp to\nattackvariousdevicesatmultipledistancesandvoicecommands.\nIntotal,westudied5victimdevicesandshowitisfeasibletoinjectavoicecommandof“Openthedoor”atadistanceof10.5cmintoan\niPhone 4s. In short, our contributions are summarized as follows:\n•Wevalidatethefeasibilityofproducingvoicesviacapacitorsandempiricallystudythefactorsthataffectthestrengthand\nfrequency of the produced voices.\n•We design CapSpeaker that relies on malware to enable\ncapacitors to produce malicious voice commands. The mali-\nciousvoicecommandsadoptaPWMmodulationmechanism\nto overcome the limitation imposed by the frequency re-\nsponse of capacitors and have the benefit of being inaudible\nto humans.\n•We evaluate the performance of CapSpeaker by using an\nLEDlampagainst5victimdevicesincludingiPhone4s,iPad\nmini5,iWatch,HuaweiNova5iPro,andRedmiK30Ultra.\nTheexperimentresultsshowthat CapSpeaker canfoolthe\nautomaticspeec hrecognition(ASR)ofaniPhone4stoexe-\ncute a command of “Open the door” at a distance of 10.5 cm.\n2 SOUND PRINCIPLE OF MLC CAPACITORS\nIn this section, we present the mechanical structures of a capacitor\nto illustrate the underlying principle of producing sounds, and dis-\ncussthefactorsthataffectthesoundstrengthofthecapacitorswithCOMSOL[\n3]simulationandexperiments.Tounderstandcommand\nextraction at the microphones, we present the background knowl-\nedgeof microphones’nonlinearitythat enablesthedemodulation\nof the injected voice commands.\n2.1 How Can Capacitors Produce Voices\nThemechanicalstructuresofanMLCcapacitorandaspeakershare\nsimilarities, and thus a capacitor can produce voices.\n2.1.1 How Do Speakers Play Voices? Fundamentally, a speaker\nconverts the input electrical signals into mechanical vibrationsto produce voices. Most commercial devices, e.g., smartphones,\nlaptops,andsmartspeakers,useelectrodynamicspeakers,which\nare mainly composed of a diaphragm, a voice coil, a permanent\nmagnet, and a bracket, as shown in Fig. 2a. When a current passes\nthroughthevoicecoil,itproducesamagneticfieldthatinteracts\nwith the magnetic field of the permanent magnet, and an Ampere\nforce is exerted from the stable permanent magnet to the free-\nmovingvoicecoil.Thus,anACcurrentthatflowsthroughthevoice\ncoil will drive the diaphragm to vibrate and convert the motioninto sound pressure level (SPL). Suppose the magnetic induction\nintensity generatedby themagnet is 𝐵, thecurrent flowingin the\ncoil is𝐼, the number of turns of the coil is 𝑁, the circumference of\nthecoilis 𝐿,theDCandACcomponentsofthecurrentare 𝐼𝐷𝐶and\n𝐼𝐴𝐶respectively. Then, the Ampere force applied to the coil can be\nexpressed as:\n𝐹=𝑁𝐵𝐼𝐿 =𝑁𝐵𝐿(𝐼𝐷𝐶+𝐼𝐴𝐶𝑐𝑜𝑠2𝜋𝑓𝑡) (1)\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1916Voice coilPermanent \nmagnetDiaphragm\nࡲ\n0Ft\n(a)Aspeakerproducessoundsbecause\nthe diaphragm attached to the voice\ncoilisvibratedwhenacurrentisflow-\ning across.\nࡲࡱ\n0F\nt\nInternal electrodeCeramic Material\n݀\n(b)AnMLCcapacitorproducessounds\nbecausethecapacitorisvibratedunder\nthe inverse piezoelectric effect when\nan electric field is applied to it.\nFigure 2: The principle of producing sounds for a speaker\nand an MLC capacitor respectively.\nyz\nx0mm\n-5mm5mm\n-5mm0mm5mm\nFigure3:TheCOMSOLsimulationlayoutofanMLCcapacitor\nsoldered on a PCB.\nOnlytheACcomponentcausesthecoiltovibrate,andthevibration\nfrequency 𝑓is the same as the frequency 𝑓of the current signal\napplied to the voice coil, generating sounds of frequency 𝑓.\n2.1.2 How Do Capacitors Produce Sounds? Electronic devices, e.g.,\nlaptops, smartphones, LED lamps, are equipped with AC/DC or\nDC/DC power electronic components, resulting in inevitable high-\nfrequency interference such as ripple signals. Capacitors play a\nsignificant role in filtering unnecessary signals and stabilizing volt-\nage supply by alleviating voltage overshoot or undershoot [ 23].\nWiththetrendofhighcompactnessofnowadayselectronicdevices,\nMLCcapacitors[ 46]havebecomedominantinelectronicdevices\ndue to their low costs and small volumes [43].\nMLC inverse piezoelectric. An MLC capacitor is a fixed-value\ncapacitor using ceramic material as dielectric. As shown in Fig. 2b,\nanMLCcapacitorconsistsofmultiplealternatinglayersofceramics\nand metal, acting as dielectric layers and electrodes respectively.\nThe ceramics have the inverse piezoelectric characteristics [ 43],\ni.e., applied electric fields can induce mechanical strain force3.\nWithout loss of generality, denote the mechanical strain force as\n𝐹=𝑝𝐸, where𝑝is piezoelectric constant, and 𝐸is the electric\nfield,respectively. 𝐸canbecalculatedby 𝐸=𝑈/𝑑,where𝑑isthe\ndistance between the two electrodes, and 𝑈is the voltage across\nthe capacitor. 𝑈contains both a DC component 𝑈𝐷𝐶and an AC\ncomponent,i.e., 𝑈𝐴𝐶𝑐𝑜𝑠2𝜋𝑓𝑡,andthereforethededucedmechanical\nstrain force upon an MLC capacitor can be expressed as:\n𝐹=𝑝𝑈\n𝑑=𝑝\n𝑑(𝑈𝐷𝐶+𝑈𝐴𝐶𝑐𝑜𝑠2𝜋𝑓𝑡) (2)\n3The piezoelectric is the electric charge that accumulates in solid materials (e.g.,\ncrystals, ceramics) in response to applied mechanical stress.\nSignal \nGenerator\nRecorderMOSFET\nRheostatA Group of \nCapacitors\nFigure 4: The real-world experimental setup to study the\ninput signal frequency, capacitance, and package factors.\nSimilarto theAmpereforce denotedbyEqu. 1,themechanical\nstrain force 𝐹in an MLC capacitor contains components of fre-\nquency𝑓of the voltage signals, which drives the MLC capacitor\nto vibrate with the frequency 𝑓. In addition, 𝐹is proportional to\n𝑈𝐴𝐶. Given that the voltage across the capacitor has one single\nfrequency, we have Δ𝑉=2𝑈𝐴𝐶, where Δ𝑉is the peak-to-peak\namplitudeofthevoltagesacrossthecapacitor,i.e.,thedifference\nbetween the highest and lowest voltages.\nRemark. An MLC capacitor can produce sounds because of the\ninversepiezoelectriceffect.Thefrequencyofthesoundsdepends\non the frequency of the voltage signal applied on the capacitor and\nits strength is determined by the peak-to-peak amplitude of the\nvoltage, the piezoelectricconstant 𝑝, and theprinted circuit board\n(PCB)layout, etc.We willelaborateonthose influentialfactorsin\nthe following section.\n2.2 Impact Factors of MLC Capacitor Sound\nIncommercialproducts,MLCcapacitorsaresolderedtoacircuit\nboard.Inadditiontothepiezoelectricconstant,theproducedsounds\ncanbeaffectedbythePCBlayouts,theMLCcapacitors,andtheap-\nplied voltage signal. To quantify those impacts, we conducted both\nsimulationinCOMSOLsoftware [ 3],andreal-world experiments.\nThe validated factors include voltage frequencies, PCB sizes, MLC\ncapacitorpositions,numbersofMLCcapacitors,andPCBmaterials\nas shown in Tab. 1.\n2.2.1 COMSOL simulation. First, we study the factors that are\ndifficulttocontrolexperimentallybyutilizingCOMSOL,popular\nsimulation software for physics-based simulation tools, and the\nfactorsincludethePCBsizes,capacitorlocations,numbersofca-\npacitors, and PCB materials.\nTable1:SimulationparametersoftheMLCcapacitorsoldered\non a PCB.\nImpact factors Parameters Default Additional\nApplied voltage signal Δ𝑉(V) 20 4-20\nCapacitorCapacitance (nf) 1000 0.1-1000\nPackage 0805 0603, 1206\nPCBSize (cm) 4*4 1*1, 10*10\nMaterial (MPa) 150 15, 1500\nCapacitor location on PCB (0,0) (0, -1), (-1, -1), (-1, 0)\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1917-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm\n(a) 5 kHz (b) 10 kHz (c) 20 kHz-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm\n(d) 30 kHz (e) 40 kHz (f) 60 kHz\n50\n25\n0\n-25\n-50\n-11.08dB 11.71dB 24.31dB 32.03dB 12.97dB -13.6dB-200 0 200mm\n200\n0\n-200\nmm\n(a) 1 kHz-66.25dB\nFigure5:FrequencyresponseoftheMLCcapacitorsolderedonaPCBviaCOMSOLsimulation.Thenumberinredindicates\nthe maximum sound strength for each frequency.\nFigure6: Frequencyresponsevs. capaci-\ntanceviareal-worldexperiment.“Base”\nis the noise from other devices.Figure7:Frequencyresponsevs.package\nviareal-worldexperiment.“Base”isthe\nnoise from other devices.Figure8:SPLofMLCcapacitorswithvar-\nious load levels at 30 kHz. A higher volt-\nage change means a higher load level.\nSetup.Webuildafiniteelementmodeltosimulatethescenar-\nios of a capacitor welded on a PCB, as shown in Fig. 3. An MLC\ncapacitor,which isdenotedbyacube of0805packagesize [ 12]in\nthe middle, is wrapped between two copper plates that are welded\non the PCB using high-leaded tin alloy solder joints. All these com-\nponents are surrounded by an air area, which is a cube with a side\nlength of 40 cm. These materials and setup are supported by the\nCOMSOL inner material library. For each simulation, we excite the\nelectric field with a voltage, resulting in the vibration of piezoelec-\ntric ceramics. The vibration of piezoelectric ceramics drives the\nvibration of PCB through solder joints. These solid substances will\npushthesurroundingairastheboundaryofstructuralacoustics,\nandfinally,producesounds.Wemeasurethesoundfielddistribution\nup to 5 cm away from the board with the default setup parameters\nlistedinTab.1:ThecapacitorelectrolyteisLeadZirconateTitanate\n(PZT-4), the input current frequency is 30 kHz, the size of the PCB\nis 4*4 cm with the capacitor located in the center of the board, and\nthe material of PCB is glass wool board.\n2.2.2 Real-world experiments. InadditiontotheCOMSOLsimu-\nlation, we conduct experiments on MLC capacitors with various\ncapacitancevalues,packages,voltages,andinputsignalfrequencies.\nAsshowninFig.4,theexperimentalsetupconsistsofacircuitwith\na20Vpoweradapter,ametaloxidesemiconductorfield-effecttran-\nsistor(MOSFET),andaslidingrheostatsetto10 Ω.TheMOSFET\nactsasaswitchtocontrolvoltagesacrossthecapacitorstogenerate\nlow/high voltage levels, and a RIGOL DG811 [5] signal generator\nisusedtocontroltheMOSFETwithasquarewaveasthecontrol\nsignal.TovalidatethefrequencyresponseofMLCcapacitors,we\nsweptfrom0Hzto96kHzwithastepsizeof88Hzandrecordedthe\nproducedsoundsusingan AigoR6611 voicerecorderatadistanceof\n5cm.Therecordedsoundsareprocessedbyan SYBAFG-EAU02A\nsound card [ 2]. Note that we placed the other devices that maygenerate noises, e.g., the sliding rheostat and the power supply,\n10mawayfromtherecordertoreducetheirinfluences.Thedefault\nsettingsandinstancesofthestudiedcapacitorsarelistedinTab.1.\n2.2.3 Results. AccordingtotheCOMSOLsimulationandexperi-\nmentsoftheaforementionedparameters,wereporttheresultsof\ntheinputvoltagesignal,theMLCcapacitor,andthePCB,respec-\ntively.\nApplied voltage signal. We measured the sounds produced by\nthe MLC capacitor on a PCB with various voltage frequencies inCOMSOL, and the results are shown in Fig. 5. We observed thatthe frequency response peaks at the 30 kHz band with 32\n.03 dB\nandtheonesbelow5kHzarelessthan −11.08dB,indicatingthat\nit is extremely difficult, if ever possible, for MLC capacitors to\nproducesoundsinhumanaudiblefrequencybands.Notethatthe\npeak frequency response of the real-world capacitors welded ona PCB is around 80 kHz, which is different from the simulation\nresults, as shown in Fig. 6 and Fig. 7. This is because the PCB sizes\nandthematerialsofsimulationandreal-worldexperimentsetup\nare different.\nWe measured the SPL by changing the peak-to-peak magnitude\nof the voltage signals Δ𝑉from 4 V to 20 V. The results (shown\nin Fig. 8) indicate that the SPLs of the produced sounds increase\nalmost linearly when Δ𝑉is larger than 6 V.\nCapacitor capacitance and package. Capacitors with various\ncapacitance and packages are evaluated in real-world experiments,\nand the peak-to-peak amplitude of the voltage across the capacitor\nisΔ𝑉=20 V. We have the following observations. 1) For capacitor\ncapacitance,Fig.6indicatesthattheSPLsremainalmostunchanged\nwithcapacitancevalues.ThereasonmaybethatalthoughtheMLC\ncapacitors with higher capacitance have extra layers, the force\nfrom the inverse piezoelectric effect is mainly decided by the peak-\nto-peak amplitude of the applied voltages. 2) For MLC capacitor\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1918packages,i.e.,0603,0805,and1206[ 12]4,Fig.7showsthattheSPLs\nof capacitors with various packages remain almost unchanged, i.e.,\nat most 2 .5 dB at frequencies larger than 20 kHz.\nPCB sizes and materials. To study whether the PCB sizes\nand materials will amplify the produced sounds by capacitors in\nCOMSOL,wechoosethreetypicalPCBsizes(i.e.,1*1cm,4*4cm,\nand 10*10 cm) and simulate PCB materials with various elasticities,\nwhile applying a 30 kHz voltage signal. We have the following\nobservations. 1) Results of PCB sizes, as shown in Fig. 9, show that\nthe 1*1 cm board produces the strongest sound while the 10*10 cm\nboard producesthe weakestsound. Thisis becausethe vibration\nfrom capacitors is amplified at a larger amplitude by a smallerPCB and vice versa. 2) To simulate PCB with various elasticities,\nwe changed Young’s modulus [\n59] of the PCB. A higher Young’s\nmodulus maps to a less elastic board, i.e., harder. The results in\nFig.10indicatethatthehigherelasticthematerialisthestronger\nthe sound produced by the PCB.\nCapacitorlocationonPCB. IntheCOMSOLsimulation,we\nplace the MLC capacitor at various positions of the PCB, e.g.,\n(0,0) cm, (0,-1) cm, (-1,-1) cm, and (-1, 0) cm, where the coordi-\nnateoriginisthecenterofthePCB.TheresultsinFig.11showthat\nthe locations of the capacitor will affect the SPLs. Interestingly, the\nSPLsproducedwhenthecapacitorislocatedintheleft-bottomand\nthecenterofthePCBarehigherthantheonesofmiddle-bottom\nand middle-left locations.\nRemark. Insummary,althoughthecapacitanceandpackages\nof capacitors, as well as the PCB properties, of a device may affect\ntheproducedsoundmoreorless,foragivenelectronicdevicethese\nfactors are fixed. Thus, the sound strength produced by capacitors is\nfundamentally determined by the input voltage signal. To boost the\nSPL of the produced sounds, the voltage signal should be carefully\ndesigned to match the frequency response of the capacitors.\n2.3 Voice Assistant and Its Vulnerability\nThe nonlinearity of microphones. A microphone is a nonlin-\near component, whereby its output contains square and higher-order items of the input, and thus it can produce harmonics andcross-products. The utilization of such a hardware property is\nfirstreportedbyDolphinAttack[ 49,50,63].Theworkutilizesan\nAM modulation to create malicious voice commands embedded\nin an ultrasonic carrier. Formally, suppose a base-band signal is\n𝑚(𝑡)=𝑐𝑜𝑠(2𝜋𝑓𝑚𝑡), the AM carrier frequency is 𝑓𝑐, then the modu-\nlated signal fed into the microphone can be expressed as:\n𝑠𝑖𝑛=𝑚(𝑡)𝑐𝑜𝑠(2𝜋𝑓𝑐𝑡)+𝑐𝑜𝑠(2𝜋𝑓𝑐𝑡) (3)\nWith the help of the nonlinearity of the microphone, the output\nsignalcontains 𝑓𝑚andthelineartermsof 𝑓𝑐,𝑓𝑐−𝑓𝑚,𝑓𝑐+𝑓𝑚.After\nthe low pass filter, the output ofthe voice signal only contains 𝑓𝑚.\nTherefore, an attacker can successfully inject voice commands into\nvoice assistants with inaudible ultrasonic signals.\n3 THREAT MODEL\nThe goal of an attacker is to utilize CapSpeaker , i.e., the capacitors\ninelectronicdevices,toinjectmaliciousvoicecommandsintovoice\n4Thenumberindicatesthephysicalsizeofthecapacitor,a0805-packagedcapacitor,\nfor example, means its length and width are 0.08 inch and 0.05 inch respectively.assistants on smartphones, smartwatches, and smart speakers, e.g.,\nSiri, Google Now, Amazon Echo. Note that CapSpeaker may be\nleveragedtoinjectvoicesintootherapplicationsthatinvolvemi-\ncrophones,e.g.foolingaudio/videoconversation,telephonecalls.\nNevertheless,inthispaper,wefocusonattackingvoiceassistants\nwith the following assumptions.\nMalwareinjection. Theattackercaninstallmalwareortamper\nwiththefirmwareofthedevice(e.g.,anLEDlamp)tomanipulate\nitsload,i.e.,itspowerconsumption.Themalwarecanbeembeddedinsideanormalapplicationwithahiddenfunction,e.g.maliciously\nmanipulate the LED brightness in the brightness control program\nofthe LEDlamp. Oncethe deviceis turnedon andthe programis\nexecuted, desired sounds are generated and injected into nearby\ndevices to cause malicious consequences.\nNodirect accesstothe victim’svoiceassistant. Weassume\nthat the attacker has no direct access to the victim’s voice assis-tant. She cannot install malware, change the device settings, norphysically touch it. However, she is aware of the device and the\nembedded microphone models of the voice assistant, and thus she\ncan obtain a device of the same model to collect the necessary\ninformation to ensure a successful attack.\nProximity to the victim’s voice assistant. Without loss of\ngenerality, we assume that the victim’s voice assistant device (e.g.,\nasmartphone)isplacedclosetothedevicewithcapacitors,e.g.,the\nLED lamp.\n4 DESIGN OF CAPSPEAKER\n4.1 Overview\nCapSpeaker is essentially malware preinstalled in an electronic\ndevice. For a given malicious voice command, CapSpeaker will\ninduce the carefully crafted voltage signals across the capacitors\nonthePCBinsidethedevicebyexecutinghigh-levelprogramming\ninstructions.Particularly, CapSpeaker consistsoftwomodules:a\nsignalcraftingmoduleandaGPIOcontrollingmodule,wherebythe\nsignal crafting module creates an intermediate signal that contains\nthemaliciousvoicecommandyetcandrivetheGPIOcontrolling\nmoduletoinducethecapacitorstoproduceasoundwiththechosen\nvoice command. As shown in Fig. 12, for a given command of\n“open the door”, CapSpeaker inside the LED lamp will perform the\nfollowing.\n1)Thesignalcraftingmodulechoosesthedesiredcarrierfrequency\nthat eventually can induce a loud voice from the capacitors and\nmodulates the baseband signals of the voice command onto the\ncarrier.\n2)The voltage across the capacitors is indirectly controlled by the\nGeneral Purpose Input/Output (GPIO), which is the standard\ninterface connecting microcontrollers to the peripheral devices.\nThus,aGPIOcontrollingmoduleswitchestheGPIOthatcontrols\nthe LED lamp based on the modulated signals generated by the\nsignalcraftingmodule,inducingthedesiredvoltageacrossthe\ncapacitors.\n4.2 Crafting the Attack Signal\nThe signal crafting module addresses two issues: 1) Selecting a\nproper carrier frequency for modulation to make the attack signal\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1919-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm\n(a) 1*1 cm\n-200 0 200mm\n200\n0\n-200\nmm\n(b) 4*4 cm\n (c) 10*10 cm\n50\n25\n0\n-25\n-5037.87dB 32.03dB 13.52dB\nFigure 9: The MLC capacitorsound field vs. PCB size simu-\nlated with COMSOL.-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm\n50\n25\n0\n-25\n-50\n(a) 15 MPa (b) 150 MPa (c) 1500 MPa\n36.35dB 32.03dB 29.83dB\nFigure10:TheMLCcapacitorsoundfieldvs.PCBmaterial\nsimulated with COMSOL.\n-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm-200 0 200mm\n200\n0\n-200\nmm\n50\n250-25\n-50\n(b) (0,-1) cm (c) (-1,-1) cm (d) (-1,0) cm\n-200 0 200mm\n200\n0\n-200\nmm\n(a) (0,0) cm32.03dB 15.81dB 21.85dB 31.66dB\nFigure11: TheMLC capacitorsound field vs.capacitor loca-\ntions on PCB via COMSOL simulation.\ninaudibleyetmatchthefrequencyresponseofthecapacitors.2)Uti-\nlizingafeasiblemodulationschemetomodulatethevoicecommand\nontotheselectedcarrierfrequency,consideringthelimitationof\ndevice hardware and software.\n4.2.1 Selecting the Carrier Frequency. The carrier frequency di-\nrectly determines the attack performance of CapSpeaker , and it\nshouldmaximizethesignal-to-noiseratio(SNR)ofthevoicecom-\nmands received by the victim’s voice assistant while ensuring that\nthegeneratedvoicecommandsremaininaudibletohumans.Denotethecarrierfrequencyby\n𝑓𝑃𝑊 𝑀,andfactorstobeconsideredinclude\nthe frequency response of capacitors, the nonlinearity property of\nthe microphones, and the inaudibility of the attacks.\nFrequency responses of capacitors. We define the frequency\nresponse of capacitors as the voice signal amplitude in responseto a single frequency voltage signal of a peak-to-peak amplitude.\nFollowing the findingsin both the COMSOL simulation (inFig. 5)\nand the real-world experiments (in Fig. 6, Fig. 7), the frequencyresponses for capacitors are extremely weak in human audible\nfrequencybandsandastrongfrequencyresponseoccurabove20\nkHz. For example, consider the frequency response curve obtained\nby real-world experiments on a capacitor of 1uf, depicted as the\norangelineinFig.13,thenthechoiceofacarrierfrequencyshould\nbe above 20 kHz and below 80 kHz.\nThenonlinearityof microphones. CapSpeaker exploitsthe\nnonlinearity of the microphone to demodulate the inaudible voice\ncommand. However, the frequency response of the nonlinearity\npropertyvarieswithfrequency.Toverifythefrequencyresponse\nof the microphone after nonlinearity demodulation, we experimen-\ntally tested the nonlinearity property of microphones on iPhone\n4s,iWatch,andRedmiK30Ultra,respectively,usingaViFaUltra-\nSoundGate [ 13]. We used a sinusoidal wave as the baseband signal\nand modulated it on carriers ofvarious frequencies. For the iPhone\n4s smartphone, we plot the normalized strength of the received\nsound after demodulation with increasing carrier frequencies inFig. 13 as a blue line. The trend is that the received signal strength\ndecreases with the increase of the carrier frequency, and the fre-quency bands of [2 kHz,20 kHz], and [27 kHz,38 kHz] perform\nwell with their normalized strength larger than 0 .6. This finding is\nconsistent with that reported in DolphinAttack [63].\nInaudibility. In addition, the selection of carrier frequency\nshouldguaranteethestealthinessoftheattack.Sincethefrequency\nbandofaudiblesoundisbetween20Hzand20kHz,asshownin\nthe shaded gray area of Fig. 13, the carrier frequency should be\nabove 20 kHz to ensure inaudibility.\nIn summary, CapSpeaker has to simultaneously consider fre-\nquency responses of capacitors, the nonlinearity property of the\nvictim’smicrophone,andtheaudibilitytofindthefeasiblecarrier\nfrequency. For example, according to the data of iPhone 4s plotted\nin Fig. 13, the feasible carrier frequency shall range from 27 kHzto 38 kHz. In reality, an attacker can obtain the information onthe LED lamp and typical frequency ranges of victim devices in\nadvance.\n4.2.2 PWM-based Modulation. Afterselectingthepropercarrier\nfrequency, a modulation scheme is needed to modulate the base-\nbandsignalontothecarrier.Typicalmodulationschemesinclude\namplitude-modulation(AM),frequency-modulation(FM),etc,where\ntheAMmodulationispopularandisusedinDolphinAttack[ 63]\nto generate inaudible voice commands. However, CapSpeaker can-\nnot use the AM modulation scheme because the victim device, i.e.,\ntheLEDlampor otherIoTdevices,isunabletooutput signalsof\nfine-grained amplitudes. Instead, the controllable general purpose\ninput/output(GPIO)canonlyoutputtwolevels,i.e.,a“low”level\nora“high”level,whichareoften0Vand5Vforcommercialsmartdevices.Therefore,weresorttothepulse-widthmodulation(PWM)\nscheme which only needs two levels of output voltage. The princi-\nple of PWM modulation is illustrated in Fig. 14, where the average\nvalueofthebasebandsignaliscontrolledbyswitchingonandoff\natafastrateandthusmodulatedontoacarrierfrequency.Inour\nimplementation,theswitchiscontrolledbytheGPIOoutputpin\nwith only a low or high voltage level.\nThe voice command signal and the modulated signal are plotted\nin Fig. 12 in both time and frequency domains. After the PWMmodulation, the deduced signal includes the baseband signal\n𝑓𝑚,\nthecarriersignal 𝑓𝑃𝑊 𝑀,andafewharmonicfrequenciessuchas\n𝑓𝑃𝑊 𝑀+𝑓𝑚,𝑓𝑃𝑊 𝑀−𝑓𝑚,𝑓𝑃𝑊 𝑀+2𝑓𝑚,𝑓𝑃𝑊 𝑀−2𝑓𝑚,etc.Notethatthe\nbaseband 𝑓𝑚existsinthisstagebuthasextremelylowamplitude\nduetothepoorfrequencyresponseofcapacitorsatlowfrequencies.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1920TimeVictim’s Voice \nAssistant“Open the door”\nVictim’s \nDevice\nInaudible\nVoice Command\nPWM Modulated Signalfm fPWMAmp\nf 20 kHztAmp\nOriginal SignalfmAmp\nf 20 kHztAmp\nTransmitted SignalfPWMAmp\nf 20 kHztAmp\nfm\nReceived SignalfmAmp\nf 20 kHztAmpCarrier Frequency \nSelection\nPWM ModulationTimer Settings\nGPIO ControlMalicious Voice \nCommand\nFrequencyMalware: Capspeaker\nSignal Crafting GPIO Controlling\nFigure 12: Workflow of CapSpeaker . To inject a malicious voice command of “open the door”, CapSpeaker first selects an\nappropriatecarrierfrequency,andthenPWM-modulatesthebasebandsignalwithvoicecommandsontothecarrier.Then,\nCapSpeaker manipulates the GPIO pin using high-level programming instructions to generate the PWM-modulated signal,\nwhichdrivesthecapacitors toproducethedesiredinaudiblevoicecommands.Finally,theproducedvoicecommands canbe\nreceivedanddemodulatedbythevictim’svoiceassistant,whichexecutesthecommand.Weplotthesignalinthetimeand\nfrequency domain at various stages.\nFigure13: Carrierfrequencyselection. CapSpeaker hasto si-\nmultaneouslyconsiderthefrequencyresponsesofcapacitors,\nnonlinearityeffectofthevictim’smicrophone,andtheau-\ndibility of the attack signal. The nonlinearity effect curve is\nfrom the measurement of the iPhone 4s smartphone.\nTheimplementationofthePWMmodulationcanbereferredtothe\nMatlab Toolbox [48].\n4.3 GPIO Controlling\nAfter we derive the PWM-modulated signal, the next step is to\nexecute the malware on the victim device to generate the attack\nsignal.RecallthatcommercialdevicessuchastheLEDlamphaveno\naccessible programming interfaces to directly control the voltages\nacrosscapacitors,andwecanonlyrelyonhigh-levelprogramming\ninstructions tocontrol theGPIO thatconnecting tothe peripheral\nload.Toensurethestealthinessofthemalware,themalwareshould\nnot affect the normal function of the devices, e.g., a brightness\ncontrol function.Most of the microcontroller units (MCU) of IoT devices support\nPWMoutputcontrol,andPWMiswidelytorealizevariousfunc-\ntions, e.g., the brightness control of monitors, the speed control\nof motors used in fans, the temperature control for heaters, andthe volume control for loudspeakers. Thus,\nCapSpeaker can use\nPWMoutputcontroltoadjustthevoltagesacrosscapacitorsina\nsimilar style as controlling the brightness of LED lamps. To runthe malware of\nCapSpeaker on the victim device, we exploit the\noff-the-shelfhardwarePWMAPIonMCUs,whichisusuallyimple-\nmented and controlled by a timer. Suppose the period of the PWM\nwaveform is 𝑇, and theduty cycle is 𝐷. Then the PWMwaveform\nwithparameters 𝑇,𝐷isachievedbysettingtheGPIOoutputto1\nduring the active state and vice versa.\nFor computation-resource-constrained IoT devices, we face the\nchallenge that the maximum carrier frequency supported by the\nPWM modulation is limited by the MCU clock cycles. For example,\nthe MCU in our setup is ESP-WROOM-32D, which cannot support\nreal-time fine-grained (i.e., 32 kHz) PWM calculation. Therefore,to strike the balance between accuracy and implementation, weincrease the duty cycle to every two PWM periods to decrease\nthecalculationoverhead.Suppose thatthedutycycletraceofthe\nmalicious voice command is 𝐷𝑢𝑡𝑦[0],𝐷𝑢𝑡𝑦[1],𝐷𝑢𝑡𝑦[2],...,w e\nselect𝐷𝑢𝑡𝑦[0],𝐷𝑢𝑡𝑦[2],𝐷𝑢𝑡𝑦[4],...to set the PWM duty value.\nOfcourse,thespecificPWMmodulationschemecanbeconfigured\naccording to the calculation capability of the victim device.\nHow the signal is changed at different stages. After the\nsignal is transmitted from the victim device, i.e., the LED lamp,\nthevictim’svoiceassistantshallreceivetheattacksignalandde-\nmodulateitduetothenonlinearityeffect.Thesignalinbothtime\nand frequency domain from the original voice command signal, tothe PWM-modulated one, the transmitted one from the LED lamp,\nand the finally received one from the voice assistant are plotted\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n19210 0.5 1 1.5 2\nTime(ms)-101AmplitudeBaseband signal\nPWM modulated signal\nFigure14:Pulse-widthmodulation(PWM).Theamplitudeof\nthebasebandsignalisconvertedtodutycyclesofthePWM\nwaveform using PWM modulation.\ninFig.12.Itisworthytomentionthatevenifthefinallyreceived\nvoicecommandsignalisnotthesameastheoriginalone,i.e.,the\ndemodulatedonehasa2 𝑓𝑚component,thevoiceassistantcanstill\nrecognize it with high probability. In the evaluation section, we\nprovide a detailed evaluation of the recognition rate of injected\nvoice commands.\n4.4 Verification of the PWM-modulation\nTo verify the validityof the effectivenessof the PWM-modulation\nscheme, we use one capacitorof 1uF. to generate the attack signal\nfollowingtheexperimentalsetupinFig.4.Theonlydifferenceisthat\ntherecorderisreplacedbyaniPhone4ssmartphone.Weusedan\nonlinetext-to-speechwebsite[ 1]toconvert“Turnonairplanemode”\ninto the voice command. The PWM-modulated signal is converted\nto executed program instructions using Alg. 1. The spectrogram of\nthe received speech command after demodulation from the iPhone\n4smicrophoneisplottedinFig.15b,whichexhibitssimilarpatterns\nas that of the original signal shown in Fig. 15b, indicating the\neffectiveness of the PWM-modulation scheme.\nAlgorithm 1: CapSpeaker malware.\nData:PWM duty cycle trace 𝐷𝑢𝑡𝑦, PWM Frequency 𝑓𝑃𝑊𝑀,PW M\noutput pin 𝑃\n1𝑠𝑒𝑡𝑃𝑤𝑚𝑂𝑢𝑡𝑝𝑢𝑡𝑃𝑖𝑛 (𝑃)\n2𝑠𝑒𝑡𝑇𝑖𝑚𝑒𝑟𝑃𝑒𝑟𝑖𝑜𝑑 (1/𝑓𝑃𝑊𝑀)\n3𝑐𝑜𝑢𝑛𝑡←0\n4𝑠𝑒𝑡𝐷𝑢𝑡𝑦𝐶𝑦𝑐𝑙𝑒 (𝐷𝑢𝑡𝑦[𝑐𝑜𝑢𝑛𝑡])\n5𝑠𝑡𝑎𝑟𝑡𝑇𝑖𝑚𝑒𝑟 ()\n6Function Interrupt():\n7 𝑐𝑜𝑢𝑛𝑡←(𝑐𝑜𝑢𝑛𝑡+1)mod𝑙𝑒𝑛(𝐷𝑢𝑡𝑦)\n8 𝑠𝑒𝑡𝐷𝑢𝑡𝑦𝐶𝑦𝑐𝑙𝑒 (𝐷𝑢𝑡𝑦[𝑐𝑜𝑢𝑛𝑡])\n9return\nTable 2: Experimental setups: The self-implemented LED\nlamp is for factors evaluation, and the commercial one is for\nfeasibility validation.\nSetup Self-implemented lamp Commercial lamp\nLEDs 3 W ×11 0.5 W ×42\nDriver board 700 mA PT4205 LED driver 700 mA PT4205 LED driver\nMCU ESP-WROOM-32D ESP-WROOM-32D\nPurposeImpact factors\nevaluationFeasibility validation oncommercial products\n0.5 1 1.5 2\nTime (s)100020003000400050006000Frequency (Hz)\n(a) Original voice command signal.\n2 2.5 3 3.5\nTime (s)100020003000400050006000Frequency (Hz)\n(b) The demodulated attack signal.\nFigure15:Theoriginal“Turnonairplanemode”signal(a)and\nthe received one by the iPhone 4s from the sound emitted\nby a capacitor (b). The spectrograms of two signals showsimilar patterns, indicating the effectiveness of the PWM-\nmodulation scheme.\n5 IMPLEMENTATION AND EVALUATION\nIn this section, we implement and evaluate of CapSpeaker using\nthe LED lamp scenario.\n5.1 Experiment Setup\nWe utilized a self-implemented LED lamp and a commercial one\nto validate the performance of CapSpeaker . The former is used to\ntest the performance of CapSpeaker at various distances, ambient\nnoises,etc.ThecommercialLEDlampproductisutilizedtovalidate\nthe feasibility of the attack against an off-the-shelf product instead\nof the self-implemented one, listed in Tab. 2.\nTheself-implementedLEDlampprototype. Weimplemented\na prototype of CapSpeaker using a group of LEDs, an LED driver,\nand an MCU board as shown in Fig. 16. We used 11 LEDs in series,\nand each LED is of 3 W power. The LED driver is a commercial\noff-the-shelf(COTS)onewitharatedcurrentof700mA,andisused\ntodrivetheLEDs.Thedriverwaspoweredbya48VDCadapter,\nandithasadimminginterfaceforadjustingthebrightnessofthe\nLEDs. We used the ESP-WROOM-32D MCU, which is widely used\nin commercial products such as Xiaomi Lamp 1S [ 9], to control the\ndriver board through the dimming interface. Due to the limited\ncurrent ofthe I/O port ofthe MCU,we use atriode-basedamplifier\ncircuit to drive the LED driver board. We developed a malwarethat can generate a 32 kHz PWM wave and PWM-modulated 3different voice commands. The detail of the hardware setup and\nthe malicious voice commands are listed in Tab. 3.\nThecommercialsmartLEDlamp. Tovalidatetheeffective-\nness of CapSpeaker against commercial products, we utilized a\nXiaomi Lamp 1S [ 9]. The LED lamp also uses the ESP-WROOM-\n32D MCU. There are 42 LEDs and each is of 0.5 W power. Sincereverse engineering the lamp firmware requires intensive work,\nwereplaceitscircuitboardwithanMCUofthesamemodel(ESP-\nWROOM-32D)andthemalwarehasbeenimplantedinsidetheMCU\ninadvanceforconvenience.Theotherhardwarecomponentsare\nkept unchanged. The detailed specification of the commercial LED\nlamp setup can be referred to Tab. 2.\nUnderbothsetups,weplacedthevictim’svoice assistants,e.g.,\nthe smartphones, smartwatches, and tablets close to the LED lamp\nat various settings, e.g., distance, ambient noises, the impact ofother devices, etc., and the microphones of the voice assistants\narefacingtheLEDlamptoreceivetheattacksignal.Thedetailed\nexperimental parameters and settings of the evaluation are shown\nin Tab. 3.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1922Voice \nAssistant\nLED Series\nAmplifierMCU5V DC48V DCDriver \nBoard\nSound \nMeter\nCapacitors\nFigure16:TheimplementationoftheLEDlampprototype.\n11 LEDs are connected in series and they are driven by a\ndriverboardwhichisofthesamemodelastheoneusedin\nthecommercialXiaomi1SsmartLEDlamp.(Setup#1: Self-\nimplemented lamp.)\n5.2 Evaluation Metrics\nWe define 3 metrics for the evaluation of CapSpeaker under the\nabove setups.\n•Recognitionsuccessrate 𝑅𝑐=𝑁𝑐/𝑁,where𝑁isthenumber\nof attacks while 𝑁𝑐is the number of correctly recognized\ncommands by the voice assistant.\n•Respondingrate 𝑅𝑟=(𝑁𝑐+𝑁𝑤)/𝑁,where𝑁𝑤isthenumber\nof commands that can be responded to but are incorrectly\nrecognized as any other commands.\n•The maximum attack distance 𝐷𝑚𝑎𝑥, i.e., the maximum dis-\ntance that the command can be successfully recognized.\n5.3 Impact of Distance and Direction\nToevaluatetheeffectivenessofthemaliciousvoicecommandgener-\nated by CapSpeaker at each location, we use the self-implemented\nLEDprototype(inTab.2)andexperimentalsettingsinTab.3.We\nmeasuretherecognitionsuccessrateandrespondingrateofiPhone\n4s using executable speechcommands including “call my wife”,\n“openthedoor”or“turnonairplanemode”atvariousdistances.We\nconsecutively tested each command at each distance 20 times with\nan ambient noise of 30 dB. The remaining experimental setting\nparameters are by default.\nRecognition rate vs. distances. Fig. 17 shows the results. The\nbars with complete opacity indicate the ratio of correctly recog-\nnizedvoicecommands,whilethebarswithtransparencyindicate\nTable 3: Experimental settings of the evaluation.\nSettings Default Additional\nTarget device iPhone 4s Nova 5i Pro, iPad mini 5, K30 Ultra, iWatch S1\nVoice assistant Siri Xiaoyi [10], iFlytek [8]Inductors On board Far awayNoise (dB) 30 37, 43, 46.8, 54.5, 60.5Distance (cm) 10.5 0-10.5Prox. devices None Fan, laptop, router, monitorCurrent (A) 0.41 0.35, 0.31, 0.24, 0.16Command Open the door Call my wife, Turn on airplane modeFigure 17: Recognition success rate vs. attack distances. Bars\nin opaque colors are the successful recognition rate, while\nbars of transparent colors are the rate of incorrectly recogni-\ntion. The sum of them represents the responding rate.\nFigure 18: Recognition success rate vs. directions. The green\nrectangle in the middle represents the LED driver board,\nwhose geometric center is the origin of the contour map.\nThe number on each contour line is the maximum height\n(along Z axis) that the attack can succeed at the coordinates.\nTheplotindicatesthatthevoicecommandscanbeemitted\nin all directions in the X-Y plane with various strengths.\ntheratioofincorrectlyrecognizedvoicecommands(butstillacti-\nvated the voice assistants). The recognition success rate 𝑅𝑐and the\nresponding rate 𝑅𝑟can beobtained fromthe top valueof the bars\nwithcompleteopacityandthebarswithtransparency,respectively.\nThe results show that the recognition success rate is decreasing\nwith the increase of distance and the maximum attack distance un-\nder the self-implemented LED lamp setup can achieve 10.5 cm and\ntherecognitionsuccessrateforallthreecommandsisabove80%.\nWith larger distances, both the recognition rate and the chances to\nmakethevoiceassistantrespondingrategraduallydecrease.This\nis because, at large distances, the emitted voice commands from\ntheLEDlampattenuateandshallbeinterferedwithbytheambient\nnoises.\nRecognition rate vs. directions. In addition, we tested the\nmaximum attack distance at 28 different locations from different\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1923Table4:Experimenteddevices,voiceassistantsofvarioustypesandbrands,andtheresults.Thecarrierfrequencyandmaximum\nattack distances are measured in an environment with a background noise of 30 dB SPL.\nType Manufacturer Model Rel. Date OS/Version Voice Assistant Recognition 𝑓𝑝𝑤𝑚(𝑘𝐻𝑧)Max. Dist. (cm)\nSmartphone Apple iPhone 4s 2011.10 iOS 9.3.5 Siri Yes 32 10.5\nSmartphone Huawei Nova 5i Pro 2019.07 EMUI 10.1.0 Xiaoyi [10] Yes 33 9\nTablet Apple iPad mini 5 2019.03 iOS 13.5.1 Siri Yes 24 3.5\nSmartphone Redmi K30 Ultra 2020.08 MIUI 12.0.18 iFlytek [8] Yes 28 0.5\nSmartwatch Apple iWatch S1 2015.04 watchOS 3.1 Siri Yes 22.3 0.2\nFigure19:Thenormalizedsoundampli-\ntudeofLEDdriverboardwhentheinduc-\ntorisontheboardandtheinductorisfar\naway.Figure20:maximumattackdistancevs.\nSPL of ambient noises. With 40 dB am-bient noise, the attack distance is still\naround 6 cm.Figure21:maximumattackdistancevs.\ncurrent. The attack distance can be in-\ncreasedbyincreasingthecurrent,i.e.,us-\ning fewer LEDs to get a heavier load.\ndirectionsfromtheLEDdriverboard.Wefitthepointscorrespond-\ning tothe maximum attackdistance of eachdirection to asurface,\nandplottedthecontourmapofthesurfaceindifferentdirections\nas shown in Fig. 18. The LED driver board is located at a heightof 0 cm from the center of the figure. The height value at each\npointindicatestheheightofthesurfaceatthatpoint.Theresults\nillustrate that CapSpeaker can be successful in all directions, even\nthemaximumattackdistancevariesindirectionsduetotheunevensoundfieldgenerated,whichcoincideswiththesimulationinFig.5.\n5.4 Impact of Voice Assistants\nIn addition to the iPhone 4s, we tried several other voice assistants.\nWetested10devicesintotal,includingsmartphones,smartwatches,\ntablets,andspeakers.TheexperimentalsetupisshowninFig.16.\nThe ambient noise level is 30 dB. For each device, we chose the\ncarrierfrequencywiththebestperformanceinadvanceandkept\nthe microphone of the device facing towards the LED driver board.\nWe measured the maximum attack distance of each device and\nrecordedthevoicecommandsusedatthemaximumattackdistance.\nThe results are shown in Tab 4. It shows that except iPhone 4s,\nHuaweiNova5iProcanalsobesuccessfullyattackedasfaras9cm,\nand iPad mini 5 can be successfully attacked as far as 3.5 cm. Note\nthat both Huawei Nova 5i Pro and iPad Mini 5 were released in\n2019 and sold 2 million and 40 million units respectively [ 7,25]. In\naddition, iWatch and Redmi K30 Ultra can be attacked successfully\nataverycloserange.Thisisbecausethemicrophones’nonlinearity\nofthesetwodevicesisnotassignificantastheotherdevices.We\nbelieve that more devices can be successfully attacked when the\ncapacitors can emit stronger sounds, such as using a higher power\nload.5.5 Impact of Background Noise\nControllingbackgroundnoise. Todemonstratethatour CapSpeaker\nis robust to background noise, we carried out a set of experiments\nunderdifferentambientSPLsettings.Themainsourcesofthenoises\nareanairconditionerandaservercoolingfan.Wecontrolledthe\nsound pressure levels by putting the attack devices at various loca-\ntions and used BENETECH GM1357 sound level meter to measure\ntheSPLinthevicinityoftheLEDdriverboard.Allexperimental\nsetupsarethesameasinSec.5.3exceptfortheSPL.Fig.20gives\nthe relationship between the maximum attack distances under the\ncorrespondingSPLsoftheambientnoises.Theresultsshowthat\nthe maximumattack distance decreaseslinearly with theincrease\nof noise SPL. We refer to a Decibel Table [ 4] which presents the\ncomparison between SPL and loudness. We found that 30 dB isequivalent to a quiet bedroom at night, 40 dB is equivalent to a\nquiet library, 50 dB is equivalent to an average home, and 60 dB is\nequivalent to a conversational speech at 1 m. Therefore, we con-\ncludethat CapSpeaker canachieveanattackdistancelargerthan\n3cminaverageinhomeenvironments.Foravictimwithaquiet\nhomeenvironment, CapSpeaker canevenachieveadistancelarger\nthan 10 cm.\nInterfering devices nearby. In addition to the impact of back-\nground noises,we investigatedthe impactof otherinterfering de-\nvicesinproximitytothevictimdeviceinpractice,asotherelectrical\nappliances have capacitors and inductors that can generate sounds.\nWe used a cooling fan, a laptop, a router, and a monitor at 50 cm\nfromtheLEDdriverboardrespectively,andtestedthemaximum\nattackdistance usingthe experimentalsetupin Sec.5.3.All ofthe\n4 devices were in operation and their locations with respect to\ntheLEDprototypeareshowninFig.22andtheirsoundpressure\nlevelsaremeasuredinadvanceshowninthecaptionofeachfigure.\nTab. 5 shows the results. We can find that only the cooling fan has\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1924asignificantimpactonthemaximumattackdistancebecausethe\nnoisefromthefanhasafrequencyoverlapwiththatofthevoice\ncommand. The laptop and monitor only have a slight impact on\nCapSpeaker, i.e., the maximum attack is only decreased by 1 cm.\n5.6 Impact of Inductors\nSimilar to MLC capacitors that vibrate due to voltage changes,\ninductorsalso vibrateduetocurrent changes.Therefore,weneed\nto confirm the sound of the LED driver board is mainly emitted\nby the capacitor instead of the inductor. Fig. 24 (in Appendix A)\nshowstheLEDdriverboardweuseforthisinvestigation.Thereare\n3 MLC capacitors and 1 inductor on the board. We used a heat gun\nto remove the inductor. To make the driver board work, we kept\ntheinductorconnectedusingalongwirebutplaceditataposition\n60 cm away from the LED driver board as shown in Fig. 24. The\nintroducingresistanceofthelongwireisonly0 .023Ωtothecircuit\nandcanbeomitted.TheLEDcircuitispoweredbya48Vpoweradapter, and the load of the LED driver is the LED array used in\nSec.5.3.ThevoicerecordingdeviceisthesameasthatinSec.2.2.\nWe used a 20 kHz to 39 kHz swept square wave (in steps of 1 kHz)\ntodrivetheLEDdriverboard.Werecordedthesoundgeneratedby\nthe LED driver in two cases: 1) the inductor-on-board case shownin Fig. 16; 2) the inductor-far-away case shown in Fig. 24.\nTheresultsareshowninFig.19.Theblueandorangelinesshow\nthe frequency responses for both the (1) inductor on board and\nthe(2)inductorfarawaycases.Case(2)representsthefrequency\nresponseofthecapacitorswhilecase(1)isthecombinedfrequency\nresponse of both the capacitors and the inductor. The results show\nthatafterremovingtheinductor,thefrequencyresponsechanges\nsignificantly in both amplitude and frequency. Without the induc-\ntor, the amplitude of the sound is larger, and the best frequencyshifts to around 34 kHz from around 26 kHz. This indicates that\ntheinductorcanindeedproducesoundswhileitssoundstrengthis\nweakcomparedtothatofthecapacitors.Thereasonwhythesound\nbecomes stronger after removing the inductor is that the PCB reso-\nnancechangesaftertheremovaloftheinductor,i.e.,thePCBhas\na lighterwight and becomes moreelastic. Therefore, weconclude\nthat the MLC capacitors are the main source of sound for the LED\ndriver board,and the existenceof inductors caninterfere with the\nproduced sound by modifying the PCB resonance frequency.\n5.7 Impact of Various Loads\nTo verify whether the attack distance can be increased by using\nlargerloads,i.e.,largercurrentorhighervoltagechanges,wetestedthemaximumattackdistancewith5differentloads.Theexperiment\nTable 5: Other devices working in the vicinity of the LED\ndriverboard.TheSPLsoftheoperatingdevicesandthe\nmaximum attack distance for each case are measured.\nDevice SPL (dB) Maximum Attack Distance (cm)\nCooling Fan 49.9 4.8\nLaptop with Fan On 32.1 9.5\nRouter 31.2 10.5\nMonitor 30.9 9.5isbasedontheexperimentalsetupinSec.5.3,withtheinputcurrentsignaloftheLEDdriverboardchanged.Specifically,withaconstant\nsupplyvoltage,weobtainedvariousinputcurrentsbycontrolling\nthe number of LEDs in series. We used 15, 14, 13, 12, 11 LEDs inseries respectively, and the generated input currents are 0.164 A,\n0.239A,0.307A,0.35A,0.41A,respectively.Wetestedthemaximumattackdistanceforeachcurrent,andtheresultsareshowninFig.21.\nAsthecurrentincreases,themaximumattackdistanceincreases\naccordingly. This gives up the opportunity to get a higher attack\ndistance by using a higher power load.\n5.8Evaluation of Commercial Smart LED Lamp\nInadditiontotheself-implementedLEDprototype,wevalidated\nthe feasibility of CapSpeaker against a commercial LED lamp. The\ncommercialproductisaXiaomi1SLamp[ 9].Toeasetheburdenof\nreverseengineeringthefirmware,wedirectlyreplaceitsMCUboard\nwith one of the same models (ESP-WROOM-32D), and implant the\nmalwareinsidethenewMCUboardinadvance.Theexperimentwasconducted ina 30dB noiseenvironment. Thedetailed specification\nof the off-the-shelf smart LED lamp can be referred to Tab. 2.\nPWMmodulationimplementation. Theonlyconcernforthe\ncommercial LED experiment is the setting of the PWM modulation\nscheme.HereweusedanLEDPWMcontrollermoduleinsidethe\nESP-WROOM-32DMCUtogeneratethePWMsignal.ThePWM\ncontroller module is already implemented in the MCU and it is\nprimarily designed to control the intensity of LEDs [ 6]. To achieve\na high resolution of the PWM signal, we chose APB_CLK as theinternal clock source as it has a higher clock frequency (80MHz)\nthan that of REF_TICK (1MHz).\nResults.AsFig.23shows,thecommercialLEDlampcansuccess-\nfully respond and make the victim’s voice assistant, i.e., iPhone 4s\nSiri recognizes the “open the door” voice command. The maximum\nattack distance can be as far as 3.2 cm, i.e., the distance from the\nlamp’soutercasetothesmartphone.Inaddition,thecommercial\nlamp can attack other voice assistants. For Huawei Nova 5i Pro,the maximum distance is 2.9 cm, and for iPad mini 5 it is 0.5 cm\nrespectively.\n6 DISCUSSION\nInthissection,wediscussthedefensestrategiesagainst CapSpeaker\nattacks and introduce components that can be used to produce\nsounds, e.g., inductors and rheostats.\n6.1 Countermeasures\nAt the hardware level, anaive method to defend CapSpeaker is to\navoid using MLC capacitors, but use electrolytic capacitors or tan-\ntalumcapacitors instead.However, electrolyticcapacitorsare too\nlarge. With the miniaturization trend of electronic devices, devices\ndo not always have enough space to use electrolytic capacitors.\nAlthough tantalum capacitors have small sizes, they are expensive\nandhaverisksoffailure[ 39].Therefore,MLCcapacitorsareirre-\nplaceable. To reduce the sound emitted by MLC capacitors, onefeasible way is to mount the MLC capacitor on an interposer todecrease the amount of vibration that will be transmitted to the\nPCBsubstrate[ 54].TheotherwayistofabricatetheMLCcapacitor\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1925AmplifierSound \nMeterVoice \nAssistant\nMCULED \nSeriesCooling \nFan\nDriver \nBoard\n(a) Fan (49.9 dB)\nMCU AmplifierSound \nMeterVoice \nAssistant\nLED \nSeriesDriver \nBoardLaptop\n(b) Laptop (32.1 dB)\nSound \nMeterVoice \nAssistant\nAmplifierMCULED \nSeriesRouter\nDriver \nBoard\n(c) Router (31.2 dB)\nSound \nMeter\nMCUAmplifierVoice \nAssistant\nMonitor\nLED \nSeriesDriver \nBoard\n(d) Monitor (30.9 dB)\nFigure 22: Impactof other electrical appliances.We put 4 runningdevices, i.e., a coolingfan, a laptop, a routerand a monitor\n20 cm away from the LED driver board to test their interference with the voice commands.\nVoice \nAssistant\nSmart \nLamp\nFigure23:EvaluationonacommercialLEDlamp.TheXiaomi\n1S Lamp is used to inject an “open the door” voice command.\nVoiceassistantsincludingSirioniPhone4scanbesuccess-\nfullyattackedwithamaximumdistanceof3.2cm.(Setup#2:\nCommercial LED lamp.)\nbyaddingtwometal“legs”madeofferricalloywithNi/Sntoisolate\nthe capacitor vibration from the board [54].\nAt the software level, detection mechanisms can identify the\npossibility of malicious content in benign PWM control programs.\nForexample,inbrightnesscontrolofLEDsandtemperaturecontrol\nofheaters,thedutycycleofthePWMwavedoesnotchangedrasti-callyinnormalscenarios,while\nCapSpeaker continuouslychanges\nthedutycycletobeupanddownrapidly.Thus, CapSpeaker can\nbe detected by monitoring the frequency and amplitude of duty\ncycle changes.\n6.2 Alternative Potential ‘Speakers’\nInadditiontocapacitors,inductorsandrheostatsarewidelyused\nin commercial electronic devices and can produce sounds, too.\nInductors. Aninductortypicallyconsistsofaninsulatedwire\nwoundontoacoil[ 58],anditisapassivetwo-terminalelectrical\ncomponent that stores energy in a magnetic field when electric\ncurrentflowsthroughit[ 58].Thestructureofaninductorissimilar\nto a speaker, and thus the coil can vibrate according to the input\ncurrents.Toinvestigatethefeasibilityofusinganinductortoattack\nthevoiceassistant,weproducedtheattackvoicecommandusing\na single inductor and a DC-DC converter with the same type ofinductor, following the experimental setup shown in Fig. 25 (in\nAppendix A). The frequency of the PWM wave is set to 50\n𝑘𝐻𝑧.\nBoth settings can successfully cause the iPhone 4s to recognize theattackcommand“Turnonairplanemode”.However,inreality,most\nof the current electronic devices use inductors of metallic integral\nmolding types, whose produced acoustic signal is mitigated to 1/10\nof the original sounds [56].\nRheostats. Similar to inductors, a rheostat is made of a coil and\ncan generate sounds with varying currents, due to the repellingforce from the magnetic field. To validate, we carried out an in-dividual experiment on the rheostat, with no MLC capacitors orinductors in the circuit. We sweep the frequency to obtain thefrequency response of sound produced by the rheostat, and the\nfrequencyresponseisapproximately5dB,lowerthanthatofcapac-\nitors.NotethatinourexperimentsofMLCcapacitors,weplaced\nthe rheostat outside of the room to avoid the interference from\nrheostats.\n6.3 Limitations\nAdmitted that the attack distance of CapSpeaker is 10.5 cm and\nrequiresthetargeteddevicestobenearby,theattackdistancecanbeincreasewithahighervoltagesignal,possiblyinelectronicdevices\nwith a larger power, e.g., LED lamps with a higher power, rice\ncookers. Nevertheless, the goal of the work is to raise awareness of\nsuch an attack, since people tend to put their smartphones on the\ndesk and in the vicinity of other devices such as a lamp.\n7 RELATED WORK\n7.1 Implicit Voice Commands\nUsingimplicitvoicecommandstoattack speechrecognitionsys-\ntemsiswellknownandstudied.Zhangetal.[ 63]achieveinaudible\nvoice commands by modulating low-frequency voice commands\non ultrasonic carriers. The modulated low-frequency voice com-\nmands can be demodulated by the nonlinearity of microphones.Such an attack can attack most of the off-the-shelf smartphones,\nsmart speakers, and laptops. Roy et al. [ 50] extend the attack range\nanddevelopadefenseagainstthisclassofvoiceattacksthatexploit\nnonlinearity.\nIn addition to inaudible voice commands, commands that are in-\ndistinguishable can also be implicit, although they are audible. The\nattacker can generate implicit voice commands by removing the\naudiofeaturesthatare notusedi nthespeec hrecognitionsystem\nbut a human listener might use them for comprehension [ 19]. In\ndetail,theyfirstcalculatetheMel-frequencycepstralcoefficients\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1926(MFCC) of theoriginal speech.Then, they use theMFCCs to recon-\nstructtheoriginalspeech.There constructedspeech losesthephase\ninformationofthespeech,andthuscannotbecomprehended.Yuan\netal.[62]findthatthevoicecommandscanbestealthilyembedded\nintosongs.Whenthesongisplayed,thevoicecommandcanberec-\nognized by the speech re cognition system while not being noticed\nbyhumans.Schönherretal.[ 51]introduceanewtypeofadversarial\nexamples based on psychoacoustic hiding. Du et al. [ 24] propose a\nmethod to generate adversarial audios which can attack both black\nbox and white box. Abdullah et al. [ 15] make hidden command\nattacks more practical through black-box attacks. Specifically, they\nperturbtheoriginalaudiobytimedomaininversion,randomphase\ngeneration, high frequency addition, and time scaling.\n7.2 Privacy Leakage by Devices\nThe privacy leakage through devices can be divided into side-\nchannel attacks and covert channel ones.\nSide-channel attacks exploit unintended information leakage\nofcomputingdevicesorimplementationstoinfersensitiveinfor-\nmation. When a device is computing, it consumes power whichdissipates in various forms of physical signals including sound,\nlight, electromagnetism, force, and heat. Those signals contain in-\nformation related to the computation process and thus can be used\nto extract sensitive data. Existing physical side-channel attackscan be categorized as acoustic ones [\n26], electromagnetic ones\n[16,17,22,64,67], motion ones [ 60], optical ones [ 20] and thermal\nones[42].In addition,thereareside-channel attacksinthedigital\ndomain,includingcache-basedside-channelattacks[ 47],timing-\nbased side-channels [ 53] and encrypted-traffic-based side-channels\n[21,66]. Multiple attacks can be realized through a side-channel.\nFor example, Genkin et al. [ 28] use the ground electric potential of\ncomputers to infer RSA keys. They also achieve screen contents in-\nference via the acoustic noise generated by the screen circuits [ 26].\nCovert channel is defined as the channel that is not intended\nforinformation transferatall butleakssensitive data[ 45].As the\ncommunity becomes more and more aware of network security,\nair-gap networks are widely used in security-aware organizations\nsuchaspowergridsandmilitary bases.However ,covertchannel\ncan break the air gap because devices inevitably generate physical\nsignals during operations. If an attacker can control the operation\nof the devices, she can leak sensitive information from the air-\ngappednetworks.Covertchannelscanbeclassifiedaccordingtothe\ntype of physical signals they use, such as voltage signals on power\nlines [35,41,52], electromagnetic signals emanated from memory\nreadingandwriting[ 30],USBcable[ 31],magneticsignalsproduced\nby CPU [37,65], acoustic signals generated by hard-drive [ 33] and\nultrasonic communications [ 34]. In addition, optical signals [ 36]\nand thermal signals [32] can be used to leak sensitive data.\n7.3 Utilization of Non-Speaker Devices and\nNon-Microphone Devices\nThere have been some works that focus on utilizing the sound\ngenerated by non-speaker devices. Guri et al. [ 29] use the sound\ngeneratedbypowersuppliestocreateacovertchannel.Specifically,\ntheysupposethatmalwarecanbeimplantedinacomputerinad-\nvance.Then,themalwarecontrolstheCPUcorestobebusyandidle, causing the current drained from the power supply to change\nperiodically.Then,thepowersupplycangenerateasoundofthe\ncorrespondingfrequency.Thus,themalwareembedsinformation\nintosound,andthesoundcanbereceivedbyageneralmicrophone.Genkinetal.[\n27]showthatacousticnoiseofthescreencircuitscan\nbeusedtoinferscreencontent.Theprincipleisthatthemomentary\npower draw induced by the monitor’s digital circuits varies as a\nfunctionofthescreencontentbeingprocessedinrasterorder.Thisprocessaffectstheelectricalloadonthepowersupplycomponents.\nAsthepowersupplycomponentshavecapacitorsandinductors,the\nripple current and voltage will cause vibrations and thus generates\nsounds.Yangetal.[ 61]usesoundfrompowersupplytofingerprint\nappliance. As switching-mode power supply (SMPS) is widely usedinoff-the-shelfelectronicdevices,thedifferencesofSMPSworking\nmodes, frequencies, topologies can be used to fingerprint an appli-\nance. Comparedwith traditional devicefingerprint methodssuch\nas electromagnetic-based methods, their method is low-cost and\neasy to deploy.\nInaddition,non-microphonedevicescanbeusedtosensesound.\nTrippel et al. [ 57] found that although a MEMS accelerometer is\nnot a microphone, it can still be interfered with by sound waves\nand even controlled by sound waves. Likewise, the shock sensor in\ntheharddrivecanalsobeinterferedwithbysoundwaves[ 18],and\ntheThisinterferencecouldcausemajordatacenterstogodown.Inaddition,theheadoftheharddrivecanbeusedasamicrophoneto\nrecord sound by recording the Position Error Signal (PES) of the\nhead [44].\n8 CONCLUSION\nIn this paper, we demonstrated that acoustic noises produced by\nMLC capacitors may appear to be benign, yet they can be manipu-\nlated to inject malicious voice commands to nearby voice assistant,\nwhich we call CapSpeaker attacks. After studying the factors that\ninfluence the strength of the sounds produced by the MLC capaci-\ntors,wefoundthatMLCcapacitorscanproducesoundsinthein-\naudible range much better than audible ranges. Thus, CapSpeaker\nmodulatesthemaliciousvoicecommandstoaninaudiblefrequency\ncarriertotakeadvantageofthehighfrequencyresponse,andex-\nploitsthenonlinearitypropertyofthemicrophonetoautomaticallydemodulatethePWM-modulatedsignalsembeddedwithmalicious\nvoicecommands.Weimplementthe\nCapSpeaker attackonasmart\nLED lamp, and evaluate the performance of CapSpeaker attacks\nwith various voice commands, receiving devices, ambient noise\nlevels, and distances between the capacitor to the receiver. Theresults show that malicious voice commands can be successfully\nrecognizedbyaniPhone4satadistanceof10.5cm.Theworkaims\nto raise awareness ofsuch vulnerabilities in light of thegrowing\ntrends of voice assistants.\n9 ACKNOWLEDGMENTS\nWethankallanonymousreviewersfortheirinsightfulcomments\non this paper. We thank You Wu for conducting experiments on\nMLC capacitors with various impact factors. We thank Shuai Chen\nfor conducting simulations and experiments on verification of the\nPWM-modulation.ThisworkissupportedbyChinaNSFCGrant\n62071428, 61925109, and 61941120.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1927REFERENCES\n[1]2020. FromTextToSpeech-FreeOnlineTTS Service. http://www.fromtexttosp\neech.com/.\n[2]2021. 192/24 PCI-E 8-Channel sound card. Retrieved 20-August-2021 from\nhttp://www.syba.cc/e/wap/show.php?classid=24&id=418&style=0&cpage=4&c\nid=3&bclassid=1\n[3]2021. COMSOL-SoftwareforMultiphysicsSimulation. Retrieved20-August-\n2021 from https://www.comsol.com/\n[4]2021. Decibel Table - SPL - Loudness Comparison Chart. Retrieved 20-August-\n2021 from http://www.sengpielaudio.com/TableOfSoundPressureLevels.htm\n[5]2021. DG800seriesRIGOLwaveformgenerators. https://www.rigolna.com/pr\noducts/waveform-generators/dg800/dg811/.\n[6]2021. ESP32 Technical Reference Manual. Retrieved 20-August-2021 from\nhttps://www.espressif.com/sites/default/files/documentation/esp32_technical_\nreference_manual_en.pdf#ledpwm\n[7]2021. HuaweiNova5SeriesSalesCross2MillionUnitsinaMonth. Retrieved\n20-August-2021from https://gadgets.ndtv.com/mobiles/news/huawei-nova-5-\npro-5i-pro-2-million-sales-china-2077454\n[8]2021. iFLYTEK - Empower The World With A.I. Retrieved 20-August-2021 from\nhttps://www.iflytek.com/en/\n[9]2021. mi-led-desk-lamp-1s. Retrieved20-August-2021from https://www.mi.c\nom/global/mi-led-desk-lamp-1s/overview/\n[10]2021. [NEWS] HUAWEI UNVEILS ITS OWN VOICE ASSISTANT. Retrieved 20-\nAugust-2021from https://consumer.huawei.com/ae-en/community/details/NEW\nS-HUAWEI-UNVEILS-ITS-OWN-VOICE-ASSISTANT-CELIA/topicId_82910/\n[11] 2021. Siri. https://www.apple.com/siri/.\n[12]2021. Surface mount component packages. Retrieved 20-August-2021 from\nhttps://www.surfacemountprocess.com/smd-component-packages.html\n[13]2021. UltraSoundGate. Retrieved07-May-2021from http://www.avisoft.com/ul\ntrasoundgate/\n[14]2021. Xiaomi XiaoAI Art Speaker. https://xiaomi-mi.com/portable-speakers/xia\nomi-xiaoai-art-speaker/.\n[15]Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, KevinR. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks against\nSpeech and Sp eaker Recognition Systems. In Proceedings of 26th Annual Network\nand Distributed System Security Symposium, NDSS 2019. The Internet Society.\n[16]Lejla Batina, Shivam Bhasin, Dirmanto Jap, and Stjepan Picek. 2019. CSINN:\nReverse Engineering of Neural Network Architectures Through Electromagnetic\nSide Channel. In Proceedings of the 28th USENIX Security Symposium (USENIX\nSecurity 19). 515–532.\n[17]AlexandruBoitan,SimonaHalunga,ValericăBîndar,andOctavianFratu.2020.\nCompromisingElectromagneticEmanationsofUSBMassStorageDevices. Wire-\nless Personal Communications (April 2020).\n[18]Connor Bolton, Sara Rampazzi, Chaohao Li, Andrew Kwong, WenyuanXu, and\nKevin Fu. 2018. Blue note: How intentional acoustic interference damages avail-\nability and integrity in hard disk drives and operating systems. In Proceedings of\n2018 IEEE Symposium on Security and Privacy (SP). IEEE, 1048–1062.\n[19]NicholasCarlini, PratyushMishra,Tavish Vaidya,YuankaiZhang, MicahSherr,\nClay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden voice commands.\nInProceedingsof25thUSENIXSecuritySymposium(USENIXSecurity16).513–530.\n[20]S.Chakraborty,W.Ouyang,andM.Srivastava.2017. LightSpy:OpticalEaves-\ndroppingonDisplaysUsingLightSensorsonMobileDevices.In Proceedingsof\nthe 2017 IEEE International Conference on Big Data (Big Data). 2980–2989.\n[21]Yushi Cheng, Xiaoyu Ji, Tianyang Lu, and Wenyuan Xu. 2018. DeWiCam: De-\ntecting Hidden Wireless Cameras via Smartphones. In Proceedings of the 2018 on\nAsia Conference on Computer and Communications Security (ASIACCS ’18). ACM,\n1–13.\n[22]YushiCheng,XiaoyuJi,WenyuanXu,HaoPan,ZhuangdiZhu,Chuang-WenYou,\nYi-Chao Chen, and Lili Qiu. 2019. MagAttack: Guessing Application Launching\nand Operation viaSmartphone. In Proceedings of the2019 ACM Asia Conference\non Computer and Communications Security - Asia CCS ’19. ACM, 283–294.\n[23]S.KnudtsenG.ShirnD.Burks,R.Hofmaier.1989. AceramiccapacitorforAC\napplications. (1989), 194–201.\n[24]Tianyu Du, Shouling Ji, Jinfeng Li, Qinchen Gu, Ting Wang, and Raheem Beyah.\n2020. Sirenattack: Generating adversarial audio for end-to-end acoustic systems.\nInProceedingsofthe15thACMAsiaConferenceonComputerandCommunications\nSecurity. 357–369.\n[25]Facebook, Twitter, and LinkedIn. 2021. Did You Know This Many iPads Had\nBeen Sold? https://www.lifewire.com/how-many-ipads-sold-1994296 Section:\nLifewire.\n[26]DanielGenkin,MihirPattani,RoeiSchuster,andEranTromer.2019. Synesthesia:\nDetecting Screen Content via Remote Acoustic Side Channels. In Proceedings of\nthe 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 853–869.\n[27]DanielGenkin,MihirPattani,RoeiSchuster,andEranTromer.2019. Synesthesia:\nDetecting screen content via remote acoustic side channels. In Proceedings of\n2019 IEEE Symposium on Security and Privacy (SP). IEEE, 853–869.\n[28]Daniel Genkin, Itamar Pipman, and Eran Tromer. 2015. Get Your Hands offMy Laptop: Physical Side-Channel Key-Extraction Attacks on PCs. Journal ofCryptographic Engineering 5, 2 (2015), 95–112.\n[29]MordechaiGuri.2020. POWER-SUPPLaY:LeakingDatafromAir-GappedSys-\ntemsbyTurningthePower-SuppliesIntoSpeakers. arXiv:2005.00395[cs] (May\n2020). arXiv:2005.00395\n[30]MordechaiGuri, AssafKachlon, OferHasson,Gabi Kedma,YisroelMirsky,and\nYuval Elovici. 2015. GSMem: Data Exfiltration from Air-Gapped Computers over\nGSMFrequencies.In Proceedingsof24thUSENIXSecuritySymposium(USENIX\nSecurity 15).\n[31]Mordechai Guri, Matan Monitz, and Yuval Elovici. 2016. USBee: Air-Gap Covert-\nChannel via Electromagnetic Emission from USB. In Proceedings of the 14th\nAnnual Conference on Privacy, Security and Trust (PST). 264–268.\n[32]Mordechai Guri, Matan Monitz, Yisroel Mirski, and Yuval Elovici. 2015. BitWhis-\nper: Covert Signaling Channel between Air-Gapped Computers Using Thermal\nManipulations. In Proceedings of the 28th IEEE Computer Security Foundations\nSymposium. 276–289.\n[33]Mordechai Guri, Yosef Solewicz, Andrey Daidakulov, and Yuval Elovici. 2017.\nAcousticDataExfiltrationfromSpeakerlessAir-GappedComputersviaCovert\nHard-Drive Noise (‘DiskFiltration’). In Proceedings of European Symposium on\nResearch in Computer Security. Springer, 98–115.\n[34]MordechaiGuri,YosefSolewicz,andYuvalElovici.2018. MOSQUITO:Covert\nUltrasonicTransmissionsBetweenTwoAir-GappedComputersUsingSpeaker-\nto-SpeakerCommunication.In Proceedingsof2018IEEEConferenceonDependable\nand Secure Computing (DSC). 1–8.\n[35]Mordechai Guri, Boris Zadov, Dima Bykhovsky, and Yuval Elovici. 2019. Power-\nHammer:ExfiltratingDatafromAir-GappedComputersthroughPowerLines.\nIEEE Transactions on Information Forensics and Security (2019), 1–1.\n[36]MordechaiGuri,BorisZadov,andYuvalElovici.2017. LED-It-GO:Leaking(A\nLot of) Data from Air-Gapped Computers via the (Small) Hard Drive LED. In\nProceedings of Detection of Intrusions and Malware, and Vulnerability Assessment.\nSpringer, 161–184.\n[37]MordechaiGuri,BorisZadov,andYuvalElovici.2020. ODINI:EscapingSensitive\nData From Faraday-Caged, Air-Gapped Computers via Magnetic Fields. IEEE\nTransactions on Information Forensics and Security 15 (2020), 1190–1203.\n[38]J.Ho,T.R.Jow,andS.Boggs.2010. HistoricalIntroductiontoCapacitorTechnol-\nogy. 26, 1 (Jan. 2010), 20–25.\n[39]JiaoyingHuang,YongkangWan,ChengGao,andYuanyuanXiong.2015. Discus-\nsion on multilayer ceramic replacements for tantalum capacitors. In Proceedings\nof 2015 Prognostics and System Health Management Conference (PHM) . IEEE, 1–5.\n[40]Larry E Humes. 1996. Speech understanding in the elderly. Journal-American\nAcademy of Audiology 7 (1996), 161–167.\n[41]Mohammad A. Islam and Shaolei Ren. 2018. Ohm’s Law in Data Centers: A\nVoltage Side Channel for Timing Power Attacks. In Proceedings of the 2018 ACM\nSIGSAC Conference on Computer and Communications Security. ACM, 146–162.\n[42]Mohammad A. Islam, Shaolei Ren, and Adam Wierman. 2017. Exploiting a Ther-\nmalSideChannelforPowerAttacksinMulti-TenantDataCenters.In Proceedings\nofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity.\nACM, 1079–1094.\n[43]Dongjoon Kim, Byung-Han Ko, Sanggeuk Jeong, No-Cheol Park, and Young-Pil Park. 2015. Vibration reduction of MLCC considering piezoelectric and\nelectrostriction effect. In Proceedings of 2015 Joint IEEE International Symposium\non theApplications of Ferroelectric(ISAF), International Symposium onIntegrated\nFunctionalities (ISIF), and Piezoelectric Force Microscopy Workshop (PFM). IEEE,\n186–189.\n[44]Andrew Kwong, Wenyuan Xu, and Kevin Fu. 2019. Hard Drive of Hearing:\nDisksthatEavesdropwithaSynthesizedMicrophone.In Proceedingsof2019IEEE\nSymposium on Security and Privacy (SP). IEEE, 905–919.\n[45]ButlerWLampson.1973. Anoteontheconfinementproblem. Commun.ACM\n16, 10 (1973), 613–615.\n[46]Stratistics Market Research Consulting Pvt Ltd. 2020. Multi-Layer Ceramic\nCapacitor - Global Market Outlook (2019-2027). (2020).\n[47]Yangdi Lyu and Prabhat Mishra. 2018. A Survey of Side-Channel Attacks onCaches and Countermeasures. Journal of Hardware and Systems Security 2, 1\n(March 2018), 33–50.\n[48]MathWorks.2021. PulseWidthModulation-MATLAB&Simulink-MathWorks.\nhttps://www.mathworks.com/help/physmod/sps/pulse-width-modulation.html\n[49]Nirupam Roy, Haitham Hassanieh, and Romit Roy Choudhury. 2017. Backdoor:\nMakingmicrophoneshearinaudiblesounds.In Proceedingsofthe15thAnnual\nInternational Conference on Mobile Systems, Applications, and Services. 2–14.\n[50]NirupamRoy,ShengShen,HaithamHassanieh,andRomitRoyChoudhury.2018.\nInaudible voice commands: The long-range attack and defense. In Proceedings of\n15thUSENIXSymposiumonNetworkedSystemsDesignandImplementation(NSDI\n18). 547–560.\n[51]Lea Schonherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea\nKolossa.2019. AdversarialAttacksAgainst AutomaticSpeec hRecognitionSys-\ntems via Psychoacoustic Hiding. In Proceedings 2019 Network and Distributed\nSystem Security Symposium. Internet Society, San Diego, CA.\n[52]Zhihui Shao, Mohammad A. Islam, and Shaolei Ren. 2020. Your Noise, My\nSignal: Exploiting Switching Noise forStealthy Data Exfiltration from Desktop\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1928Computers.In ProceedingsoftheACMonMeasurementandAnalysisofComputing\nSystems. ACM, 1–39.\n[53]LaurentSimon,WenduanXu,andRossAnderson.2016.Don’tInterruptMeWhile\nIType:InferringTextEnteredThroughGestureTypingonAndroidKeyboards.\nInProceedings on Privacy Enhancing Technologies. 136–154.\n[54]YinSun,JianminZhang,ZhipingYang,ChulsoonHwang,andSongpingWu.2019.\nMeasurementInvestigationonAcousticNoiseCausedby“Singing”Capacitors\nonMobileDevices.In inProceedingsofthe2019IEEEInternationalSymposium\non Electromagnetic Compatibility, Signal & Power Integrity (EMC+ SIPI). IEEE,\n505–510.\n[55]James A. Svoboda and Richard C. Dorf. 2013. Introduction to Electric Circuits.\nJohn Wiley & Sons.\n[56]TDK. 2021. Measures Against Acoustic Noise in Power Inductors. https:\n//product.tdk.com/en/techlibrary/solutionguide/acoustic-noise.html\n[57]Timothy Trippel, Ofir Weisse, Wenyuan Xu, Peter Honeyman, and Kevin Fu.\n2017. WALNUT:WagingdoubtontheintegrityofMEMSaccelerometerswith\nacoustic injection attacks. In Proceedings of 2017 IEEE European symposium on\nsecurity and privacy (EuroS&P). IEEE, 3–18.\n[58]Wikipedia contributors. 2021. Inductor. https://en.wikipedia.org/wiki/Inductor.\n[59]Wikipedia contributors. 2021. Young’s modulus — Wikipedia, The Free Encyclo-\npedia. https://en.wikipedia.org/w/index.php?title=Young%27s_modulus&oldid\n=1039311706\n[60]Zhi Xu, Kun Bai, and Sencun Zhu. 2012. TapLogger: Inferring User Inputs on\nSmartphone Touchscreens Using on-Board Motion Sensors. In Proceedings of the\nFifthACMConferenceonSecurityandPrivacyinWirelessandMobileNetworks.\nACM, 113–124.\n[61]Lanqing Yang, Honglu Li, Zhaoxi Chen, Xiaoyu Ji, Yi-Chao Chen, Guangtao Xue,\nand Chuang-Wen You. 2020. Appliance fingerprinting using sound from power\nsupply. (2020), 160–163.\n[62]XuejingYuan,YuxuanChen,YueZhao,YunhuiLong,XiaokangLiu,KaiChen,\nShengzhiZhang,HeqingHuang,XiaoFengWang,andCarlAGunter.2018. Com-\nmandersong: A systematic approach for practical adversarial voice recognition.\nIn27th USENIX Security Symposium (USENIX Security 18). 49–64.\n[63]Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and\nWenyuan Xu. 2017. Dolphinattack: Inaudible voice commands. In Proceedings\nofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity .\n103–117.\n[64]Juchuan Zhang, Xiaoyu Ji, Yuehan Chi, Yi-chao Chen, Bin Wang, and Wenyuan\nXu.2021. OutletSpy:Cross-OutletApplicationInferenceviaPowerFactorCor-\nrection Signal. In Proceedings of the 14th ACM Conference on Security and Privacy\nin Wireless and Mobile Networks (WiSec ’21). 181–191.\n[65]Juchuan Zhang, Xiaoyu Ji, Wenyuan Xu, Yi-Chao Chen, Yuting Tang, and Gang\nQu.2020. MagView:ADistributedMagneticCovertChannelviaVideoEncod-\ningandDecoding.In ProceedingsofIEEEInternationalConferenceonComputer\nCommunications. IEEE.\n[66]Xuan Zhao, Md Zakirul Alam Bhuiyan, Lianyong Qi, Hongli Nie, Wajid Rafique,\nandWanchunDou.2018. TrCMP:AnAppUsageInferenceMethodforMobile\nService Enhancement. In Proceedings of Security, Privacy, and Anonymity in\nComputation, Communication, and Storage. Springer, 229–239.[67]Zhou Zhuang, Xiaoyu Ji, Taimin Zhang, Juchuan Zhang, Wenyuan Xu, Zhenhua\nLi,andYunhaoLiu.2018. FBSleuth:FakeBaseStationForensicsviaRadioFre-\nquencyFingerprinting.In Proceedingsofthe2018onAsiaConferenceonComputer\nand Communications Security (ASIACCS ’18). ACM, 261–272.\nA EXPERIMENT SETUP OF INDUCTORS\n5V DC48V DCRecorder\nAmplifierLED \nSeries\nSeparated\nInductorCapacitors\nDriver \nBoard\nFigure 24: Experimental setup of inductorfactor validation.\nTheinductoristakendownfromtheboardandputfaraway\nyet connected to the driver board with long wires.\n(a) Inductor.\nVoice assistantDC-DC Module\nInductor\n(b) Inductor on a DC-DC module.\nFigure 25: Generating the malicious voice command using\nan inductor in a DC/DC module.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1929"}
{"title": "Charting the Atack Surface of Trigger-Action IoT Platforms Qi", "content": "Charting the Atack Surface of Trigger-Action IoT Platforms\nQi\nWang,†∗Pubali Datta,†∗Wei Yang,‡Si Liu,†Adam Bates,†Carl A. Gunter†\n†University of Illinois at Urbana-Champaign,‡The University of Texas at Dallas\n{qiwang11,pdatta2,siliu3,batesa,cgunter}@illinois.edu,wei.yang@utdallas.edu\nABSTRACT\nInternet of Things (IoT) deployments are becoming increasingly\nautomatedandvastlymorecomplex.Facilitatedbyprogramming\nabstractions such as trigger-action rules, end-users can now easily\ncreate new functionalities by interconnecting their devices and\nother online services. However, when multiple rules are simulta-\nneously enabled, complex systembehaviors arise that are diicult\nto understand or diagnose. While history tells us that such con-\nditions are ripe for exploitation, at present the security states of\ntrigger-action IoT deployments are largely unknown.\nInthiswork,weconductacomprehensiveanalysisoftheinterac-\ntionsbetweentrigger-actionrulesinordertoidentifytheirsecurity\nrisks.UsingIFTTTasanexemplarplatform,weirstenumeratethe\nspace ofinter-rule vulnerabilities that exist within trigger-action\nplatforms.Toaidusersintheidentiicationofthesedangers,wego\non to present iRuler, a system that performs Satisiability Modulo\nTheories (SMT) solving and model checking to discover inter-rule\nvulnerabilitieswithinIoTdeployments. iRuleroperatesoveranab-\nstracted information low model that represents the attack surface\nofanIoTdeployment,butwediscoverinpracticethatsuchmodels\narediiculttoobtaingiventheclosednatureofIoTplatforms.To\naddress this, we develop methods that assist in inferring trigger-\naction information lows based on Natural Language Processing.\nWedevelopanovelevaluativemethodologyforapproximatingplau-\nsiblereal-worldIoTdeploymentsbasedontheinstallationcounts\nof 315,393 IFTTT applets, determining that 66% of the synthetic\ndeploymentsintheIFTTTecosystemexhibitthepotentialforinter-\nrule vulnerabilities. Combined, these eforts provide the insight\ninto the real-world dangers of IoT deployment misconigurations.\nCCS CONCEPTS\n·Securityand privacy →Formal methods and theory of security ;\nVulnerabilityscanners ;Softwaresecurityengineering; ·Comput-\ning methodologies →Natural language processing ;·Computer\nsystems organization →Embedded and cyber-physical systems .\nKEYWORDS\nTrigger-ActionIoTPlatform;Inter-ruleVulnerability;FormalMeth-\nods; NLP; Information Flow\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforproitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the irst page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,\ntopostonserversortoredistributetolists,requirespriorspeciicpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’19, November 11ś15, 2019, London, United Kingdom\n©2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-6747-9/19/11...$15.00\nhttps://doi.org/10.1145/3319535.3345662ACM Reference Format:\nQiWang,†∗PubaliDatta,†∗WeiYang,‡SiLiu,†AdamBates,†CarlA.Gunter†.\n2019. Charting the Attack Surface of Trigger-Action IoT Platforms. In 2019\nACM SIGSAC Conference on Computer& Communications Security (CCS ’19),\nNovember 11ś15, 2019, London, United Kingdom. ACM, New York, NY, USA,\n15 pages. https://doi.org/10.1145/3319535.3345662\n1 INTRODUCTION\nTheInternetofThings(IoT)isgrowingrapidly.Withpredictionsof\n20billiondeployedIoTdevicesby2020[ 1],theIoThasevolvedfrom\nisolatedsingledevicestointegratedplatformsthatfacilitateinterop-\nerabilitybetweendiferentdevices andonlineservices(e.g.,Gmail).\nSamsung’sSmartThings[ 11],Apple’sHomeKit[ 4],IFTTT[ 5]and\nZapier[17]arejustafewexamples.IoTplatformssupportend-user\ncustomizations,withmanygoingsofarastoprovideprogramming\nframeworksforthedesignofsimpleautomationlogicthatenable\ncustomizedfunctionality.Currently,trigger-actionprogramming\n(TAP)isthemostcommonly-usedmodeltocreateautomationsin\nIoT. Studies have shown that about 80% of the automation require-\nments of typical users can be represented by TAP and that even\nnon-programmers can easily learn this paradigm [85].\nUnfortunately, as IoT deployments grow in complexity, so do\ntheir attack surface ś as users further automate their homes, un-\nexpected interactions between the automation rules may give rise\ntoalarmingnewclassesofsecurityissues[ 81].Considerthepos-\nsibilitythatauserhasinstalledtherule Iftemperatureexceeds30\n◦C, then open my windows ; while this may be innocuous in isola-\ntion, it could be leveraged by an attacker to gain physical entry to\nthehouseiftheuserhasalsoinstalledtherule (Ifyousay)łAlexa,\ntrigger heaterž, then turn the heater on. While IoT presents a vari-\nety of novel security challenges, the threats created by the ease of\ntrigger-action automation are worthy of careful consideration.\nReasoning about the security of trigger-action IoT platforms\nrequires a precise understanding of the interplay between trigger-\nactionrules.Thecircumstancesunderwhichtheinteractionsbe-\ntween two rules should be designated as a bug or vulnerability, as\nopposed to a feature, are not presently clear. Even among small\nrulesets, such as the real-world example shown in Figure 1, it is\nnotimmediatelyobviouswhetherthiscompositionof5rulescould\nleadtoabreachintheuser’shomesecuritysystem;infact,because\nthethreerules( r2,r4,r5)allmodifythesecuritymodeoftheuser’s\nSomfy Home Security System, there is a legitimate risk that the sys-\ntem could reach an unsafe state. What further frustrates analysis is\nthefact thattrigger-actionIoT ecosystemsareclosed-sourced and\ndeveloped by a variety of third parties, rendering existing program\nanalysis techniques unusable.\nIn this work, we describe three distinct and inter-related ef-\nforts to enable precise reasoning about IoT security postures. To\n* Joint irst authors.\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1439Button \nW\nidgetLocation \nService\nManything \nCameraSomfy \nSecurity \nSystemr2 r3 r4 r1 r5New \nCommandExit \nRegionEnter \nRegion\nStart \nRecordingChange \nSecurity Mode\nFigure 1: Interaction of rules between popular home security\nser\nvices from real-world examples [6]. Rules are represented as\nhexagon vertices, triggers using oval vertices, actions using rectan-\ngle vertices, and services using cloud vertices.\nbetterunderstandtrigger-actionrulebugs,weirstexhaustivelyex-\nplorethespaceof inter-rulevulnerabilities withintrigger-actionIoT\nplatforms.Thistaxonomyofinter-rulevulnerabilitiesattemptsto\nsystematize problems identiied by other recent work in this space\n[30,32,52,70] and uncovers new subclasses of this vulnerability.\nSecond,weleverageformalmethodstoenablethedetectionofthese\nbugs; we present the design and implementation of iRuler, an IoT\nanalysisframeworkthatleveragesSatisiabilityModuloTheories\n(SMT)solvingandmodelcheckingtodiscoverinter-rulevulnera-\nbilities. However, iRulerrequires an information low graph of the\nIoTdeploymenttooperate,whichatpresentisunavailabledueto\nthe opacity of commodity IoT platforms. To overcome this obstacle\nin the absence of viable program analysis techniques, the third\nandinalelementofourdesignisanapproachtoinferinter-rule\ninformation lows by using Natural Language Processing (NLP)\ntoinspectthetextdescriptionsoftriggersandactionsontheIoT\nplatform website.\nWeevaluate iRuleragainstareal-worlddatasetof315,393ap-\npletsfoundontheIFTTTwebsite.Testingagainstamanually-coded\nground truth ofinter-rule lows,we indthat ourNLP tool isable\nto eliminate 72% of false dependencies in the IFTTT ecosystem\nwith minimal Type I error, the sources of which we characterize\nindiscussion. iRulerdetectsvulnerabilitiesinspeciic conigura-\ntionsof IoT deployments, but at present robust data on realistic\nconigurationsisnotpubliclyavailable.Toaddressthis,wedevelop\na method for synthesizing plausible rulesets based on publicly-\nvisible installcounts ofIFTTTapplets. Bytesting iRuleron these\nsynthetic conigurations, we discover the widespread potential for\ninter-rule vulnerabilities in the IFTTT platform, with 66% of the\nrulesets being associated with at least one such vulnerability.\n2 BACKGROUND\n2.1 Trigger-action IoT Platforms\nHome automation IoT platforms commonly use the trigger-action\nprogramming paradigm, which provides an intuitive abstraction\nfor non-technical users wishing to automate their devices. Broadly,Table 1: A comparison of several popular trigger-action platforms,\nwhich vary in their support for conditions, rules with multiple ac-\ntions, parameter passing from triggers to actions, and a rule store.\nPlatformSupport Multiple Trigger Values Rule\nConditions Actions used in Actions Store\nSmartThings [11] ✓ ✓ ✓ ✓\nIFTTT [5] ✓ ✓ ✓ ✓\nopenHAB [10] ✓ ✓ ✓ ✓\nMicrosoft Flow [8] ✓ ✓ ✓ ✓\nZapier [17] ✗ ✓ ✓ ✓\nHomeKit [4] ✗ ✗ ✗ ✗\nIris [7] ✗ ✗ ✗ ✓\nWink [15] ✗ ✗ ✗ ✗\na trigger-action (TA) program speciies that when a certain trig-\nger event occurs (e.g., motion is detected), one or more actions\n(e.g., turn on the light) should be subsequently executed. Emerging\ntrigger-action models are also becoming more expressive through\ntheintroductionof advancedfeatures.InTable 1,wecomparethe\ntrigger-action models in 5 popular smart home platforms and 3\npopular task automation platforms. While we note the diferences\nbetween these platforms, our study considers a generalized trigger-\naction model in which each rule can have one trigger, one or more\nactions, and a condition associated with each action.\nTrigger-action Rule Chaining. The power of the trigger-action\nprogramming paradigm is that rules can be chained together [ 81];\ntheexecutionofanactioncaninvokeanothertriggerevent,causing\nanother ruleto execute.There aretwo waysrules canbe chained,\nexamples of which are given in Figure 2 in the form of trigger-\naction graphs : rulesAandBareExplicitly Chained if (1)A’s action\nandB’s trigger belong to the same service and (2) executing A’s\nactiondirectlysatisies B’striggerevent;rules AandBareImplicitly\nChainedif (1)A’s action and B’s trigger connect to a global shared\nmediumorstateand(2)executingA’sactionmanipulatestheshared\nmedium such that B’s trigger is satisied.\nThe IFTTT Platform. If-this-then-that (IFTTT) [ 5] is a web-based\ntask-automation platform which allows users to connect diferent\nservicesto create automations using the trigger-action paradigm.\nServicesaretypicallypublishedbythirdparties,facilitatinginter-\noperability with smart devices (e.g., Nest thermostat) or online\nservices (e.g., Gmail and Facebook). Each supported service pub-\nlishes a set of triggers and actions that are akin to a service API. A\ntriggerisasourceofeventsinaservice.Forexample,atriggerin\ntheNestthermostatserviceisłTemperaturedropsbelowž,which\nireseverytimethetemperaturedropsbelowathreshold.An action\nisataskthataservicecanperform,e.g.,sendinganemail.An applet\n(i.e.,arule)isanautomationprogramthatconsistsofonetrigger\nand one or moreactions. For example, a user can create anapplet\nto send an email if the temperature drops below a threshold. Most\ntriggers,liketheoneabove,have triggerields thatdetermineunder\nwhat circumstances the trigger event should occur. Similarly, most\nactions have action ields which are the parameters of the action.\nEach trigger also has ingredients (i.e., parameters) which are basic\ndataavailablefromthecorrespondingtriggerevent.Forexample,\nthesubjectandthesender’semailaddressaretwoingredientsofan\nemailtrigger.Inanapplet,triggeringredientscanbeusedaspartof\na parameter by an action. An applet developer can also set further\nconditions on the invocation of an action by using the ilter code\nfeature,whichaddsextralexibilityintheformofaTypeScript[ 14]\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1440Motion\nDetectedUnlock \nDoorDoor\nUnlockedSend\nSMSService 2\nRule 1 Rule 2Service 1 Service 3\n(a) Rule 1 and Rule 2 are explicitly linked through Service 2.\nTemperature\nUser is  \nHome Turn On\nHeaterTemperature\nHighOpen\nWindowService 2\nRule 1 Rule 2Service 3 Service 1 Service 4\n(b) Rule 1 and Rule 2 are implicitly linked through the temperature.\nFigur\ne 2: Trigger-action graphs depicting (a) explicit chaining and\n(b) implicit chaining. Solid and dotted-line edges represent explicit\nand implicit chains, respectively.\ncode snippet. The ilter code has access to the data returned by the\ntriggerandmetadatalikethecurrenttime.Itcanusetheinforma-\ntiontooverrideactionieldvaluesorskipanaction.Anexample\nilter code snippet is provided in Appendix A.\n2.2 Model Checking and Rewriting Logic\nModel checking [ 48] is a technique that checks if a system meets a\ngivenspeciication bysystematicallyexploringthe system’sstate.\nInanidealcase,amodelcheckerexhaustivelyexaminesallpossible\nsystem states to verify if there is any violation of speciications.\nRewritinglogic[ 61],alogicofconcurrentchangethatcannat-\nurally deal with state and with concurrent computations, ofers\naclean-yethighlyexpressive-mathematicalfoundationtoassign\nformal meaning to open system computation. In rewriting logic,\nconcurrent computations are axiomatized by (possibly conditional)\nrewrite rules of the form l→r, meaning that any system state\nsatisfyingthepattern lwillbetransitedtoasystemstatesatisfying\nthe pattern r. For any given state, many rewrite rules can be active,\nthus allowing for non-determinism. Rewriting logic has been used\nto model and analyze diferent distributed systems [54ś57].\n3 THREAT MODEL & ASSUMPTIONS\nWeconsideranadversarythatseekstocovertlycompromiseanIoT\ndeploymentvia rule-levelattacks thattargetthelogiclayerofanIoT\nplatform. Rule-level attacks seek to subvert the intent of the end\nuserbyexploitingtheinteractionsoftheIoTautomationrules.Such\ninteractions may enable the attacker to execute privileged actions,\ncausedenialofserviceondevicesoraccesssensitiveinformation\nbelonging to the user. These attacks are enabled solely through\nthe invocation of automation rules that were legitimately installed\nbytheuser.Therearemanyscenariosthroughwhichanattacker\ncould create or detect the opportunity for rule-level attacks.\n•Exploitation: An adversary discovers an exploitable interaction\nbetween two or more benign apps or invokes a trigger event\nthrough manipulation of a 3rd party service [41].\n•TargetedRules: Anadversarytricksauserintoinstallingrulesthat\nenable an attack, e.g., through phishing or social engineering.\n•MaliciousApps: Anadversarydevelopsanddistributesamalicious\napp that contains hidden functionality [23, 38, 49, 84].T\nAA0T0\nRule0\nRule1A1\nT1Rule2\nRule3\nCondition3Condition2\nCondition1\nAT\nRule1\nA1\nT1Rule2\nRule3\nCondition3Condition2\nCondition1\nAT\nRule1\nCondition1Rule2\nCondition2\nT R1 C1 AR2 C2\ntb cb abci · · ·\ntb cb abciFigure 3: The condition bypass vulnerability. Two paths exist from\ntbtoabandci/nequalcb.\nThe red line shows a rule chain to bypass cb.\nRecent work has considered powerful adversaries that obtain\nroot access to devices [ 3] or compromise communication protocols\n[2], which are out of scope in this work. While important, these\nstrongadversarialmodelsruntheriskofdownplayingthepotential\ndangersposedbyeverydayattackerswithoutadvancedtechnical\nknowledge. Prior work has demonstrated that IoT end users often\nmake errors in writing trigger-action rules [ 46,68,86]. Since they\nareoftenunawareoftheimplicationsofrulesinteractions,itstands\ntoreasonthatusers’creation,deletion,ormisconigurationofrules\nleadstosecurityvulnerabilitiesintheirhomes.Ourthreatmodel\nalsoaccountsforthesafetyrisksofbenignmisconigurations,which\nposeareal-worldthreat.Wethusarguethatrule-levelattacksarean\nimportant consideration for IoT security, and note also that similar\nthreat models have appeared in related work [23, 30, 49, 70, 87].\n4 INTER-RULE VULNERABILITIES\nIn this section, we consider and deine the interference conditions\nfor trigger-action rules, which we call inter-rule vulnerabilities. For\ngenerality, we deine each inter-rule vulnerability as a property\nof an abstracted information low graph for an IoT deployment;\nweconcretizethesedeinitionsinlatersectionsoncethestatefor\nvarious devices and automation rules are known.\nConsiderthegraph G=<V,E>thatencodestheactiveautoma-\ntion logic for an IoT deployment. Vertices Vcan be of type T,C, or\nA,respectivelyrepresentingtriggers,conditions,andactions.All\nedgescarrystatefromonevertextoanother,butthisstateisdevice\nandconiguration-speciic;fornow,weonlydeineanabstractstate\nforconditionverticesasabooleanlag,i.e., STATE(c)∈{0,1}.Edges\nthatlowintoconditionsmayupdatethisstate,i.e., ON(c)orOFF(c).\nNull conditions can also exist in the graph where STATE(c)=1\nalways. An individual rule Rjis given by{tj,cj,aj}; rule vertices\nare otherwise elided. Using the above system, events in the IoT\ndeploymentcanberepresentedaspathtraversalsingraph G.An\nevent trigger tbeing ired is represented by ACTIVATE (t), which\ncausesbranchingtraversaloftheoutbounddirectededgesofvertex\nt. Traversal automatically proceeds from all trigger and action ver-\ntices, leading to additional ACTIVATE (t)andACTIVATE (a)events.\nTraversal only proceeds from condition vertices if STATE(c)=1.\nTraversal concludes when all paths have reached either a childless\naction vertex or a condition vertex where STATE(c)=0. A path\np∈Pdescribestheseriesofvalidtransitionsthatoccurredinthe\ngraph traversal, with the set Pdeining all valid paths.\nWe now enumerate the space of inter-rule vulnerabilities in\ntermsofpropertiesofIoTinformationlowgraphs.Wewilldoso\nwithrespecttoabenignrule Rb={tb,cb,ab}and(whennecessary)\nan interference rule Ri={ti,ci,ai}.\nCondition Bypass. Security-sensitive actions (e.g., open the win-\ndow)areoftenguardedbysomesecurityconditions(e.g.,Iamat\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1441tb cb abti ai\nONci\n(a) Not enough rulestion1  t o false2\ntb cb abti ai\nON\ntbai\nab· · · OFFci\nci\ncb\n(b) Active blocking\nFigur\ne 4: Condition blocking scenarios. In 4a, removing aiwill\nmakecbunsatisiable.In4b, ai’sactivationmakes cbunsatisiable.T1\nA1Rule1\nT2\nA3Rule2\nT1\nA2Rule3T1 R1 A1\nR2 T2 A2A2\ntb\nti ab'ab\n· · ·\ncicb\n(a) Action revertingtbab' \nab ci\ncb\n(b) Action conlict\nFigur\ne5:(a)Actionreverting: a′\nbhastheoppositeefectasaction ab.\n(b) Action conlict: tbactivates abanda′\nbin an unknown order.\nhome). However, when a trigger is ired, all associated rules are\nactivated; if there are multiple paths to the security-sensitive ac-\ntion, the burden is on the user to apply the condition for all active\nrules. The security guarantee of an action thus follows the weakest\nprecondition, creating the potential for condition bypass:\n∃p∈P s.t.{tb,ab}∈p∧{cb}/nelementp\nConditionbypassisvisualizedinFigure3.Asanexampleofthecon-\nditionbypassthreat,considertherule łIftemperatureishigherthan\n30◦C,when I am at home andtime is between 8am to 6pm ,thenopen\nthe windowž . If another rule exists with a null condition, i.e., łIf\ntemperature is higher than 30◦C, then open the windowž then the\nprior condition is trivially bypassed.\nConditionBlock. Analternatevulnerabilityrelatedtoconditions\nis that a given condition is simply unsatisiable. Broadly, the deini-\ntion for condition blocking can be given as follows:\n∀p∈P,ACTIVATE (ai)=⇒OFF(cb)\nWeidentifytwoscenariosinwhichconditionblockingisapotential\nissue,NotEnoughRules andActiveBlocking,visualizationsforwhich\nareshowninFigure4.Fortheformerscenario,aconditionmayde-\npend on other devices’ states but there is no rule to manipulate the\nstateinsuchawaytosatisfythecondition.Forexample,ifauserhas\na rulełIf motion is detected at the door when home is in armed state ,\nthen send me a notiicationž. If no action in the deployment sets the\nhome’ssecuritysystemtothearmedstate,thisconditioncannot\nbe satisied. Conversely, when Active Blocking occurs there is a\nbuggy or malicious rule that actively disables the condition before\nthe action can be activated. For example, another rule using the\nłIfmotionisdetectedatthedooržtriggercouldspecifyanaction\nthatsetsthehome’ssecuritysystemtothedisarmedstate.Ineither\ncase, the user’s intended action is unreachable.\nAction Revert. An alternate mechanism for preventing an action\nfromhavingitsintendedefectistoimmediatelyreverseit.Fora\ngiven action ab, let there be an opposite action a′\nbthat negates theab’s efect. With this in mind, action reverting can be deined as:\n∃p∈P s.t.ACTIVATE (ab)=⇒ACTIVATE (a′\nb)\nActionrevertingisshowninFigure5a.Therevertingactionpair\nshown here could be lockandunlockcommands on a door. It is\nalso possible that ab=a′\nb, e.g., an action that toggles a switch.\nAction Conlict. In contrast to action reverting, which determin-\nistically negates ab, action conlicts activate abanda′\nbin a non-\ndeterministic ordering, potentially putting the deployment in an\nunstable or unknown state. Action conlicts are deined as:\n∃p1,p2∈P s.t.{tb,ab}∈p1∧{tb,a′\nb}∈p2∧p1/npropersubsetp2\nThat is, there exist paths from tbto bothabanda′\nb, but the former\npathisnotasubsetofthelatterpath.Inanactionconlict,adoor\ncould be left in either a locked or unlocked state depending on\nnon-deterministicstateintheIoTplatform.Forease ofintuition,\nin the above deinition we consider an action conlict that arises\nbasedonthe sametrigger,butinfactanevenmoregeneraldeini-\ntion would accommodate diferent triggers. For example, the rules\nłWhenmotionisdetected,unlockthedoorž andłEverydayat11pm,\nlock the doorž will conlict if motion is detected at 11pm.\nAction Loop. Intuitively, this vulnerability describes when an ac-\ntion’s activation cyclically leads to its own re-activation. We can\ndeine action looping as follows:\n∃p∈P s.t.ACTIVATE (ab)=⇒ACTIVATE (ab)\nAn example of action loop are the rules łIf the bedroom light is\nturnedon,thenturnoftheliving-roomlight\" andłIftheliving-room\nlightisturnedof when the home state is away ,thenturnonbedroom\nlightž.Further,attacksthatexploittheactionloopconditionhave\npreviouslybeenpresentedintheliterature.Forexample,anattacker\ncanuseanactionlooponasmartbulbtocreatestrobelightthat\ncould potentially induce seizures [ 76]. An attacker can also use\naction looping as a side channel to leak information [49].\nAction Duplicate. Unexpected duplicate activation of an action\ncan lead to user harm. For example, the duplication of an action to\ninject somemedicine couldcause health problemto a patient,or\naduplicatetransactioncancauseinancialloss.Actionloopingis\nan instance of the action duplication vulnerability; a more general\ndeinition is as follows:\n∃p1,p2∈P s.t.{ab}∈p1∧{ab}∈p2∧p1/nequalp2\nIn addition to action looping, this deinition accommodates the\nduplicateactionsbeinginvokedbythesameordiferenttriggers.\nAnother circumstance in which action duplication arises is the\nevent where one action in the deployment coniguration subsumes\nanother action, which we do not deine here but account for when\nconcretizing rules in the subsequent sections.\n5 IRULER\nIn this section, we describe iRuler, our tool to detect inter-rule\nvulnerabilities in TA rulesets. The architecture and worklow of\niRuleris shown in Figure 6. Given a set of IoT apps from a TA\nplatform,the RuleParser extractstrigger-actionrulesfromtheapps\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1442iRuler\nRule \nPa\nrser Checking \nEn\ngine  Model \nBu\nilder \nDevice/Service\nMe\ntadataDeployment \nC\nonﬁgInter-rule\nV\nulnerabilitiesRRs IR  \nAp\nps\nFigure 6: The architectureand worklow of iRuler. RR: Rule Repre-\nsentations; IR: Intermediate Representation.\nListing 1: The iRulerrule representation format.\nrule ::= (trigger) (action)+\nt\nrigger ::= (event) (constraint)\naction ::= (condition) (subject).(command) (arguments)\nevent ::= (subject).(attribute)\ncondition ::= logical expression | null\nconstraint ::= logical expression | null\nandtransformstherulesintoRuleRepresentations(RR).The Model\nBuildertakes the rule representations, device metadata and the\nuser’sdeploymentconigurationasinputandgeneratesanInter-\nmediateRepresentation(IR)oftheIoTdeployment.The Checking\nEngineperforms checking over the IR and outputs potential inter-\nrulevulnerabilitiesasintroducedinSection4.Itisthenuptothe\nusertodeterminetheseverityofthewarningandwhetherornot\nto correct the rules. In Figure 6, the components in yellow are pro-\nvidedbythe user,thecomponents ingreenare platform-speciic\nand the components in blue are platform-agnostic. Our tool can be\neasily extended to another platform by implementing a rule parser\nandbuildingdevicemetadatafortheplatform.Belowwediscuss\neach component in more detail.\n5.1 Rule Parser\nAnIoTappcouldcontainmultipleTArules.Theruleparserirst\nextracts all the rules in the app, then transforms the rules into\nuniform rule representations which are used by the model builder.\nListing 1 shows the format of our rule representation. A ruleis\ncomposed of a trigger and one or more actions. A triggeris de-\nined as an event with a constraint and an eventis deined in\nterms of subject(e.g., a certain device) and attribute . For exam-\nple,thetriggerłiftemperaturedropsbelow30žisrepresentedas\ntemperature_sensor.temperature <30. The event here is the value\nchangeinthemeasurementofthetemperaturesensor.An action\ncomprisesa condition ,thesubject,thecommand toexecuteand\nthearguments to the command. A condition or aconstraint could\nbe null (i.e., no condition) or a logical expression. The diference\nbetweenthemisthataconstraintisapredicateovertheeventdata\nwhile a condition could be a predicate over other subjects.\n5.2 Formal Modeling with Model Builder\nThe model builder generates a model of the IoT deployment us-\ningrulerepresentations,deploymentconigurationdescribingthe\nuser’sIoTdeployment(e.g.,thetypesofdevicesandwheretheyare\nlocated), and device metadata. It then generates an intermediate\nrepresentation for the checking engine. As an IoT deployment isessentiallyadistributedsysteminteractingwithanondeterministic\nenvironment, we model the deployment as an event-based (e.g.,\ndevice events and time events) transition system and we model the\ntransitions with rewriting logic. Below we describe how we model\ndiferent aspects of an IoT system.\nDevice/Service Modeling. Each device has a set of attributes, rep-\nresenting the states of the device, and supported commands (i.e.,\nactuatorcapability).Forexample,aheaterdevicemayhavea switch\nattribute and two commands turn_onandturn_off. A device com-\nmand can change the values of one or more attributes, e.g., the\nturn_oncommand sets the value of the switchattribute to łonž.\nFurther, the execution of a command can afect one or more en-\nvironmental variables, e.g., the turn_oncommand can afect the\ntemperature environmental variable. Devices can also observe mul-\ntiple environmental variables (i.e., sensor capability). For example,\na temperature sensor monitors the environment temperature. Each\ndeviceinstanceismodeledasadeviceobject,i.e.,aninstanceofa\nparticulardevicetype.Forexample,aheaterinstanceismodeled\nas<oid:Heater|switch:_>, whereoidis the id of the device.\nDeviceStateTransitions. Tomodeltheinteractionofrules,itis\nimportant to model the state transitions of devices (or services) as\ntheactionofarulecouldcauseastatetransitionwhichinvokesthe\ntrigger of another rule. For a device command that can change the\ndevice’sattributes,wemodelthecommandexecutionasatransition\nfrom one device state to another. The value change of a device\nattribute is modeled as a device event. For example, the turn_off\ncommand of the heater is modeled as a transition from state <\nswitch:on>to state<switch:of>with a switch change event\nEvent(oid,switch:of)whereoidis the id of the device.\nEnvironment Modeling. Implicit chaining is achieved through\nenvironmentalvariablessuchastemperature.Wemodeleachen-\nvironmental variable as an environment object, for example, <\nenv.temperature|value:_>. As a device usually only observes\norafectsenvironmentalvariablesinthesameplacethedeviceis\ndeployed, we consider the same type of environmental variable in\ndiferentzones(locations)asdiferentvariables.Forexample,the\ntemperatureofthebedroomandthetemperatureofthelivingroom\nare treated as two diferent variables. Further, when the value of\nan environmental variable is updated, the corresponding attribute\nofadevicethatobservethevariablewillalsobeupdated.Forex-\nample,whenthevalueof env.temperature_bedroom ischanged,the\ntemperature attribute of a temperature sensor in the bedroom will\nbeupdatedtothesamevalue.Thisisachievedwithparallelstate\ntransitions which change both the environment object and the de-\nvice object. If no location coniguration is provided for a device,\nwe consider it as deployed in the common zone. Note that, our\nmainpurposeforenvironmentmodelingistomodeltheimplicit\nchainingofadevice’scommandtoanotherdevice’sevent(e.g.,tem-\nperature is higher than 30). Thus, we model each environmental\nvariable with discrete values. A full modeling of environmental\nvariables, such as dealing with real-time continuous environments\nwithdynamiclawsand timedelays,andmodelingcorrelationsof\nenvironmental variables are out of our scope.\nTimeModeling. Wesupporttemporalbehaviormodelingbymod-\nelingtimeasa monotonically increasingvariable.Timeadvances\nwhenthereisnoothertransitionavailable.Time-basedtriggers(e.g.,\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1443atimerat8am)aremodeledastimeeventswhenthetimevariable\nadvances to the speciic values. For device actuation that can afect\nenvironmental variables, we make state transitions of the environ-\nment objects to update their values as time advances. The updates\naremadebasedontheefectscausedbytheactuation.Currently,we\nsupportincrease(i.e.,increasingbyarate), decrease(i.e.,decreasing\nbyarate)and changeto efects(i.e.,directlychangingtoavalue).\nFor example, if a heater increases the temperature with a rate r.\nFor each time unit that the switchattribute of the heater is łonž,\nwe make a state transition from <env.temperature|value:T>to\n<env.temperature|value:T+r>. If no rate ris provided, we use\n1 as default. One optimization we use to reduce system states is to\nupdatethevaluesoftimeandenvironmentalvariablesonlywith\nthe values used in the ruleset. For example, if there are two timers,\none at 8 am and the other at 9 am , in the rules, we will advance\ntime from 0 to 8 am then to 9 am instead of advancing the time by\none time unit in the transitions.\nDevice/ServiceMetadata. Thedevicemetadatacontainsthenec-\nessaryinformationfordevicemodelingandenvironmentmodeling.\nFor example, it deines the attributes and commands of a device\ntype,theefectsonenvironmentalvariables(e.g.,increasingtem-\nperature)ofacommand,andstatetransitionsofadevicecommand\n(i.e., what events will be generated by the execution of a com-\nmand).Device/Servicemetadatacanbeconstructedbyanalyzing\nthe documentation of an IoT platform or provided by the platform\ndevelopersorexperts[ 28,51].FortheIFTTTplatform,weconstruct\ntheservicemetadatabycrawlingthewebpageofeachserviceto\ngetwhattriggersandactionstheservicesupports.Wedescribehow\nweextractstatetransitionsofserviceactionsusingNLPtechniques\nin Section 6. We show examples of a device metadata and a service\nmetadata in Appendix C.1. The service metadata is generated with\nthe help of the NLP techniques in Section 6.\nIntermediate Representation. The model builder could generate\nintermediaterepresentationfordiferentmodelcheckers.Dueto\nits maturity and expressiveness, we use Maude [ 13], which is a lan-\nguageandtoolthatsupportstheformalspeciicationandanalysisof\nconcurrent systems in rewriting logic [ 62], as our checking engine.\nWith rewriting logic, an IoT system, which is a concurrent system,\ncan be naturally speciied as a rewrite theory R=(Σ,E,R)with\n(Σ,E)an equational theory describing system states, and Rrewrite\nrules describing the system’s concurrent transitions. Rewrite rules\nof the form crl[l] :t(− →x)→t′(− →x,− →y)ifϕ(− →x,− →y)describe an l-\nlabeled transition in an open system from an instance of tto the\ncorresponding instance of t′; the extra variables− →yon the right-\nhand side of the rule are fresh new variables that can represent\nexternal nondeterminism (e.g., sensor probing); ϕis a constraint\nsolvable by an SMT solver. In the generated intermediate repre-\nsentation, devices, environmental variables and time are modeled\nasobjects;eventsandcommandsaremodeledasmessages;state\ntransitions and trigger-action rules are modeled as rewrite rules\n(rlfor rules and crlfor conditional rules). Consider an example\nof an IoT deployment consisting of a temperature sensor sensor\nsensing the temperature from the environment and an air condi-\ntionerac, which collaborate to maintain the in-house temperature\nat a desired setpoint. In this case, the state of the system can be\nmodeled as<ac|setpoint:_,switch:_>,<sensor|temp:_>,<env.temp|temp:_>and<Time|time:_>, where the\nattributes time,temp, andsetpointare integers representing the\nwall-clock,thetemperatureinthehouse,andthedesiredtemper-\nature setpoint, respectively, and the attribute switchis a Boolean\nreferringtowhethertheairconditioneristurnedonorof.Notethat\ntimeandtempareundercontroloftheenvironment,while setpoint\nandswitchare under control of the system. The state transitions\ncan then be modeled by the following three rewrite rules:\ncrl [turn-on] :\n(< ac | setpoint:S, switch:false >\n< sensor | temp:T > ; ϕ)\n→(< ac | setpoint:S, switch:true >\n< sensor | temp:T > ; ϕ∧T>S) if sat( ϕ∧T>S) .\ncrl [turn-off] :\n(< ac | setpoint:S, switch:true >\n< sensor | temp:T > ; ϕ)\n→(< ac | setpoint:S, switch:false >\n< sensor | temp:T > ; ϕ∧T≤S) if sat( ϕ∧T≤S) .\nrl [time-advance] :\n< Time | time:R > < Temp | temp:T > < sensor | temp:T >\n→< Time | time:R+1 > < Temp | temp:T' > < sensor | temp:T' > .\nRules [turn-on] and [turn-of] model the situations in which the\ntemperature sensed by the sensor exceeds the setpoint or not, and\nthus the air conditioner is turned on or of. Rule [time-advance]\nmodelstheadvanceofwall-clocktime(advancingthetimerbyone\ntimeunitinthiscase)andthestatetransitionoftemperatureand\nthe sensor. Note that the extra variable T′indicates the external\nnondeterminism resulting from temperature changes in the house.\nAlsonotethatweembedinthesystemstatetheconstraints(e.g.,\nϕ∧T>S)alongthewayduringthesystemtransitions,whichwill\nbe solved by the SMT solver in the symbolic reachability analysis.\n5.3 Formal Analysis by Checking Engine\nThecheckingenginetakestheIRasinputanduses rewritingmodulo\nSMT[75]todiscoverinter-rulevulnerabilities.Rewritingmodulo\nSMT is a symbolic technique combining the power of rewriting\nmodulo theories, SMT solving, and model checking. For each com-\nbinationofdevicestates,weuseitasaninitialstatetocheckthe\nvulnerable properties as deined in Section 5.2. Since our goal is to\nindexistenceofviolations,weusethe searchcommandtosearch\na reachable state that reveals the vulnerabilities. As an example,\nthe following search command looks up to 1 solution and a search\ndepth15forareachablestateinwhichtheairconditioneristurned\non, while the temperature sensed by the sensor from the house\ndoes not exceed the current setpoint:\nsearch [1,15] (< sensor | temp: T:Integer > < ac | setpoint: S:\nInteger, switch: false > ; true)\n=>* (< sensor | temp: T':Integer > < ac | setpoint: S:Integer,\nswitch: true > ; B':Boolean)\nsuch that sat(T':Integer <= S:Integer and B':Boolean) .\nNotethatthe trueontheleft-handsideofthearrowindicatesno\ninitialconstraints.Similarwith[ 70],weperformboundedmodel\nchecking [ 25,26] with the argument like ł[1,15]ž to bound the\nsearchtasktoacertaindepthtoreducethesearchspace.Thesearch-\nbased model checker returns either a vulnerable state reachable\nfromtheinitialstateornosolution,indicatingnosuchvulnerability.\nBesides the inter-rule vulnerabilities, our tool can also check\notherpropertiesusingthebuilt-inLTL(LinearTemporalLogic)[ 19]\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1444SmartthingsC\nlose \nDeviceLockSwitch onOpen \nDevice\nUnlock\nSwitched \nonUnlocked\nTemperature \nrises aboveLocked Humidity \nrises aboveBrightness \nrises aboveNew \nmotion \ndetectedActivate \nDevice\necobee\nIndoor \nhumidity \nchangePresence \nDetected\nThermostat \nMode \nChange Indoor temp \nchangeLight Switch \nTurned offLight Switch \nTurned onSet \nThermostat \nModeResume \nThermostatTurn  \nSwitch off\nTurn  \nSwitch on\nRule R1Rule R2\nFigure 7: Initial attempts at building trigger-action information\nlo\nw graphs sufered from state explosion and false dependencies.\nmodelchecker.Forexample,theairconditionerwillbeturnedonif\nthe in-house temperature exceeds the desired setpoint. The follow-\ning command analyzes, from the initial state, if the air conditioner\nwill be eventually turned on in all reachable states once the tem-\nperature is above the setpoint:\nreduce modelCheck(init, above(C1:Config) -> []<> on(C2:Config)) .\nNote that aboveandonare two user-deined predicates on the\nsystemstates.Thetemporaloperator →representsthenotionof\nłimplicationž, and □ ♢the LTL notion of łalways eventuallyž.\n6 IOT INFORMATION FLOW MODELING\nAsdiscussedinthepriorsection, iRulerrequiresanunderstanding\nof how triggers and actions interact to detect inter-rule vulnera-\nbilities. In this section, we describe our approach to the automatic\nextraction of such lows from proprietary trigger-action platforms.\nAt irst glance, identifying such lows seems trivial. However, in\npractice, identifying these links proves surprisingly diicult.\nPreliminary Experiment: Following the methodology of [ 86] and\n[63],wescrapedthedescriptionsof674servicesand315,393applets\nfromtheIFTTTwebsite.Recallthateach triggerandactioninan\nappletrepresentanAPIdeinedbyathird-party service(channel).\nFor example, the SmartThings service provides an action łLock a\nSmartThingsdevicež andatrigger łIfaSmartThingsdeviceisturned\nonž. The simplest way to model action-to-trigger lows within a\nserviceistoconservativelyassumethatalloutboundtriggersde-\npend on all inbound actions. However, applying this naïve strategy\ngenerates 6637intra-servicelows,manyofwhicharespuriousand\nrepresentfalsedependencies.Forexample,inFigure7,the łLockž\naction of the SmartThings would not afect the łHumidity rises\nabovežtrigger;thesearetwoindependentattributesthatcanbema-\nnipulated through this service. Thus, while information low within\na rule (trigger-to-action) is deinitionally apparent, understanding\ninter-ruledependencies(action-to-trigger)requiresdecompositionof\nservices into their underlying components so that true lows can be\nidentiied.\n6.1 NLP-based Information Flow Analysis\nGiventheproprietarynatureoftrigger-actionIoTplatforms,our\noptionsforanalyzingtheinternalstateofservicesareextremely\nlimited.Asobservedinpriorwork[ 81,84,86],analyzingtextde-\nscriptions of IoT components that appear on the platform websites1. POS tagging\n2\n. Depedency tree \ngeneration\n3. Grammar heuristicsTextual Descriptions\nA: This action will turn off the air \nconditioner.\nT: This trigger fires every time \nthe air conditioner is turned off .1. Main Task [turn off ]\n2. Object [conditioner ]\n3. Object properties [air ]\n1. Semantic similarity \nscore (word-vector \nembedding)\n2. Semantic Relation \nMining (Babelnet)Syntactic Analyzer\nSemantic \nAnalyzer\n<A,T> Pairwise Numeric \nFeature Extraction1. Classification\n2. Cross validation\nTraining Set\nTest Set\nUnseen \nDatasetTrained ModelAccuracy Analysis\nReal world information \nflow graphClassifierSyntactic Elements\nFigure 8: An overview of our NLP-based information low analysis\nof trigger-action IoT platforms.\n                This   Action   will   turn   off   the   air   conditioner   .\n                      DET       NOUN    MODAL  VERB    PRT    DET   NOUN         NOUN        PUNCT\n   detnsubj\naux\nROOTcompound:prtdet\ncompounddobjpunct\nPart of SpeechRelationDependency\nFigure 9: An example dependency tree that encodes the grammati-\ncal structure of an action description.\nprovidesonemeansofovercomingthisobstacle.Wenowpresent\nan approach that leverages Natural Language Processing (NLP) in\nthedesignofaninformationlowanalysisframework,anoverview\nofwhichisgiveninFigure8.Toeliminatethespuriouslowsand\nto detect the true information lows, we pose this problem as a\nsupervisedclassiicationproblem.Ourframeworklearnsafunction\nto map an Action ( A) and Trigger ( T) pair from a Service ( S) to a\nbinary output specifying whether an information low exists from\nAtoT. As a irst step toward our goal, we need to encode each\n⟨A,T⟩pair as a set of numeric features.\n6.1.1 Syntactic Element Extraction. To simplify the analysis of un-\nstructured text, we irst perform Part-of-Speech (POS) tagging and\nDependencyParsing usingtheStanfordCoreNLP[ 12]librarytopro-\nduceadependencytreeforthedescriptionofeachrulecomponent.\nAn example dependency tree for an action description is shown\nin Figure 9. The parser performs Dependency Parsing to identify\ntheroot verb representing the main task of the rule component.\nAll other syntactic units are either directly or indirectly connected\nto the rootby dependency edges, whichencode a grammatical re-\nlation between a source node (governor) and a destination node\n(dependent).Whiletherearemanydependencyrelationships,those\nwe use in our analysis are:\n•DirectObject: Thedependentofthisrelationwithrespecttothe\nroot is the object that the main task is acted upon.\n•Compounds: These relations are part of the root verb or direct\nobject of the task (e.g., łair conditionerž, łturn of ž).\n•Modiiers: These relations encode words that modify the meaning\nofanounbyspecifyingsomeadditionalquality,association,or\nattribute(e.g.,ł newsubscriberž-adjectivemodiiertosubscriber).\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1445Table 2: A summary of our feature vector, calculated as a compari-\nson\nbetween the text descriptions of an action and trigger.\nFeature Type Description\nVerb Similarity Continuous Semantic similarity scores of ⟨A,T⟩v erb-pairs.\nObject Similarity Continuous Semantic similarity scores of ⟨A,T⟩obje ct-pairs.\nVerb Synonym Binary Is the trigger verb a synonym of the action verb?\nVerb Hypernym Binary Is trigger verb (mo ve) a hypernym1of action verb (walk )?\nVerb Causation Binary Can the trigger verb (eat ) be caused by the action verb (feed )?\nVerb Entailment Binary Does the trigger verb (wake ) entail2the action verb(sleep )?\nObject Synonym Binary Is the trigger object a synonym of the action object?\nObject Hypernym Binary Is trigger object (publication ) a hypernym of action object (book )?\nObject Meronym Binary Is the trigger object (lo ck) a meronym3of action object (door )?\nObject Holonym Binary Is the trigger object (do or) a holonym4of the action object (lock )?\nObject-Property\nMatchBinary Does action object property match the trigger object property?\nVerb-Particle\nMatchBinaryDo the verb-particles5match between action verb and trigger verb,\nif the verbs are multi-word expression (turn of )?\nUsually,rootdeines the main task while Direct Object andCom-\npoundtogetherdeinetheobject,inadditionto Modiiers thatde-\nine the properties of the object (Figure 9). However, sometimes\nthe clausal complement to the root verb describes the main task\ninstead.Forexample,inthetriggerdescriptionłThisTriggerires\nevery time an audio event is detectedž, the root verb łirež is not\nthe main task, but łdetectž is, which is a clausal complement to\nłirež.Moreover,łaudioeventžisa passivenominalsubject tołdetectž\ninsteadoftheDirectObject relationship.So,thereareafewother\ndependencyrelations,e.g., NominalandPassiveNominal subjects\nandClausalComplements [21],thatwetracktodetectsyntacticele-\nmentsinordertoaccommodatethevariabilityinunstructuredtext.\nThese grammatical dependencies comprise the syntactic elements\nof interest for the remainder of our analysis.\nAfter performing POS tagging, parsing and extracting the rel-\nevant syntactic elements, we also attempt to detect and exclude\ntheNamedEntities[ 9]fromeachtextdescription.Inpreliminary\nexperimentation, we found that this was necessary because named\nentities appearing in extracted object descriptions often seemed to\nencodesimilaritybetweendissimilarobjects.Forexample, WeMo\nHumidiier andWeMo Lighting are likely to be unrelated in spite\nof a shared Named Entity WeMo. We therefore decide to exclude\nnamed entities to avoid bias when calculating object similarity.\n6.1.2 Semantic Feature Extraction. After extracting the relevant\ntextelements,wethenencodethesemanticrelationshipbetween\nthesyntacticelementsoftheactionandtriggerasavectorof(contin-\nuous and binary) numerical features. These features are calculated\nby processing the syntactic elements of AandTin a pairwise fash-\nion (i.e., verb-verb, object-object). Intuitively, if the elements of the\ntrigger and action description have related semantics, it is likely\nthatthereexistsadependencybetweenthem.Asummaryofthe\nfeature vector is given in Table 2.\nContinuous Feature Computation: We leverage the Word Vector\nEmbedding techniqueto calculate Verb Similarity andObjectSimi-\nlarityfeatures,whichmapswordsfromavocabularyintovectorsof\nreal numbers. These vector representations are able to encode ine-\ngrainedsemanticregularitiesusingvectorarithmetic[ 64].Based\n1Hypernym: generic term used to designate a class of speciic instances.\n2Entailment: the trigger verb cannot happen unless the action verb happens.\n3Meronym: a constituent part, the substance of, or member of some object.\n4Holonym: The name of the object of which the meronym names a part.\n5Theverb-particles,i.e., OforOnaretaggeddiferentlybythePOS-Taggerthan On\nas a preposition.onvectorarithmetic,wethenusethewordembeddingtools(e.g.,\nword2vec[ 16],GloVe[ 18])tocalculatearealnumberscorerepre-\nsentingthesemanticsimilaritybetweenthetwosyntacticelements.\nWe calculate pairwise semantic similarity scores for each pair of\nverbs and objects extracted from AandT. To calculate the simi-\nlarityscoreformulti-wordelements,wecalculateaphrasevector\nas the average of the vectors of the component words [ 47]. Let\nphrasePbecomposedofwords (w1,w2,...,wn)withvectorem-\nbeddings (uw1,uw2,...,uwn).Thevectorfor Pisthendeinedas:\nuP:=1\nn/summationtextn\ni=1uwi. Finally, the semantic similarity score for the\naction and trigger phrases is calculated as the cosine similarity\nbetween the two vectors.\nBinarySemanticFeatureComputation: Weareultimatelyinter-\nested in speciic causalrelationships between actions and triggers,\nbut our continuous features relect anyrelationship between the\nsyntactic elements. As a result of this broader focus, the similarity\nscores may underweight the relationship between two elements\nwithinthecontextofIoT;forexample, word2vec(lock,door) withthe\nWikipedia-trainedmodelweusedyieldsamiddlingsimilarityscore\nof0.53,butintheIoTdomainitishighlylikelythatachangeinlock\nstatesuggestsachangeindoorstate.Tocorrectforthis,wealsocal-\nculateaseriesofbinaryfeaturesforeachactiontriggerpair,which\nwe deine to capture generic semantic relationships that we found\nwere commonly relevant to action-trigger lows during manual\ncoding of our IFTTT dataset. For example, multi-word expressions\n(e.g.,łturnonž)arecommonlyfoundindescriptions,buttheverb\nparticleonis often tagged as a preposition by the POS tagger, so\nwe introduce a feature that tests if the verb particles match. These\nfeatures are calculated using the lexical database Babelnet [ 69],\nannotated and interlinked with semantic relations.\n6.2 Classiication Problem\nWecastinformationlowdetectionasasupervisedbinaryclassiica-\ntionproblembetweenanactionandtriggerpair ⟨A,T⟩,whereboth\nTandAbelong to the same service S. Each⟨A,T⟩pair is labeled\nsuch that 1 signiies the existence of a low from AtoTwhile 0\nsigniies the contrary. We divide the dataset into training and test\nsets byserviceso that the classiier is unable to leverage service-\nspeciicsemanticswhenclassifyingtestsamples.Weuse4diferent\nclassiicationalgorithms-SupportVectorMachine,RandomForest,\nMultilayerPerceptronandLogisticRegression.WeuseGridSearch\nwith Cross Validation to search the hyperparameter space to op-\ntimize the classiier performance for a high recall (i.e., maximize\nproportion of actual positives identiied correctly) value. The deci-\nsion of recall optimization comes from the intuition that it is safer\nto admit false lows than exclude true lows.\nOneissuewithourdatasetisthatitishighlyimbalancedbecause\nthere are more spurious non-lows than true lows, i.e., the number\nof positive examples is far less than the number of negative exam-\nples. We use two diferent techniquesto combat this problem. First,\nweuse class-weightsinverselyproportionalto thepercentageof\nclass examples in the training set. This assigns a higher misclassii-\ncationpenaltytotraininginstancesoftheminorityclass.Second,\nwe useRandom Oversampling to balance the data by randomly\noversampling the minority class. We do not use undersampling of\nmajority class since we have a limited sized dataset.\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1446Table3:Asummaryoftheclassiicationperformance(percentages).\nClassiier Accuracy AUC RecallFP\nRateFN\nRateFalse Flow\nRe\nduction\nSVM (RBF K ernel) 80.279.890.722.39.2 72\nRandom Forest 85.780.588.215.211.878.7\nMultilayer Perceptron 86.882.788.616.411.477.6\nLogistic Regression 83.179.584.420.415.674.3\n6.3 Classiication Performance\nBasedonthemethodologydescribedabove,wenowevaluatethe\noverall accuracy of our NLP-aided information low analysis tool.\n6.3.1 Experimental Setup. Our featureextraction toolwas imple-\nmented using the Stanford CoreNLP [12] library for POS tagging\nduring syntactic element extraction, the FastText[27] project’s\nWikipediadatasetwordvectorstocalculatesimilarityscores,and\nBabelnet [69] to extract binary semantic features.\nThe classiier’s training and test sets were derived by randomly\nselecting 512 services from our IFTTT dataset, which is described\nin greater detail in Section 7.1. We divided this into 374 services\nfortrainingand138servicesfortesting.Becausewewereunable\ntopurchase,conigure,andrunallofthedevicesandserviceson\nIFTTT,ourlabeledgroundtruthisbasednotonappletinvocations,\nbutonmanualcodingbytwooftheauthors;weconsiderthepoten-\ntial limitations of this approach in Section 8. Each coding decision\nentailedexaminingthetextdescriptionsoftheservicetodetermine\nwhether it was possible for a given action to lead to the invocation\nofagiventrigger.Theexistenceorabsenceofalowwasusually\nobvious;occasionallythecodersneededtolookupthefunctionality\nof a service if they were not familiar with it. Manual coding en-\ntailedanauthorspendingapproximately40hoursmanuallycoding\nthe intra-service lows, followed by a second author spending 5\nhours on reliability coding [ 82]. for a total of 45 hours of human\nefort.Therewereasmallnumber(lessthan10intotaloutof512\nservices) of discrepancies identiied by the reliability coder, which\nwereeasilyresolvedbetweenthetwocodersthroughabriefdiscus-\nsion. While this strategy for deriving intra-service lows is already\ntedious, we argue that it will shortly become entirely untenable\nasIoTplatformscontinuetogrowinpopularity.Thereisalready\nevidence that this expansion of IFTTT is underway ś during a 5\nmonthwindowin2017,theplatformsservices,triggersandactions\ngrew by 11%, 31%, and 27% respectively [63].\n6.3.2 Results. Weusedthetrainingsettotraintheclassiierand\nthetestsettocomputetheaccuracyandAUCscore.Thenwefed\ntheentiretrainingsetandtestsettogethertoourtoolandcomputed\nrecall, error rates and the amount of false low reduction. These\nresults are summarized in Table 3. We compare the performance\nof our NLP-aided tool using diferent classiication models against\nthe baseline naïve strategy used in our preliminary experiments,\nwhichconservativelyassumesalowexistsbetweenallactionsand\ntriggersofaservice. Comparedtothisbaselinewhichgenerates 6637\nlows, our NLP-based tool with SVM classiier minimizes the FN rate\nto9.2% while causing an overall reduction in graph complexity of\n72%.This inding demonstrates that an NLP-based approach is a\nirst step towards overcoming the opacity of IoT platforms.\n6.3.3 Discussion. Inlightofthelargenumberoffalsedependencies\nthat exist using the naïve information low strategy, we feel thatourerrorratesarepromising.Here,afalsepositivesigniiesthat\nour attack surface model is overly conservative, encoding a low\nbetweentworulesthatdoesnotactuallyexist,whileafalsenegative\nfails to identify a legitimate low.\nWeidentifytwoerrorsourcesthatcanbedirectlyattributedto\nour methodology. First, our approach depends on an accurate text\ndescription of the rule behavior; in cases where the trigger/action\ndo not contain verbs that explain the behavior, we are unable to\nidentifythelow(TrueError).Inafewcases,theclassiier’sdecision\nboundary detected ⟨A,T⟩pairs with high verb or object similarity\nas a non-low, or pairs with lower similarity scores as a low (Clas-\nsiication Error). However, we did not want to overit our model\nto the dataset, so we restrained from ine-tuning the classiier to\naddress this.\nThe larger sources of error in our system can be attributed to\nlimitationsintheunderlyingNLPtoolsweemployed.(1)Textde-\nscriptionsthatgeneratedcomplexsyntaxtrees(withuncommon\ngrammaticalrelations)ledtofalsepositivesbecausewewereunable\nto track the language elements indicating a non-low (Syntax Tree\nComplexity). (2) The POS-tagger sometimes labeled words incor-\nrectly, leading toerrors; forexample, the łonžin łTurnonž might\nbedetectedasprepositioninsteadof averb-particle,third-person\nverbssometimesdetectedaspluralnouns,ortheword everytime\nis detected as a verb (POS Tagger Error). (3) Parsing errors by the\nCoreNLPparsermoduleproducedincorrectdependencytrees,lead-\ning to incorrect feature vectors (Dependency Parsing Error). (4) De-\nscriptionsthatcontainedcomplexobjectmodiiersledtosomefalse\npositives,e.g.,łThisActionwillcreatearegularpostonyourBlogger\nblogž and łThis Trigger ires every time you publish a new post on\nyourBloggerblogwithaspeciiclabel ž(ComplexObjectModiier).(5)\nWordembeddingsoftenassignhighsimilarityscoretocontextually\nsimilar verb pairs, for example łopen-closež, łactivate-deactivatež,\nthus confusing the classiier to record a false positive. (6) A signii-\ncant source of error was that the word embedding models we used\nwerenottrainedfortheIoTdomain,butamoregeneralvocabulary\n(i.e.,Wikipedia).Thiswasespeciallyproblematicwhennovelwords\n(e.g., łcool-modež) were encountered.\nTheseerrorsourcescouldpotentiallybeaddressedinfuturework\nthroughadvancementsinthesetechniquesorbytrainingNLPtools\nspeciicallyfortheIoTdomain.Alternately,ourmethodcouldbe\naugmented with prediction uncertainty analysis and quantiication\ntechniques [ 43] to request human intervention when the classiier\nis not conident enough in its prediction.\n7 EVALUATION\nHavinggeneratedaninformationlowgraphofIoTdeployments\nusing our NLP-aided analysis tool, we are now able to leverage\niRulertoidentifyinter-rulevulnerabilitieswithinreal-worldIoT\nplatforms.Inthissection,weexaminethepotentialforinter-rule\nvulnerabilities within the IFTTT ecosystem.\n7.1 Dataset\nWe conduct our evaluation on a dataset crawled from the IFTTT\nwebsiteinOctober2018 usingthemethodologyintroducedbyUr\net al. in [ 86]. The data we collect is entirely public and includes\nonlymetadataaboutthepublishedappletsandservicesśalluser\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1447 0.01 0.1 1 10 100\n 0  10  20  30  40  50  60Average # of violations\n# of rulesLooping\nConflict\nConflict_2\nReverting\nDuplication\nDuplication_2\n(a) Random Strategy 0.01 0.1 1 10 100\n 0  10  20  30  40  50  60Average # of violations\n# of rulesLooping\nConflict\nConflict_2\nReverting\nDuplication\nDuplication_2\n(b) Install Count Strategy 0.01 0.1 1 10 100 1000\n 0  10  20  30  40  50  60Average # of violations\n# of rulesLooping\nConflict\nConflict_2\nReverting\nDuplication\nDuplication_2\n(c) Service-based Strategy\nFigur\ne 10: Average number of vulnerabilities discovered for diferent coniguration synthesis strategies (averaged over 50 trials per number\nof rules). Diferent inter-rule vulnerability classes are separated by color; Conflict_2 stands for action conlict with diferent triggers and\nDuplication_2 stands for group action duplication (i.e., one action subsumes another action). Duplication violations can exceed # of rules\nbecause a single action can be involved in multiple duplications.\ndata in IFTTT is private, and thus not contained in our dataset,\nwith the exception of aggregate applet install counts which are\nmadepublic.6Ourcrawlidentiies315,393appletsand674services.\nThe applets make use of 1,718 distinct triggers and 1,327 distinct\nactions. The applets were written by either service providers or\n131,768third-partyauthors(i.e.,users).SomecomponentsofIFTTT\nappletsarenotpubliclyvisible,makingusunabletodiscovercertain\nclasses of inter-rule vulnerabilities; for example, because applet\niltercodeisnotpublic,wecannotanalyzeIFTTTforthecondition\nbypassingvulnerability.Instead,welimitourevaluationtoaction\nloop, conlict, revert, and action duplicate vulnerabilities.\nThesecurityofagivenIoTdeploymentultimatelydependsonits\nconiguration,i.e.,thecurrentlyactivesetofrules.However,weare\nnot aware of a publicly available dataset that describes how actual\nusersconiguretheirIoTdeployments;forexample,onIFTTTeach\nuser’sinstalledrulesareprivate.Thisknowledgegapisnotspeciic\ntoourstudybutbeliesabroaderlimitationinstate-of-the-artIoT\nsecurityresearch.Unfortunately,withoutanaccuratepictureofIoT\nconigurations,we arelimited inourability toidentifyreal-world\nvulnerabilities in smart homes.\nInordertoevaluate iRuler,wemaketheobservationthatIFTTT\nactuallyexposesalimitedamountofusageinformationthatwill\nallowusto approximate realisticIoTconigurations.Weleverage\nthis usage information in the form of 3 competing heuristics for\nsynthesizing plausible trigger-action rule sets:\n•Install Count Strategy . IFTTT reports the total number of installa-\ntions ofeach applet.Wenormalize these installcounts to assign\neachappletaweightandconstructanIoTconigurationof rrules\nbyperformingaweightedrandomwalkstartingatarandompoint\nintheIFTTTinformationlowgraph.Thisstrategyrelectsthe\nintuitionthatpopularappletsaremorelikelytobesimultaneously\ninstalled.\n•Service-Based Strategy. We construct an IoT coniguration by ran-\ndomlyselectingasmallnumberofservices,thenrandomlyselect-\ningrrulesfromwithinthoseservices.Thisstrategyrelectsthe\nintuition that a user is likely to make use of only a small number\nof services.\n6We argue that this is analogous to security surveys of mobile app markets (e.g., [ 37])\nand therefore consistent with community norms governing ethical data collection. 0 20 40 60 80 100\n 0  10  20  30  40  50  60percentage (%)\n# of rules\n(a) Including duplication 0 20 40 60 80 100\n 0  10  20  30  40  50  60percentage (%)\n# of rules\n(b) Excluding duplication\nFigur\ne 11: The percentage of applet authors whose applets have at\nleast one vulnerability.\n•Author-Based Strategy. In IFTTT, authors have the option of shar-\ningtheirappletspublicly.WeconstructanIoTconigurationby\nassuming that an author has all of their public applets simultane-\nously installed. This strategy relects the intuition that authors\nare likely to use their own applets.\nWe compare each of these heuristics to a baseline Random Strat-\negythatuniformlyselectsatrandom rrulesfromtheIFTTTdataset.\nThus,ourindingswillnotonlyservetovalidate iRulerbutalso\ncharacterize the potential for real-world inter-rule vulnerabilities.\n7.2 Results\nWe apply each IoT coniguration synthesis strategy for variable\nnumbers of rules between 2 and 60, reporting the average number\nof discovered violations across 50 trials. Figure 10 shows the av-\neragenumberofvulnerabilitiesidentiiedasthenumberofactive\nrules increases using the Random Strategy, Install Count Strategy,\nand Service-Based Strategy, respectively. In Figure 10, action du-\nplication is the most prevalent concern in the IFTTT ecosystem.\nLooping behaviors are also quite frequent, occurring at least once\nperconigurationwhenmore than15rulesaresimultaneouslyac-\ntive.Whilelessprevalent,wealsoidentifythepotentialforconlicts\nand reverting behaviors in many of the synthesized conigurations.\nThe group action duplication vulnerability, while rare, was also ob-\nservedinourtests.UsingtheInstallCountStrategy,intotal,66%of\nthe rulesets are associated with at least one inter-rule vulnerability.\nWe consider the Author-Based Strategy in a separate analysis\nbecause,unliketheotherstrategies,weareunabletocontrolthe\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1448Table 4: Rule chaining in IFTTT. Actions/Triggersis the number of\nchainable mechanisms in IFTTT, while Observed signiies the num-\nber of linkable mechanisms observed in at least one IFTTT rule.\nType Actions (Observed) Triggers (Observed)\nExplicit chaining 204,510 (200,030) 62,013 (61,967)\nImplicit chaining 10,128 (9931) 6262 (5228)\nnumberoftrials andthenumberofactive rules.Figure11ashows\nthe percentage of authors of applets with at least one vulnerability.\nAlmost all authors’ applets show evidence of at least one inter-\nrule vulnerability. Again, similar to prior test, duplication is the\nmostcommonconcern;Figure11bshowsthefrequencyofvulnera-\nbilitiesexcludingduplication.Concerningly,about1in5authors\nwillexperienceanon-duplicationvulnerabilityintheirrulesetif\nthey activate at least 10 rules. However, some authors might not\nsimultaneously activate all their applets, meaning that this test\nmay overestimate the frequency of vulnerabilities. However, taken\nasawhole,thistestprovidescompellingevidencethatinter-rule\nvulnerabilities currently exist in the wild.\nOurstudyalsopresentsanopportunitytocharacterizethepo-\ntentialforrulechainingwithinTAplatforms.Becauserulechaining\nincreases the complexity of an IoT coniguration, we theorize that\nit also increases the potential for security violations within the de-\nployment.Across the674 IFTTTservices weanalyzed, thereexist\n509actionsthatcanexplicitlylinktootherrulesand518triggers\ncan be explicitly triggered by some action. In addition, we identify\n460actionsthatcanafectanenvironmentvariableinordertoin-\ndirectly invoke 392 triggers that monitor environmental variables.\nTable4summarizesourrulechainingresults.Weidentifyatotal\nof204,510(64.8%)rulesthatcanexplicitlylinktootherrules,and\n62,013 (19.5%) rules that can be explicitly linked by other rules.\nThereexist10,128(3.2%)rulescanimplicitlylinktootherrules,and\n6262 (2.0%) rules that can be implicitly linked by other rules.\n7.3 Vulnerability Analysis\nConditionBypassing&ConditionBlocking. Whileweintroduce\nthenotionofcondition-basedvulnerabilitiesinğ4,weareunable\nto detect themon IFTTT becauseapplets’ iltercode isnot public.\nWeveriiedthepresenceofconditionvulnerabilitiesusingourown\napplets but leave large-scale validation of this issue to future work.\nActionReverting. Ourdatasetcontains1127appletswithmultiple\nactions, 50 of which contain contrary action pairs that revert each\nother. A rule susceptible to action-reverting by another rule/applet,\nusuallyoccurwithindistance1or2ofoneanotherintheIFTTT\ninformation low graph, but the longest distance observed was 5\nin a coniguration of 26 applets; such violations would likely to be\ndiicult to identify manually. One example of such violation in our\ndataset consists of an applet that turns the lights on when motion\nis detected, but another applet turns of the lights whenever a light\nis turned on. A more concerning violation we observed was a rule\nthatwould disconnecta HomeSeer devicefrom Wi-Fithe moment\nit was turned on, creating a DoS attack because the device cannot\nfunction or receive commands without a network connection.\nActionLooping. Mostoftheloopsweobservedconsistof2or3\nrules, while the longest loop contains 9 rules in a coniguration of\n30applets.WeobservedonerulechainthattriggeredIFTTTtocallthe user whenever their calendar received an appointment, while a\nsecond rule triggered IFTTT to make an appointment to the user’s\ncalendarwhenevertheymissedacall.Hence,ifausersentIFTTT’s\nautodial to voicemail, IFTTT would continue to call back while\nsimultaneously illing her calendar with pointless appointments.\nAction Conlicts. Most of the conlicting action pairs are direct\nactionsofthesametrigger(i.e.,distance1).Therearealsorulesthat\nconlict with other rules in another branch, including rule chain of\nlength 4, longest in a coniguration of 23 rules. We observed a rule\nchainwheretworulesconlict:łArmtheScoutAlarmwhentheuser\nentersanareaž,andłTurnoftheuser’sphoneWi-Fiwhentheuser\nenters an areaž. The second rule disconnects the phone from the\nnetwork, so IFTTT is unable to trigger the irst rule, i.e., arm Scout\nAlarm. We observe that the sequence of the iring triggers usually\ndetermines the inal states of the conlicting actions. We found one\nexample where scoutalarm enters armed mode everyday from 10\nAMuntiltheuser’sphoneconnectstohomeWi-Fi,butasecond\nrule disables the home Wi-Fi every day at 9:55 AM. Combined,\nthese will cause scoutalarm to irst disarm at 9:55 AM and then\nre-enter armed mode at 10 AM, even when the user is at home.\nAction Duplication. Asseen fromSection 7.2,action duplication\nis very common. It is perhaps not surprising to observe redundant\nrules in the community-based IFTTT ecosystem as developers may\npublishappletswiththesamefunction.Achainlengthof8inacon-\nigurationof38rulesisthelongestweobservedtocontainanaction\nduplicateviolation.Thenumberofgroupduplicationviolationswe\ndetected is very small as there are only 113 applets that use group\nactions.WefurtherinvestigatedthatIoTservicesinIFTTTprovides\nmoregroupactions,suchas Turnofdevice vs.Turnofalldevices\n(Linn) or Disarm all cameras vs.Disarm a camera (Eagle Eye Nubo-\nCam).Weenvisionthatasmorefunctionalitiesareintroducedin\nIoTdevices,thesesupersedingrelationshipswillbecomemorecom-\nmon,creatingthepotentialforaction-duplicationvulnerabilitiesto\nsigniicantly frustrate the debugging of IoT deployments.\n8 DISCUSSION & LIMITATIONS\nUsability. The motivation of this work is to help users better\ndiagnosepotentialsecurityproblemsintheirIoTdeployments.In\nfuturework,weplantoevaluatetheusabilityof iRulerthrough\nrealworldIoTuserstudies,andfurthercharacterizeactualsecurity\nthreats.Animportantcomponentofthefutureworkistoextend\niRulerto provide further assistance to non-expertusers when an\ninter-rule vulnerability is found.\nTheIFTTTAppletsDataset. SimilartoUr’sIFTTTrecipedatasetin\n[86],ourdatasetismissingrelevantinformationthatisnotpublicly\navailable, including values for the trigger ields in each applet and\nthe applet’s ilter code (i.e., conditions). An interesting direction\nfor further study is leveraging applet descriptions to attempt to\nrecover theseields; forexample, theapplet łGet aphone callalert\nwhenadoorisopenedduringsleepinghours,ž suggeststhecondition\nłduringsleepinghoursžisappliedtothe call_my_phone action.Note\nthe model checker of iRuleralready supports conditions.\nSynthetic IoT conigurations. Because we lack real-world exam-\nplesofIoTdeploymentconigurations,inourevaluation,weuse\nheuristic strategies to synthesize IoT deployments from our IFTTT\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1449dataset.Becauseiltercodeisnotpublicallyvisible,weconserva-\ntively assume in our analysis that any action that maylow to a\ntriggerwilllowtoit.Wealsoassumethatenvironmentalfactors\narealwaysafectedsuchthatthelowfromactiontotriggeroccurs.\nThus, the vulnerabilities we detect may be absent from real-world\nconigurations. However, this method demonstrated the validity of\niRulerfor cases in which coniguration data is available. In our\nfuturework,weplantoconductuserstudiestoevaluateourtool\nwith real-world IoT conigurations.\nManual Coding of Action-Trigger Flows. Due to the diiculty and\ncost of registering for hundreds of IFTTT services, many of which\nwould require the purchase of one to dozens of devices in order to\nexercise,wehadtorelyonmanualcoding(notphysicalinvocation)\nas our ground truth for information low on IFTTT. It is diicult\ntojudgethecorrectnessofourmanuallabelingwithoutphysical\ngroundtruth;however,becauseservicesareincentivizedtowrite\ninformative text descriptions of their functionalities, we believe\nthatourcodingwasaccurateenoughtodemonstratethevalidity\nof our NLP approach. Regardless, this coding is a potential source\nof error in our analysis.\nApplicability. We ensure the generality of our approach through\npresenting a realistic trigger-action rule model. While we have\nimplemented iRulerfor IFTTT, this model holds for other sys-\ntems(e.g.,ZapierandMicrosoftFlow),asdoestheobservationthat\nNLP-based analysis is required due to the closed nature of these\nplatforms.\n9 RELATED WORK\nIoT Security. Numerous vulnerabilities have been identiied in\nIoT devices [ 3,45,78], protocols [ 2,42], apps and platforms [ 38].\nAlrawietal.[ 22]proposedamodelingmethodologyforIoTdevices,\nassociated apps and communication protocols to analyze device-\nspeciicsecuritypostures.Diferentfromthenetwork-based[ 79,89],\nplatform-based[ 39]andapp-based[ 49,87]IoT-securitysolutions\nwhich detect vulnerabilities at runtime, iRulerleverages NLP and\nmodel checking to statically check vulnerabilities before an app\nis installed and executed. Celik et al. [ 29] use static analysis to\nidentify sensitive data lows in IoT apps, while our work studies\nvulnerabilitiescaused bytheinteraction of multipletrigger-action\nrules. Several other studies consider challenges related to access\ncontrol in IoT [44, 50, 74, 77].\nTrigger-Action Programming (TAP) in IoT. Researchers have stud-\niedhowsmarthomes[ 33,85,88]andcommercialbuildings[ 66]can\nbe customized using TAP, and the usability of existing TAP frame-\nworks to propose guidelines for developing more user-friendly\ninterfaces[ 46,83].Uretal.[ 86]createadatasetofIFTTTrecipes\nand analyze diferent aspects of the recipes. Bastys et al. [ 23,24]\ndiscussuserprivacyissuesinIFTTTanddevelopedaframeworkto\ndetectprivatedataleakagetoattackercontrolledURLs.However,\ntheyconcentrateonlyontheprivacyviolationsintheiltercode\nof individual applets, not the interaction between applets. Fernan-\ndes et al. [ 40] consider the efect of OAuth-related overprivilege\nissues on the IFTTT platform and proposed a way to decouple the\nuntrusted cloud from trusted clients on the user’s personal devices.NLP-aidedFlowAnalysis. FlowCog[ 71]extractsapp-semantics\nandcontextualinformationthatdeinesanandroidappbehavior,\nandusesNLPtocorrelatetheappbehaviorwiththeinformation\nlowsintheapp.OtherworkhasusedNLPtolocatesensitiveinfor-\nmationinmobileappsandtrackinformationleakagetothird-party\nlibraries [ 35,67]; evaluate the semantic gap between mobile app\ndescriptions and app permissions [ 72], and match IoT app descrip-\ntion with actual app behavior [ 84]. Ding et al. [ 36] use keyword\nidentiication in the app description of SmartThings apps to detect\nappinteraction-chainsthroughphysicalchannels.Surbatovichet\nal.[81]deineaninformation-lowlatticetoanalyzepotentialse-\ncrecy or integrity violations in IFTTT recipes. While their work\nmanuallyrewritesandlabelstriggersandactionstoidentifyrule-\ninteractionschains,ourapproachusesNLPtoautomatethisprocess.\nThere are also eforts to build semantic parsers that creates exe-\ncutablecodefromIFTTT-stylenaturallanguagerecipes[ 53,73],\nwhich are orthogonal to our contributions.\nIoT Automation Errors. IoT automation errors have been studied\nfromvariousaspects,includinganalyzinglogicinconsistenciesand\nsupportingend-userdebuggingtoresolvethem[ 20,34,51,52,90]as\nwell as assisting IoT app developers with GDPR [ 58]. Chandrakana\net al. [68] identify that too few triggers in automation rules is a\nsourceoferrorsandsecurityissues.Theyproposeatooltodeter-\nmine a necessary and suicient set of triggers based on the actions\nwrittenbyendusers.However,theirtoolanalyzeseachruleinisola-\ntion while we consider vulnerabilities from rule interactions. Some\nwork has also been done on detecting and resolving automation\nconlictsinsmarthomeandoiceenvironments[ 59,60,65,66,80];\nin this work, we consider a broader class of vulnerabilities.\nIoT Properties Checking. Several recent studies have proposed to\nchecksecurityorsafetypropertiesofIoTwhenmultiplerules/apps\nare enabled. We compare our approach with other existing ap-\nproachesindiferentaspectsinTable5; iRulerisamongtheworks\nthat support the more advanced features of TA platforms (Multiple\nActions),incorporatesabroadsetofcharacteristicsintoitsmodel\n(Environment Modeling ,Device Location, Time Modeling, Support\nChecking Other Properties), and identiies new classes of inter-rule\nvulnerabilities.7Conversely,theseworksalsoprovideseveraluse-\nful properties that we did not consider in iRuler. AutoTap [ 90]\npresents a method for verifying coniguration properties as ex-\npressed by novice users, and joins MenShen [ 28], Salus [51], and\nSIFT [52] in supporting automated creation and repair of rules\n(Rule Writing). Systems like Soteria [ 30], IoTSan [ 70], and Home-\nGuard(arXivpreprintonly:[ 32])arebasedonsourcecodeanalysis\nofIoTappsandcanthereforeconsideradditionalfactorssuchas\niner-grained reduction of state explosion and speciic malicious\ninput sequences. IoTGuard [ 31] instruments apps to check security\nand safety properties at runtime. Conversely, rather than leverage\nsource code analysis, instrumentation, or a priori knowledge of\napp behaviors, our technique uses an NLP-based approach to infer\ninformation low. As a result, iRuleris necessarily less precise\nandine-grainedinitsanalysisbuthastheadvantageofworking\nout-of-the-boxoncommodityIoTplatformswheresourcecodeis\ntypically unavailable.\n7We show the vulnerabilities considered by other work in Table 6 in Appendix B.\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1450Table5:ApproachesforcheckingsecurityandsafetypropertiesofIoTrules/apps.[31]checkspropertiesatruntimewhileallothersperform\nstatic\nchecking.Thesesystemsallhavediferentaimsandadvantages;thistablefocusesspeciicallyonthesimilarityoftheirdesignto iRuler.\nMultiple\nA\nctionsEnvironment\nMo\ndelingDevice\nLo\ncationTime\nMo\ndelingSupport Checking\nOther\nProperties# Inter-rule Vuln\nT\nypes ConsideredRule\nW\nritingAccess Required\niRuler ✓ ✓ ✓ ✓ ✓ 8 ✗ Applet Descriptions, Conig Data\nSoteria [30] ✓ ✗ ✗ ✗ ✓ 3 ✗ App Source Code1, Device Handler Code\nIoTSan [70] ✓ ✗ ✗ ✓ ✓ 2 ✗ App Source Code, Conig Data\nAutoTap [90] ✗ ✗ ✗ ✓ ✓ N/A ✓ App Behaviors,2De vice Speciications\nMenShen [28] ✗ ✓ ✗ ✓ ✓ N/A ✓ App Behaviors,2De vice Schema\nSalus [51] ✗ ✓ ✓ ✓ ✓ N/A ✓ App Behaviors,2Conig Data, Device Schema\nSIFT [52] ✗ ✓ ✗ ✓ ✓ 1 ✓ App Behaviors,2De vice Metadata\nHomeGuard [32] ✓ ✗ ✗ ✗ ✗ 5 ✗ App Source Code, Conig Data\nIoTGuard [31] ✓ N/A ✗ N/A ✓ 3 ✗ App Source Code, Instrumentation\nSurbatovich et al. [81] ✗ ✗ ✗ ✗ ✗ N/A ✗ Applet Descriptions1\n1. Coniguration factors are not considered.\n2. Assumes knowledge of app behaviors is available a priori.\n10 CONCLUSION\nWhile the trigger-action programming paradigm promotes the cre-\nationofrichandcollaborativeIoTapplications,italsointroduces\npotentialsecurityandsafetythreatsifusersdonottakeprecautions\nin combining these apps. In this work, we generalize and examine\ninter-rulevulnerabilitiesintrigger-actionIoTplatforms,presenting\na tool for their automatic detection. iRulercombines the power\nof SMT solving and model checking to model the IoT systems and\ncheckvulnerableproperties.Asarelatedcontribution,wehavealso\ndemonstrated an NLP-aided technique for inferring information\nlow between rules in proprietary trigger-action platforms.\nACKNOWLEDGEMENTS\nThisworkwassupportedinpartbyNSFCNS13-30491,NSFCNS\n17-50024, and NSF CNS 16-57534. The views expressed are those of\ntheauthorsonly.WeappreciatedvaluableinsightsfromourCCS\nreviewers and our shepherd, Blase Ur.\nREFERENCES\n[1]2014. Gartner Says the Internet of Things Will Transform the Data Center.\nhttp://www.gartner.com/newsroom/id/2684616.\n[2]2015. Critical Flaw identiied In ZigBee Smart Home Devices. https://goo.gl/\nBFBa1X.\n[3] 2016. Mirai Attacks. https://goo.gl/QVv89r.\n[4] 2018. Apple HomeKit. http://www.apple.com/ios/home.\n[5] 2018. IFTTT. https://ifttt.com.\n[6]2018. IFTTT Home Security Applets. https://ifttt.com/search/query/home%\n20security.\n[7] 2018. Iris by Lowe’s. https://www.irisbylowes.com/.\n[8] 2018. Microsoft Flow. https://low.microsoft.com.\n[9]2018. NamedEntityRecognition(NER)andInformationExtraction(IE). https:\n//nlp.stanford.edu/ner/.\n[10] 2018. openHAB. https://www.openhab.org/.\n[11] 2018. SmartThings. https://www.smartthings.com.\n[12] 2018. Stanford CoreNLP. https://stanfordnlp.github.io/CoreNLP.\n[13]2018. TheMaudeSystem. http://maude.cs.illinois.edu/w/index.php?title=The_\nMaude_System.\n[14] 2018. TypeScript. https://www.typescriptlang.org/.\n[15] 2018. Wink. https://www.wink.com/.\n[16] 2018. Word2Vec. https://code.google.com/p/word2vec.\n[17] 2018. zapier. https://zapier.com/.\n[18]2019. GloVe:GlobalVectorsforWordRepresentation. https://nlp.stanford.edu/\nprojects/glove.\n[19]2019. Linear temporal logic. https://en.wikipedia.org/wiki/Linear_temporal_\nlogic.\n[20]2019. Supporting end-user debugging of trigger-action rules for IoT applications.\nInternational Journal of Human-Computer Studies 123 (2019), 56 ś 69.\n[21]2019. Universal Grammatical Dependency Relation Deinitions. http://\nuniversaldependencies.org/u/dep/.[22]O. Alrawi, C. Lever, M. Antonakakis, and F. Monrose. 2019. SoK: Security Evalu-\nation ofHome-Based IoTDeployments. In 2019 2019IEEE Symposiumon Security\nand Privacy (SP), Vol. 00. 208ś226.\n[23]Iulia Bastys, Musard Balliu, and Andrei Sabelfeld. 2018. If This Then What?:\nControllingFlowsinIoTApps.In Proceedingsofthe2018ACMSIGSACConference\non Computer and Communications Security (CCS ’18). ACM, New York, NY, USA,\n1102ś1119.\n[24]IuliaBastys,FrankPiessens,andAndreiSabelfeld.2018. TrackingInformation\nFlow via Delayed Output. In Secure IT Systems, Nils Gruschka (Ed.). Springer\nInternational Publishing, Cham, 19ś37.\n[25]Armin Biere, Alessandro Cimatti, Edmund Clarke, and Yunshan Zhu. 1999. Sym-\nbolic model checking without BDDs. In International conference on tools and\nalgorithms for the construction and analysis of systems. Springer, 193ś207.\n[26]ArminBiere,AlessandroCimatti,EdmundMClarke,OferStrichman,Yunshan\nZhu,et al .2003. Boundedmodel checking. Advancesin computers 58,11 (2003),\n117ś148.\n[27]Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. 2016.\nEnriching Word Vectors with Subword Information. CoRR(2016).\n[28]LeiBu,WenXiong,MikeChieh-JanLiang,ShiHan,ShanLin,DongmeiZhang,\nandXuandongLi.2018. SystematicallyEnsuringTheConidenceofRealTime\nHome Automation IoT Systems. TCPS (ACM Transactions on Cyber-Physical\nSystems)(June 2018).\n[29]Z. Berkay Celik, Leonardo Babun, Amit Kumar Sikder, Hidayet Aksu, Gang Tan,\nPatrick McDaniel, and A. Selcuk Uluagac. 2018. Sensitive Information Tracking\nin Commodity IoT. In 27th USENIX Security Symposium (USENIX Security 18).\nUSENIX Association, Baltimore, MD, 1687ś1704.\n[30]Z. Berkay Celik, Patrick McDaniel, and Gang Tan. 2018. Soteria: Automated\nIoTSafetyandSecurityAnalysis.In 2018USENIXAnnualTechnicalConference\n(USENIX ATC 18). Boston, MA, 147ś158.\n[31]Z. Berkay Celik, Gang Tan, and Patrick D. McDaniel. 2019. IoTGuard: Dynamic\nEnforcement of Security and Safety Policy in Commodity IoT. In 26th Annual\nNetwork and Distributed System Security Symposium, NDSS 2019, San Diego, Cali-\nfornia, USA, February 24-27, 2019.\n[32]Haotian Chi,Qiang Zeng, XiaojiangDu, and JiapingYu. 2018. Cross-App Inter-\nference Threats in Smart Homes: Categorization, Detection and Handling. CoRR\nabs/1808.02125 (2018).\n[33]LuigiDeRussisandFulvioCorno.2015. HomeRules:Atangibleend-userpro-\ngramming interface for smart homes. In Proceedings of the 33rd Annual ACM\nConference Extended Abstracts on Human Factors in Computing Systems. ACM,\n2109ś2114.\n[34]Luigi De Russis and Alberto Monge Rofarello. 2018. A Debugging Approach for\nTrigger-ActionProgramming.In ExtendedAbstractsofthe2018CHIConference\nonHumanFactorsinComputingSystems (CHIEA’18).ACM,NewYork,NY,USA,\nArticle LBW105, 6 pages.\n[35]SoterisDemetriou,WhitneyMerrill,WeiYang,AstonZhang,andCarlA.Gunter.\n2016. Free for All! Assessing User Data Exposure to Advertising Libraries on\nAndroid. In 23rd Annual Network and Distributed System Security Symposium,\nNDSS 2016, San Diego, California, USA, February 21-24, 2016.\n[36]Wenbo Ding and Hongxin Hu. 2018. On the Safety of IoT Device Physical Inter-\nactionControl.In Proceedingsofthe 2018ACMSIGSACConference onComputer\nand Communications Security (CCS ’18). ACM, New York, NY, USA, 832ś846.\n[37]William Enck, Peter Gilbert, Byung-Gon Chun, Landon P. Cox, Jaeyeon Jung,\nPatrickMcDaniel,and AnmolN.Sheth.2010. TaintDroid:AnInformation-low\nTrackingSystemforRealtimePrivacyMonitoringonSmartphones.In Proceedings\nofthe 9thUSENIX SymposiumonOperating SystemsDesign andImplementation\n(OSDI’10).\n[38]Earlence Fernandes, Jaeyeon Jung, and Atul Prakash. 2016. Security Analysis of\nEmerging Smart Home Applications. In IEEE S&P.\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1451[39]Earlence Fernandes, Justin Paupore, Amir Rahmati, Daniel Simionato, Mauro\nConti,andAtulPrakash.2016. FlowFence:PracticalDataProtectionforEmerging\nIoT Application Frameworks. In USENIX Security.\n[40]Earlence Fernandes, Amir Rahmati, Jaeyeon Jung, and Atul Prakash. 2017.\nDecoupled-IFTTT:ConstrainingPrivilegeinTrigger-ActionPlatformsforthe\nInternet of Things. arXiv preprint arXiv:1707.00405 (2017).\n[41]EarlenceFernandes,AmirRahmati,JaeyeonJung,andAtulPrakash.2018. De-\ncentralized Action Integrity for Trigger-Action IoT Platforms. In NDSS.\n[42]BehrangFouladiandSahandGhanoun.2013. Honey,I’mhome!!-HackingZ-Wave\nHome Automation Systems. Black Hat USA (2013).\n[43]ZGhahramani.2015. Probabilisticmachinelearningandartiicialintelligence.\nNature521, 7553 (May 2015), 452ś459.\n[44]Weijia He, Maximilian Golla, Roshni Padhi, Jordan Ofek, Markus Dürmuth, Ear-\nlence Fernandes, and Blase Ur. 2018. Rethinking Access Control and Authentica-\ntion for the Home Internet of Things (IoT). In 27th USENIX Security Symposium\n(USENIX Security 18). USENIX Association, Baltimore, MD, 255ś272.\n[45]Grant Ho, Derek Leung, Pratyush Mishra, Ashkan Hosseini, Dawn Song, and\nDavid Wagner. 2016. Smart Locks: Lessons for Securing Commodity Internet of\nThings Devices. In ASIA CCS.\n[46]Justin Huang and Maya Cakmak. 2015. Supporting mental model accuracy in\ntrigger-action programming. In Ubicomp. 215ś225.\n[47]MohitIyyer,VarunManjunatha,JordanBoyd-Graber,andHalDauméIII.2015.\nDeepUnorderedCompositionRivalsSyntacticMethodsforTextClassiication.\nInProceedingsofthe53rdAnnualMeetingoftheAssociationforComputationalLin-\nguisticsandthe7thInternationalJointConferenceonNaturalLanguageProcessing\n(Volume 1: Long Papers).\n[48]RanjitJhalaandRupakMajumdar.2009. Softwaremodelchecking. ACMCom-\nputing Surveys (CSUR) 41, 4 (2009), 21.\n[49]YunhanJackJia,QiAlfredChen,ShiqiWang,AmirRahmati,EarlenceFernan-\ndes, Z. Morley Mao, and Atul Prakash. 2017. ContexIoT: Towards Providing\nContextual Integrity to Appiied IoT Platforms. In NDSS.\n[50]Sanghak Lee, Jiwon Choi, Jihun Kim, Beumjin Cho, Sangho Lee, Hanjun Kim,\nand Jong Kim. 2017. FACT: Functionality-centric Access Control System for IoT\nProgramming Frameworks. In Proceedings of the 22Nd ACM on Symposium on\nAccess Control Models and Technologies (SACMAT ’17 Abstracts). ACM, New York,\nNY, USA, 43ś54.\n[51]Chieh-Jan Mike Liang, Lei Bu, Zhao Li, Junbei Zhang, Shi Han, Börje F. Karlsson,\nDongmeiZhang,andFengZhao.2016. SystematicallyDebuggingIoTControl\nSystemCorrectnessforBuildingAutomation.In Proceedingsofthe3rdACMInter-\nnational Conference on Systems for Energy-Eicient Built Environments (BuildSys\n’16). ACM, New York, NY, USA.\n[52]Chieh-Jan Mike Liang, Börje F Karlsson, Nicholas D Lane, Feng Zhao, Junbei\nZhang, Zheyi Pan, Zhao Li, and Yong Yu. 2015. SIFT: building an internet of\nsafe things. In Proceedings of the 14th International Conference on Information\nProcessing in Sensor Networks. ACM, 298ś309.\n[53]ChangLiu,XinyunChen,EuiChulShin,MingchengChen,andDawnSong.2016.\nLatentattentionforif-thenprogramsynthesis.In AdvancesinNeuralInformation\nProcessing Systems. 4574ś4582.\n[54]Si Liu, Peter Csaba Ölveczky, Keshav Santhanam, Qi Wang, Indranil Gupta, and\nJosé Meseguer. 2018. ROLA: A New Distributed Transaction Protocol and Its\nFormal Analysis.. In FASE. 77ś93.\n[55]SiLiu,PeterCÖlveczky,QiWang,IndranilGupta,andJoséMeseguer.2018. Read\natomic transactions with prevention of lost updates: ROLA and its formal analysis.\nTechnical Report.\n[56]SiLiu,PeterCsabaÖlveczky,QiWang,andJoséMeseguer.2018. Formalmodeling\nand analysis of the Walter transactional data store. In International Workshop on\nRewriting Logic and its Applications. Springer, 136ś152.\n[57]Si Liu, Peter Csaba Ölveczky, Min Zhang, Qi Wang, and José Meseguer. 2019.\nAutomaticanalysisofconsistencypropertiesofdistributedtransaction systems\ninMaude.In InternationalConferenceonToolsandAlgorithmsfortheConstruction\nand Analysis of Systems. Springer, 40ś57.\n[58]TomLodge,AndyCrabtree,andAnthonyBrown.2018. IoTAppDevelopment:\nSupportingDataProtectionbyDesignandDefault.In Proceedingsofthe2018ACM\nInternationalJointConferenceand2018InternationalSymposiumonPervasiveand\nUbiquitous Computing and Wearable Computers (UbiComp ’18). ACM, New York,\nNY, USA, 901ś910.\n[59]Hong Luo, Ruosi Wang, and Xinming Li. 2013. A rule veriication and resolution\nframeworkinsmartbuildingsystem.In ParallelandDistributedSystems(ICPADS),\n2013 International Conference on. IEEE, 438ś439.\n[60]Meiyi Ma, S Masud Preum, W Tarneberg, Moshin Ahmed, Matthew Ruiters, and\nJohn Stankovic. 2016. Detection of runtime conlicts among services in smart\ncities. InSmart Computing (SMARTCOMP), 2016 IEEE International Conference on.\nIEEE, 1ś10.\n[61]JoséMeseguer.1992. Conditionalrewritinglogicasauniiedmodelofconcur-\nrency.Theoretical computer science 96, 1 (1992), 73ś155.\n[62]José Meseguer. 2000. Rewriting logic and Maude: Concepts and applications.\nInInternationalConferenceonRewritingTechniquesandApplications.Springer,\n1ś26.[63]Xianghang Mi, Feng Qian, Ying Zhang, and XiaoFeng Wang. 2017. An Empirical\nCharacterizationofIFTTT:Ecosystem,Usage,andPerformance.In Proceedings\nofthe2017InternetMeasurementConference (IMC’17) .ACM,NewYork,NY,USA,\n398ś404.\n[64]TomasMikolov,IlyaSutskever,KaiChen,GregSCorrado,andJefDean.2013.\nDistributedRepresentationsofWordsandPhrasesandtheirCompositionality.\nInAdvances in Neural Information Processing Systems 26.\n[65]Sirajum Munir and John A Stankovic. 2014. DepSys: Dependency aware inte-\ngrationofcyber-physicalsystemsforsmarthomes.In Cyber-PhysicalSystems\n(ICCPS), 2014 ACM/IEEE International Conference on. IEEE, 127ś138.\n[66] Alessandro ANacci, BharathanBalaji, PaolaSpoletini, RajeshGupta, Donatella\nSciuto,andYuvrajAgarwal.2015. Buildingrules:atrigger-actionbasedsystem\nto manage complex commercial buildings. In Adjunct Proceedings of the 2015\nACM International Joint Conference on Pervasive and Ubiquitous Computing and\nProceedings of the 2015 ACM International Symposium on Wearable Computers.\nACM, 381ś384.\n[67]Yuhong Nan, Zhemin Yang, Xiaofeng Wang, Yuan Zhang, Donglai Zhu, and Min\nYang.2018. FindingCluesforYourSecrets:Semantics-Driven,Learning-Based\nPrivacyDiscoveryinMobileApps.In 25thAnnualNetworkandDistributedSystem\nSecuritySymposium,NDSS2018,SanDiego,California,USA,February18-21,2018.\n[68]Chandrakana Nandiand MichaelD Ernst.2016. AutomaticTriggerGeneration\nfor Rule-based Smart Homes. In PLAS. 97ś102.\n[69]Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic con-\nstruction,evaluation andapplication ofawide-coverage multilingualsemantic\nnetwork. Artiicial Intelligence 193 (2012), 217 ś 250.\n[70]Dang Tu Nguyen, Chengyu Song, Zhiyun Qian, Srikanth V. Krishnamurthy,\nEdwardJ.M.Colbert,andPatrickMcDaniel.2018. IotSan:FortifyingtheSafety\nofIoTSystems.In Proceedingsofthe14thInternationalConferenceonEmerging\nNetworking EXperiments and Technologies (CoNEXT ’18). ACM, New York, NY,\nUSA, 191ś203.\n[71]XiangPan,YinzhiCao,XuechaoDu,BoyuanHe,GanFang,RuiShao,andYan\nChen. 2018. FlowCog: Context-aware Semantics Extraction and Analysis of\nInformationFlowLeaksinAndroidApps.In 27thUSENIXSecuritySymposium\n(USENIX Security 18). USENIX Association, Baltimore, MD, 1669ś1685.\n[72]RahulPandita,XushengXiao,WeiYang,WilliamEnck,andTaoXie.2013. WHY-\nPER: Towards Automating Risk Assessment of Mobile Applications. In Presented\naspartofthe22ndUSENIXSecuritySymposium(USENIXSecurity13).USENIX,\nWashington, D.C., 527ś542.\n[73]Chris Quirk, Raymond J Mooney, and Michel Galley. 2015. Language to Code:\nLearning Semantic Parsers for If-This-Then-That Recipes.. In ACL (1). 878ś888.\n[74]A.Rahmati,E.Fernandes,K.Eykholt,andA.Prakash.2018. Tyche:ARisk-Based\nPermission Model for Smart Homes. In 2018 IEEE Cybersecurity Development\n(SecDev), Vol. 00. 29ś36.\n[75]CamiloRocha, JoséMeseguer,andCésar Muñoz.2017. Rewriting modulo SMT\nand open system analysis. Journal of Logical and Algebraic Methods in Program-\nming86, 1 (2017), 269ś297.\n[76]Eyal Ronen and Adi Shamir. 2016. Extended functionality attacks on IoT devices:\nThe case of smart lights. In EuroS&P. 3ś12.\n[77]Roei Schuster, Vitaly Shmatikov, and Eran Tromer. 2018. Situational Access Con-\ntrol in the Internet of Things. In Proceedings of the 2018 ACM SIGSAC Conference\non Computer and Communications Security (CCS ’18). ACM, New York, NY, USA,\n1056ś1073.\n[78]VijaySivaraman,DominicChan,DylanEarl,andRoksanaBoreli.2016. Smart-\nPhones Attacking Smart-Homes. In WiSec. 195ś200.\n[79]Vijay Sivaraman, Hassan Habibi Gharakheili, Arun Vishwanath, Roksana Boreli,\nand Olivier Mehani. 2015. Network-level security and privacy control for smart-\nhome IoT devices. In WiMob. 163ś167.\n[80]Yan Sun, Xukai Wang, Hong Luo, and Xiangyang Li. 2015. Conlict detection\nschemebasedonformalrulemodelforsmartbuildingsystems. IEEETransactions\non Human-Machine Systems 45, 2 (2015), 215ś227.\n[81]Milijana Surbatovich, Jassim Aljuraidan, Lujo Bauer, Anupam Das, and Limin\nJia. 2017. Some Recipes Can Do More Than Spoil Your Appetite: Analyzing\nthe Security and Privacy Risks of IFTTT Recipes. In Proceedings of the 26th\nInternational Conference on World Wide Web. 1501ś1510.\n[82]Moin Syed and Sarah C. Nelson. 2015. Guidelines for Establishing Reliability\nWhen Coding Narrative Data. Emerging Adulthood 3, 6 (2015), 375ś387.\n[83]Kazuki Tada, Shin Takahashi, and Buntarou Shizuki. 2016. Smart home cards:\nTangible programming with paper cards. In Proceedings of the 2016 ACM Interna-\ntionalJointConferenceonPervasiveandUbiquitousComputing:Adjunct .ACM,\n381ś384.\n[84]Yuan Tian, Nan Zhang, Yueh-Hsun Lin, Xiaofeng Wang, Blase Ur, Xianzheng\nGuo, and Patrick Tague. 2017. SmartAuth: User-Centered Authorization for the\nInternet of Things. (2017).\n[85]BlaseUr,ElyseMcManus,MelwynPakYongHo,andMichaelL.Littman.2014.\nPractical Trigger-action Programming in the Smart Home. In CHI.\n[86]Blase Ur, Melwyn Pak Yong Ho, Stephen Brawner, Jiyun Lee, Sarah Mennicken,\nNoah Picard, Diane Schulze, and Michael L Littman. 2016. Trigger-action pro-\ngramminginthewild:Ananalysisof200,000iftttrecipes.In Proceedingsofthe\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n14522016 CHI Conference on Human Factors in Computing Systems . ACM, 3227ś3231.\n[87]QiWang,Wajih UlHassan,AdamBates,andCarlGunter.2018. FearandLogging\nin the Internet of Things. In Network and Distributed Systems Symposium.\n[88]Jong-bum Woo and Youn-kyung Lim. 2015. User experience in do-it-yourself-\nstyle smart homes. In Proceedings of the 2015 ACM international joint conference\non pervasive and ubiquitous computing. ACM, 779ś790.\n[89]TianlongYu,VyasSekar,SrinivasanSeshan,YuvrajAgarwal,andChenrenXu.\n2015.Handlingatrillion(unixable)lawsonabilliondevices:Rethinkingnetwork\nsecurity for the Internet-of-Things. In HotNets.\n[90]Lefan Zhang,Weijia He,Jesse Martinez,Noah Brackenbury, ShanLu, andBlase\nUr. 2019. AutoTap: synthesizing and repairing trigger-action programs using\nLTL properties. In Proceedings of the 41st International Conference on Software\nEngineering. IEEE Press, 281ś291.\nA IFTTT APPLET\nA.1 Filter Code\nInListing2,weshowanexamplesnippetofiltercode.Thecode\nsnippet conditionally execute actions based on the time of a day.\nListing 2: An example snippet of IFTTT applet ilter code.\n1vartimeOfDay = Meta.currentUserTime.hour()\n2\n3if(timeOfDay >= 22 || timeOfDay < 8 ) {\n4// Skip sending me a push notification\n5I fNotifications.sendNotification.skip( \"Too late\" )\n6}else{\n7// Skip saving the article to Feedly\n8F eedly.createNewEntryFeedly.skip( \"I already know\" )\n9}\nB\nINTER-RULE VULNERABILITIES\nIn Table 6, we show the inter-rule vulnerabilities considered by\nexisting work.\nTable 6: The types of inter-rule vulnerabilities considered by exist-\ning work.\nVulnerabilities Considered\niRulerconlict, loop, revert, duplicate, group duplicate\ncondition\nbypass, action blocking, not enough rules\nSoteria [30] conlict, duplicate, inconsistent events\nIoTSan [70] conlict, duplicate\nSIFT [52] conlict\nHomeGuard [32] conlict, duplicate, loop, condition disabling, condition enabling\nIoTGuard [31] conlict, duplicate, loop\nC IOT SYSTEM MODELING\nC.1\nDevice/Service Metadata\nInListing3,weshowthedevicemetadataofasimpleheaterwitha\nswitchattribute and two commands turn_onandturn_off.\nListing 3: An example device metadata of a simple heater.\n1{\n2\" ModelType\" :\"SimpleHeater\" ,\n3\" Attributes\" :[\n4 {\n5 \" Name\":\"switch\" ,\n6 \" Type\":\"bool\",\n7 \" Default\" :\"false\"\n8 }\n9],\n10\" Commands\" :[\n11 {\n12 \" Name\":\"turn_on\" ,\n13 \" Arguments\" :[],\n14 \" Transition\" :{15 \" assignments\" :{\n16 \" switch\" :\"true\"\n17 }\n18 },\n19 \" Effects\" :[\n20 {\n21 \" EnvironmentalVariable\" :\"Temperature\" ,\n22 \" Effect\" :\"Increase\" ,\n23 \" Rate\":1\n24 }\n25 ]\n26 },\n27 {\n28 \" Name\":\"turn_off\" ,\n29 \" Arguments\" :[],\n30 \" Transition\" :{\n31 \" assignments\" :{\n32 \" switch\" :\"false\"\n33 }\n34 }\n35 }\n36]\n37}\nIn Listing 4, we show the generated service metadata of the\nLockitron8service in IFTTT with our NLP-aided information low\nanalysis tool. The Lockitron service has two triggers łLockitron\nlockedžand łLockitron unlockedž, andtwo actionsłLockLockitronž\nand łUnlock Lockitronž.\nListing4:TheservicemetadataofLockitrongeneratedwiththehelp\nof our NLP tool.\n1{\n2\" ServiceType\" :\"Lockitron\" ,\n3\" Attributes\" :[],\n4\" Commands\" :[\n5 {\n6 \" Name\":\"Lock_Lockitron\" ,\n7 \" Arguments\" :[\n8 {\n9 \" Name\":\"lock_id\" ,\n10 \" Type\":\"string\"\n11 }\n12 ],\n13 \" Transition\" :{\n14 \" Events\" :[\n15 {\n16 \" Name\":\"Lockitron_Locked\"\n17 }\n18 ]\n19 }\n20 },\n21 {\n22 \" Name\":\"Unlock_Lockitron\" ,\n23 \" Arguments\" :[],\n24 \" Transition\" :{\n25 \" Events\" :[\n26 {\n27 \" Name\":\"Lockitron_Unlocked\"\n28 }\n29 ]\n30 }\n31 }\n32]\n33}\n8https://ifttt.com/Lockitron\nSession 7A: Internet of Things\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1453"}
{"title": "DeMiCPU: Device Fingerprinting with Magnetic Signals Radiated by CPU", "content": "DeMiCPU: Device Fingerprinting with Magnetic Signals\nRadiated by CPU\nYushi Cheng\nZhejiang University\nyushicheng@zju.edu.cnXiaoyu Ji∗\nZhejiang University\nxji@zju.edu.cnJuchuan Zhang\nZhejiang University\njuchuanzhang@zju.edu.cn\nWenyuan Xu\nZhejiang University\nwyxu@zju.edu.cnYi-Chao Chen\nUniversity of Texas at Austin\nyichao@utexas.edu\nABSTRACT\nWiththewidespreaduseofsmartdevices,deviceauthenticationhas\nreceived much attention. One popular method for device authen-\ntication is to utilize internally-measured device fingerprints, such\nas device ID, software or hardware-based characteristics. In this\npaper, we propose DeMiCPU , a stimulation-response-based device\nfingerprinting technique that relies on externally-measured infor-\nmation, i.e., magnetic induction (MI) signals emitted from the CPU\nmodulethatconsistsoftheCPUchipanditsaffiliatedpowersupply\ncircuits. The key insight of DeMiCPU is that hardware discrepancies\nessentially exist among CPU modules and thus the corresponding\nMI signals make promising device fingerprints, which are difficult\nto be modified or mimicked. We design a stimulation and a discrep-\nancy extraction scheme and evaluate them with 90 mobile devices,\nincluding 70 laptops (among which 30 are of totally identical CPU\nand operating system) and 20 smartphones. The results show that\nDeMiCPU can achieve 99 .1% precision and recall on average, and\n98.6%precisionandrecallforthe30identicaldevices,withafinger-\nprinting time of 0 .6s. In addition, the performance can be further\nimproved to 99 .9% with multi-round fingerprinting.\nCCS CONCEPTS\n•Security and privacy →Security services.\nKEYWORDS\nDevice Fingerprinting; Electromagnetic Radiation; CPU; Smart De-\nvices.\nACM Reference Format:\nYushi Cheng, Xiaoyu Ji, Juchuan Zhang, Wenyuan Xu, and Yi-Chao Chen.\n2019. DeMiCPU: Device Fingerprinting with Magnetic Signals Radiated by\nCPU. In2019ACMSIGSACConferenceonComputerandCommunications\nSecurity (CCS’19), November 11–15, 2019,London, UnitedKingdom. ACM,\nNew York, NY, USA, 14 pages. https://doi.org/10.1145/3319535.3339810\n∗Corresponding faculty author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nCCS ’19, November 11–15, 2019, London, United Kingdom\n© 2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-6747-9/19/11...$15.00\nhttps://doi.org/10.1145/3319535.3339810\nAccess\nDenied\nDeMiCPU SensorDeMiCPU Server\nAccess\nPermitted\nAuthorized \nDeviceUnauthorized \nDevice\nDeMiCPU SensorCPU MI Signal\nOpen\n XXX fileOpen\n XXX file\nFigure 1: Based on CPU fingerprints, DeMiCPU provides the\nability to fingerprint devices for software and applications.\n1 INTRODUCTION\nMobile devices have emerged as the most popular platforms to\nassist daily activities and exchange information over the Internet.\nAccording to Gartner [ 16], there are more than 11 billion phones,\ntabletsandlaptopsbytheendof2018.Alongwiththerapidgrowth\nis the rising demand of deviceauthentication : it is useful for applica-\ntions to recognize whether they are executing on the same device\nas the previously registered one, e.g., during payments, to ensure\nthe safety of personal privacy or cyber assets.\nOne of the strategies for device authentication is devicefinger-\nprinting. Existing device fingerprinting solutions are mainly based\noninternaldevice information (e.g., IMEI (device ID), serial num-\nbersoflaptops),orbuiltoutofsoftwareorhardwarecharacteristics.\nSoftware-based fingerprints utilize wireless traffic patterns [ 33],\nbrowser properties [ 46], and etc., while hardware-based finger-\nprints utilize hardware characteristics such as clock skews [ 26,34],\naccelerometers[ 13],gyroscopes[ 2],microphones[ 11],cameras[ 14,\n29], and Bluetooth implementation [1].\nInthispaper,weproposetofingerprintdevicesexploitingthefea-\ntured electromagnetic interference (EMI) signals radiated by CPU\nmodules on devices, which we call CPUfingerprints. The advantage\nof such a CPU fingerprint is that it can be measured externally\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1149ratherthan internally bytheoperatingsystem(OS),whichcouldbe\na useful feature for applications on external devices to authenticate\nthe devices. In addition, a CPU module is indispensable for almost\nall mobile or smart devices, and thus the CPU fingerprint is likely\ntobemoreuniversalcomparedwithaforementionedbuilt-insensor\nbased approaches.\nBased on it, we design DeMiCPU , a device fingerprinting scheme\nconsistingofatrusted DeMiCPU server,astimulationprogramonthe\ntarget device, and a trusted stand-alone DeMiCPU capturing module\nwithabuilt-inmagneticsensor(inshort DeMiCPU sensor),asshown\nin Fig. 1, and it works as follows. Once an application requests for\ndevice fingerprinting, DeMiCPU starts the stimulation program, and\ntheDeMiCPU sensormeasuresandpackagesthemeasurementswith\nprotectionanduploadsthepackagedmeasurementstothe DeMiCPU\nserverforfingerprintmatching.Anattackermaytrytoimpersonate\na target device by emulating the EMI radiated by its CPU module,\nbut it is almost impossible to produce an EMI pattern close enough\nto that of the target device, as analyzed in Sec. 7.\nDeMiCPU is promising yet challenging. First, EMI spans a wide\nspectrum, including high frequency that may produce data at the\nrate ofGbps. Such computation and communication costs are unac-\nceptable, especially for the DeMiCPU sensor. Second, all electronic\ncomponents inside a device emit EMI and their operation status\naffects the level of EMI. It is difficult, if ever possible, to control\nthe status of each component across various attempts of measure-\nment.Besides,itisunclearwhethertheEMIradiatedfromthesame\ndevice at various time instants or locations is consistent and the\nones from different devices are distinct. Last but not least, the EMI\nradiation may contain a large amount of noise and how to extract\nfingerprints efficiently out of the noisy EMI radiation is nontrivial.\nThis paper addresses aforementioned challenges and validates the\nfeasibility of CPU fingerprint.\nWhichfrequencytomeasureandhowtomeasure? After careful\nanalysis and experimental validation, we choose low-frequencymagnetic induction (MI) signals (\n<100kHz). EMI generated by\nelectronic components includes both electromagnetic radiation\n(EMR) in the far field ( >two wavelengths) and magnetic induction\n(MI) in the near field ( <a wavelength). Since EMR is the main\ncause that affects interoperability of devices, it is suppressed for\nelectromagneticcompatibility[ 18].YetMIsignalsdominatethenear\nfield and do not propagate as far as EMR. Being less a concern of\ninterference, MI signals are not intentionally suppressed and serve\nas an excellent candidate for extracting hardware fingerprints.\nHow to induce consistent MI? It is almost impossible to control\nthe status of each component, and thus we focus on controllingthe one that emits the majority of MI signals, i.e., the CPU mod-\nule that consists of the CPU chip and its affiliated power supply\ncircuits. In this way, MI signals contributed by other components\non the motherboard can be neglected. CPU fingerprints are made\npossible because even for devices of the same model, CPU mod-\nules are discrepant due to hardware diversities introduced during\nthe manufacturing process. However, various applications may\nlead to various MI signals of the CPU module (as our experiments\nconfirmed). To ensure that the CPU load and operation status are\nsimilar across measurements, we analyze the cause and influencing\nfactors of the emitted MI signals and design a set of instructions\nFigure 2: An illustration of a simplified CPU module. A\nDC/DC converter is connected to the CPU chip for voltageconversion. The inductor in the DC/DC converter can pro-ducestrongMIsignalswhenlargecurrentsflowthroughit.\nto generate an identical 100% utilization stimulation to the CPU\nmodule.\nHow to extract fingerprints despite of noise? To distinguish the\nsubtle discrepancies of CPU modules when the measurement of MI\nsignals could be noisy, we remove the effects of the geomagnetic\nfield and environmental noise in the pre-processing phase before\nextractingasetof15carefully-selectedfeatures,whichservesasthefingerprintofthedevice.Tofurtherensurehighaccuracy,reliability\nand usability in DeMiCPU , we compare 10 common classifiers to\nelect the appropriate classification algorithm. In summary, our\ncontribution includes the following:\n•We propose to fingerprint mobile devices by monitoringthe MI signals emitted from the CPU module. To the bestof our knowledge, this is the first work to attempt device\nfingerprinting based on the fingerprints of CPU modules.\n•We design an efficient MI-based fingerprinting scheme con-\nsisting of identical stimulation generation, effective feature\nextractionandvalidfingerprintmatching,whichcanidentify\ndevices reliably and accurately.\n•We validate DeMiCPU on 90 mobile devices, including 70 lap-\ntops and 20 smartphones. The results show that DeMiCPU\ncanachieve99 .1%precisionandrecallonaverage,and98 .6%\nprecision and recall for 30 identical devices, with a finger-\nprintingtimeof0 .6s.Bothprecisionandrecallcanbefurther\nimproved to 99 .9% with multi-round fingerprinting.\n2 BACKGROUND\n2.1 Magnetic Induction of Electronic Devices\nAll electronic components emit electromagnetic interference (EMI)\nwhen currents flow. EMI emitted from electronic components (e.g.,\nCPUs, fans, GPUs) includes two types: high-frequency electromag-\nnetic radiation (EMR) signals and low-frequency magnetic induc-\ntion (MI) signals. EMR refers to electromagnetic waves that are\nsynchronized oscillations of electric and magnetic fields and propa-\ngate at the speed of light. High-frequency EMR waves are mainly\nat an order of MHzor above, and are always effectively reduced\nor shielded [ 18] to eliminate interference with other electronic\ncomponents or devices. By contrast, MI signals are non-radiative\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1150waves generated by currents and are typically not intentionally\nsuppressed. In addition, MI signals have a relatively larger strength\nand a lower frequency than EMR, and thus can be measured by\nlow-frequency magnetic sensors. Therefore, MI signals are good\nrepresentatives of EMI emitted from a device.\n2.2 The CPU Module\nThe CPU module of a device refers to the CPU chip and its affili-\nated DC/DC converter. The computation-intensive nature of the\nCPU chip draws heavy currents from the DC/DC converter, which\ngenerate strong MI signals.\nCPU.A CPU chip consists of hundreds of millions of CMOS\n(complementary metal oxide semiconductor) transistors arranged\nin a lattice form, which performs basic arithmetic, logical, control\nand input/output (I/O) operations. The CPU current depends onthe power consumption of the CMOS circuits, which has three\ncomponents: static power dissipation, short-circuit power dissipa-\ntion, and dynamic power dissipation, mathematically denoted as\nfollows [38]:\nPcmos=Pstatic+Pshort−circuit+Pdynamic (1)\nPstatic, a.k.a., leakage power dissipation, is a steady and constant\nenergycostcausedbytheleakagecurrentsoftransistors. Pshort−circuit\nariseswhentwotransistorsinaCMOSgateareonatthesametime,\nwhich creates a short circuit from the voltage supply to the ground\nand thus consumes energy. Pdynamic is caused by the switching of\nCMOS gates. Energy consumption of a CPU mainly depends on the\ndynamic power dissipation of the CMOS lattice, which is roughly\nequal to the energy change in the output capacitance of CMOS\ntransistors. Average power consumption of a multi-core CPU can\nbe modeled as follows [39]:\nPavд=N/summationdisplay.1\ni=1CiV(α)2AF(α)\n2(2)\nwhereNisthenumberofCPUcores. Ci,A,VandFareinfluencing\nfactors, with their meanings summarized in Tab. 1. VandFare\nfurther related to the CPU load αdue to the power-management\ntechnique DVFS (dynamic voltage and frequency scaling) [ 28] ap-\nplied by modern devices. DVFS decreases the clock frequency and\nallows a corresponding reduction in the supply voltage for energy\nsaving. For example, for a ThinkPad T440p laptop, VandFare\n0.899Vand 3095 .95MHzwhen the CPU load is 100%, and they\ndropto0 .668Vand798.95MHzwhentheCPUbecomesidle(2 −3%\nload on average). As all the four factors are hardware related andCMOS circuits are various across CPUs, those factors are distinct\nfrom device to device (detailed in Sec. 2.3).\nIn this section, we begin with the principle of magnetic signals,\nthen elaborate how CPU modules can produce magnetic signals,and finally explain why magnetic signals from CPU modules are\ndifferentiated in nature.\nDC/DC converter. Due to the difference of voltage levels be-\ntweentheCPUandthepowersupplysystem(eitherabatteryoran\nexternal power source), a DC/DC converter is placed close to the\nCPU chip to convert a high voltage to a low one [ 10]. In Fig. 2, we\nshow the key components of a DC/DC converter and its relation-\nship with the CPU chip. In principle, the high-frequency switch\n(a) Heatmap of MI signals from T440p.\n (b) Physical structure of T440p.\nFigure3:InvestigationofMIsignalsemittedfromtheT440plaptop. (a) The heatmap of measured MI signal strength. (b)Physical structure of the laptop.\nin the DC/DC converter works in a duty-cycle mode to generate a\nlower voltage. Electronic components including the capacitors, in-\nductors, and diodes are utilized to make the output voltage smooth\nand continuous. The regulated voltage and currents are then fed\ninto the CPU chip to satisfy its computation requirements.\nIn short, CPU chips nowadays exploit a reduced voltage for en-\nergyefficiency,butincurheavycurrentswhenperformingcomputation-\nintensive tasks. The heavy currents flowing through the CPU mod-\nule generate strong MI signals, which are further amplified by the\ninductor inside the DC/DC converter, due to the effect of coils.\n2.3 CPU Module Discrepancy\nHardware discrepancies exist among devices, or more precisely,\ntheir CPU modules. For CPUs of various models, all the four fac-\ntorsCi,V,AandFthat affect the CPU power consumption, can\nbe different due to the discrepancies in hardware structure andspecification. Even for CPUs of the same model, e.g., Intel Corei5-3210M for ThinkPad T440p laptops, discrepancies exist due tothe imperfections introduced during the manufacturing process.\nAs shown in Tab. 1, manufacture techniques have influence upon\nthreefactors Ci,V,andF,i.e.,thetransistorsizes,workingvoltages,\nand working frequencies of CPU chips can be distinct. Besides,\nthe DC/DC converter of the CPU module further enlarges the dif-\nferences. Therefore, MI signals from CPU modules of the sameor various models are distinct due to the hardware discrepancies\nacross devices.\nInsummary,MIsignalsfromCPUmodulesaredifferentinnature\nandcanserveasacandidateofdevicefingerprints.Inaddition,CPU\nloadαaffects MI signals since it influences VandF. As a result, MI\nsignals can be strengthened by increasing the CPU load. Thus, to\nmaintain a stable observation of MI signals, the CPU load shall be\naccurately controlled.\nTable 1: Impact factors of CPU power consumption.\nPavдFactorsMeaningHα\nCi/checkCMOS capacitance, related to\nthe transistor size and the wire length\nV/check/check Supply voltage to CPU\nA/check Average switching frequency of transistors\nF/check/check Clock frequency\nH: Hardware related. α: CPU load.\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n11510 0.2 0.4 0.6 0.8 1−30−20−10010\nt(s)B(uT)100% idle\nFigure 4: MI signal is highly\nrelated to the CPU workingperiod.100101102103104105\nFrequenc y(Hz)01500300045006000AmplitudeT440p-1, CPU(T440p-1)\nT440p-1, CPU(T440p-2)\nT440p-2, CPU(T440p-2)\nT440p-2, CPU(T440p-1)\nFigure 5: Histograms of MI\nsignals before and after ex-changing CPUs.10010110210310410501500300045006000\nFrequency(Hz)AmplitudeInstant−1\nInstant−2\nInstant−3\nInstant−4\nInstant−5\nFigure 6: Histograms of MIsignals at five instants.10010110210310410501500300045006000\nFrequency(Hz)AmplitudeLocation−1\nLocation−2\nLocation−3\nFigure 7: Histograms of MIsignals at three locations.\n3 PRELIMINARY ANALYSIS\nIn this section, we verify the feasibility of CPU fingerprints em-\npirically. As shown in Fig. 10, we collect MI signals emitted from\nthe CPU models with a magnetic-field sensor DRV425 [ 22]f r o m\nTexas Instruments (TI), and conduct AD conversion with a data\nacquisition (DAQ) card U2541A [ 25] from Keysight at a sampling\nrate of 200 kHz. Each collection lasts for 1 s(0.5sis shown to be\nsufficient to fingerprint a device in Sec. 6).\n3.1 MI Signals from CPU Module\nDoes the CPU module produce the strongest MI? To verify\nwhether the CPU module emits the strongest MI signals among\nall components, we execute a while(1) loop (in C++) to generate\na CPU utilization of 100%, and measure the MI signal strength by\nplacing the sensor on various spots (33 spots in total) of a Lenovo\nThinkPad T440p laptop’s surface (device No. 31 in Tab. 3). We plot\nthe heatmap of the MI signals measured across the laptop’s surfaceinFig.3(a),fromwhichwecanfindthatthestrongestMIsignalsare\nobserved at “ S” and “D” keys. Dismantling the laptop reveals that\ntwo inductors of the DC/DC converter that powers the CPU chip\nare located right below these two keys, as shown in Fig. 3(b). This\nindicates that the CPU module, specifically the DC/DC converter,\nproduces the strongest MI signals when the CPU is under a high\nload.\nDoes the CPU load affect the MI Signals? To understand\nwhether the variation of the CPU load affects MI signals emitted\nfrom the CPU module, we force the CPU to work in a duty-cyclemode at a frequency of 5\nHz, i.e., alternating between a 100% uti-\nlization and an idle mode at an interval of 100 ms. Throughout the\nexperiments, the sensor was placed above the CPU module, i.e., on\nSandDkeys,tomeasuretheemittedMIsignals.Theresultsshown\nin Fig. 4 confirm that the CPU load does affect the MI signals. Thus,it is important to create a consistent software stimulation to ensure\nthe same CPU load such that the fingerprints generated from the\nCPU module are consistent for the same device.\nDo other componentsaffect the MI Signals? Modifying the\nstatus of other computer components may lead to variation of the\nMI signals. However, MI signals generated by others attenuate\nrapidly with distance due to the near field effect. We observe no\nnoticeable difference between the MI signals collected right above\nthe CPU module when the fan was turned on and off. As a re-sult,\nDeMiCPU does not control other components during device\nfingerprinting.100101102103104105\nFrequenc y(Hz)01500300045006000Amplitude\nT440p-1\nT440p-2\nXPS13\nR720\nXPS14\nFigure 8: Histograms of MI signals from 5 laptops. Even for\nthetwolaptopsofthesamemodel,i.e.,T440p-1andT440p-2,the MI signals show discrepancies.\n3.2 Evidence of CPU Fingerprint\nTo explore the existence of CPU fingerprint, we conduct an ex-\nperiment with 5 laptops, which are two Lenovo ThinkPad T440p\n(T440p-1 and T440p-2, for short), Dell XPS 13, Lenovo R720, and\nDell XPS 14. Detailed specifications of these laptops (Device No. 31,No. 32, No. 61, No. 49 and No. 62) are summarized in Tab. 3, among\nwhich two laptops (T440p-1 and T440p-2) are from the same model\nand installed with the same operating system and the rest are of\ndifferent models.\nWe execute the while(1) program to keep the CPU at a 100%\nutilization and measure MI signals above the CPU module of each\nlaptop. We then perform Fast Fourier Transform (FFT) on the col-\nlected MI signals and plot their one-dimensional histograms inFig. 8, with a logarithmic bin size of 10\n0.1. The histogram repre-\nsents the frequency distribution of the MI signals, from which we\ncan observe distinct “patterns” for the 5 laptops in the frequency\nrange from 20 Hzto 10kHz. Especially, laptops of different models\nshow more discrepancies compared with those of the same model.\nNevertheless, the two T440p laptops remain distinguishable even\nonly with one histogram feature.\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1152The above findings shed light on the existence of CPU finger-\nprints. However, to make the fingerprint robust and accurate, es-\npecially for devices from the same model, more features in both\ntime and frequency domains should be investigated to enhance the\nfingerprint.\n3.3 What Contributes to CPU Fingerprint?\nTo understand whether the fingerprint is created by the CPU chip,\nthe DC/DC converter, or the combination of both, we exchange\nthe CPUs of the two T440p laptops and obtain two “new” laptops\n(T440p-1 with CPU from T440p-2 and T440p-2 with CPU from\nT440p-1). Similar to previous experiments, the CPU utilization is\nsetto100%duringcollectionandMIsignalsaremeasuredabovethe\nCPU module before and after swapping the CPUs. The results in\nFig. 5 show that MI signals for four configurations are all different,\nwhichindicatesthatthefingerprintoriginatesfromthecombination\nof the CPU chip and its affiliated DC/DC converter, i.e., the CPU\nmodule.\n3.4 Temporal and Spatial Consistency\nThe MI signal from a device should be consistent across time and\nspace to serve as a robust fingerprint. To investigate the temporal\nconsistency, we collect 30 MI signals from the T440p-1 laptop at 5\ntimeinstantsacrosstwodays,i.e.,thefirstthreeinstantsarewithin\none day (morning, afternoon and evening) and the other two are\nin the next day (morning and evening). The T440p-1 laptop is set\nto 100% utilization and one-second MI signals are collected each\ntime. The results depicted in Fig. 6 indicate that MI signals remain\nconsistent regardless of time.\nTo investigate the spatial consistency, we collect 30 MI signals\nfrom the T440p-1 laptop at 3 locations (one in a lab, two at home;\nand the two places are about 3 kilometers apart). Note that we\ndo not intentionally avoid or remove metal and magnetic materi-\nals around the collecting device during experiments. As a result,\ndue to the impact of the earth’s magnetic field and ambient noise\n(especially in the lab, with numerous electronic devices surround-\ning), the initial magnetic magnitude of the sensor is geo-spatial\ndependent. However, the strength of the earth’s magnetic field and\nambient noise is relatively static at a specific spot and thus mainly\ncontributes to the constant part of the collected MI signals. As aresult, the FFT operation shall have eliminated the impact of the\nearth’s magnetic field as well as the ambient noise. The results in\nFig. 7 also validate that the frequency-domain MI signals remain\nconsistent regardless of locations.\nAlltheseexperimentsprovidestrongevidencethatCPUmodules\ncanproducestrongMIsignalsthatmaintaingooddistinguishability\nand consistency, and the MI signals from CPU modules serve as\npromising device fingerprints.\n4 THREAT MODEL\nIn this paper, we have the following assumptions.\nImpersonation. Although it is feasible for attackers to launch\na Denial-of-Service (DoS) attack by emitting EMI or even placing a\nstrongmagnetclosetothe DeMiCPU sensor,thegoaloftheattackers\nis to impersonate a legitimate device. Thus, we focus on replay or\nmimic attacks.0 0.1 0.2 0.3 0.4 0.5 0.6−30−15015\nt(s)B(uT)Preamble )LQJHUSULQWLQJ\nFigure 9: Structure of the MI signal, including a 0.1spream-\nble and a 0.5sfingerprinting sample.\nAcquisition of Similar Device. We assume the adversary can\nobtain similar devices as the target one, e.g., a device of the same\nmodel, to imitate the target device and have full control of them.\nSecureCommunication. We assume that the communication\nbetween the DeMiCPU sensor and the DeMiCPU server and between\nthe server and the software (application) is secure. For instance,\nDeMiCPU can package the MI measurements or matching results\nwith encryption, by the well-known secure communication pro-\ntocols [3,31,32]. As a result, the attacker cannot create forged\nmeasurements or modify the measurements/matching results.\n5 DESIGN\nInthissection,wedescribethe3sub-modulesoftheoverall DeMiCPU\nsystem: (1) Fingerprint generation; (2) Fingerprint extraction; (3)\nFingerprint matching.\n5.1 DeMiCPUFingerprint Generation\nTo obtain MI measurements that produce consistent fingerprints, it\nis important to solve the following two challenges.\n•How to stimulate the CPU such that it generates the MI\nsignal that can produce a consistent device fingerprint?\n•How to collect and identify the MI signal segment that mapsto the one under stimulation even if an attacker may disturb\nthe communication between the stimulation program and\nthe trusted capturing sensor?\nToaddressthesetwochallenges,wedesignthestimulationprogram\nsuchthatitproducestheMIsignaltraceinFig.9,whichiscomposed\nof a preamble and a fingerprinting signal that are both generated\nby controlling the CPU load in a proactive way. As thus, DeMiCPU\nonly needs to transmit a signal as short as 0 .6sfor fingerprinting.\n5.1.1 Preamble. To identify the MI signal segment that is under\nstimulation, a preamble is used for the trusted capturing sensor to\ndetect the start of the fingerprinting signal. DeMiCPU stimulates the\ndevice such that a unique MI pattern is generated as a preamble,\ntherebyallowingthesensortoidentifyitwithcross-correlation.We\nrealize the preamble by manipulating the CPU load and generate a\nsequence of [1,0,1,0] (“1” for full-utilization mode and “0” for idle\nmode) as shown in Fig. 9, which lasts for 100 msin total.\n5.1.2 Stimulating CPU. The strength of the MI signals emitted\nfrom the CPU module depends on the current, which is related to\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1153the CPU load. In order to obtain stable MI signals to produce CPU\nfingerprints, we stimulate the CPU by controlling its utilization\nratio. Without loss of generality, the total CPU utilization is the\nsum of CPU utilization from all running processes, including both\nsystem and user processes, which can be modeled as follows:\nCPU_util=Sys_processes +User_processes (3)\nUtilization Ratio. One intuitive question is what utilization\nratio to use, 100%, 50%, or other values? In fact, it is difficult toprecisely control the utilization since 1) it is hard to accurately\nrestrictsystemanduserprocessestoacertainlevel,and2)theCPU\nscheduling policy further worsens the problem. For instance, 50%\nCPU utilization means that the CPU works in 5 clock cycles andis idle in the remaining 5. Without inspecting and modifying thescheduling algorithm, it is almost impossible to ensure that the\nCPU behaves the same in all clock cycles.\nTo address it, we choose to keep the CPU running in the full-\nutilization (100%) mode to obtain an identical output. Another ben-\nefit of such an implementation is that higher CPU utilization gen-\nerates stronger MI signals, which helps to lighten the impact ofambient noise. We achieve the full-utilization mode by invoking\nCPU-consuming instructions, such as while(1) in our implemen-\ntation.Asthus,systemprocesses, DeMiCPU stimulationprocess,and\nother user processes together compose the 100% utilization.\nDeMiCPU Priority. During fingerprinting, however, other user\nprocesses,i.e.,backgroundapplications,arenotlikelytobethesame,\nwhich may render the stimulation nonidentical. To eliminate the\ninfluence of other user processes, we assign a superior priority to\ntheDeMiCPU stimulationprogram,whichishigherthanthebaseone\nof other user processes yet lower than that of the system processes\nsince they only account for 1-2% CPU utilization on average.\nMainstreamoperatingsystemssuchasWindows,Linux,andMac\nOS X, are all able to support such an implementation. For instance,\nWindows implements a priority-driven, preemptive scheduling sys-\ntem, where the highest priority runnable threads are executed first.\nEach thread, which is the smallest unit of program execution flow,\nhas a base priority as a function of its process priority class andrelative thread priority. Normally, user applications and services\nstart with a base priority level 8, i.e., both process and thread pri-\norities are normal[37]. Thus, we shall at least assign the DeMiCPU\nstimulation program with a priority level higher than that.\nInparticular,weexaminethehighestpriorityoftheuserthreads,\nwhich is usually a priority level 8 as mentioned before. Then, we\nassign a higher priority to the DeMiCPU thread, e.g., a normalpro-\ncess priority but an above normal thread priority, i.e., a priority\nlevel 9, to eliminate the impact of other user processes. In addition,\nsince modern CPU chips support multi-core and multi-thread, we\nbind a stimulation thread to each available logical processor core,\nincluding the virtual ones created by Hyper-Threading [ 30]. As\nthus, the CPU utilization under stimulation is as follows:\nCPU_util_stimu=Sys_processes +DeMiCPU =100% (4)\nFeedback. In general, such a design is able to generate an iden-\ntical stimulation. However, in a rare case, a thread with a higher\npriority may be launched during fingerprinting, making the stimu-\nlation different than planned. To further guarantee the validity of\ntheDeMiCPU stimulation, we introduce a feedback mechanism, i.e.,Algorithm 1: DeMiCPU Stimulation\n1CPU_Frequency ←Get_Current_CPU_Freqency()\n2ifCPU_Frequency >threshold _1then\n3C_priority←Get_Current_Highest_Priority()\n4//get the highest priority level of running user threads\n5DeMiCPU _priority←Gen_Priority( C_priority)\n6cpunum←Get_CPU_Core_Num()\n7// get the number of CPU logical processors\n8fori∈ranдe(1,cpunum)do\n9 hThread(i)←CreateThread()\n10 // create the ithDeMiCPU stimulating thread\n11 SetThreadPriority( hThread(i),DeMiCPU _priority)\n// set the ithDeMiCPU stimulating thread with the\ngenerated DeMiCPU priority level\n12 C_Thread←GetCurrentThread ()\n13 C_Mask=0x0001∗2i−1\n14 SetThreadAffinityMask ( C_Thread,C_Mask)\n15 // bind the ithDeMiCPU stimulating thread to the ith\nCPU logical processor\n16 preamble_gen()\n17 fingerprinting_signal_gen()\n18Stim_Util←Get_Util_Feedback()\n19Stim_Freq←Get_Freq_Feedback()\n20ifStim_Util<threshold _2then\n21 DeMiCPU Stimulation\n22ifStim_Freq<threshold _1then\n23 sleep(5)\n24 DeMiCPU Stimulation\n25else\n26sleep(5)\n27 DeMiCPU Stimulation\nexamining system logs after stimulation to confirm that DeMiCPU\nexclusively uses the CPU during fingerprinting. If not, DeMiCPU\nabandons the current measurements and triggers a second collec-\ntion. Moreover, the CPU frequency may drop due to a high CPU\ntemperature or low battery. Thus, the feedback mechanism exam-\ninestheCPUworkingfrequencybeforeandduringstimulation.Ifaprevious or midway frequency drop is detected,\nDeMiCPU abandons\nthe current measurements and defers its collection till the CPU\nrecovers from the low frequency mode, as revealed in Algorithm 1.\nIn this way, we minimize the influence of software environment\nand output stable fingerprinting signals as shown in Fig. 9.\n5.2 DeMiCPUFingerprint Extraction\n5.2.1 Pre-processing. Preliminary analysis confirms the temporal\nand spatial consistency of the MI signals in the frequency domain.However, the time-domain MI signal is geo-spatial dependent due\nto the impact of the earth’s magnetic field and ambient noise. As\nthe strength of the earth’s magnetic field and ambient noise is\nrelatively static at a specific spot, we assume it mainly contributes\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1154to the constant part of the collected MI signals. To eliminate its\nimpact, we normalize the raw MI signal, i.e., the measured signal\nin Fig. 9, before extracting features.\nDenote the measured signal as B, we normalize Bto obtain the\npre-processed MI signal Mfor feature extraction as follows:\nM=B−min(B)\nmax(B)−min(B)(5)\nNote that although the above solution is designed for scenarios\nwhere ambient MI signals are relatively static, we argue it also\nworkswithtime-varyingmagneticsignalssuchaspowerfrequency\ninterference from nearby electrical equipment, because that the\ntime-varying MI signals from other devices quickly attenuate and\nthus have little influence.\n5.2.2 FeatureSelection. For each pre-processed signal M,w ee x -\ntract 30 scalar features from both time and frequency domains. We\nexploit LibXtract [ 7], a lightweight feature extraction library for\ntime series, which can output a number of statistical feature can-\ndidates. Besides the features offered by LibXtract, we investigate\nthe physical meaning of the MI signal, and manually select fea-\ntures, e.g., Spectrum Kurtosis and Spectrum Smoothness, on which\nremarkable distinctions can be observed in Fig. 8.\nTo further determine critical features, we rank them with the\nhelp of FEAST toolbox [ 6], which is a commonly used feature rank-\ning tool in machine learning. From the results, we obtain the top\n15 features in time and frequency domains and construct a feature\nset as: F={Spectrum Roll Off, Spectrum Kurtosis, Average Deviation,\nSpectrumSpread,SpectrumSmoothness,RMSAmplitude,Spectrum\nStandard Deviation, Spectrum Irregularity-K, Spectrum Skewness,\nSpectrumFlatness,StandardDeviation,SpectrumIrregularity-J,Mean,Skewness,SpectrumMean}. Theordersinthesetindicatetheirrank-\ning orders with Spectrum Roll Off giving the largest information\ngain.\nFor a fingerprinting signal ifrom a device, hereafter we define\nthe feature set Fias thefingerprint of the device.\n5.3 DeMiCPUFingerprint Matching\nTheDeMiCPU cloud server utilizes supervised learning to classify\neachtracewiththeextractedfeatureset F.Toselecttheappropriate\nclassification algorithm, we compare 10 commonly-used classifiers\nand the detailed results can be found in Fig. 11(a). For the sake of\nhigh classification accuracy and robustness over a single classifi-\ncation algorithm, we employ an ensemble classification approach\nExtraTrees [ 19], which fits a number of randomized decision trees\non various sub-samples of the dataset and uses averaging to im-\nprove prediction accuracy and avoid over-fitting.\nTraining. During the training process, for a specific device, k\ntraces from it are utilized as the positive class, and ktraces from\neach of the rest devices serve as the negative class to train a binary\nclassifier. Therefore, for jdevices,jbinary classifiers are trained in\ntotal. In real-world deployment, we may need to extend the clas-sification system when a new device comes and registers. Under\nthat circumstance, the feature sets of the new device are extracted\nand trained to obtain a new binary classifier without the need of\nretraining the original jclassifiers. The new classifier is finally\nFigure10:Experimentalsetup.Themagneticsensorisverti-\ncallyplacedonthesurfaceofthetargetlaptopforMIsignalcollection.\nincorporated with the existing classifiers to constitute a new classi-\nfication system.\nMatching. When matching, the server analyzes the fingerprint\nsignal from the device to be identified and extracts its feature set F.\nThen, the server feeds it to the classifier of which class the device\nclaims to be, to verify its identity.\n6 EVALUATION\nTo evaluate the performance of DeMiCPU , we have conducted ex-\nperiments with 70 laptops and 20 phones across 30 days, among\nwhich 30 laptops are of the same model. The detailed information\nof each device is shown in Tab. 3 (in Appendix A.1). In summary,\nthe performance of DeMiCPU is:\n•DeMiCPU achieves99 .1%precisionandrecallforbothlaptops\nand phones, and more than 98 .6% precision and recall for\n30 identical devices with one-round fingerprinting, and the\nperformance can be further improved to 99 .9% with multi-\nround fingerprinting.\n•DeMiCPU can operate with little influence from operating\nsystems, background applications, fan on/off states or CPU\ntemperature.\n•DeMiCPU supports low sampling rate which makes it a uni-\nversal approach running on ubiquitous smart devices.\n6.1 Experiment Setup\nWiththeexperimentsetupdescribedinTab.3andFig.10,wecollect\n100 MI traces for each of the 90 devices and each trace lasts for\n0.5 s (excluding the preamble). The settings for the laptops and\nsmartphones are as follows.\nStimulation Program Setup. We implement the stimulation\nprogram in Algorithm 1 on five operating systems, i.e., Windows\n(in C++), Linux (in C++), Mac OS (in Java), Android (in Java), and\niOS (in C++), to stimulate the CPU and generate a fingerprinting\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1155123456789 1 0\nClassifier Number0.60.70.80.91Performance\nPrecision Recall F1-Score\n(a) Performance of 10 common classifiers.Win7 Win8 Win10 Linux\nTraining OS0.60.70.80.91F1-Score\nWin 7 Win 8 Win 10 Linux\n(b) Impact of OSs.12345\nApplication0.60.70.80.91Performance\nPrecision Recall F1-Score\n(c) Impact of background applications.123456789 1 0\nPosition Offset (mm)0.40.50.60.70.80.91Performance\nPrecision Recall F1-Score\n(d) Impact of test point offset.\nFigure 11: Micro-benchmark evaluation results of DeMiCPUon 5 randomly-chosen devices.\nsignal.Thelightweightprogramispre-installedontheexperimental\nlaptops/ smartphones.\nData Collection Setup. We collect MI signals from the 90 de-\nvicesusingamagnetic-fieldsensorDRV425[ 22]fromTI.Asshown\ninFig.10,thesensorisverticallyplacedonthesurfaceoflaptopsor\nphones (test points are shown in Tab. 3 in detail) since MI signals\nemitted from the CPU modules are in the vertical direction. A data\nacquisition (DAQ) card U2541A [ 25] from Keysight is utilized for\nAD conversion with different sampling rates, e.g., 100 Hz, 200Hz,\n1kHz, and etc. A data processing laptop connects with the DAQ\ncardthroughaUSB,whichlocallystoresandprocessesthecollected\ndata.\n6.2 Performance Metrics\nGiven an MI fingerprint from a device, DeMiCPU verifies whether\nit belongs to the device (classifier) that it claims to be. For each\nclassifieri,wedefine TPiasthetruepositivesforclassifier i,i.e.,the\nnumber of fingerprints that are correctly accepted as i. Similarly,\nFNiandFPirefer to the number of fingerprints that are wrongly\nrejected, and wrongly accepted as i, respectively. We define the\nstandard classification metrics for each classifier ias:\nPrecision (i)=TPi\n(TPi+FPi)(6)\nRecall(i)=TPi\n(TPi+FNi)(7)\nF1−Score(i)=2×Pri×Rei\n(Pri+Rei)(8)\nThe final precision, recall and F1-Score for DeMiCPU are the av-\nerage of the 90 classes.\n6.3 Micro-benchmark Evaluation\nIn this subsection, we evaluate the impact of classifier choices,\noperating systems, background applications, on/off states of fans,\ntemperatures and displacements of test points. Five devices from\nTab. 3 are randomly chosen for the micro-benchmark evaluation.\n6.3.1 Classifier Choice. To select the appropriate classifier for\nDeMiCPU , we compare 10 commonly-used supervised learning algo-\nrithms.Theyare1)LogisticRegression,2)GaussianNaiveBayes,3)\nK-NearestNeighbors,4)LinearDiscriminantAnalysis,5)QuadraticDiscriminantAnalysis,6)DecisionTree,7)SupportVectorMachine,\n8) ExtraTrees, 9) Random Forest, and 10) Gradient Boosting. Weemploy the 10-fold cross validation to evaluate the classifier perfor-\nmance, which can combine measures of fit and thus derive a more\naccurate estimation for model prediction performance.\nWe randomly choose 30 traces from each device, feed them into\nthe classifiers and record the corresponding accuracy. The results\ninFig.11(a)showthat6outof10classifiersshowanF1-scoreabove\n0.9, with the classifier 8) ExtraTrees, 9) Random Forest, and 10)\nGradient Boosting being the best 3 classifiers. Thus, we can assumethat the data possesses good property in terms of discrepancies, i.e.,\nCPU fingerprints are able to discriminate devices. In the following\nexperiments, we employ ExtraTrees since 1) it shows the best accu-racy,and2)it’sanensembleclassificationapproachwhichachieves\nbetter robustness over a single classification algorithm.\n6.3.2 OperatingSystems. AdevicemayinstalldifferentOSsduring\nits lifetime. To investigate whether OSs affect DeMiCPU , we install 4\nOSs which are 1) Window 7 Home Basic 7601, 2) Kali Linux 2.0, 3)\nWindows 8 Professional 9200, and 4) Windows 10 Enterprise 10240\non the experimental laptops, and conduct experiments under each\nOS to investigate the impact of OSs. We train the classifier with\ntraces from one OS and test it under all the four OSs. The results in\nFig. 11(b) indicate that with the DeMiCPU stimulation program, the\nsamedevice canbesuccessfully identifiedacrossdifferent OSswithprecision, recall and F1-Score of 1. It confirms that with elaborately\ndesigned stimulation, OS-associated processes only account for a\ntiny portion of the CPU utilization during fingerprinting, which is\nwithin the tolerance of DeMiCPU . Thus, we believe DeMiCPU finger-\nprint is independent on OSs.\n6.3.3 BackgroundApplications. DeMiCPU stimulation is designed\nto be undisturbed by other user processes. To evaluate its perfor-\nmance against background applications in practice, we conductexperiments on each device with several daily-used applications.\nThey are 1) WeChat, 2) Microsoft Word, 3) Google Chrome, 4)\nYouTube, and 5) MATLAB, with statistically increasing CPU utiliza-\ntion when normally used. We train the classifier using traces with\nno background application, and test it using traces with one of the\naforementioned background applications, respectively. The results\nshown in Fig. 11(c) confirm that, background applications barely\nhave impact on the performance of DeMiCPU since it can preempt\nthe CPU even if user applications run.\n6.3.4 Displacement of Test Point. Due to that all electronic compo-\nnents inside a device emit MI signals, the measuring sensor may\ncaptureMIsignalsfromothercomponentswhenmovedawayfrom\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n11560.75 0.8 0.85 0.9 0.95 1\nPrecision00.20.40.60.81CDFTraining Trace Size: 10\nTraining Trace Size: 20\nTraining Trace Size: 30\nTraining Trace Size: 40\n(a) Overall precision for laptops.0.75 0.8 0.85 0.9 0.95 1\nRecall00.20.40.60.81CDFTraining Trace Size: 10\nTraining Trace Size: 20\nTraining Trace Size: 30\nTraining Trace Size: 40\n(b) Overall recall for laptops.0.75 0.8 0.85 0.9 0.95 1\nPrecision00.20.40.60.81CDFTraining Trace Size: 10\nTraining Trace Size: 20\nTraining Trace Size: 30\nTraining Trace Size: 40\n(c) Overall precision for smartphones.0.75 0.8 0.85 0.9 0.95 1\nRecall00.20.40.60.81CDFTraining Trace Size: 10\nTraining Trace Size: 20\nTraining Trace Size: 30\nTraining Trace Size: 40\n(d) Overall recall for smartphones.\nFigure 12: Overall performance of DeMiCPUwith different training data sizes (10, 20, 30 and 40).\nthe CPU module. To investigate the impact of the test point dis-\nplacement, we vary the position of the sensor as follows: Starting\nfrom the center of the original test point (depicted in terms of key\npositions in Tab. 3), we gradually move the sensor with a step of\n1mmin four directions: upwards, downwards, left and right. The\nclassifier is trained at the original test point, and tested at each\nchanged position. For each displacement, we average the preci-\nsions, recalls and F1-scores in four directions, and show the final\nresults in Fig. 11(d). From the results, we can see that within anoffset of 8\nmm,DeMiCPU achieves a high accuracy ( >99%). That\nis, a user can conduct DeMiCPU fingerprinting with a displacement\ntolerance of around a key size, which is approximately 10 −15mm\nwide.\n6.3.5 Fans. When fingerprinting a laptop, an electric fan aside the\nCPU module emits MI signals as well. To investigate the impactof fans, we collect 200 traces from each device with fan on andoff, i.e., 100 traces each. We train the classifier with the fan-on\ntraces and test it with the fan-off traces. The resulting F1-Score\nis 1, indicating that MI signals from the fan have little influence.\nWe assume it is because that fans have much lower power (several\nwatts) compared with CPUs (tens of watts), and the large distance\n(around 10 cm) between fan and CPU makes the MI signal from a\nfan quickly attenuate.\n6.3.6 Temperature. CPU temperature changes over time and load,\nandmightbeaninfluencefactorfor DeMiCPU .Toinvestigate,wetest\nDeMiCPU under different CPU temperatures. Note that in DeMiCPU\nstimulation, we introduce a CPU frequency check before stimula-\ntion since the CPU protection mechanism will decrease the CPU\nfrequencywhenitstemperaturebecomestoohigh,e.g.,above90oC.\nThus, DeMiCPU normally works when the CPU temperature is not\ntoo high to cause a frequency drop and we first test DeMiCPU under\nthis range. We train the classifier using traces collected when CPU\ntemperature is 65oC, and test it under the cases of 43oC, 52oC,\n60oC, 68oC, and 78oC, respectively. The F1-Scores for the five\ncases are all 1. To further explore the performance of DeMiCPU un-\nder a high temperature, we manually turn off the CPU protection\nmechanismandtestthesystemunder90oC.TheresultingF1-score\nis also 1, indicating that DeMiCPU works as well. Thus, we believe\nDeMiCPU is robust to CPU temperature changes.\n4.0%4.0%\n4.0%5.0%\n1.0%\n4.0%\n1.0% 2.0%1.0%\n2.0%2.0%\n1.0%\nFigure 13: Confusion matrix of 30 identical laptops.\n6.4 Overall Performance\nIntheoverallperformanceevaluation,100tracesarecollectedfrom\neachdeviceinTab.3,andtheemployedclassifierisExtraTreeswith\na tree number of 100.\n6.4.1 Impact of Training Size. In the first set of experiments, we\ntrain the system with xtraces and test it with the rest 100 −x\ntraces(theyareneverusedfortraining). xissetto10,20,30,and40\n(correspondto5,10,15,and20seconds)respectively,toevaluatethe\nappropriate size of training data. We calculate the Precision (i)and\nRecall(i)for each device (class) i, and plot their CDFs in Fig. 12(a)\n- 12(d) with different training data size x. Even with 10 training\ntraces (correspond to 5 seconds), 90% of the precisions and recalls\nare above 93 .0% for all the laptops and smartphones. The average\nprecision and recall are 98 .3% and 98 .2% for the 70 laptops, and\n99.4% and 99 .3% for the 20 smartphones. With the increasing of\ntraining data size, both precision and recall are improved. Given\nthetrainingsize20, DeMiCPU isabletoachieveanaverageprecision\nand recall of 99 .0% and 99 .0% for the laptops, and 99 .8% and 99 .8%\nfor the smartphones. Besides, when the training data size further\nincreases, the performance of DeMiCPU approaches 100%. To strike\nthe balance between usability and accuracy, we choose 20 traces\nfor training, which only amount to 10 s. Training data size is then\nset to 20 in the rest of the evaluation.\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1157100 200 1K 5K 25K 100K 200K\nSampling Rate (Hz)0.60.70.80.91Performance\nPrecision Recall F1-Score\nFigure 14: Impact of different sam-\npling rates.True Negative Rate0.8 0.85 0.9 0.95 1CDF\n00.20.40.60.81\nFigure 15: Performance of DeMiCPU\nagainst 5 random aliens.0.9 0.92 0.94 0.96 0.98 1\nRecall0.90.920.940.960.981Precision\nLaptop\nSmartphone\nFigure 16: Precision-recall curves for\nlaptops and smartphones.\n6.4.2 Performance of Devices of Same Model. The reason why pre-\ncision and recall behave better on smartphones is that there are\nmore devices of the same model for laptops. As a result, false posi-\ntives and false negatives may occur. To take a close look, we plot a\nconfusion matrix for devices No. 1-30 (i.e., the 30 ThinkPad T430\nlaptops) in Fig. 13. These 30 laptops are of the same model and\ninstalled with the same operating system, and thus are more likely\nto be confused with each other. From the confusion matrix, wecan observe that device No.23 and No.24, as well as device No.25\nand No.26 contribute a relatively lower accuracy, with the worst\nprecision of 91 .6%. Nevertheless, DeMiCPU can still achieve an av-\nerage precision of 98 .7%, and an average recall of 98 .6% for the 30\nidentical devices.\n6.4.3 Impact of Sampling Rate. To investigate the sampling rate\nrequirementof DeMiCPU ,wetestthesystembysettingthesampling\nrate to 100, 200, 1 k,5k,2 5k, 100k, and 200 kHzrespectively. 100\ntraces from each of the 90 devices are collected at each sampling\nratefortrainingandtesting.Theresultingprecisionsandrecallsare\nshown in Fig. 14, from which we can observe that precisions and\nrecallsof DeMiCPU donotchangesignificantlywithlowersampling\nrates. Especially, with a 1 kHzsampling rate, DeMiCPU achieves a\nprecisionof98 .5%andarecallof98 .3%,whicharenearlyequivalent\nto the results under higher sampling rates. Even with a 100 Hz\nsampling rate, the precisionand recall can be as high as 93 .2%. This\nfinding is encouraging since it indicates that DeMiCPU can even use\nubiquitous smart devices with limited sampling rate capability for\nfingerprint collection. For instance, most smartphones nowadays\nare equipped with a built-in magnetometer that supports 100 Hz\nsampling rate. Low requirement of sampling rate makes DeMiCPU a\nmore universal device fingerprinting mechanism.\n6.4.4 Scalabilityof DeMiCPU.Althoughit’sdifficulttoevaluatethe\ncapability of DeMiCPU with a very large set of devices, we conduct\nseveral experiments in which we increase the number of tested\ndevices gradually to get a sense of how DeMiCPU scales. With the\nsame settings in the 90-device experiments, we change the total\nnumber of tested devices and repeat the experiments. First, werandomly choose and use 20 devices to obtain the precision andrecall of\nDeMiCPU . Then, we increase the quantity of devices to\n30, 50, 70 and 90, and recalculate the precisions and recalls. Tab. 2\nshowshowaccuracychangeswiththeincreasingnumberofdevices,Table 2: Average precision, recall and F1-Score of DeMiCPU\nwith different numbers of tested devices.\nNumber of devices Precision Recall F1-Score\n20 1.000 1.000 1.000\n30 0.997 0.996 0.996\n50 0.997 0.997 0.997\n70 0.995 0.994 0.994\n90 0.991 0.991 0.991\nfrom which we can find that the performance of DeMiCPU does not\nchange significantly as the number of devices increases. It provides\nencouraging signs that DeMiCPU is likely scalable to a large number\nof devices.\n6.4.5 ImpactofAlienDevices. Inreal-worlddeployment,itislikely\nthat DeMiCPU needs to identify alien devices, i.e., devices that are\nnottrainedbeforehand.Tounderstandhow DeMiCPU performswith\nalien devices, we conduct the following experiments. From the 90\ndevices, we randomly choose 85 devices for training and get the\ncorresponding 85 binary classifiers. The rest 5 devices, which serve\nas aliens to the trained system (they are never used for training),are utilized to test the performance. The 5 devices take turns to\ninput their traces to each of the 85 classifiers to see if they can be\naccepted. We repeat the experiment for 10 times to eliminate the\nrandom errors and plot the CDF of true negative rates in Fig. 15.\nTheresultsrevealthat DeMiCPU cansuccessfullyrejectaliendevices\nwith a minimum probability of 98 .2% and an average probability of\n98.7%, which indicates its high reliability.\n6.4.6 Multi-roundFingerprinting. In aforementioned evaluation,\nthe threshold for each binary classifier is 0.5 by default. However,\nin practice, precision is likely to be prior to recall for the sake of\nhigh reliability and security, and recall can be further improved\nthrough multi-round fingerprinting.\nTo investigate the appropriate threshold to achieve high preci-\nsion and the minimum fingerprinting round to achieve high recall,\nweplottheprecision-recallcurvebyvaryingthethresholdforeach\nclassifier.As DeMiCPU isasystemconsistingofmultiplebinaryclas-\nsifiers,weemploythesamethresholdineachclassifierandaverage\ntheir precisions and recalls as the final performance. The results\nshown in Fig. 16 reveal that, for both laptops and smartphones, the\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1158Figure 17: DIY replay attack equipment with a handcrafted\ninduction coil. The recorded MI sample is emitted by the\nMSP430intheformofdiscretevoltages,whicharefirstcon-\nverted into analog signals by a Digital-to-Analog Converter\n(DAC) and then converted into corresponding current sig-\nnals by a Voltage-to-Current Converter (VCC).\nprecision approaches 100% when the threshold increases. Specif-\nically, for laptops, the recall is 97 .0% when the precision is 99 .9%\nwith a threshold of 0.54, which can be further improved to 99 .9%\nwith two-round fingerprinting and 99 .99% with three-round fin-\ngerprinting. Similarly, for smartphones, the recall is 98 .3% when\nthe precision is 99 .9% with a threshold of 0.64, and the recall can\napproach 99 .999% with only three-round fingerprinting. Therefore,\nwith three-round fingerprinting, DeMiCPU can achieve a 99 .9% pre-\ncision and an over 99 .99% recall on both laptops and smartphones.\nTo summarize, our evaluation with 90 laptops and smartphones\nshows that smart devices can be identified leveraging the finger-\nprints of their CPU modules. While even a larger study is needed\nto confirm the scalability of our findings, to the best of our knowl-\nedge, this is the first work to attempt device fingerprinting based\non fingerprints of CPU modules.\n7 DISCUSSION\nIn this section, we conduct the security analysis and discuss the\nlimitations of DeMiCPU.\n7.1 Security Analysis\nSince the goal of the attackers is to impersonate a legitimate device,\nwe discuss two attacks: replay attacks and mimicry attacks. To\nlaunch a replay attack, an adversary may have a brief physical\naccess to the target device. She may record the MI signal of the\ntarget device and replay the recorded sample to fool the DeMiCPU\nsensor.Formimicryattacks,shemayfindasimilardevicetoimitate\nthe legitimate one.\n7.1.1 Replay Attack. A replay attack consists of two steps: record-\ning and reproducing. We study the feasibility of such attacks based\non two sets of equipment: commercial off-the-shelf (COTS) devices\nand DIY sets with handcrafted coils.\nCOTSdevice. Theeffectivenessofrecordingandemittingradia-\ntionsignalsisdeterminedbythesensitivityofthesamplingdevicesand the gain of the antennas. Much work has demonstrated the\nfeasibility of replaying radio frequency (RF) signals at reasonable\ncost, e.g., utilizing a Universal Software Radio Peripheral (USRP)\nwithamatchingantennatoreplaysignalsat2.4or5 GHzforWi-Fi,\n900MHzfor GSM (Global System for Mobile Communications),\n13.56MHzfor NFC (Near-field Communication), and etc. These\nRF bands are at least at the order of MHzand a variety of off-the-\nshelf matching antennas are available. In comparison, the effective\nfrequency range of DeMiCPU is below 10 kHz, whose matching an-\ntennas, i.e., VLF (very low frequency) antennas, are usually used\nfor military communication with submarines and few commodity\nantennas are available. Moreover, VLF antennas are typically large,\ne.g., a dipole antenna for 10 kHzcan be longer than 7.5 km.\nWithout matching antennas, we may refer to dedicated equip-\nment to record MI samples. For instance, we found a N9038A MXE\nEMIreceiverfromKeysightthatcananalyzesignalsfrom3 Hzto44\nGHzat the cost of $90 ,000 USD. However, we were unable to find\nequipment that can reproduce the recorded samples with abundant\nsignals ranging from DC to 10 kHzsince most RF generators on\nthe market only support frequency higher than 9 kHz.\nDIY set with handcrafted coils. Unable to replay MI signals\nwithCOTSdevices,wedesignourownreplayequipment:Werecord\nthe MI sample with the DRV425 magnetic sensor and replay the\nsignal with a handcrafted induction coil driven by a MSP430F5529\nLaunchPad [ 23], as shown in Fig. 17. We program the LaunchPad\nto output the recorded MI sample in a form of discrete voltages,\nwhicharethenconvertedintoanalogsignalsbyaDigital-to-Analog\nConverter (DAC). The analog voltage signals are further converted\ninto corresponding current signals to drive the induction coil. A\nferrite core is inserted into the coil to augment its permeability. A\nConstant Voltage Source (CVS) is utilized to power the VCC, and\nan oscilloscope is used to monitor the output voltage of the DAC.\nTo quantify the MI signals measured by sensors, we refer to\nthe Ampere’s circuital law [ 45], which models the magnetic flux\ngenerated by a charged coil as follows:\nΦB=μNIScosθ (9)\nwhereμis the magnetic permeability of the coil, Nis the number\nof turns,Iis the current flowing through the coil, Sis the area of\nthe magnetic sensor’s sensing surface, and θis the angle between\nthe magnetic field lines and the normal line (perpendicular) to S.\nTherefore, although we elaborately reproduce the MI signal, the\ndistance and angle between the coil and sensor affect the measure-\nment.Giventhedynamicnatureoftheproducedmagneticfieldandthe noise introduced during DA conversion, it is extremely difficult\nfor the sensor to record MI signals that equal the recorded one.\nTo validate, we randomly choose five samples from five devices,\nand obtain 10 replayed samples for each. Although we try our best\nto obtain a similar replayed signal, none of them matches with the\nenrolled fingerprints. We believe that is because the fingerprint dis-crepancy caused by the CPU hardware is subtle and the differences\nas well as noises introduced during the replay attack is likely toruin such subtle characteristics. Thus, replay attacks targeted at\nDeMiCPU are challenging to perform even at a single point and the\ndifficulty will increase dramatically with the increasing of testing\nsensors.\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n11597.1.2 MimicryAttack. The mimicry attack utilizes a similar device\nto imitate the target device by manipulating the software or config-\nurations of the attack device. To impersonate the target device, the\nattack device has to precisely learn and mimic the fingerprint of\nthe victim. However, the essential discrepancies of DeMiCPU finger-\nprints originate from the hardware of CPU modules. Manipulating\nsoftware or configurations may alter the CPU fingerprint but the\nmapping between the configurations and the fingerprint is difficult\nto profile. As a result, the mimicry is likely to be unsupervised. In\naddition,accordingtoourobservations,thefingerprintdiscrepancy\ncaused by the hardware of the CPU module is subtler compared\nwith that caused by configurations. Thus, mimicry attack is not\nlikely to make the attack device’s fingerprint exactly the same as\nthe one of the target device.\nIn summary, given the low frequency nature and the high preci-\nsion of DeMiCPU , we believe it is difficult for adversaries to launch\neither a replay attack or a mimicry attack against DeMiCPU.\n7.2 Limitation\nAuthenticationPoint. DeMiCPU thatreliesononesensorrequires\nthe test point within a 16 mmrange, which may affect the usability.\nA significant displacement of the DeMiCPU sensor from the CPU\nmodulemayleadtofailureinidentification.However,weenvisionit\ncanbeaddressedbyexploitingasensorarray,whichshalleffectivelyreducetherequirementoftestpointsandenlargethefingerprinting\narea.\nLong-termConsistency. We conducted our experiments over\n30 days. Howeve r, a smart device usually can be used for years and\nit may experience changes due to aging, which in turn may changethe features gradually. For example, the number of available CMOS\ntransistors in the CPU may decrease due to the hardware aging.Nevertheless, we assume that we can compensate the aging by\npostulating a fingerprint slow updating technique: We update the\nfingerprints in the database occasionally if the current fingerprint\nis still classified to the legitimate user yet a small constant offset is\ndetected, such that slow changes can be compensated.\nUser Process Suppress .DeMiCPU employs a higher priority\nfor stimulation compared with other user processes. As a result,\nother user applications will be suppressed during fingerprinting.However, as\nDeMiCPU stimulation only lasts for 0.6 s, we argue it\nis relatively short and might be acceptable for most applications\nwithout affecting user experience.\nFirmware-updateResistance. ThefirmwareandCPUmicrocode\nof a smart device can be updated in accordance with requirements.\nDuring our experiments, the devices were kept natural and haven’t\nbeen updated intentionally. As the firmware and CPU microcode\nmayaffecttheexecutionofCPUinstructions,theymayhaveimpact\nonDeMiCPU fingerprinting. We remain it as the future work.\n8 RELATED WORK\nDevice Fingerprinting. Fingerprint is one of the most common\nbiometrics in user identification [ 24,35]. The same concept was\nextended to device identification by the US government in 1960s\nto identify and track unique mobile transmitters [ 27]. Since then,\nmuch effort has been devoted to identifying network devices by\nbuildingafingerprintoutoftheirsoftwareorhardware.Intermsofsoftware-based fingerprint, the combination of chipsets, firmware\nanddevicedrivers[ 15],timingintervalofproberequestframes[ 12],\npatterns of wireless traffic [ 33], and browser properties [ 46], can\nbe used to identify devices. The downside of these methods is that\nfingerprintswillchangeoncedeviceconfigurationoruserbehavior\nchanges. Hardware-based approaches fingerprint a device through\ntheirphysicalcomponentsorproperties.Clockskews[ 26,34],radio\nfrequency (RF) discrepancy at the waveform [ 20,36,41] or modula-\ntion [5] levels are well explored to identify wireless devices such as\nWi-Firouters.Mobiledevicefingerprintingutilizesthedifferencein\nhardware compositions [ 34,40] or components such as accelerom-\neters [13, 42], gyroscopes [2], microphones [11, 48], speakers [47],\ncameras [ 14,29], Bluetooth implementation [ 1], or some of them\nin combination [ 4,21]. The advantage of hardware-based device\nfingerprinting is that fingerprints are generated essentially from\nmanufacture discrepancies, which can remain stable during the\nlifecycle of the device and are difficult to mimic.\nEMI Leakage Based Side-channels. The use of EMI leakage\nas a side-channel has been widely investigated. This work [ 17]e x -\ntracts the key of RSA software implementation on a Lenovo laptop\nusinganear-fieldmagneticprobewithafrequencyaround100 kHz.\nVaucelle et al. [ 43] detect the existence of ambient electromagnetic\nfields using a magnetometer bracelet with a frequency of up to 50\nkHz. DOSE [ 9] detects the usage of electrical appliances by moni-\ntoring device EMI radiations with an expensive EMI measurement\nequipment. Magnifisense [ 44] recognizes the electrical appliance\nusage using a wrist-worn magnetic sensor and a set of data ac-quisition device, with a sampling rate of 16-bit resolution at 44.1\nkHz. ZOP [8] utilizes electromagnetic emanations generated by\ncomputing systems during program execution to track a program’s\nexecution path and generate profiling information.\nDeMiCPU is inspired by the aforementioned work and utilizes\nthe natural discrepancies existing in CPU modules. Given the fact\nthat a CPU module is indispensable for almost all mobile or smart\ndevices, DeMiCPU makes a more universal method compared with\naforementioned built-in sensor based approaches.\n9 CONCLUSION AND FUTURE WORK\nIn this paper, we propose DeMiCPU , an effective device fingerprint-\ning approach utilizing the unique features of magnetic induction\n(MI) signals generated from CPU modules, as a result of hardware\ndiscrepancy. We evaluate DeMiCPU with 90 mobile devices, includ-\ning 70 laptops and 20 smartphones. The results show that DeMiCPU\ncan achieve 99 .1% precision and recall on average and 98 .6% preci-\nsion and recall for 30 identical devices, with a fingerprinting time\nof 0.6s. Both precision and recall can be further improved to 99 .9%\nwith multi-round fingerprinting.\nFuture directions include exploring a larger study to confirm the\nscalability of DeMiCPU.\nACKNOWLEDGMENTS\nWethankallanonymousreviewersfortheirinsightfulcommentson\nthis paper. This work is supported by China NSFC Grant 61702451,\nZJNSF Grant LGG19F020020, and the Fundamental Research Funds\nfor the Central Universities 2019QNA4027.\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1160REFERENCES\n[1]Aksu, H., Uluagac, A. S., and Bentley, E. Identification of wearable devices\nwith bluetooth. IEEE Transactions on Sustainable Computing (2018).\n[2]Baldini,G.,Steri,G.,Dimc,F.,Giuliani,R.,andKamnik,R. Experimentaliden-\ntification of smartphones using fingerprints of built-in micro-electro mechanical\nsystems (mems). Sensors 16, 6 (2016), 818.\n[3]Bellovin, S. M., and Merritt, M. Cryptographic protocol for secure communi-\ncations, Aug. 31 1993. US Patent 5,241,599.\n[4]Bojinov, H., Michalevsky, Y., Nakibly, G., and Boneh, D. Mobile device\nidentification via sensor fingerprinting. arXiv preprint arXiv:1408.1416 (2014).\n[5]Brik, V., Banerjee, S., Gruteser, M., and Oh, S. Wireless device identification\nwith radiometric signatures. In MobiCom (2008), ACM, pp. 116–127.\n[6] Brown, G. FEAST, January 2017. https://github.com/Craigacp/FEAST.\n[7]Bullock, J. LibXtract, July 2014. http://jamiebullock.github.io/LibXtract/\ndocumentation/.\n[8]Callan, R., Behrang, F., Zajic, A., Prvulovic, M., and Orso, A. Zero-overhead\nprofiling via em emanations. In ISSTA(2016), ACM, pp. 401–412.\n[9]Chen, K.-Y., Gupta, S., Larson, E. C., and Patel, S. Dose: Detecting user-driven\noperating states of electronic devices from a single sensing point. In PerCom\n(2015), IEEE, pp. 46–54.\n[10]Cleveland, T. L. Bi-directional power system for laptop computers. In APEC\n(2005), vol. 1, IEEE, pp. 199–203.\n[11]Das, A., Borisov, N., and Caesar, M. Do you hear what i hear?: Fingerprinting\nsmart devices through embedded acoustic components. In CCS(2014), ACM,\npp. 441–452.\n[12]Desmond, L. C. C., Yuan, C. C., Pheng, T. C., and Lee, R. S. Identifying unique\ndevices through wireless fingerprinting. In WiSec(2008), ACM, pp. 46–55.\n[13]Dey, S., Roy, N., Xu, W., Choudhury, R. R., and Nelakuditi, S. Accelprint:\nImperfections of accelerometers make smartphones trackable. In NDSS(2014).\n[14]Dirik,A.E.,Sencar,H.T.,andMemon,N. Digitalsinglelensreflexcameraiden-\ntification from traces of sensor dust. IEEETransactionsonInformationForensics\nand Security 3, 3 (2008), 539–552.\n[15]Franklin, J., McCoy, D., Tabriz, P., Neagoe, V., Randwyk, J. V., and Sicker, D.\nPassive data link layer 802.11 wireless device driver fingerprinting. In USENIX\nSecurity (2006), vol. 3, pp. 16–89.\n[16]Gartner. Gartner Forecasts Flat Worldwide Device Shipments Until 2018, January\n2017. http://www.gartner.com/newsroom/id/3560517.\n[17]Genkin, D., Pachmanov, L., Pipman, I., and Tromer, E. Stealing keys from pcs\nusing a radio: Cheap electromagnetic attacks on windowed exponentiation. In\nCHES(2015), Springer, pp. 207–228.\n[18]Getz,R.,andMoeckel,B. Understandingandeliminatingemiinmicrocontroller\napplications. National Semiconductor (1996).\n[19]Geurts, P., Ernst, D., and Wehenkel, L. Extremely randomized trees. Machine\nlearning 63, 1 (2006), 3–42.\n[20]Hall, J., Barbeau, M., and Kranakis, E. Radio frequency fingerprinting for\nintrusion detection in wireless networks. IEEETransactionsonDefendableand\nSecure Computing 12 (2005), 1–35.\n[21]Hupperich, T., Hosseini, H., and Holz, T. Leveraging sensor fingerprinting\nfor mobile device authentication. In Detection of Intrusions and Malware, and\nVulnerability Assessment. Springer, 2016, pp. 377–396.\n[22]Instrument,T. IntegratedFluxgateMagneticSensorICforOpen-LoopApplications,\nMarch 2016. https://www.ti.com/product/DRV425.\n[23]Instruments, T. MSP430F5529 LaunchPad Development Kit, April 2017. http:\n//www.ti.com/lit/ug/slau533d/slau533d.pdf.\n[24]Jain, A. K., Hong, L., Pankanti, S., and Bolle, R. An identity-authentication\nsystem using fingerprints. IEEE 85, 9 (1997), 1365–1388.\n[25]Keysight. U2541A250kSa/sUSBModularSimultaneousDataAcquisition, June\n2017. https://tinyurl.com/yb5r768y.\n[26]Kohno, T., Broido, A., and Claffy, K. C. Remote physical device fingerprinting.\nIEEE Transactions on Dependable and Secure Computing 2, 2 (2005), 93–108.\n[27]Langley, L. E. Specific emitter identification (sei) and classical parameter fusion\ntechnology. In WESCON (1993), IEEE, pp. 377–381.\n[28]Le Sueur, E., and Heiser, G. Dynamic voltage and frequency scaling: The laws\nof diminishing returns.\n[29]Lukas,J.,Fridrich,J.,andGoljan,M. Digitalcameraidentificationfromsensor\npattern noise. IEEE Transactions on Information Forensics and Security 1, 2 (2006),\n205–214.\n[30]Marr, D., Binns, F., Hill, D., Hinton, G., Koufaty, D., et al. Hyper-threading\ntechnology in the netburst® microarchitecture. Hot Chips (2002).\n[31]Mondri, R., and Bitan, S. Inspected secure communication protocol, Sept. 1\n2009. US Patent 7,584,505.\n[32]Nguyen, K. T., Laurent, M., and Oualha, N. Survey on secure communication\nprotocols for the internet of things. Ad Hoc Networks 32 (2015), 17–31.\n[33]Pang, J., Greenstein, B., Gummadi, R., Seshan, S., and Wetherall, D. 802.11\nuser fingerprinting. In MobiCom (2007), ACM, pp. 99–110.\n[34]Radhakrishnan, S. V., Uluagac, A. S., and Beyah, R. Gtid: A technique for\nphysical device and device type fingerprinting. IEEE Transactions on Dependableand Secure Computing 12, 5 (2015), 519–532.\n[35]Ratha, N. K., Bolle, R. M., Pandit, V. D., and Vaish, V. Robust fingerprint\nauthentication using local structural similarity. In WACV(2000), IEEE, pp. 29–34.\n[36]Remley, K., Grosvenor, C. A., Johnk, R. T., Novotny, D. R., Hale, P. D., McKin-\nley, M., Karygiannis, A., and Antonakakis, E. Electromagnetic signatures of\nwlan cards and network security. In ISSPIT(2005), IEEE, pp. 484–488.\n[37]Solomon, D. A., Russinovich, M. E., and Ionescu, A. Windowsinternals. Mi-\ncrosoft Press, 2009.\n[38]Suleiman, D., Ibrahim, M., and Hamarash, I. Dynamic voltage frequency\nscaling (dvfs) for microprocessors power and energy reduction. In ICEEE(2005).\n[39] Travers, M. Cpu power consumption experiments and results analysis of intel\ni7-4820k.\n[40]Uluagac, A. S., Radhakrishnan, S. V., Corbett, C., Baca, A., and Beyah,\nR. A passive technique for fingerprinting wireless devices with wired-side\nobservations. In CNS(2013), IEEE, pp. 305–313.\n[41]Ureten, O., and Serinken, N. Wireless security through rf fingerprinting.\nCanadian Journal of Electrical and Computer Engineering 32, 1 (2007), 27–33.\n[42]Van Goethem, T., Scheepers, W., Preuveneers, D., and Joosen, W.\nAccelerometer-baseddevicefingerprintingformulti-factormobileauthentication.\nInESSoS(2016), Springer, pp. 106–121.\n[43]Vaucelle, C., Ishii, H., and Paradiso, J. A. Cost-effective wearable sensor to\ndetect emf. In CHI(2009), ACM, pp. 4309–4314.\n[44]Wang, E. J., Lee, T.-J., Mariakakis, A., Goel, M., Gupta, S., and Patel, S. N.Magnifisense: Inferring device interaction using wrist-worn passive magneto-\ninductive sensors. In UbiComp (2015), ACM, pp. 15–26.\n[45]Wikipedia. Ampère’s circuital law, May 2018. https://en.wikipedia.org/wiki/\nAmp%C3%A8re%27s_circuital_law.\n[46]Yen, T.-F., Xie, Y., Yu, F., Yu, R. P., and Abadi, M. Host fingerprinting and\ntracking on the web: Privacy and security implications. In NDSS(2012).\n[47]Zhou, Z., Diao, W., Liu, X., and Zhang, K. Acoustic fingerprinting revisited:\nGenerate stable device id stealthily with inaudible sound. In CCS(2014), ACM,\npp. 429–440.\n[48]Zou,L.,He,Q.,andWu,J. Sourcecell phoneverificationfroms peechrecordings\nusing sparse representation. Digital Signal Processing 62 (2017), 125–136.\nA APPENDIX\nA.1 Experimental Device\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1161Table 3: Experimental devices and their detailed specifications. A total of 90 devices are used, including 70 laptops and 20\nsmartphones. Among them, 1-30, 31-33, 50-51, 84-85 and 88-89 are of the same model and OS respectively.\nNo.Manuf. Model OSCPU Parameters\nModel Core Number Thread Number Test Point\n1-30 Lenovo ThinkPad T430 Win 7 i5-3320M 2 4 S\n31-33 Lenovo ThinkPad T440p Win 7 i5-4210M 2 4 S\n34Lenovo G480 Win 7 i5-3210M 2 4 R\n35Lenovo G480 Win 10 i5-3210M 2 4 R\n36Lenovo ThinkPad X201 Win 10 i5-540M 2 4 F6\n37Lenovo ThinkPad T440 Debian i7-4500U 2 4 N\n38Lenovo ThinkPad W520 GNOME i7-2760QM 4 8 E\n39Lenovo ThinkPad Edge E431 Win 10 i7-3632QM 4 8 S\n40Lenovo ThinkPad Edge E530 Win 10 i5-3210M 2 4 S\n41Lenovo IdeaPad Y470 Win 7 i5-2450M 2 4 E\n42Lenovo IdeaPad Y485 Win 7 A8-4500M 4 4 F5\n43Lenovo Yoga2 13 Win 10 i5-4210U 2 4 F4\n44Lenovo Yoga 710 Win 10 i5-6200U 2 4 O\n45Lenovo U430P Win 10 i5-4200U 2 4 F1\n46Lenovo Erazer Z410 Win 10 i7-4702MQ 4 8 6\n47Lenovo E47a Win 7 i5-2520M 2 4 S\n48Lenovo X200 7455 GNOME Intel P8600 2 2 F\n49Lenovo R720 Win 10 i5-7300HQ 4 4 7\n50-51 Apple MacBook Air A1466 OS x i5-4260U 2 4 W&E\n52 Apple MacBook Pro A1707 OS x i7-6920HQ 4 8 W&E\n53 Apple MacBook Pro A1502 OS x i5-4278U 2 4 C\n54 Dell Inspiron N4050 Win 7 i3-2350M 2 4 F\n55 Dell Inspiron N5110 Win 7 i5-2450M 2 4 F\n56 Dell Inspiron 14 7460 Win 10 i5-7200U 2 4 6\n57 Dell Inspiron 15R 5520 Win 10 i5-3210M 2 4 Fn\n58 Dell Inspiron 15 7559 Win 10 i5-6300HQ 4 4 F6\n59 Dell Latitude E4300 Win XP Intel SP9400 2 2 F\n60 Dell Latitude E7440 Win 10 i5-4200U 2 4 E&R\n61 Dell XPS13 Win 10 i5-3317U 2 4 6\n62 Dell XPS14 L421X Win 10 i7-3537U 2 4 4\n63 Asus Eee PC 1201HA Win 7 Intel Z520 1 2 A\n64 Asus N46V Win 8.1 i5-3210M 2 4 B&N\n65 Asus X450EI323VC-SL Win 10 i5-3230M 2 4 F\n66 Acer V5-471G Win 7 i5-3337U 2 4 D\n67 HP TPN-Q173 Win 10 i5-6300HQ 4 4 Backspace\n68 MSI MS16-H8 Win 10 i7-6700HQ 4 8 Scroll Lock\n69 Sony SVT131A11T Win 7 i5-3317U 2 4 X\n70 Sony SVT131A11T Win 10 i5-3317U 2 4 X\n71 Mi 5 Android 6.0 Snapdragon 820 4 4 BVK∗\n72 Mi 5S Android 6.0 Snapdragon 820 4 4 BVK∗\n73Huawei Honor 5X Android 5.1 Snapdragon 616 8 8 BVK∗\n74Huawei Honor 8 Android 6.0 Kirin 950 8 8 BVK∗\n75Huawei Honor V8 Android 6.0 Kirin 950 8 8 BVK∗\n76Huawei P9 Android 6.0 Kirin 955 8 8 BVK∗\n77 LG Nexus 5 Android 4.4 Snapdragon 800 4 4 BVK∗\n78 LG Nexus 5X Android 6.0 Snapdragon 808 4 4 BVK∗\n79 Vivo X7 Android 5.1 Snapdragon 652 4 4 BVK∗\n80Samsung Galaxy S6 Android 5.0 Exynos 7420 8 8 BVK∗\n81 Apple iPhone 6 iOS 10.2.1 Apple A8 2 2 BPK•\n82 Apple iPhone 6 iOS 11.0.3 Apple A8 2 2 BPK•\n83 Apple iPhone 6 Plus iOS 11.1.1 Apple A8 2 2 BPK•\n84-85 Apple iPhone 6s iOS 10.3.3 Apple A9 2 2 BPK•\n86 Apple iPhone 6s iOS 10.2.1 Apple A9 2 2 BPK•\n87 Apple iPhone 6s iOS 11.2.1 Apple A9 2 2 BPK•\n88-89 Apple iPhone SE iOS 11.2.1 Apple A9 2 2 BPK•\n90 Apple iPhone 7 Plus iOS 10.3.3 Apple A10 4 2 BPK•\n∗BVK = Beside Volume Key •BPK = Beside Power Key\nSession 5E: Fingerprinting\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1162"}
{"title": "EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile Devices", "content": "EchoHand: High Accuracy and Presentation Attack Resistant\nHand Authentication on Commodity Mobile Devices\nCong Wu\nWuhan University, China\ncnacwu@whu .edu.cnJing Chen\nWuhan University, China\nchenjing@whu .edu.cnKun He\nWuhan University, China\nhekun@whu .edu.cn\nZiming Zhao\nUniversity at Buffalo, USA\nzimingzh@buffalo .eduRuiying Du\nWuhan University, China\nduraying@whu .edu.cnChen Zhang\nWuhan University, China\nwhuhdc@whu .edu.cn\nABSTRACT\nBiometric authentication schemes, i.e., fingerprint and face authen-\ntication, raise serious privacy concerns. To alleviate such concerns,\nhandauthenticationhasbeenproposedrecently.However,exist-\ning hand authentication schemes use dedicated hardware, such as\ninfraredordepthcameras,whicharenotavailableoncommodity\nmobiledevices.Inthispaper,wepresentEchoHand,ahighaccu-\nracyandpresentationattackresistantauthenticationschemethat\ncomplementscamera-based2-dimensionalhandgeometryrecog-\nnitionofonehandwithactiveacousticsensingoftheotherhand.\nEchoHand plays an inaudible acoustic signal using the speaker to\nactivelysensetheholdinghandandcollectstheechoesusingthe\nmicrophone.EchoHanddoesnotrelyonanyspecializedhardware\nbut uses the built-in speaker, microphone and camera. EchoHand\ndoesnotplacemoreburdensonusersthanexistinghandauthentica-\ntion methods. We conduct comprehensive experiments to evaluate\nthe reliability and security of EchoHand. The results show that\nEchoHand has a low equal error rate of 2.45% with as few as 10\ntraining data points and it defeats presentation attacks.\nCCS CONCEPTS\n•Securityandprivacy →Usabilityinsecurityandprivacy; Multi-\nfactor authentication; Biometrics ;Mobile and wireless security .\nKEYWORDS\nHandAuthentication,PresentationAttack,AcousticSensing,Hand\nGeometry.\nACM Reference Format:\nCong Wu, Jing Chen, Kun He, Ziming Zhao, Ruiying Du, and Chen Zhang.\n2022. EchoHand: High Accuracy and Presentation Attack Resistant Hand\nAuthenticationonCommodityMobileDevices.In Proceedingsofthe2022\nACMSIGSACConferenceonComputerandCommunicationsSecurity(CCS\n’22), November 7–11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA,\n15 pages. https://doi .org/10.1145/3548606 .3560553\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9450-5/22/11...$15.00\nhttps://doi .org/10.1145/3548606 .35605531 INTRODUCTION\nBiometric authentication methods have become ubiquitous on mo-\nbiledevices.However,thetwowidelydeployedschemes,namely\nfingerprint and face authentication, utilize users’ sensitive biologi-\ncal traits and have raised privacy concerns [ 8,22]. To alleviate the\nconcerns,handauthenticationhasbeenproposedasapromising\nmethod [ 22,37] for the following reasons: i) hands have rich in-\ntrinsic biometric features, e.g., palmprint, hand geometry, etc., that\ncanprovidereliableauthentication[ 66];ii)usersarelessconcerned\nwith hand privacy [ 22], while the fingerprint is widely used for\nlaw enforcement in many countries. The face is the most sensitive\ninformation for a person, and facial recognition is even prohibited\nin some regions. Since 2019, Amazon has launched a contactless\nhandauthenticationpaymentsystembasedonpalmveinandpalm-\nprint [7,9]. Other hand authentication solutions, such as LG Hand\nID [10] and PalmID [6], have also been proposed and deployed.\nSimple hand authentication can be implemented with a camera.\nForinstance,palmprintauthenticationsusehigh-resolutioncam-\neras to catch the skin patterns of a palm, such as lines, points, and\ntexture[16,28].However,thisapproachislessaccurateandvulner-\nabletopresentationattacks,e.g.,theattackercaneasilyspoofthe\nsystem using images [ 2]. Other systems use specialized hardware,\nwhich is not available on commodity mobile devices, to capture\nsophisticated traits, such as 3-dimensional hand geometry or palm\nveininformation. Forexample,GesID [ 60]uses adepthcamera to\ncollecthandthickness.PalmID[ 6]andHandID[ 10]usetime-of-\nflightcameras[ 36]andinfraredsensorstomapouttheveinsunder\nthe hand skin.\nInthispaper,wepresentEchoHand,ahighaccuracyandpresen-\ntation attack resistant hand authentication scheme for commodity\nmobiledevices.EchoHandcomplementscamera-basedhandge-\nometry recognition of one hand with active acoustic sensing of\nthe other holding hand. To this end, EchoHand plays an inaudible\nacousticsignalusingthespeakertoactivelysensetheholdinghand\nand collects the echoes using the microphone. EchoHand is based\non the observation that the way a user holds the phone affects the\nphone’svibration,whichresultsindelayandattenuationofthesig-\nnal propagating through structure-borne and air-borne paths [ 57].\nEchoHand does not rely on any specialized hardware but uses the\nbuilt-in speaker, microphone and camera. Moreover, EchoHand\ndoes not place more burdens on users than existing hand authenti-\ncation methods [6, 10, 50, 60] since it senses the holding hand.\nEventhoughacousticsensinghasbeenusedtodetectandrecog-\nnize motions [ 20,39,54,70] and faces [ 74], existing approaches all\n2931\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\nData Capturer\nEnrl. Auth.\nEnrl.ZC signal interpolation\nSignal transmitting/Recording\nHand gesture catchingHand segmentation and \ncontour detectionData Preprocessor\nNoise removal\nDemodulation\nSignal extractionFeature Extractor\nLandmark detection\nLandmark rectification and \nfinger joint detectionSpectrogram Analysis\nLearning-based feature \nextraction\nJoint feature representationGeometry representation Authenticator\nEnrl. Auth.\nModel \ntrainingPredicting\nUser’s profile\nAuthentication \nresult Auth.Enrl.\nAcc. Rej.Auth.\nImage augmentation\nFigure 1: The workflow of EchoHand\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\u0005\t\n\u0005\u0002\u000b\u0005\f\u0007\n\r\u000e\u0007\u0003\u000f\u0010\f\n\u0011\u0010\u000f\u0012\f\u0013\r\n\u0005\u0007\u0006\u0004\u0012\u0010\f\u0007\n\u0014\u000f\u0015\u0005\u0006\u0007\u000b\b\u000f\u0010\u0006\u0016\u0013\u000b\u000b\u0013\u0010\u0017\u0007\nFigure 2: Illustration of EchoHand\nrequire the sensed objects to be at least centimeters away from the\nsensorforbetteraccuracy.Forinstance,VSkin[ 54]usesacoustic\nsensingtoidentifyfingermotionsandtouchgesturesatthebackof\nthedevice.Chaperone[ 20]detectswhetherauserisleavingaphone\ntopreventphonelosses.VoiceGesture[ 70]andLippass[ 39]relyon\ntheDopplershiftsresultingfromarticulatormotionsforliveness\ndetection to complement voiceprint authentication. EchoPrint [ 74]\ncharacterizesauser’sfaceandcombinesacousticfeaturesandfacial\nlandmarks to authenticate users.\nHowever, when authenticating a holding hand, the distance be-\ntweenthehandandsensorisshort,makingitdifficulttoextracttheechoesreflectedbytheholdinghandanddistinguishitsfeatures.To\novercomethesechallenges,EchoHandusestheZadoff-Chu(ZC)\nsequence[ 68]asthebasesignalandmodulatesittoaninaudible\nfrequency band. EchoHand distinguishes the echoes reflected by\nthe holding hand since the signals from different paths arrive at\nthe microphone with different delays due to different propagation\nspeedsand pathdistances.Toextractsalientacousticfeaturesfrom\ntheseparatedsignals,wetransferapre-trainedneuralnetworkas\nthe generalized learning-based feature extractor.\nAttackModels. Weconsideradversarieswhocanconductthree\ntypesofattackstobypassEchoHand:i)gesturespoofingattack,\nwhereadversariesknowthevictim’sregisteredhandgestureandtry\ntospoofthesystembyperformingthesamegesture;ii)presentationattack,inwhichadversarieshaveapictureofthevictim’sregisteredhandgestureandattempttospoofthesystemusingthepicture;iii)\nmimicry attack, in which adversaries have a picture of the victim’s\nhandgestureandalsomimictheholdingstyleofthevictim.The\ncontributions of this paper are summarized as follows:•WepresentEchoHand,whichcharacterizestheholdinghandus-\ningacousticsensingtocomplementhandgeometryfeaturesfrom\ntheotherhand.Toextractacousticfeatures,wedesignalearning-\nbased feature extractor. We also implement a hand geometry\nfeatureextractionapproach,extendsstate-of-artcamera-based\nhand authentication;\n•We conducted comprehensive experiments to evaluate the effec-\ntiveness of EchoHand under different settings and real environ-\nments, e.g., low light, audible noise, different devices, periods,\nand hardware settings. The experiment results show that Echo-\nHandcan achievea low equalerror rate (EER)of 2.45%with asfew as 10 training data points;\n•\nWe evaluated EchoHand’s ability to defeat the aforementioned\nthreetypesofattacks.Theexperimentresultsshowthatattack\nsuccessratesarebelow1.35%.Theoverheadevaluationshows\nthat EchoHand is efficient with a low authentication latency of\n0.59secondsandmemoryusageof83MB.Wealsoperformeda\nuser study to understand users’ acceptance of EchoHand.\n2 OVERVIEW OF EchoHand\nAsshowninFigure2,EchoHandusesthespeakerandmicrophone\nforacousticsensingtocomplementgeometry-basedhandauthenti-cation.Similartootherauthenticationschemes,EchoHandconsistsoftwophases:enrollmentandauthentication.Inenrollment,Echo-\nHand builds a legitimate user’s profile, which includes acoustic\nsensedand thecameracaptureddata. Theuserisrequired tohold\nthedeviceinhandandperformahandgesturefacingthecamera\nfor registration. In the authentication phase, EchoHand compares\nboth acoustic sensed and the camera captured biometrics.\nAsshowninFigure1,EchoHandconsistsoffourmodules:data\ncapturer, data preprocessor, feature extractor, and authenticator.\nThe data capturer applies interpolation to the ZC sequence and\nmodulates it to an inaudible frequency band. EchoHand transmits\ntheinaudibleacousticsignalusingspeakerandcapturestheechoes\nusing microphone. It captures the hand gesture image using thecamera. For the received echoes, the data preprocessor removes\nnoisewithaband-passfilterandappliessignaldemodulation.Echo-\nHand performs signal extraction using cross-correlation to derive\nthe target signal shaped by the holding hand. For the hand gesture\nimage,EchoHandperformssegmentationtoremovebackground\nand contour detection to derive the hand contour.\n2932CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nThe feature extractor applies continuous wavelet transform \n(CWT) for the extracted signal to generate its time-frequency spec-\ntrogram and uses a learning-based approach to extract acoustic \nfeatures. With the hand gesture image and its contour, EchoHand \nperforms landmark detection and rectification to find accurate key \npoints, and offers the hand geometry representation based on these \nkey points. It marks the acoustic and hand geometry features as \na joint feature representation. To profile the legitimate user, the \nauthenticator uses the combined feature set to train a machine \nlearning model based on a one-class classifier, which is later used \nfor authentication.\n3 ACOUSTIC SIGNAL PROPAGATION\nWhen using the speaker and microphone on the same device for \nacoustic sensing, the received acoustic signals are a collection of \nthe transmitted signal propagating through different paths, which \nis subject to the multi-path effect [45]. These paths have differ-\nent time delays, phase delays, and energy attenuation thanks to \nthe characteristics of different propagation media and distances. \nMulti-path propagation can be modeled as a linear time-invariant \nsystem [45], where the received signal (𝑦[𝑛]) can be described as a \nconvolution of the input (𝑥 [𝑛]) and the impulse response (IR, ℎ[𝑛]) \nof the multi-path propagation as shown in Eq. 1.\n𝑦[𝑛]=𝑥[𝑛]∗ℎ[𝑛]=𝑀−1/summationdisplay.1\n𝑖=0𝑎𝑖𝑒−𝑗𝜃𝑖𝑥[𝑛−𝜏𝑖] (1)\nwhere𝑛∈N,𝑦[𝑛]is the𝑛𝑡ℎsample in the sequence, ∗is the\nconvolutionoperator, 𝑀isthenumberofpropagationpaths, 𝑎𝑖is\nattenuation coefficient of the 𝑖𝑡ℎpath,𝜃𝑖is phase delay, and 𝜏𝑖is\ntime delay. The IR can be formulated as Eq. 2.\nℎ[𝑛]=𝑀−1/summationdisplay.1\n𝑖=0𝑎𝑖𝑒−𝑗𝜃𝑖𝛿[𝑛−𝜏𝑖] (2)\nwhere𝛿[𝑛]is the Dirac’s delta function ( 𝛿[𝑛]=1 for𝑛=0, oth-\nerwise𝛿[𝑛]=0). The IR of multi-path propagation depends on\nmanyfactors,suchasdevicelayout,material,theholdinghand,etc.\nGivenalineartime-invariantsystem,thesystemoutput 𝑦[𝑛]can\nbe formulated as Eq. 3.\n𝑦[𝑛]=𝑥[𝑛]∗ℎ[𝑛]=𝑁−1/summationdisplay.1\n𝑘=0𝑥[𝑘]ℎ[𝑛−𝑘] (3)\nwhere N is the maximum length between 𝑥[𝑛]and𝑦[𝑛]. In partic-\nular,thecross-correlationoftheoutput 𝑦[𝑛]andinput 𝑥[𝑛]canbe\nformulated as Eq. 4.\n𝑟𝑦𝑥[𝜏]=𝑁−1/summationdisplay.1\n𝑘=𝜏𝑦[𝑘]𝑥★[𝑘−𝜏]=𝑁−1/summationdisplay.1\n𝑘=𝜏(𝑁−1/summationdisplay.1\n𝑗=0𝑥[𝑗]ℎ[𝑘−𝑗])𝑥★[𝑘−𝜏]\n=𝑁−1/summationdisplay.1\n𝑗=0𝑁−1/summationdisplay.1\n𝑘=𝜏𝑥[𝑗]𝑥★[𝑘−𝜏]ℎ[𝑘−𝑗] (4)\nIn particular, if 𝑦[𝑛]is same as 𝑥[𝑛],𝑟𝑦𝑥[𝑛]is also namely auto-\ncorrelation of 𝑥[𝑛], i.e.,𝑟𝑥[𝜏]. Its formulation is given as Eq. 5.\n𝑟𝑥[𝜏]=𝑁−1/summationdisplay.1\n𝑘=𝜏𝑥[𝑘]𝑥★[𝑘−𝜏]=𝜎2\n𝑥𝛿[𝜏] (5)where𝜎𝑥is the standard deviation of the input signal 𝑥[𝑛].A sa\nresult, the cross-correlation 𝑟𝑦𝑥[𝜏]can be expressed as Eq. 6.\n𝑟𝑦𝑥[𝜏]=𝑁−1/summationdisplay.1\n𝑗=0𝜎2\n𝑥𝛿[𝜏]ℎ[𝜏−𝑗]=𝜎2\n𝑥ℎ[𝜏] (6)\nThus, given that the transmitting signal 𝑥[𝑛]is constant, the\n𝑟𝑦𝑥[𝜏]is linearly dependent on ℎ[𝜏](Eq. 6). To characterize the\nholding hand, we estimate the IR using the received signal and\ntransmitted signal. The estimation of IR ˆℎ[𝑛]can be formulated as\nEq.7,whichisbasedonthecross-correlationofthereceivedsignal\n𝑦[𝑛]and the transmitted signal 𝑥[𝑛].\nˆℎ[𝑛]=1\n𝜎2𝑥𝑟𝑦𝑥[𝑛]=1\n𝜎2𝑥𝑁−1/summationdisplay.1\n𝑘=𝑛𝑦[𝑘]𝑥★[𝑘−𝑛] (7)\nwhere𝑥★[𝑛]isthecomplexconjugationof 𝑥[𝑛].𝜎𝑥isthestandard\ndeviation of 𝑥[𝑛].\nWeusecross-correlationtomeasurethedisplacementofasig-\nnal relative to another [ 52]. Figure 3(a) shows an example cross-\ncorrelationofthereceivedmulti-pathsignalandthetransmitted\nsignal.Becausethesignalpropagatesthroughthedeviceandair,the\nreceivedsignalconsistsofthestructure-bornepropagationthrough\nthedeviceand air-bornepropagation.Thestructure-bornepropa-\ngation (Path 1) arrives first due to higher speed (>3,000m/s). The\nair-borne propagations, which consist of the direct transmission\nandthereflectionoftheholdinghand(Path2)andthereflections\nfrom other surrounding objects (Path 3), arrive later.\nFigure 4 compares the IR estimation results with two subjects in\nourstudy.SincetheIRestimationisacomplex-valuedsignal,we\ncalculate its magnitude with real and imaginary parts as shown in\nFigure 4(a) and (b), and show the trace of real and imaginary parts\nin Figure 4(c) and (d). As the figures show, the IR estimations of\ntwo subjects aremuch different. But, the two differentexecutions\nfrom the same user are similar. Also, it shows that the trace of\nreal and imaginary parts of two subjects are significantly different,\nwhereas the two traces of the same user are consistent. This ob-\nservation clearly shows that acoustic sensing can be exploited for\ncharacterizing hand to distinguish different subjects.\n4 CHARACTERIZING ACOUSTIC ECHOES\nInthissection,wepresenthowEchoHandextractsacousticfea-\ntures that can effectively characterize the holding hand.\n4.1 Acoustic Data Capturer\nWe have the following design considerations for the transmitted\nsignal: i) to better locate and separate the target signal reflectedby hand from the received signal, the transmitted signal should\nhaveanarrowmainlobeinitsauto-correlation[ 51];ii)thetrans-\nmittedsignalshouldbeinaudibletoavoidannoyingusers;iii)thefrequency range of the transmitted signal should be supported by\nthefrequencyresponseofaudiohardwareoncommoditymobile\ndevices, i.e., less than 24kHz.\nBase signal selection. Existing acoustic sensing-based authen-\ntications [ 39,65,74] only consider magnitude characteristics by\nusing a chirp signal, whose frequency changes with time. Chirp\nsignal is usually used for ranging [ 32,35]. We choose ZC sequence\n2933EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile DevicesCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\nPath 1Path 2\nPath 3\n(a) (b) (c) (d)\nFigure3:Anexampleofcross-correlationofreceivedmulti-pathsignalandthetransmittedsignal(a),real(I)andimaginary(Q)\npart of interpolated ZC sequence (b), auto-correlation of interpolated ZC sequence (c), and modulated sequence (d)\n(a) Two subjects (b) The same user (c) Two subjects (d) The same user\nFigure4:IRestimationsusingcross-correlationofthereceivedsignalandthetransmittedsignalfortwosubjects:themagnitude\nof IR from two subjects (a); the magnitude of IR from the same subject at two times with 48kHz sampling rate (b); trace of the\nreal/imaginary parts from two subjects (c); trace of the real/imaginary parts from the same subject at two times (d)\nas the base signal [ 54,68], which has a narrower main lobe of\nitsauto-correlation.AsshowninFigure3(c),theauto-correlation\nof ZC sequence has an extremely narrow main lobe. The auto-\ncorrelation of ZC sequence is close to zero when delay 𝜏is not\nzero, whereasits auto-correlationis maximizedonly witha delay\n𝜏=0. To separate the multi-path signal arriving at different delays,\nwe can perform cross-correlation of the received multi-path signal\nand the transmitted signal. Also, ZC sequence is a complex-valued\nsignalwithaconstantamplitude,whichcontainsnotonlythetime-\nvariedmagnitudeinformationbutalsophaseinformation,which\ncan help distinguish signals. A ZC sequence 𝑥[𝑛]is formulated\nas𝑥[𝑛]=exp(−𝑗𝜋𝑅𝑛(𝑛+1)/𝑁),where𝑁isthelengthofZCse-\nquenceand 𝑛∈[0,𝑁−1],𝑅isaconstantwith 𝑅<𝑁,𝑁and𝑅are\nodd-valued positive integer and coprime, i.e. 𝑔𝑐𝑑(𝑅,𝑁)=1.\nInterpolation. SincetherawZCsequencecoverstheentirefre-\nquencyband,weneedtofititsbandwidthtoanarrowfrequency\nbandforsignaltransmitting.WeemployFourierinterpolation[ 3]to\nincreasethesequencelength,whichpadszerosinthefrequencydo-\nmain. After interpolation, we obtain the interpolated ZC sequence\n𝑥/prime[𝑛]as shown in Figure 3(b).\nModulation. The interpolated ZC sequence lies in an audible\nlow-frequency band. We modulate the interpolated sequence to an\ninaudiblehigh-frequencyband.Consideringthatmostsmartphones\nonlysupportthesamplingrateupto48kHz,wesetthesampling\nrate𝑓𝑠as48kHz,andthecenterfrequencyofcarrier 𝑓𝑐as20kHz.\nWemodulatetherealandimaginaryprobabilitiesofthecomplex-\nvaluedsequencetoasinglerealsequence.Themodulatedsequence𝑦[𝑛]is formulated as Eq. 8.\n𝑦[𝑛]=cos/parenleftbigg2𝜋𝑓𝑐𝑛\n𝑓𝑠/parenrightbigg\n𝑥/prime\n𝐼[𝑛]−sin/parenleftbigg2𝜋𝑓𝑐𝑛\n𝑓𝑠/parenrightbigg\n𝑥/prime\n𝑄[𝑛](8)\nwhere𝑥/prime\n𝐼[𝑛]and𝑥/prime\n𝑄[𝑛]is the real and imaginary part of 𝑥/prime[𝑛],\nrespectively; 𝑛∈[0,𝑁/prime−1];and𝑁/primeisthelengthofinterpolated\nsequence 𝑥/prime[𝑛]. Figure 3(d) shows an example modulated signal. A\nHammingwindowisappliedtothefirstandlastpointstoreduce\nthe audible noise caused by spectral leakage.\nEchoHand first plays a modulated signal using the speaker and\natthesametimestartsrecordingwiththemicrophone.Theplayingtakes\n𝑁/prime/𝑓𝑠seconds,whiletherecordingtakes 2𝑁/prime/𝑓𝑠seconds.The\nrecorded signal is passed to the acoustic data processor module.\n4.2 Acoustic Data Processor\nThe acoustic data processor performs signal preprocessing and\nextraction to derive the signal shaped by the holding hand.\n4.2.1 SignalPreprocessor. Itperformsnoiseremovalanddemod-\nulationforthecapturedsignaltoreconstructthecomplex-valued\nbaseband signal. EchoHand first performs noise removal to re-move out-band interference. To separate high-frequency echoes\nfromlow-frequencyambientnoise,weuseaButterworthband-passfilter(BPF)tofilterthetargetsignalinthetransmissionband.Tore-\nconstruct the baseband complex-valued signal, EchoHand demod-\nulatesthefilteredhigh-frequencysignal.Itderivesrealandimag-\ninary components by multiplying the signal and two orthogonal\nsubcarriersthatareusedformodulation.WealsouseaButterworth\nlow-passfilter(LPF)toeliminatethehigh-frequencyinterference\nincurred by multiplication.\n2934CCS ’22, November 7–11, 2022, Los Angeles, CA, USA EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile Devices\nTable 1: Propagation speed, distance, delay, and energy level \nof different propagation paths\nPath Speed(m/s) Distance (cm) †Delay (ms) / Points Energy\n1 >3,000 15.2 0.05/-19 Medium\n2 ∼343 [15.2, 15.2×2] [0.44/0, 0.89/22] High\n3 ∼343 [15.2×2, ∞] [0.87/22, ∞]L o w\n†: As an example, we use the distance of Pixel 3A in which the microphone and\nbottom speaker are 15.2cm apart.\n4.2.2 Signal Extractor. Table 1 presents the propagation speed,\ndistance, delay, and energy of Path 1, 2, and 3. We aim to extract\nthe Path 1 and 2 propagation from the received signal since they\nareshapedbytheholdinghand.WefirstestimateIRusingcross-correlationofthedemodulatedsignalandthetransmittedsignal.\nThen we leverage the magnitude of IR estimation to locate the\ncandidatepropagationpathwiththehighestenergy,andidentify\notherpropagationpathsbasedontheknownrelativedelays.Finally,\nwesegmentthetargetsignalbasedonthedifferentarrivaldelays\nof different propagation paths.\nAs shown in Table 1, the air-borne propagation via direct trans-\nmissionfromthespeakertothemicrophonehasthemostenergy\ncompared with Path 1 and 3, because acoustic signal energy at-tenuates fast through solid device body and is absorbed more by\nenvironmentalobjectsthroughtheair[ 57].Figure3(a)illustrates\nthe energy and arrival time of three paths, the highest peak repre-\nsentstheair-bornepropagationthroughdirecttransmission.We\ndetermine the arrival time of Path 2 by detecting the highest peak.\nGiven the distance between the microphone and speaker as 𝑑,\nPath 1 arrives with (𝑑𝑓𝑠\n𝑣𝑎−𝑑𝑓𝑠\n𝑣𝑠)-point ahead of direct transmission\nthroughtheair,where 𝑣𝑎and𝑣𝑠arethepropagation speedofair-\nborne and structure-borne, respectively. The target signal of Path 1\niswithintherangeof [−(𝑑𝑓𝑠\n𝑣𝑎−𝑑𝑓𝑠\n𝑣𝑠),0],where0denotesthedetected\narrival time of air-borne propagationthrough direct transmission.\nTo separate air-borne propagation signal shaped by the holding\nhand, we focus on Path 2 with a propagation distance ranged from\n𝑑to 2𝑑, where𝑑is the propagation distance of direct transmission.\nThe target signal of Path 2 ranges from of [0,𝑑𝑓𝑠\n𝑣𝑎]-point after Path\n2. Therefore, the structure-borne and air-borne signal shaped by\nthe holding hand is within a range of [ −(𝑑𝑓𝑠\n𝑣𝑎−𝑑𝑓𝑠\n𝑣𝑠),𝑑𝑓𝑠\n𝑣𝑎] relative\nto Path 2. For example, when 𝑣𝑎= 343 m/s, 𝑣𝑠= 3000 m/s, 𝑓𝑠=\n48kHz, and 𝑑= 15.2cm (Pixel 3A), the signal shaped by the holding\nhand is in the range of [-19, 22] as shown in Table 1. Finally, the\noutput ofacoustic dataprocessor isthe separatedstructure-borne\nandair-bornecomplex-valuedsignal,whichiswiththelengthof\n(2𝑑𝑓𝑠\n𝑣𝑎−𝑑𝑓𝑠\n𝑣𝑠)-point.\n4.3 Acoustic Feature Extractor\nWe adopt time-frequency spectrogram analysis and learning-based\nfeature extraction to characterize the holding hand.\n4.3.1 SpectrogramAnalyzer. Forthecomplex-valuedsignalshaped\nbytheholdinghand,wecalculatethemagnitudeandphaseinforma-\ntion.Thenweemploycontinuouswavelettransform(CWT)[ 42,64]\nto construct a time-frequency representation of the magnitude and\nphase.Weremovenoisewithlowenergyandperformnormaliza-\ntion. CWT has better time and frequency resolution to perform\n(a)\n (b)\nFigure 5: An example CWT result of the magnitude: the raw\nCWT result (a); the CWT result after applying threshold (b)\nTable 2: The size, number of parameters, and mean/standard\ndeviation of inference time transferring different neutral\nnetworks as a feature extractor\nBase model Size (MB) # Of parameters Inference time (ms)\nVGG16 512.23 134,259,392 15.92/0.01\nResNet50 90.43 23,581,440 38.47/0.48\nInceptionV3 83.97 21,802,208 59.53/1.37\nDenseNet121 27.90 7,031,232 68.61/3.27\ntime-frequency analysis than other approaches, such as short-time\nFourier transform [42].\nAs an example, Figure 5(a) illustrates the CWT result of the\nmagnitude. We observe that the major components lie in a low-frequencybandof0-500Hz,whichisshapedbytheuser’sdevice\nholdingstyleandthephysiologicalcharacteristicsofthehand.Thetime-frequencyspectrogramalsoshowsasignificantdecreaseafterthedelayofover30points,whicharenoisecomponents.Wesetthe\nthresholdasthestandarddeviationoftheinputsignaltoremove\nnoisecomponents.Figure5(b)showstheCWTresultafterapplyingthethresholdandnormalization,wherethenoisecomponentshave\nlittle influence on the time-frequency spectrogram.\n4.3.2 Learning-basedFeatureExtractor. Toanalyzethedistinguish-\nable features from the time-frequency spectrogram, we build a\nlearning-basedextractorbasedontransferlearning[ 61].Wetraina\nbasemodelusingacousticsensingdatafromdifferentsubjects,then\ntransfer the pre-trained base model to a generic feature extractor.\nBasemodelstructure. Weusealightweightconvolutionneural\nnetwork, DenseNet [ 25], as the base model. DenseNet has four\ndense blocks, in which the feature maps of all preceding layers\nandthecurrentlayerareconcatenatedandthenpassedonasthe\ninput to the subsequent layer. DenseNet recognizes input with 3\nchannels, whereas the time-frequency spectrogram has 2 channels,\ni.e.,magnitudeandphasespectrograms.Tomakeitcompatiblewith\nthe output of spectrogram analyzer, we add a 3x3 convolutionallayer before the input layer of DenseNet. Also, we add the fully-\nconnectedlayerandtheSoftMaxlayeraftertheoutputofthemodel\nto distinguish different subjects. Thanks to the lightweight basemodel with few parameters, its size is 27.90 MB and the average\ninferencetimeis68.61ms,whichisavailableonmobiledevices.We\nhave also considered other CNN structures, including VGG [ 49],\nResNet[24], and Inception [ 56]. Table 2 presents the comparison of\nusing other models. Although it has the largest inference time, this\ndelay is short enough to support user authentication.\nBasemodeltraining. Wetrainthebasemodelusingcollecteddata\npoints from 15 subjects, where each subject contributes 500 data\n2935CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\n\u0001\u0001\u0001\n\u0002\u0003\u0004\u0005\u0006\u0007\u0004\b\t\n\u000b\b\u0006\u0004\f\u0005\b\r\u000e\u0005\u0006\u000f\r\u0010\b\u0005\u0005\u0011\u000f\u0012\nBase model \ntraining\n\u0013\t\t\b\t\n\u0007\u0014\u000f\u0015\u0014\u0016\f\u0004\u0011\u0014\u000f\u0006\u0016\n\u0016\u0006\u0017\b\u0005\n\u0018\u0006\u0017\b\u0005\r\n\u0014\u0010\n\u0019\b\u000f\r\b\u001a\b\u0004 \u0013\t\t\b\t\n\u001b\u0014\u0010\u0004\u001c\u0006\u0003\n\u0016\u0006\u0017\b\u0005\u0013\t\t\b\t\n\u0010\f\u0016\u0016\u0017\u001d\u0007\u0014\u000f\u000f\b\u0007\u0004\b\t\n\u0016\u0006\u0017\b\u0005\u0001\u0001\u0001Feature extractor \ntransferring\u000e\u0005\u0006\u000f\r\u0010\b\u0005\u0005\u0011\u000f\u0012\nFigure6:Transferringthebasemodelasthefeatureextractor\n(a) (b)\nFigure 7: L2 distance of acoustic features under three scenar-\nios (a), participants’ perception of whether the hand gesture\nis easy to perform (b)\npoints.WeuseAdamoptimizerforparametersoptimization[ 31]\nand categorical cross-entropy as the loss function. The training\nbatchsizeandepochsaresetas100and5,000.WeusedDenseNet121\nin Keras [ 5] as the base model and TensorFlow as the backend.\nTrainingthebasemodeltakesaroundtwohoursusing1xTeslaP40\nGPU.Thebasemodelonlyrequirestobetrainedonlyonce,andthen\ncan be transferred to unseen subjects for feature extraction [61].\nTransferring the base model as a feature extractor. The basic idea\noftransferlearningistotransfertheknowledgefromapre-trained\nteacher model (base model) to a new student model (feature ex-\ntractor).Since theshallow layers,i.e. forwardlayers, havealready\nlearned representative features for the student task during base\nmodeltraining,theoutputoftheseshallowlayerscanbeusedas\nthe extracted features [ 58,74]. Figure 6 presents the illustration of\ntransferring the base model as a feature extractor. We build the fea-\nture extractor by dropping the fully-connected layer and SoftMax\nlayer, and saving the former layers as the feature extractor. The\noutput is a 1024-dimensional acoustic feature vector.\nWe also investigated the distinguishability of using acoustic\nsensing to sense three typical scenarios, where the device is in\nthe user’s hand, pocket, and on a table. Figure 7(a) shows the L2\ndistanceofacousticfeaturesunderthreescenarios,where50data\npoints of each scenario are used to extract acoustic features. Weobserve that the features of the same scenario present a higher\ncorrelation than that of different scenarios.\n5HAND GEOMETRY FEATURE EXTRACTION\nInthissection,wepresentourhandgeometryfeatureextraction\nmethodtohelpvalidatetheeffectivenessof EchoHand.ComparedTable 3: Parameters of image augmentation\nOperation Parameters\nScaling Scaling factor ∈[0.8, 1.2]\nRotation Rotation angles ∈[-60°, 60°]\nTranslation Translation percent ∈[-0.1, 0.1]\nShearing Shearing factor ∈[-30, 30]\nAB C D E\nFigure 8: Five hand gestures, where fingers and palm should\nbe roughly in the same plane, and fingers should be straight\n(a)\n (b)\n (c)\nFigure9:Anexampleoftheoriginalimage(a),handsegmen-\ntation (b), and detected hand contour (c)\nwith the existing methods [ 13,15,33], our implementation con-\ntributesnewmethodsinhandsegmentation,landmarkrectification,\nhand joint detection, and geometry representation.\n5.1 Hand Gesture Image Processing\nHand gesture. To capture 2-dimensional hand geometry features\nfromanimage,oursystemimposesthefollowingrules:i)thefingersandpalmshouldbeapproximatelyinthesameplane;ii)thefingers\nshould be straight and not overlap with each other. These rules\ncanbeseeninmostmaturehandauthenticationsystems,suchas\nAmazon One [ 9] and Hand ID [ 10]. Figure 8 presents five example\nhand gestures in our experiments. These hand gestures are easyto perform, and these restrictions will not undermine the userexperience. Figure 7(b) presents participants’ perception of the\ndifficulty of performing five hand gestures. In enrollment, the user\nisrequired tochoosea handgestureto register,andthen perform\nthe registered hand gesture in the authentication phase.\nHand segmentation and contour detection. To eliminate the im-\npact of cluttered image backgrounds, we utilize the DeepLabv3+model [\n1] to identify the location of the hand in the image. We\ntransformRGBtoHSVcolorspaceandapplyacolorrangetoob-\ntainthecleanhandimage[ 34].Afterderivingthecleanhandimage,\nweconducthandcontourdetection[ 55].Thedetectedcontouris\nthe collection of pixel location of hand edges. Figure 9 presents an\nexample of hand segmentation and contour detection.\n2936EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile Devices CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nFigure 10: Generated hand gesture images under image aug-\nmentation\nTable 4: List of extracted hand geometry features\nFeature Description #Of features\nFinger length Lengthofeachfinger,including3-5,6-9,10-13,14-7,and18-21 5\nFinger width Distance between pairs of finger joints, including 22-23, 24-25,\n26-27, 28-29, 30-31, 32-33, 34-35, 36-37, 38-399\nPalm size Area and length of polygons consisting with lines 1-3-6-10-14-\n18. Distance of 1-3, 1-6, 1-10, 1-14, 1-187\nFinger dis-\ntanceDistance between 2 adjacent fingers, including 2-6, 3-7, 4-8,\n5-9, 6-10, 7-11, 8-12, 9-13, 10-14, 11-15, 12-16, etc.16\nImage augmentation. To generate more training data, we use\nimage augmentation for each captured image in enrollment [ 44].\nTheideaistogeneratenewimagesthataresimilartotheregistered\nhand gesture image. We consider four image augmentation opera-\ntions:scaling,rotation,translation,andshearing.Specifically,we\nperform image augmentation using the combination of these oper-\nations.Table3presentstheparameterrangefortheseoperations.\nAs an example, Figure 10 shows the captured raw hand gesture\nimage, and generated images under different image augmentation\noperations.\n5.2 Hand Geometry Representation\nTo extract geometry features from hand gesture images, we first\ndetect the hand landmarks.Next, we rectify the biased landmarks\nand detect the finger joints. Finally, we extract hand geometry\nfeatures using the rectified landmarks.\nLandmarkdetection. Toanalyzethehandlandmarks,weemploya\nreleasedhandlandmarkdetectionmodelinOpenpose[ 4,48],which\nwas trained to detect 21 hand landmarks. As shown in Figure 11(a),\nthe labeled red points (#1-21) are detected hand landmarks, i.e.,\nhand skeleton nodes.\nLandmarkrectification. Althoughthemodelhasachievedgreat\nperformanceindetectingthe handlandmarks,theestimatedland-\nmarksmaynotbeaccurate.Torectifythebiasedpoints,weconsider\nthateachfingerisstraight,i.e.,thekeypointsonthesamefingerareon the same straight line. Thus, the detected point of #6, 7, 8, and 9\nshouldbeonthesamestraightline,whichwetermas fingerline.\nAsshowninFigure11(b),wefitastraightlineusingthelandmarks\non the finger line, e.g., #6, 7, 8, and 9, based on the least squares\nmethod. Then, for each point on the finger, we find its perpendicu-\nlarfootonthefingerlineastherectifiedpoint,asshownasbluepoints in Figure 11(b). We also rectify the fingertip point as the\nnearestintersectionpointofthefingerlineandhandcontour.To\n(a)\n (b)\n (c)\nFigure11:Thelabeledredpoints#1-21arethedetectedhand\nlandmarks using Openpose (a), the labeled blue points are\nrectifiedlandmarksbasedonthefingerline(b),thelabeled\nblue points are rectified fingertip landmarks and red points\nare detected finger joints (c).\nlocate the finger joints, we draw a line perpendicular to the finger\nlinebasedontherectifiedkeypoint(bluepointsinFigure11(b)).\nThetwonearestintersectionpointsoftheperpendicularlineand\nhandcontouraredetectedasapairoffingerjoints(redpointsin\nFigure 11(c)).\nGeometry representation. With rectified hand landmarks and\ndetected finger joints, we extract the following hand geometry\nfeatures: i) finger length, which isdefined as the distancebetween\nthe fingertip point and the metacarpophalangeal joint, e.g., #3, 6,\n10, 14, or 18. There are 5 features for finger length; ii) finger width,\nwhichisdefinedasthedistanceofapairoffingerjointswiththe\nhandlandmarkinthemiddle.Wecalculate9widthsfor5fingers;\niii)palmsize,whichisdefinedastheareaandlengthofpolygons\nconsistingof5landmarks,e.g.,#1,3,6,10,14,18.Todescribethe\nshape, we also calculate the distance between point #1 and eachof #3, 6, 10, 14, 18. By doing so, 7 features of the palm size are\ncalculated;iv) fingerdistance implieshowusersperformthehand\ngesture, which is relevant to the user’s hand gesture behavior. We\ndefine the finger distance as the length between 2 fingers, such as\n#2-6 and 5-9. We calculate 16 features of finger distance.\nIntotal,weextract37features,whicharesummarizedinTable4.\nFigure12(a)showsthetwo-dimensionalfeaturespaceofthreeusers’\nraw and augmented hand images, which can be easily classified.Figure 12(b) presents the differences in hand geometry features\nextracted from three users.\n6 ONE-CLASS CLASSIFIERS\nBecauseonlythelegitimateuser’sdataisavailableinenrollment,\nEchoHandusesone-classclassifiers,includingcentroidclassifier\n(CC), local outlierfactor (LOF), and one-classsupport vector ma-\nchine (OCSVM): i) CC [ 38] is a distance-based classifier, which\ncomputesthedistancebetweenthetestdatapointandthecentroid\nof training points; ii) LOF [ 17] is a density-based method to recog-\nnizetheoutlierdatapointbycomputingthelocaldensitydeviation\nbetweenthetestdatapointanditsneighbors.Thedatapointwill\nbeconsideredastheoutlierifithasasubstantiallylowerdensity\nthanitsneighbors,wherethelocaldensitydeviationisestimated\nbased on the L2 distance of its 𝑘neighbors; iii) OCSVM [ 46]i sa\ndistance-basedclassifier.Itworksbyfirstmappinginputdatapoints\n2937CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\n0.5 0.0 0.5\nFeature j0.50.00.51.01.5Feature iRaw user 1\nAu. user 1\nRaw user 2Au. user 2\nRaw user 3\nAu. user 3\n(a)\n(b)\nFigure 12: Visualized feature space of raw and augmented\n(au.) hand gesture data under PCA (a), L2 distance of three\nusers’ hand geometry features (b)\ninto another feature space with the kernel function and optimizing\na hypersphere with minimal volume that best includes the training\ndata points. The model parameters are determined by a centroid\nandaradius.Thedatapointwillberegardedastheoutlierifitis\noutside the hypersphere.\n7 DATA COLLECTION\nWe developed an Android application with the sampling rate of\naudio transmitting and recording as 48kHz for data collection. We\nusedthebottomspeakertoplaythesignalandthetopmicrophone\nto record echoes. Figure 2 shows the position of the used audio\nhardware. Afterreceivingthe IRBapproval fromour institute,we\nstarted our data collection in March 2020. We recruited 45 subjects\n(Age from 18 to 38; 19 females and 26 males). We also recruited\nanothersixsubjectstorole-playtheattackertocarryoutgesture\nspoofing,presentation,andmimicryattacks.Beforedatacollection,\nweexplainedtoeachparticipantthepurposeofthisresearchand\nthe data we collect. Each subject was asked to use the smartphone\nfor about one minute to get familiar with the device and find a\ncomfortable and relaxing device-holding style. We compiled the\nfollowing datasets.\n1)Dataset-1. We collected only acoustic signals from 15 subjects\ntotrainthebasemodelonaPixel3A.Theapptransmitstheinaudi-\nble and saves the recorded signal continuously. We collected 1,200\ndata points for each subject, and it took about three minutes for\nasubjecttocomplete.Asaresult,wecollected15×1,200=18,000\nacoustic signals for dataset-1.\n2)Dataset-2.Wecollectedhandgestureimagesandacousticsens-\ning data from 30 subjects to compile dataset-2. Besides holding the\ndeviceinacomfortablestyle,asubjectalsousedthesmartphone\ncameratocatchthehandgestureimage.Asubjectneededtoper-\nformeachhandgestureinFigure850times.Foracousticsensing,\nthe app collected 500 data points for each subject. During image\nandacousticdatacollection,subjectswereaskedtoplacedownthe\ndevice,pickitupagain,andholdthedeviceinafamiliarholding\nstyle to helpget more different data samples. Asubject spent ∼12\nminutes tocomplete thistask. As aresult,we collected30×500 =\n15,000 acoustic signals and 30×250 = 7,500 hand gesture images.\n3)Dataset-3.Toevaluatetheeffectivenessof EchoHandinnoisy\nenvironments,wecompiled dataset-3 withthesame30subjects.We\ncreated a noisy environment by playing the song ‘Sugar-Maroon 5’at∼62-65dBusingthespeakerofanothersmartphone,andtheapp\ncollected 500 data points for each subject. As a result, we collected\n30×500 = 15,000 acoustic signals in total for dataset-3.\n4)Dataset-4. To evaluate the generalization of EchoHand on\ndifferent devices, we compiled the dataset-4 on two more smart-\nphones: Xiaomi6 (5.15 inches) and Redmi Note7 (6.3 inches). We\ndivided30subjectsintotwogroupsthatareassignedtwodevices\nfor collecting acoustic data and hand images. Similar to the proce-\ndure ofdataset-2, we collected 500 acoustic signals and 250 hand\nimagesforeachsubject.Asaresult,wecollected30×500=15,000\nacousticsignalsand30×250=7,500handgestureimagesintotalfor\ndataset-4. Besides, we also used Samsung GALAXY On5 (a small\ndevicewith5inches)tocollectfivesubjects’acousticechoes.For\neach user we collected 500 acoustic signals.\n5)Dataset-5. To evaluate the effectiveness under real settings,\nwe compiled dataset-5 in four different environments: Env-1is a\nquiet meeting room with a big table and chairs. Env-2is a noisy\nbut empty meeting room with music playing at ∼42dB.Env-3is a\nnoisy and crowded room with people walking and talking. Env-4is\naquietroombutwiththeinaudiblehigh-frequencysound(same\nastheacousticsignalforsensing)continuouslyplayingnearby.We\ncalledback20subjectsanddividedthemintofourgroupstocollect\nacoustic signals in four environments respectively. Each subject is\nrequired to collect 500 acoustic signals. As a result, we collected\n15×500 = 7,500 acoustic signals in total for dataset-5.\n6)Dataset-6.Toevaluatetheauthenticationconsistency,wecom-\npileddataset-6 withfivesubjectsinfourperiodswithaninterval\nof one week. In the data collection of each period, we collected 500\nacoustic signalsand 250hand imagesfor each subject. As aresult,\nwecollected5×500×4=10,000acousticsignalsand5×250×4=5,000\nhand gesture images in total for dataset-6.\n7)Dataset-7. To evaluate the effectiveness under the low light,\nwe compiled dataset-7 with five subjects. To build the low light\nenvironment,weturnedoffthelightsourcesandclosedthecurtains\nin a meeting room in the evening. Each subject was required to\nperform each hand gesture 50 times and catch the hand gesture\nusingthesmartphonecameraandtheflash.Asaresult,wecollected\n5×50×5 = 1,250 hand gesture images in total for dataset-7.\n8)Dataset-8. To evaluate the impact of using the adjacent mi-\ncrophoneandspeaker,andcoveringthespeaker,wecollectedthe\npreviousfivesubjects’acousticdatainthetwohardware settings\non Pixel 3A. The five subjects were first required to perform hand\nsensing using adjacent bottom microphone and speaker (the dis-\ntance is 2cm) for 500 times, then using the bottom speaker and top\nmicrophone while covering the bottom speaker for 500 times. We\ncollected 2×500×5 = 5,000 acoustic echoes.\n8)Dataset-9.Wewanttoevaluateif EchoHandcandefeatthe\naforementioned attacks. To increase the possibility of successful\nattacks, we collected the acoustic sensing data and hand gesture\nimagesofsixattackers.WecalculatetheL2distancebetweenthe\nfeaturevectoroftheattackersandtheprevious30subjects.Then,\nwe assigned each attacker five subjects as his/her targets based on\nthesimilarity.Wecollectedthefollowingattackdatasets:i) dataset-\n9a:gesturespoofingattack. Similartotheprocedureof dataset-2,each\nattackerwasaskedtoholdthedevicetocollect500acousticsignalsand50handgestureimagespergesture.Wecollected6×250=1,500\n2938CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nhand gesture images and 6×500= 3,000 acoustic signals for \ndataset-9a; ii) dataset-9b: presentation attack. The attacker was \nasked to present the previously recorded hand images to the data \ncollection device using the tablet screen, and each image was only \nused to present only once. As a result, we collected 30×250 = \n7,500 hand images for dataset-9b; iii) dataset-9c: mimicry attack. We \nasked each attacker to carefully observe how the attack target holds \nthe device at a close distance (∼1.5m) and mimic the device-holding \nbehavior. After the attacker was confident about what they \nobserved, she/he would mimic the subject’s holding behavior to \ncollect acoustic sensing data. The attacker is allowed to perform \nmimicry attacks for unlimited times, but at least 50 times, where for \neach attack the app actively senses the holding hand 10 times. We \nselect 50 data points with a higher probability to be accepted by the \nauthentication model. We collected 30×500 = 15,000 data points for \nthe dataset-9c.\n8 EVALUATION\nIn this section, we report the evaluation results of the proposed \nsystem. In EchoHand, 𝑅 of ZC sequence is 63, and the length is 127. \nWe apply 1200-point interpolation to the 127-point ZC sequence.\nThus, the sequence is 25ms, i.e. 480001200 , and the frequency band of\ninterpolated sequence is 0-2.54kHz, i.e. 24\n1200𝑘 ×127. The modulated \nsequence 𝑠 [𝑘] has an inaudible frequency band of 17.46 - 22.54kHz. \nThe first and last 150 points of the modulated sequence are applied \nto a Hamming window. For the data processor, the cutoff  frequency \nof LPF is 3kHz, and the passband of BPF is 17 - 23kHz.\n8.1 Evaluation Metrics\nFalse acceptance rate (FAR) is defined as the ratio between the \nnumber of falsely accepted data points and illegal data points. It \nindicates the probability of an unauthorized user being falsely ac-\ncepted as the authorized ones. False rejection rate (FRR) is the ratio \nbetween the number of falsely rejected data points and legitimate \ndata points. It represents the probability of the authorized user be-\ning falsely rejected. Receiver operating characteristics (ROC) curve \nis a dynamic depiction of FRR against FAR at a varying decision \nthreshold. The area under the ROC curve (AUC) represents the \nprobability that prediction scores of legitimate users’ samples are \nhigher than illegal users’ samples. Equal error rate (EER) is the \npoint on the ROC curve, where FAR is equal to FRR, i.e., EER = FAR  \n= FRR. Lower EER indicates that the authentication system is more \nreliable. We use the frequency count of scores (FCS) [53] to show \nthe frequency count of all test data points’ prediction scores. FAR \n(i.e., the attack success rate) is used as the attack resistance evalua-\ntion criteria, which is defined as the ratio between the number of \nincorrectly identified data points and the number of all attack data \npoints.\n8.2 Reliability Analysis\nTo find out how distinguishable of acoustic features, we split each \nuser’s data points into training and test sets randomly, and trained \nthe authentication model  for each subject. We used the rest data \npoints and other users’ data points to evaluate the model. We per-\nformed 5-fold cross-validation to evaluate performance, and con-\nducted grid search to find the best parameter combination for each \nclassifier. The best parameter of LOF was n_estimators=3. ForTable 5: The average EERs of gesture A, B, C, D, E (Figure 8)\nClassifier A B C D E\nW. IACC 7.38% 6.90% 7.52% 6.48% 7.70%\nLOF 11.15% 10.88% 11.80% 10.13% 12.15%OCSVM 9.31% 8.83% 8.96% 8.85% 9.37%\nW/o. IACC 6.36% 6.16% 6.38% 6.06% 6.39%LOF 6.89% 5.70% 6.05% 5.91% 7.24%OCSVM 7.49% 6.97% 8.17% 7.10% 8.78%\nOC-SVM, we used radial basis function as the kernel function, and\noptimal parameters 𝛾and𝜈were 0.19 and 0.03.\n8.2.1 Performance of Acoustic Sensing. A. Finding the optimal mid-\ndlelayertotransferthebasemodelasafeatureextractor. Thebase\nmodel has four dense blocks (DB) and a fully-connected (FC) layer.\nWe used the output of each block and FC layer as the features to\ninvestigate how the choice of these layers influences the distin-\nguishability.Thebasemodelwastrainedusing18,000acousticdata\npoints of dataset-1. We used the acoustic data points in dataset-2\ntoevaluatethereliabilityofextractedfeatures,wheretheuseris\nprofiledusing10trainingdatapoints.Figure14(a)reportstheEERs\nunderthefeaturesetsextractedfromdifferentlayers.Theresults\nshowthatusingtheoutputof4 𝑡ℎdenseblockastheacousticfea-\nturesachievesthelowestEER.Figure14(b)presentsthecomparison\nof differentclassifiers using thefeatures extracted from4 𝑡ℎdense\nblock. CC achieves an average EER of 5.60%, which is much lower\nthanLOForOCSVM.Forlaterexperiments,weusetheoutputof\nthe 4𝑡ℎdense block as the extracted acoustic features.\nB.Performanceofextractedacousticfeatures Toevaluatetheeffec-\ntivenessof onlyapplying acousticsensingto distinguishbetween\nlegitimate and illegal users, we used all collected acoustic data\npoints in dataset-2. Each user was profiled with 10 data points.\nFigure13(a)showsROC curvesunderdifferent classifiers.The re-\nsults indicate that CC achieves a lower EER. CC, LOF, and OCSVM\nachieve an average EER of 5.60%, 8.77%, and 9.69%, respectively.\nFigure 13(b)(c)(d) present FCS of legitimate and illegal data points,\nshowing that prediction scores under three different classifiers\nhavesimilardistributions,whiletheoverlappingregionbetween\nthe scores of legitimate and illegal data points under CC is smaller\nthan the region of the other two classifiers. This implies that the\nCC outperforms LOF and OCSVM in terms of the error rate.\n8.2.2 Effectiveness of Hand Geometry Features. To evaluate the\neffectiveness of only applying hand geometry features to distin-guish between legitimate and illegal users, we used all collectedhand image data points in dataset-2. For each image, we applied\nimageaugmentation(IA)andgenerated100handgestureimages\nusedformodeltraining.Weevaluatedperformanceforfivehand\ngesturesrespectively.Eachuserwasprofiledwithonly10rawdatapointswhennotusingIA,andwith1,010datapoints(1,000images\nweregenerated)whenusingIA.Table5reportsEERsoffivehand\ngestures under different classifiers. The results show that image\naugmentationenhancesthegeneralizationabilityoftheauthentica-\ntion modelor template,especially LOFand OCSVM.For example,\ntheaverageEERofgestureAunderCC,LOF,andOCSVMare7.38%,\n11.15%, and 9.31% without IA. While using image augmentation,\ntheaverageEERofgestureAunderCC,LOF,andOCSVMcanbe\nimproved to 6.36%, 6.89%, and 7.49%.\n2939EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile DevicesCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\n(a) ROC curves (b) FCS under CC (c) FCS under LOF (d) FCS under OCSVM\nFigure 13: ROC curves (a) and normalized FCS (b, c, d) when using only acoustic features to authenticate users\n(a) (b)\nFigure14:Transferringdifferentmiddlelayersastheacoustic\nfeatureextractor:EERsunderthefeaturesetsextractedfromdifferentmiddlelayers(a),EERsunderthefeaturesextracted\nfrom the 4𝑡ℎdense block (b)\n8.2.3 EffectivenessofEchoHandtoAuthenticateUsers. Toevaluate\ntheeffectivenessof EchoHand,weusedthecollectedacousticdata\npointsandhandimagesin dataset-2.Inthisstep,eachrawimage\nwasusedtogenerate100newimages.Eachuserwasprofiledusing\n10rawdatapoints,i.e.,10acousticdatapointsand1,010handim-\nages. Figure 15(a) shows ROC curves when using acoustic features\nto complement hand geometry features. CC, LOF, and OCSVMachieve an average EER of 2.45%, 5.96%, and 6.82%, respectively.\nFigure15(b)(c)(d)reportFCSoflegitimateandillegaldatapoints.\nTheresultsshowthattheoverlappingregionunderCCissmaller\nthanLOFandOCSVM.Besides, there exist afew illegaldatapoints\nwithhighpredictionscoresunderthetwoclassifiers.Theresults\nsuggest that CC outperforms LOF and OCSVM, and we used CC as\nthe classifier due to its lower EER in later experiments.\n8.2.4 ImpactofAudibleNoise. Toevaluatetheimpactofaudible\nnoiseonacousticsensing,weprofiledthelegitimateuserwith10\ndatapointsfrom dataset-2,andevaluatedEERusingacousticdatain\ndataset-3 andimagedatain dataset-2,whereCCwasusedastheclas-\nsifier.Figure16(a)showsROCcurvesundertheenvironmentswith\nandwithoutnoise.Ifusingacousticfeaturestocomplementhand\ngeometryfeatures,itachievesanaverageEERof2.66%and2.45%\nunder the environment with and without audible noise, where the\nerror rate is almost approximate. If only using acoustic features, it\nachievesanaverageEERof6.12%and5.38%undertheenvironment\nwithandwithoutaudiblenoise.Resultssuggestthattheambient\nnoise has little impact on EchoHand for acoustic sensing.\n8.2.5 ConsistencyOverTime. Toevaluatetheconsistencyof Echo-\nHand over different periods, we used dataset-6. The 10 data pointsinweek1wereusedtotraintheauthenticationmodel,whilethe\nrest datain week1, 2,3, and4 were usedto evaluatethe EER.Fig-\nure 16(b) shows the results under different periods of 4 weeks. The\naverageEERsunderacousticfeaturesare5.14%,6.07%,9.15%,and\n15.98% in Week 1, 2, 3, and 4, respectively, while the EERs under\nthe hand geometry and acoustic features are 2.10%, 2.13%, 3.03%,\nand 4.53%. We observed that hand geometry features are more con-\nsistent than acoustic features under different weeks. Combining\nthesetwokindsoffeaturessignificantlyimprovesauthentication\naccuracyandconsistency.WealsofoundthattheincreasingEER\nof week 4 was due to a few subjects’ device-holding behaviors\nchanging dramatically.\n8.2.6 Performance on Different Devices. To evaluate the perfor-\nmanceof EchoHandondifferentdevices,weused dataset-1 and\n4. We trained authentication models and evaluated performanceusing the data points from the same device. CC was used as the\nclassifier and the legitimate user was profiled using 10 data points.\nFigure 17(a) shows results under the different devices. The average\nEERsonPixel3A,Xiaomi6,RedmiNote7,GALAXYOn5are2.45%,\n7.24%, 3.69%, and 10.33%, respectively. The results suggest that the\nacousticfeaturesonXiaomi6andGALAXYOn5mayundermine\nthedistinguishabilityofhandfeatures.Thismaybeduetotheshort\ndistance between the top microphone and bottom speaker.\n8.2.7 Performance Under Real Environments. We also used dataset-\n5toevaluatetheperformanceof EchoHandunderrealenviron-\nments.Wetrainedtheauthenticationmodelusing10datapoints\ninEnv-1, and tested the model using the rest data in Env-1,2,3,\nand4. Figure 17(b) shows results under different environments,\nwhere we regard the results under dataset-2 aslabenvironment.\nThe average EERs under lab and five real settings are 2.45%, 4.95%,\n4.79%,5.55%,and6.53%respectively.Theperformanceoffivereal\nsettingsisapproximatetothelabsetting.Theresultssuggestthat\nEchoHand is reliable in real environments.\n8.2.8 EffectivenessofLandmarkRectification. Toevaluatetheeffec-\ntiveness of our designed landmark rectification, we used dataset-2.\nEach user was profiled with 10 data points and CC as the classifier.\nFigure 18(a) shows ROC curves under landmark rectification. If\nonlyusinggeometryfeatures,theaverageEERsunderrectifiedand\nunrectified geometry are 6.27% and 9.25%. If using acoustic sens-ing features to complement hand geometry features, it achieves\nan average EER of 2.45% and 4.61% under rectified and unrectified\n2940CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n(a) ROC curves (b) FCS under CC (c) FCS under LOF (d) FCS under OCSVM\nFigure 15: ROC curves (a) and normalized FCS (b, c, d) when using acoustic features to complement hand geometry features\n(a) (b)\nFigure 16: ROC curves under environments with (w/)\nand without (w/o) audible noise (a), EERs under different\nweeks (b)\n(a)(b)\nFigure17:EERsunderdifferentdevices(a),andenvironments\n(b)\n(a) (b)\nFigure 18: ROC curves under landmark rectification (a), and\ndifferent hardware settings (b)\ngeometry. The result suggests our designed hand landmark rec-tification improves the robustness of hand geometry features in\nauthenticating users.Table 6: EERs and AUC under low light\nSetting Features EER AUC\nLow lightHand geometry 8.13% 0.9761\nSensing + hand geometry 2.92% 0.9955\nNormal lightHand geometry 6.27% 0.9864Sensing + hand geometry 2.45% 0.9977\n8.2.9 Performance Under Low Light Setting. To evaluate the ro-\nbustness under low light setting, we trained the authentication\nmodelusing dataset-2,andevaluatetheauthenticationmodelusing\ndataset-2 and7respectively.Table6showsEERsandAUCunder\nlowlight.Ifusingonly handgeometryfeatures,theEERs are 8.13%\nand 6.27% under low and normal light. While using acoustic fea-\ntures and hand geometry features, EchoHand achieves an average\nEERof2.92%and2.45%underlowandnormallight.Thisshowsthat\nacoustic sensing enhances the robustness of hand geometry-based\nauthentication under low light.\n8.2.10 Impact of Different Audio Hardware Settings. To evaluate\nthe impact of different audio hardware settings, we used dataset-2\nanddataset-8. 10 data points in dataset-2 were used to train the\nauthenticationmodel,whilethecombinationsofacousticdatain\ndataset-8 and handimages in dataset-2 were usedto evaluateEER.\nFigure 18 presents ROC curves under different audio hardware\nsettings. If usingthe covered bottom speaker andtop microphone,\nEchoHand achieves an average EER of 22.68%. While using the\nbottomspeakerandbottommicrophone,theaverageEERis18.32%.\n8.3 Evaluation of Attack Resistance\nTo evaluate the resistance against three different attacks, we used\ndataset-9a,b,and ctotesttheauthenticationmodeltrainedusing\ndataset-2 fromtheprevious30subjects.Wenormalizedthedecision\nthreshold(whereFARisequaltoFRR)to0,andtheninvestigatedthe\ndistributionoftheattackdataset’spredictionscores.Wereported\nFAR, i.e., attack success rate, distribution of the attack dataset’sprediction scores, the kernel density of prediction scores evalu-\natedunderGaussiankernel[ 61],andthecumulativedistribution\nfunction (CDF).\nFigure 19(a) shows the prediction scores’ distribution under ges-\nturespoofingattackusing dataset-9a.Themeanpredictionscore\nof attack data points is -2.42. The kernel density shows a narrower\nrangebutconsistentlylowpredictionscores.EchoHandcandefend\nagainstgesturespoofingattackwithaFARof0.21%.Figure19(b)\nshows the prediction scores’ distribution under presentation attack\nusing hand images of dataset-9b and acoustic data of dataset-9a.\n2941EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile DevicesCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\n(a) Gesture spoofing attack (b) Presentation attack (c) Mimicry attack (d) CDF of attack data points’ score\nFigure 19: PDF/FCS (a, b, c) and CDF (d) under gesture spoofing, presentation, and mimicry attack\nTable7:FARandmean/standarddeviationofattackdataset’s\nprediction scores\nAttack type FAR Prediction scores\nGesture spoofing attack 0.21% -2.42/ 0.86\nPresentation attack 0.62% -1.60/ 1.21Mimicry attack 1.35% -2.11/ 1.37\nTable 8: The latency of different mobile authentication\nschemes [61, 62]\nScheme Latency Motion behavior1\nPIN 1.25s \u0013\nPattern lock 3.14s \u0013\nFingerprint authentication 0.29s \u0017\nFacial authentication 1.48s \u0017\nEchoHand 0.59s \u0017\n1Require users to perform motion behavior, e.g., typing, and drawing.\nThemeanpredictionscoreis-1.60.Thekerneldensityshowsawide\nrangebutahigherscorethanthescoresunderthegesturespoof-\ning attack. Presentation attack is witha FAR of 0.62%.Figure 19(c)\nshows the prediction scores’ distribution under mimicry attack us-\ninghand imagesof dataset-9b andacoustic dataof dataset-9c.The\nmean prediction score is -2.11. The kernel density shows a wide\nrangebutiswithconsistentlylowpredictionscores,wherethere\nexist many attack data points with the scores ranging from -4 to -2.\nMimicry attack is with a FAR of 1.35%.\nThe results suggest that EchoHand can defeat gesture spoofing,\npresentation, and mimicry attacks. Table 7 reports FAR and predic-\ntionscoresofattackdatapoints.Figure19(d)presentstheCDFof\npredictionscores,wherethescoreslessthanzeroarewithahigh\nprobability.\n8.4 Latency and Memory Usage\nTheauthenticationlatencyiscomposedofthetimerequiredfordata\nprocessing,featureextraction,andmodelinference.Weevaluated\nthe latency of these modules respectively and monitored the total\nmemoryusage.Wedevelopedaprototypesystemof EchoHandon\nAndroid,andevaluatedtheaveragelatencyfor50authentications.It\ntakesaboutanaveragelatencyof0.37,0.14,and0.08secondsforthe\n3modulesrespectivelyonPixel3A(2x2.0GHz).Intotal,EchoHandrequires0.59secondstocompleteauthentication.Table8comparesthelatencybetweenEchoHandanddifferentmobileauthentication\nschemes. We also used Android Profiler to monitor the memory\nusageof EchoHand,andtheaveragememoryusageonPixel3A\nis 83MB.9 RELATED WORK\nHand authentication. Hand authentication schemes distinguish the\nlegitimate user and impostors based on the intrinsic hand traits.\nPalmprint-basedmethodsrelyonthehigh-resolutioncameratocap-\nture palmprint(i.e., acomplex setof skin lines),and sophisticated\nimageprocessingmethodstoextractthetexturefeatures[ 14,28].\nNevertheless,itisvulnerabletopresentationattacks[ 2,16].Palm\nand finger vein-based methods rely on the dedicated hardware,e.g., an infrared camera, to scan the pattern of blood vessels [\n9–\n11,29,36,63]. The dedicated hardware is not available on most\ncommodity mobile devices.\nHandgeometry-basedmethodsidentifythelegitimateuserby\nanalyzingthehandgeometryfeatures[ 15,27,33,50,60],suchas\nfingerlengths,andwidths.Simplemethodsrelyingonamonocular\nRGB camera to analyze 2D hand geometry are usually vulnera-\nbletopresentationattacks[ 13,15,33].Toenhancesecurity,these\nmethodsaredependentoncomprehensivecamerasystems,such\nasdepthcamera[ 60].Somebehavior-basedhandauthentications\nalsocharacterizethehand/fingermovementstoidentifydifferent\nsubjects[ 21,27,50,60,71,72].However,thesemethodsrequirethe\nuser to perform predefined hand gesture movements.\nCompared withhand authentications thatrequire users toper-\nform hand motion hand movement [ 27,50,60], EchoHand does\nnotrequireuserstoperformanyhandgesturemovementbutmake\na stationary hand gesture. EchoHand can also resist presentation\nattacks.Table9presentsthecomparisonofexistingmaturecom-\nmercial hand authentications and the latest research work.\nAcoustic sensing-based authentications. Acoustic sensing exploits\nspeakers and microphones to design fancy applications [ 20,26,40,\n43,54,59,67,73,75,76],e.g.,usableandsecureauthentications[ 18,\n19,30,39,69,70,74]. Sound-proof [ 30] and Proximity-Echo [ 41]\nwere proposed to validate whether the user’s phone is near the\ndevice used to log in via sensing ambient noise. Echoprint [ 74]\nenhancedthesecurityoffaceauthenticationagainstpresentation\nattacksbytransmittinganinaudibleacousticsignalandreceiving\ntheechotosensethefacialgeometry.Toenhancevoiceprintagainst\nreplay attacks, VoiceGesture [ 70] and Lippass [ 39] leveraged ac-\ntive acoustic sensing to detect mouth movements to validate thepresence of the legitimate user. To maintain the security of pat-\nternlocksandPINs,TouchPrint[ 19,75]leveragedacousticsensing\ntocharacterizefingertapping/sweepingevents.Toprovidehandauthentication using acoustic sensing, Echolock [\n65] considered\nonlythestructure-bornesignalfor sensingandanalyzedacoustic\nfeatures in the time and frequency domain. To protect smartphone\n2942CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nTable 9: Comparison of existing mature commercial hand authentications, the latest related research work\nMethod Required hardware Description of hand features EER PAR1Hand motion2\nCommercial product\nAmazon One [9] Unknowncustomizedhardware(Maybeinfrared\ncamera, RGB camera)Palm vein and palmprint patterns N/A \u0013\u0017\nHand ID [10] Infrared illuminator, TOF sensor3Palm vein patterns N/A \u0013\u0017\nPalmID [6] Infrared camera Palm vein patterns N/A \u0013\u0017\nPalmID [6] RGB camera Palmprint patterns N/A \u0017\u0017\nPalmSecure [12] Near-infrared imaging camera Palm vein patterns N/A \u0013\u0017\nVein ID [11] Near-infraredilluminator,commonRGBcamera Finger vein patterns N/A \u0013\u0017\nResearch paper\n[60] Leap motion controller43D motion depth features of gesture movement ∼2% \u0013\u0013\n[27] Leap motion controller 3D motion characteristics of fingertips and finger joints < 4% \u0013\u0013\n[50] Multi-touch screen Hand geometry and motion characteristics of swiping on a multi-touch touchscreen 5.84% \u0013\u0013\n[33] Optical scanner Hand geometry features, including finger width and length 0.59% \u0017\u0017\n[15] Optical scanner Hand geometry graph topology 3.05% \u0017\u0017\n[23] RGB camera, infrared lamp Palm dorsal veins and hand geometry features 1.87% \u0013\u0017\n[47] IntelRealSense5Palm vein patterns < 1% \u0013\u0017\n[13] RGB camera Hand images features extracted from different layers of a neural network ∼5.2% \u0017\u0017\n[65] Speaker, microphone Time-domain,frequencey-domain,MFCC6,andchromagramfeaturesofstructure-borne\nechos when holding a device (Without solid hand features)∼6% \u0013\u0017\n[26] Speaker, microphone, accelerometer Spectrogram of microphone and accelerometer incurred by notification tones when\nholding a device (Without solid hand features)∼5% \u0013\u0017\nEchoHand RGB camera, speaker, microphone Learning-based acoustic features of structure-borne and air-borne echos while sensing\nthe hand holdingdevice, hand geometry features including fingerlength, width, palm\nsize and finger distance∼2.45% \u0013\u0017\n1Presentationattackresistant.2Requireuserstoperformhandmotion.3Atypeofdepthcamerawitharangeimagingcamerasystem.4Aninfrared-based\ndepthcamerausedfortrackingmotions.5AhighqualityLiDAR-baseddepthcameras.6Mel-frequencycepstralcoefficients,akindoftypicalacoustic\nfeatures.\nnotification privacy, [ 26] leveraged vibration response from micro-\nphoneandaccelerometerspectrogramtoidentifytheuser’shand\ngripping device, where it relies on audible message tones and can-\nnot work wellin motion scenarios. EchoHand is different inthat\nitsilentlysensesandprofilesauser’shandusingthesoundprop-\nagatingthroughthedeviceandairtoprovidereliableandsecure\nhand authentication on off-the-shelf devices.\n10 LIMITATIONS\nAlthough we took great efforts to maintain our studies’ validity,\nthere arelimitations in ourstudies andexperiments. For example,\nEchoHand may notwork on deviceswhere the distancebetween\nthemicrophoneandthespeakerisextremelyshort,whichmakes\nextracting the signal shaped by the holding hand difficult. Besides,\ntheuserneedstoholdthedeviceinhandtoperformauthentication\nwith EchoHand. If the device is placed on a desktop or device\nholder during a meeting, EchoHand cannot authenticate the user.\nEchoHand might also fail to authenticate the user who wears\nthe gloves. Also, a user’s device-holding style may change over\ntime,whichmayleadtoadditionalfalserejection.Thisissuecan\nbeaddressedbyemployingthemodelupdatingmechanismasin\nFaceID. Since EchoHand detects hand landmarks based on vision\nalgorithm, it has the similar limitations to face recognition. Forexample, similar to facial recognition, hand landmarks detection\nisnotstableunderpoorlighting,andoff-normalshootingangles,\nwhich may cause more false rejections. A lower sampling rate may\nundermine the time resolution of the target signal separating, andlead to the low discernibility of extracted acoustic features among\ndifferent users.\n11 CONCLUSION\nInthispaper,wepresentahighaccuracyandpresentationattack\nresistant hand authentication method for commodity devices. Itusesbuilt-inhardwareonoff-the-shelfdevices,includingthemi-\ncrophone,speaker,andcamera.Tomitigatethethreatsofpresen-\ntation attacks, it characterizes the holding hand using acoustic\nsensingtechniquestocomplementthehandgeometryfeatures.We\ncompiled nine datasets to evaluate the reliability and security of\nEchoHand. The evaluation results demonstrate that EchoHand is\nrobust and can identify the legitimate user and impostors with a\nlow EER.\nACKNOWLEDGMENTS\nWe are grateful to the anonymous reviewers for their constructive\ncomments. This research of Wuhan University was supported in\npartbytheNationalKeyR&DProgramofChinaundergrantNo.\n2021YFB2700200, the Fundamental Research Funds for the Central\nUniversitiesundergrantsNo.2042022kf1195,2042022kf0046,and\ntheNationalNaturalScienceFoundationofChinaundergrantsNo.\nU1836202, 62076187, 62172303. The corresponding authors are Jing\nChen and Kun He.\nREFERENCES\n[1]2009. Semantic segmentation. https://github .com/PaddlePaddle/\nPaddleHub/tree/release/v2 .1/modules/image/semantic _segmentation/\ndeeplabv3p_xception65_humanseg.\n[2]2016.ISO/IEC 30107-1:2016 informationtechnology: biometric presentation attack\ndetection - part 1: framework. ISO/IEC.\n[3]2017. Interpft. https://ww2 .mathworks .cn/help/matlab/ref/interpft .html?lang =\nen.\n[4]2017. Openpose. https://github .com/CMU-Perceptual-Computing-Lab/\nopenpose.\n[5] 2018. DenseNet. https://keras .io/api/applications/densenet/.\n[6] 2018. PalmID. https://www .redrockbiometrics .com/.\n[7]2019. Amazon is apparently testing a system that lets you pay by scanning your\nhand. https://www .foxnews.com/tech/amazon-tests-whole-foods-payment-\nsystem-that-uses-hands-as-id.\n[8]2019. Data leak exposes unchangeable biometric data of over 1 mil-\nlionpeople. https://www .technologyreview .com/f/614163/data-leak-exposes-\nunchangeable-biometric-data-of-over-1-million-people/.\n2943EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile DevicesCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Cong Wu et al.\n[9]2019. One way to unlock the world, powered by your palm. https://\none.amazon.com/.\n[10]2019. Userguidelgg8thinq. https://ss7 .vzw.com/is/content/VerizonWireless/\nCatalog%20Assets/Devices/LG/LG_Alpha/lg-g8-thinq-ug .pdf.\n[11]2019. Vein id. https://www .hitachi.com.au/products/product-categories/it/\nveinid.html.\n[12]2020. PalmSecure: your business, easily secured. https://hyosungamericas .com/\nstorage/app/media/Hyosung-Fujitsu-Whitepaper .pdf.\n[13]MahmoudAfifi.2019. 11khands:genderrecognitionandbiometricidentification\nusing a large dataset of hand images. Multimedia Tools and Applications.\n[14]Somaya Al Maadeed, Xudong Jiang, Imad Rida, and Ahmed Bouridane. 2019.\nPalmprint identification using sparse and dense hybrid representation. Multime-\ndia Tools and Applications.\n[15]Shanmukhappa Angadi and Sanjeevakumar Hatture. 2018. Hand geometry\nbaseduseridentification usingminimaledgeconnectedhand imagegraph. IET\nComputer Vision.\n[16]Shruti Bhilare, Vivek Kanhangad, and Narendra Chaudhari. 2018. A study on\nvulnerability and presentation attack detection in palmprint verification system.\nPattern Analysis and Applications.\n[17]MarkusMBreunig,Hans-PeterKriegel,RaymondTNg,andJörgSander.2000.\nLOF:identifyingdensity-basedlocaloutliers.In ACMInternationalConferenceon\nManagement of Data (SIGMOD).\n[18]Jagmohan Chauhan, Yining Hu, Suranga Seneviratne, Archan Misra, Aruna\nSeneviratne, and Youngki Lee. 2017. BreathPrint: breathing acoustics-based user\nauthentication. In ACM Conference on Mobile Systems, Applications, and Services\n(MobiSys).\n[19]Huijie Chen, Fan Li, Wan Du, Song Yang, Matthew Conn, and Yu Wang. 2020.\nListen to your fingers: user authentication based on geometry biometrics of\ntouchgesture. ACMConferenceonInteractive,Mobile,WearableandUbiquitous\nTechnologies (IMWUT).\n[20]Jiayi Chen, Urs Hengartner,Hassan Khan, and Mohammad Mannan. 2020. Chap-erone:real-timelockingandlosspreventionforsmartphones.In USENIXSecurity\nSymposium.\n[21]EunyongCheon,YonghwanShin,JunHoHuh,HyoungshickKim,andIanOakley.\n2020. Gestureauthenticationforsmartphones:evaluationofgesturepassword\nselection policies. In IEEE Symposium on Security and Privacy (S&P).\n[22]RachelL.GermanandK.SuzanneBarber.2018. Consumerattitudesaboutbiometric\nauthentication. TechnicalReport.TheUniversityofTexasatAustinCenterfor\nIdentity.\n[23]Puneet Gupta, Saurabh Srivastava, and Phalguni Gupta. 2016. An accurate\ninfraredhandgeometryandveinpatternbasedauthenticationsystem. Knowledge-\nBased Systems.\n[24]KaimingHe,XiangyuZhang,ShaoqingRen,andJianSun.2016. Deepresidual\nlearningforimagerecognition.In IEEEConferenceonComputerVisionandPattern\nRecognition (CVPR).\n[25]Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger.\n2017.Denselyconnectedconvolutionalnetworks.In IEEEConferenceonComputer\nVision and Pattern Recognition (CVPR).\n[26]Long Huang and Chen Wang. 2021. Notification privacy protection via unob-trusive gripping hand verification using media sounds. In ACM Conference on\nMobile Computing and Networking (MobiCom).\n[27]SatoruImuraandHiroshiHosobe.2018. Ahandgesture-basedmethodforbiomet-\nricauthentication.In InternationalConferenceonHuman-ComputerInteraction\n(HCII).\n[28]Wei Jia, Bob Zhang, Jingting Lu, Yihai Zhu, Yang Zhao, Wangmeng Zuo, and\nHaibin Ling. 2017. Palmprint recognition based on complete direction represen-\ntation.IEEE Transactions on Image Processing (TIP).\n[29]WenxiongKangandQiuxiaWu.2014. Contactlesspalmveinrecognitionusinga\nmutual foreground-based local binary pattern. IEEE Transactions on Information\nForensics and Security (TIFS).\n[30]Nikolaos Karapanos, Claudio Marforio, Claudio Soriente, and Srdjan Capkun.\n2015. Sound-proof: usable two-factor authentication based on ambient sound. In\nUSENIX Security Symposium.\n[31]DiederikPKingmaandJimmyBa.2014. Adam:amethodforstochasticoptimiza-\ntion.arXiv:1412.6980.\n[32]JohnRKlauder,ACPrice,SidneyDarlington,andWalterJAlbersheim.1960. The\ntheory and design of chirp radars. Bell System Technical Journal.\n[33]Marek Klonowski, Marcin Plata, and Piotr Syga. 2018. User authorization based\non hand geometry without special equipment. Pattern Recognition.\n[34]SeemaKolkur,DKalbande,PShimpi,CBapat,andJanviJatakia.2017. Human\nskin detection using RGB, HSV and YCbCr color models. arXiv:1708.02694.\n[35]Patrick Lazik and Anthony Rowe. 2012. Indoor pseudo-ranging of mobile de-\nvices using ultrasonic chirps. In ACM Conference on Embedded Networked Sensor\nSystems (SenSys).\n[36] Larry Li. 2014. Time-of-flight camera–an introduction. Technical White Paper.\n[37]Chang Liu, Yulin Yang, Xingyan Liu, Linpu Fang, and Wenxiong Kang. 2020.\nDynamic-hand-gestureauthenticationdatasetandbenchmark. IEEETransactionson Information Forensics and Security (TIFS).\n[38]Giulio Lovisotto, Simon Eberz, and Ivan Martinovic. 2020. Biometric backdoors:\na poisoning attack against unsupervised template updating. In IEEE European\nSymposium on Security and Privacy (EuroS&P).\n[39]LiLu,JiadiYu,YingyingChen,HongboLiu,YanminZhu,YunfeiLiu,andMinglu\nLi. 2018. Lippass: lip reading-based user authentication on smartphones leverag-\ning acousticsignals. In IEEE InternationalConference on Computer Communica-\ntions (INFOCOM).\n[40]Li Lu, Jiadi Yu, Yingying Chen, Yanmin Zhu, Xiangyu Xu, Guangtao Xue, and\nMinglu Li. 2019. Keylistener: Inferring keystrokes on qwerty keyboard of touch\nscreenthroughacousticsignals.In IEEEInternationalConferenceonComputer\nCommunications (INFOCOM).\n[41]Xiaobo Ma, Mawei Shi, Bingyu An, Jianfeng Li, Daniel Xiapu Luo, Junjie Zhang,\nand Xiaohong Guan. 2021. Proximity-echo: secure two factor authentication\nusingactivesoundsensing.In IEEEInternationalConferenceonComputerCom-\nmunications (INFOCOM).\n[42] Stéphane Mallat. 1999. A wavelet tour of signal processing. Elsevier.\n[43]Rajalakshmi Nandakumar, Vikram Iyer, Desney Tan, and Shyamnath Gollakota.\n2016. Fingerio: using active sonar for fine-grained finger tracking. In ACM\nConference on Human Factors in Computing Systems (CHI).\n[44]Luis Perez and Jason Wang. 2017. The effectiveness of data augmentation in\nimage classification using deep learning. arXiv:1712.04621.\n[45]Jianjun Ran. 2008. Signal processing, channel estimation and link adaptation in\nmimo-ofdm systems. Cuvillier Verlag.\n[46]BernhardSchölkopf,JohnCPlatt,JohnShawe-Taylor,AlexJSmola,andRobertC\nWilliamson. 2001. Estimating the support of a high-dimensional distribution.\nNeural Computation.\n[47]Syed W Shah, Salil S Kanhere, Jin Zhang, and Lina Yao. 2021. VID: human\nidentificationthroughveinpatternscapturedfromcommoditydepthcameras.\nIET Biometrics.\n[48]TomasSimon,HanbyulJoo,IainMatthews,andYaserSheikh.2017. Handkey-\npoint detection in single images using multiview bootstrapping. In IEEE Confer-\nence on Computer Vision and Pattern Recognition (CVPR).\n[49]Karen Simonyan and Andrew Zisserman. 2015. Very deep convolutional net-\nworks for large-scale image recognition. In International Conference on Learning\nRepresentations (ICLR).\n[50]Yunpeng Song, Zhongmin Cai, and Zhi-Li Zhang. 2017. Multi-touch authentica-\ntion using hand geometry and behavioral information. In IEEE Symposium on\nSecurity and Privacy (S&P).\n[51]Katamaneni SriDevi and D Elizbath Rani. 2009. Mainlobe width reduction us-\ninglinearandnonlinearfrequencymodulation.In InternationalConferenceon\nAdvances in Recent Technologies in Communication and Computing.\n[52]Petre Stoica, Randolph L Moses, et al .2005.Spectral analysis of signals. Pearson\nPrentice Hall Upper Saddle River, NJ.\n[53]ShridattSugrim,CanLiu,MeghanMcLean,andJanneLindqvist.2019. Robust\nperformance metrics for authentication systems. In Network and Distributed\nSystem Security Symposium (NDSS).\n[54]Ke Sun, Ting Zhao, Wei Wang, and Lei Xie. 2018. VSkin: sensing touch gestures\nonsurfacesofmobiledevicesusingacousticsignal.In ACMConferenceonMobile\nComputing and Networking (MobiCom).\n[55]Satoshi Suzuki et al .1985. Topological structural analysis of digitized binary\nimages by border following. Computer Vision, Graphics, and Image Processing.\n[56]Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbig-\nniew Wojna. 2016. Rethinking the inception architecture for computer vision. In\nIEEE Conference on Computer Vision and Pattern Recognition (CVPR).\n[57]Yu-Chih Tung and Kang G Shin. 2016. Expansion of human-phone interfaceby sensing structure-borne sound propagation. In ACM Conference on Mobile\nSystems, Applications, and Services (MobiSys).\n[58]BolunWang,YuanshunYao,BimalViswanath,HaitaoZheng,andBenYZhao.\n2018. With great training comes great vulnerability: practical attacks against\ntransfer learning. In USENIX Security Symposium.\n[59]Wei Wang, Alex X Liu, and Ke Sun. 2016. Device-free gesture tracking using\nacoustic signals. In ACM Conference on Mobile Computing and Networking (Mobi-\nCom).\n[60]XuanWangandJiroTanaka.2018. GesID:3Dgestureauthenticationbasedon\ndepth camera and one-class classification. Sensors.\n[61]CongWu,KunHe,JingChen,ZimingZhao,andRuiyingDu.2020. Livenessis\nnot enough: enhancing fingerprint authentication with behavioral biometrics to\ndefeat puppet attacks. In USENIX Security Symposium.\n[62]Cong Wu, Kun He, Jing Chen, Ziming Zhao, and Ruiying Du. 2021. Toward\nrobust detection of puppet attacksvia characterizing fingertip-touch behaviors.\nIEEE Transactions on Dependable and Secure Computing(TDSC).\n[63]WeiWu,StephenJohnElliott,SenLin,ShenshenSun,andYandongTang.2019.\nReview of palm vein recognition. In IET Biometrics.\n[64]Xiangyu Xu, Jiadi Yu, Yingying Chen, Qin Hua, Yanmin Zhu, Yi-Chao Chen,and Minglu Li. 2020. TouchPass: towards behavior-irrelevant on-touch user\nauthentication on smartphones leveraging vibrations. In ACM Conference on\nMobile Computing and Networking (MobiCom).\n2944CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n[65]Yilin Yang, Yan Wang, Yingying Chen, and Chen Wang. 2020. Echolock: towards\nlow-effortmobileuseridentificationleveragingstructure-borneechos.In ACM\nASIA Conference on Computer and Communications Security (ASIACCS).\n[66]Erdem Yörük, Helin Dutağaci, and Bülent Sankur. 2006. Hand biometrics. Image\nand Vision Computing.\n[67]Jiadi Yu, Li Lu, Yingying Chen, Yanmin Zhu, and Linghe Kong. 2019. An indirect\neavesdroppingattackofkeystrokesontouchscreenthroughacousticsensing.\nIEEE Transactions on Mobile Computing(TMC).\n[68]Hans-Jurgen Zepernick and Adolf Finger. 2013. Pseudo random signal processing:\ntheory and application. John Wiley & Sons.\n[69]GuomingZhang,XiaoyuJi,XinfengLi,GangQu,andWenyuanXu.2021. EarAr-\nray: defending against DolphinAttack via Acoustic Attenuation. In Network and\nDistributed System Security Symposium (NDSS).\n[70]LinghanZhang,ShengTan,andJieYang.2017. Hearingyourvoiceisnotenough:\nanarticulatorygesturebasedlivenessdetectionforvoiceauthentication.In ACM\nConference on Computer and Communications Security (CCS).\n[71]Ziming Zhao, Gail-Joon Ahn, and Hongxin Hu. 2015. Picture gesture authen-tication: Empirical analysis, automated attacks, and scheme evaluation. ACMTransactions on Information and System Security (TISSEC).\n[72]Ziming Zhao, Gail-Joon Ahn, Jeong-Jin Seo, and Hongxin Hu. 2013. On the\nsecurity of picture gesture authentication. In USENIX Security Symposium.\n[73]BingZhou,MohammedElbadry,RuipengGao,andFanYe.2017. Battracker:high\nprecision infrastructure-free mobile device tracking in indoor environments. In\nACM Conference on Embedded Networked Sensor Systems (SenSys).\n[74]Bing Zhou, Jay Lohokare, Ruipeng Gao, and Fan Ye. 2018. EchoPrint: two-factor\nauthenticationusingacousticsandvisiononsmartphones.In ACMConference\non Mobile Computing and Networking (MobiCom).\n[75]Man Zhou, Qian Wang, Xiu Lin, Yi Zhao, Peipei Jiang, Qi Li, Chao Shen, andCong Wang. 2022. Presspin: enabling secure pin authentication on mobile de-\nvices via structure-borne sounds. IEEE Transactions on Dependable and Secure\nComputing(TDSC).\n[76]Man Zhou, Qian Wang, Jingxiao Yang, Qi Li, Feng Xiao, Zhibo Wang, and Xi-\naofeng Chen. 2018. Patternlistener: cracking android pattern lock using acoustic\nsignals. In ACM Conference on Computer and Communications Security (CCS).\n2945EchoHand: High Accuracy and Presentation Attack Resistant Hand Authentication on Commodity Mobile Devices"}
{"title": "ECMO: Peripheral Transplantation to Rehost Embedded Linux Kernels", "content": "ECMO: Peripheral Transplantation to Rehost Embedded Linux\nKernels\nMuhui Jiang\nThe Hong Kong Polytechnic University,\nZhejiang University,\nChina\ncsmjiang@comp.polyu.edu.hkLin Ma\nYajin Zhou∗\nQiang Liu\nZhejiang University, China\n{linma,yajin_zhou,qiangliu}@zju.edu.cnCen Zhang\nNanyang Technological University,\nSingapore\ncen001@e.ntu.edu.sg\nZhi Wang\nFlorida State University,\nUSA\nzwang@cs.fsu.eduXiapu Luo\nThe Hong Kong Polytechnic University,\nChina\ncsxluo@comp.polyu.edu.hkLei Wu\nKui Ren\nZhejiang University, China\n{lei_wu,kuiren}@zju.edu.cn\nABSTRACT\nDynamic analysis based on the full-system emulator QEMU is\nwidely used for various purposes. However, it is challenging to\nrun firmware images of embedded devices in QEMU, especially the\nprocess to boot the Linux kernel (we call this process rehosting\ntheLinuxkernelinthispaper).That’sbecauseembeddeddevices\nusually use different system-on-chips (SoCs) from multiple ven-\ndors and only a limited number of SoCs are currently supported in\nQEMU.\nIn this work, we propose a technique called peripheral trans-\nplantation. The main idea is to transplant the device drivers of\ndesignatedperipheralsintotheLinuxkernelbinary.Bydoingso,\nit can replace the peripherals in the kernel that are currently un-\nsupportedinQEMUwithsupportedones,thusmakingtheLinux\nkernelrehostable. After that, various applications can be built.\nWeimplementedthistechniqueinsideaprototypesystemcalled\nECMOandapplieditto815firmwareimages,whichconsistof20\nkernelversionsand37devicemodels.TheresultshowsthatECMO\ncansuccessfullytransplantperipheralsforallthe815Linuxkernels.\nAmong them, 710 kernels can be successfully rehosted, i.e., launch-\ning a user-space shell (87 .1% success rate). The failed cases are\nmainlybecausetherootfilesystemformat(ramfs )isnotsupported\nby the kernel. Meanwhile, we are able to inject rather complexdrivers (i.e., NIC driver) for all the rehosted Linux kernels by in-stalling kernel modules. We further build three applications, i.e.,\nkernel crash analysis, rootkit forensic analysis, and kernel fuzzing,\nbasedontherehostedkernelstodemonstratetheusagescenarios\nof ECMO.\n∗Corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\nand/or a fee. Request permissions from permissions@acm.org.\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3484753CCS CONCEPTS\n•Security and privacy →Virtualization and security ;Oper-\nating systems security.\nKEYWORDS\nRehosting, Linux Kernel, Peripheral Transplantation\nACM Reference Format:\nMuhui Jiang, Lin Ma, Yajin Zhou, Qiang Liu, Cen Zhang, Zhi Wang, Xiapu\nLuo, Lei Wu, and Kui Ren. 2021. ECMO: Peripheral Transplantation to\nRehostEmbeddedLinuxKernels.In Proceedingsofthe2021ACMSIGSAC\nConference on Computer and Communications Security (CCS ’21), November\n15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA,\n15 pages. https://doi.org/10.1145/3460120.3484753\n1 INTRODUCTION\nIoT devices (or embedded devices) are becoming popular [ 7], many\nof which run Linux-based operating systems [ 30]. At the same\ntime, hundreds of vulnerabilities are discovered every year for the\nLinux kernel [ 22]. Once the devices are compromised, attackers\ncan control them to launch further attacks. As such, the security\nof embedded devices, especially the kernel, deserves a thorough\nanalysis.\nDynamicanalysishasbeenwidelyusedforvariouspurposes[ 31,\n41,44,47,51,70].Itcanmonitortheruntimebehaviorofthetarget\nsystem, complementing the static analysis [ 30,45,55,61].Rehost-\ning, also known as emulation, is used to run a target system inside\nan emulated environment, e.g., QEMU, and provides the capability\ntointrospecttheruntimestate.Basedonthiscapability,different\napplications, e.g., kernel crash analysis, rootkit forensic analysis,\nandkernelfuzzing,canbebuilt.RunningtheLinuxkernelinQEMU\nfor the desktop system is a solved problem. However, rehostingembedded system is challenging. First, rehosting Linux kernel is\ndependent on the emulation of peripherals. Without the right emu-\nlationof these peripherals,Linuxkernelmay haltorcrashduring\nthe rehosting process. Second, peripherals vary widely. Due to the\ndiverse peripherals in the wild, it is not practical for QEMU tosupport all kinds of peripherals in any SoC. Third, vendors may\nnot strictly follow the GPL license [ 35,42], resulting in the lack of\npublicinformation(e.g.,specifications,datasheets,andsourcecode).\nThese obstruct the diagnosis of failures when adding emulation\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n734\nFirmware ImageECMO\nPeripherals\nto be Transplanted\nRehosted Linux Kernel\nApplications &\nPeripheral Drivers\nFigure 1: The overview of our system (ECMO)\nsupport of new SoCs in QEMU. Thus, how to rehost the embedded\nLinux kernels in QEMU is still an open research question.\nPreviousresearch[ 26,50]providesthecapabilityofrehosting\nuser-spaceprogramsbyrunningacustomizedLinuxkernelforone\nSoCthatissupportedinQEMU.Thisworkswellbecauseuser-spaceprogramsmainlydependonstandardsystemcallsthatareprovidedbytheunderlyingLinuxkernel.Differentfromuser-spaceprograms,the OS kernel interact with peripherals that are usually different in\ndifferent SoCs. Some researchers have proposed to use real devices\nto perform the dynamic analysis [ 43,54,62,69]. Such solutions\ndo not scale since there exist a large number of embedded devices.\nOthermechanismthatareforthebare-metalsystems[ 28,37,52],\ni.e.,embeddedsystemswithout anOS kernelorhaving athin layerofabstraction,cannotbedirectlyusedtorehosttheLinuxkernelas\nthe Linux kernel is far more complicated than the bare-metal ones.\nKey Insights To address the above mentioned three challenges,\nwehavethreekeyinsights.First,onlyearly-bootperipherals(i.e.,\ninterrupt controller, timer, and UART) need to be supported duringtherehostingprocess.AftersuccessfullyrehostingtheLinuxkernel,\nwe are able to install the different peripheral drivers in ramfs to\nsupporttheotherperipheralswithkernelmodules.Second,Linux\nkernelprovidesinterfacestoimplementdriversofthese peripher-\nals, which brings the chance to replace these diverse peripherals\nwithdesignatedones.Third,embeddedLinuxkernelsareusually\nmodified based on the mainstream Linux kernel, which is open-\nsourced. The modification mainly aimsto add support for specific\nperipherals while most of the other code is unchanged.\nOurApproach Withtheinsights,wepropose peripheraltrans-\nplantationtechnique,whichisdevice-independentandworkstowards\ntheLinuxkernel withouttheneedofthesource code.Themain idea\nis,insteadofmanuallyaddingemulationsupportofvariousperiph-\nerals in QEMU, we can transplant the device drivers of designated\nperipheralsintothetargetLinuxkernelbinary.Itreplacesthepe-\nripherals in the target Linux kernel that are currently unsupported\nin QEMU with supported ones, thus making the Linux kernel re-\nhostable. Specifically, our system transplants two components, i.e.,\nthe emulated models of peripheral into QEMU and their device\ndrivers into the Linux kernel (if they are not initialized originally).\nTransplanting a peripheral model requires the emulation code for\nspecified (or simplified) peripheral and integrates it into QEMU.\nThisisstraightforward sinceQEMUprovidesus withAPIstoadd\nnew peripheral models.\nHowever, transplanting a driver into the Linux kernel is non-\ntrivial.First,weneedtosubstitutetheoriginal(unsupported)devicedriver with the transplanted one. Since the peripheral driver is ini-\ntialized with indirect calls, we need to locate function pointers and\nrewrite them in a stripped binary on the fly, which is challeng-\ning.Second,the transplanted drivershouldnot affect thememory\nview of the original kernel. Otherwise, the memory holding the\ntransplanted driver can be overwritten since the Linux kernel is\nnot aware of the existence of that memory region. Third, the trans-\nplanteddriverneedstoinvokeAPIsintheLinuxkernel.Otherwise,\nthe transplanted driver cannot function as desired.\nTo overcome the difficulties of transplanting drivers, we design\nandimplementanewalgorithmtoidentifytherequiredfunction\npointers(Section4.2)andintroduce opaquememory (Section4.3)to\nguarantee that the transplanted driver does not affect the memory\nview of the original kernel. Finally, we implement and integrate\ntheperipheral transplantation technique into QEMU to create a\nprototype called ECMO. Figure 1 shows the overview of ECMO. It\nreceivesthefirmwareimageandtheperipheralstobetransplanted.\nThen it transplants the peripherals to the Linux kernel binary to\nmakeitrehostableinQEMUandlaunchashell.NotethatECMO\nfocusesontransplantingtheearly-bootperipherals(i.e.,interrupt\ncontroller, timer, and UART), which are needed to rehost the Linux\nkernel.OncetheLinuxkernelisrehosted,userscaninstalldifferent\nperipheraldriverstosupportmoreperipheralswithkernelmodules\nand build various applications to analyze the rehosted kernel.\nWe apply ECMO on 815 Linux kernels extracted from firmware\nimages,including20differentkernelversionsand37devicemod-\nels.ECMOnowonlysupportsARMarchitecture,whichiswidely\nusedinembeddedsystems[ 17].However,itdoesnotrelyonany\narchitecturespecificfeatureandcanbeeasilyextendedtotheother\narchitectures (Section 6). Our experiment shows that ECMO can\nsuccessfullytransplantperipheralsforall815Linuxkernels.Among\nthem, 710 are able to launch a shell. The failed cases are due to the\nunsupported root file system format (ramfs ) in the rehosted kernel.\nFurthermore,wesuccessfullyinstalloneEthernetdevicedriver(i.e.,\nsmc91x) on all the rehosted Linux kernel, which demonstrates the\ncapability to support more peripherals based on rehosted Linux\nkernel. To demonstrate the functionality and usefulness of our sys-\ntem,webuildandportthreeapplications,includingkernelcrash\nanalysis, rootkit forensic analysis, and kernel fuzzing. Note that,\ntheapplicationsthemselvesarenotthecontributionofourwork.\nThey are used to demonstrate the usage scenarios of our system.\nOther applications that can be built on QEMU can also be ported.\nIn summary, this work makes the following main contributions.\n•Novel technique We propose a device-independent technique\ncalledperipheral transplantation that can rehost Linux kernels of\nembedded devices without the availability of the source code.\n•Newsystem Weimplementandintegratethe peripheraltrans-\nplantation technique into QEMU, to create a prototype system\ncalled ECMO.\n•Comprehensive evaluation We apply ECMO to 815 Linux\nkernelsfromdifferentimages.Itcantransplantperipheralsfor\nall the Linux kernels and successfully launch the shell for 710\nones.\nTo engage with the community, we release the source code of\noursysteminhttps://github.com/valour01/ecmo.Wealsoprovide\nan online service [6] for the community.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n7351MACHINE_START(VE RSATILE_AB, \"ARM-Versatile AB\" )\n2 .atag_offset = 0x100,\n3 .map_io = versatile_map_io,\n4 .init_early = versatile_init_early,\n5 .init_irq = versatile_init_irq,\n6 .init_time = versatile_timer_init,\n7 .init_machine = versatile_init,\n8 .restart = versatile_restart,\n9MACHINE_END\nFigure 2: The machine description for ARM-Versatile AB.\n1//UART read call back\n2static uint64_t serial_mm _read(void*opaque,\n3 hwaddr addr, unsigned size) {\n4SerialMM *s = SERIAL_MM(opaque);\n5return serial_ioport_read(&s-> serial,\n6 addr >> s->regshift, 1);\n7}\n8//register read/write call back functions\n9static const MemoryRegionOps serial_mm_ops = {\n10.read = serial_mm_read,\n11.write = serial_mm_write,\n12...\n13};\nFigure 3: The callback functions for UART emulation in\nQEMU\n2 BACKGROUND\n2.1 Linux Kernel\nLinux kernel source code can be categorized into three types ac-\ncording to their functionalities. The first type is the architecture\nindependent code, which contains the core functionality used byall CPU architectures. The second type is architecture dependent\ncode. For instance, the sub-directories under the arch/directory\ncontain the code for multiple CPU architectures. The third typeisboard-specific code, which is used by specific board (machine).\nFor instance, the directory arch/arm/versatile/ contains the code\nused by the machine named versatile. The kernel compiled for one\nmachineusuallycannotbedirectlybootedonothermachines(or\nQEMU instances that emulate different machines.)\n2.2 ARM Machines\nEmbeddedsystemsusuallyuseSoCsfrommultiplevendorswith\ndifferentdesigns.Forinstance,theycontaindifferentperipherals.\nEach SoC is expressed as a machine in the Linux kernel. Manu-\nfacturersdevelopthe boardsupportpackage (BSP)(e.g.,driversof\nperipherals) so that Linux kernel can use these peripherals.\nLinux kernel introduces the structure machine_desc for ARM to\ndescribe different machines. The structure machine_desc provides\ninterfacestoimplementBSPs.Forexample,Figure2showsanexam-\nple of one machine ARM-Versatile AB in the Linux kernel (Version\n3.18.20).Itinitializesfunctionpointersanddatapointerswithitsim-\nplementation. Specifically, in line 5, the function pointer init_irqis\nassignedthevalueas versatile_init_irq.Duringthebootingprocess,\ntheLinuxkernelwillinvokethefunction machine_desc →init_irq\nto initialize the IC (interrupt controller). The same logic applies to\nthefunctionpointer init_time.Linuxkernelinvokesthefunction\nmachine_desc→init_time to initialize the timer.2.3 QEMU\nQEMU [16] is one of the most popular full-system emulators. It\nemulatesdifferentmachinesbyprovidingdifferentmachinemodels.\nA machine model consists of CPU, memory, and different kinds\nof peripheral models. To emulate a peripheral, QEMU registers\nthe read/write callback functions for the MMIO (memory-mapped\nI/O) address space of the peripheral. Once the Linux kernel run-\nning inside QEMU reads from or writes into the address inside the\nMMIOrange,theregisteredcallbackfunctionsinsideQEMUwill\nbe invoked to emulate the peripheral. Basically, it maintains an\ninternal state machine to implement the peripheral’s functionality.Figure 3 shows an example of the registered callback functions for\nUARTemulation.Specifically,whentheLinuxkernelreadsfrom\ntheMMIOspaceoftheemulatedUARTdevice(e.g., 0x01C42000 ),\ntheserial_mm_read functionwillbeinvokedbyQEMUtoemulate\nthe read access.\n3 CHALLENGES AND OUR SOLUTION\nThemaingoalofourworkistorehostLinuxkernelbinariesthatare\noriginallyrunningonembeddedsystemsinQEMU.Thislaysthe\nfoundation of applications that rely on the capability to introspect\nruntimestatesoftheLinuxkernel,e.g.,kernelcrashandvulnera-\nbilityanalysis[ 31,41],rootkitforensicanalysis[ 56,64],andkernel\nfuzzing [51, 59].\n3.1 Challenges\nRehosting the Linux kernel on QEMU faces the following chal-\nlenges.\nPeripheral dependency Rehosting the Linux kernel requires\nQEMUtoemulatetheperipherals,e.g.,theinterruptcontroller,that\nthe Linux kernel depends on. During the booting process, Linux\nkernel will read from or write into the peripheral registers andexecute the code according to the state specified by the value ofperipheral registers. Without the emulation of these peripherals,\nthe rehosted kernel will halt or crash during the booting process.\nPeripheral diversity SoCs vary widely [ 19] and different ven-\ndors, e.g., Broadcom, Marvell may design and develop different\nSoCs.ThesenewSoCsintroducemanynewperipheralsthatarenot\ncurrentlysupportedinQEMUandtheopen-sourcedmainstream\noftheLinuxkernel.Duetothediversityofperipherals,thereare\nstillalargenumberofdevicesthatarenotsupported.Meanwhile,\nmanuallydevelopingperipheralemulationroutineistediousand\nerror-prone, especially due to the diversity of peripherals. Thus,\nthe diversity of peripherals brings significant challenge to builda general emulator, which can re-host various Linux kernels of\nembedded devices.\nLack of public information The information (e.g., specifica-\ntions,datasheets,andsourcecode)ofSoCsandfirmwareimages\nare usually not public. This is because vendors may not release\nthe detailed hardware specification. Furthermore, vendors may not\nrelease the source code immediately after releasing the image and\nnot all vendors strictly follow the GPL license [ 35,42]. Meanwhile,\nthe binary of the Linux kernel is stripped and has no particular\nheaders(i.e.,ELFsectionheaders)ordebugginginformation.These\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n736Peripheral \nInitialization \nPeripheral \nInteraction \nAPIs Device \nDriver ECMO \nDriver\nTransplanted \nPeripheral \nModelsCPU RAMECMO Forward \nPointers\nECMO Backward \nPointers\nLinux Kernel\nQEMUOpaque\nMemoryRedirect \nInvoke 1\n2\nOther \nPeripherals\nFigure 4: The overview of peripheral transplantation.\nobstructthe diagnosisoffailures whenadding emulationsupport\nof new SoCs in QEMU.\n3.2 Our Solution: Peripheral Transplantation\nInthiswork,weproposeatechniquecalled peripheraltransplan-\ntation. The main idea is, instead of manually adding emulation\nsupport of various peripherals in QEMU, we can replace the periph-\neralsthatareusedintargetLinuxkernelswithexistingperipheralsin\nQEMU.By doing so, we can rehost the Linux kernel and the kernel\nfunctionality is intact (Section 5.4).\nFigure 4 shows the overview of peripheral transplantation. This\ninvolves the injection of peripheral models into QEMU and the\nECMODriver intotheLinuxkernel.Todistinguishthemfromorigi-\nnalonesofthe(emulated)machine,wecallthetransplantedperiph-\neralmodels ECMOPeripheral .Toletthekernelusethetransplanted\nECMO Driver, our system identities the functions that are used\ntoinitializedevicedrivers(ECMOForwardPointers )andredirects\nthemtothefunctionsinsidethe ECMODriver (Fig.4 1).Moreover,\noursystemidentifiestheAPIsthatareresponsibleforinteracting\nwithperipheralmodels.TheseAPIsareusedbythe ECMODriver\ntocommunicatewiththetransplantedperipheralmodels(Fig.4 2).\nTheaddressesofthesefunctionsarecalled ECMOBackwardPointers\ninthispaper.WewillelaboratehowtoidentifytheECMOPointers\nin Section 4.2.\nNotethat,toensurethe ECMODriver doesnotaffectthememory\nviewoftherehostedLinuxkernel,weproposetheconceptofthe\nopaque memory. This memory region is available on the emulated\nmachinebutcannotbeseenbytheLinuxkernel.Assuch,wecan\npreventthekernelfromallocatingmemorypagesthatarereserved\nfor theECMO Driver. We will elaborate this in Section 4.3.\n3.3 An Illustration Example of Peripheral\nTransplantation\nFig.5showsaconcreteexampleoftransplantingoneperipheral(i.e.,timer)intotheLinuxkernel.Inparticular,thefunction\nstart_kernel\nisresponsibleforinitializingtheLinuxkernel.Itwillinvokeseveral\ndifferent functions, including setup_arch and and time_init .\nThe function setup_arch will setup architecture-related config-\nurations and initialize the machine_desc structure (Fig. 5 1). Thisstructurecontainsmultiplefunctionpointers(ECMOForwardPoint-ers)thatwillbeusedtoinitializecorrespondingdrivers.Oursystem\nfirst locates the function setup_arch and then injects a function\n(install_ECMO_forward_pointers ) to change the pointers to our\nown ones (Fig. 5 3).\nWhenthefunction init_time isinvokedtoinitializethetimer\n(Fig.52),the ECMO_init_time ,whichispointedby machine_desc->\ninit_time , will be invoked to initialize the injected timer driver\n(ECMO Driver ) in QEMU (Fig. 5 4) (through ECMO Forward Point-\ners), instead of the original one. Accordingly, this function will\ninvokeAPIs(through ECMOBackwardPointers )intheLinuxkernel\nto interact with the ECMO Peripheral (Fig. 5 5).\nNote that, the code snippets in Fig. 5 are for the illustration\npurpose. Our system does not rely on the availability of the source\ncode.ItdirectlyworkstowardstheLinuxkernelbinarythatisretrieved\nfrom a firmware image.\n4 SYSTEM DESIGN AND IMPLEMENTATION\nInordertorehostLinuxkernels,oursystemfirstextractsandde-\ncompressesthe Linuxkernelfromthe givenfirmwareimage (Sec-\ntion 4.1). We then apply multiple strategies to identify both ECMO\nForward and Backward Pointers (Section 4.2). These pointers are\nessentialfor ECMODrivers.Atlast,wesemi-automaticallygener-\nateECMO Drivers and load them at runtime to boot the kernels\n(Section 4.3). Fig. 6 shows the overall workflow.\n4.1 Decompress Linux Kernel\nFirmware image usually consists of the OS, which is the Linux\nkernel, and user applications. However, the Linux kernel inside the\nfirmwareimagesisusuallycompressed.ToidentifyECMOPointers,\nweneedtofirstextracttheLinuxkernelanddecompressit.With\nthe decompressed Linux kernel, we can utilize different strategies\nto locate the ECMO Pointers.\nSpecifically, we feed the firmware image to firmware extraction\ntool (i.e., Binwalk) to extract the kernel image. Then we directly\nfeedtheextractedkernelimage(withaddedu-bootinformation)toQEMU.SincethecodefordecompressingtheLinuxkerneldoesnot\noperate on the peripherals (except the UART to show the message\nof decompressing Linux kernel), it can be successfully executed in\nvanilla QEMU.\nAs shown in Fig. 7, function decompress_kernel in line 16 is in-\nvokedtodecompressthekernel.Itsfirstparameter(i.e., output_start )\nindicates the start address of the decompressed kernel. Thus, if we\ncanidentifywhen decompress_kernel isinvoked,wecangetthe\nfirst parameter by checking the machine register ( R0in ARM) and\ndump the decompressed Linux kernel.\nWe notice that the function decompress_kernel is invoked by\nthe assembly code in arch/arm/boot/compressed/head.S. We observe\nthat this snippet of assembly code remains unchanged in different\nkernelversions.Withthisobservation,weidentifytheaddressof\ninstruction BL decompress_kernel bystrictlycomparingtheexe-\ncution trace of QEMU and the hard coded assembly code. After\nfindingtheinstruction,wecanobtaintheaddressofthefunction\ndecompress_kernel andthevalueof output_start accordingtothe\nexecution trace. With this information, we can dump the decom-\npressed Linux kernel after the function decompress_kernel returns.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n737start_kernel(void) {\n. . .\n/*Initialize the architecture specificProperties */setup_arch();. . .\n/*Initialize the Timer*/\ntime_init();. . .\n}\nconfigure_time_APIs(args) {\n. . .\n}setup_arch () {\n. . ./*setup_machine_fdt return the\nvalue of machine_desc */\nmachine_desc = setup_machine_fdt();\ninstall_ECMO_forward_pointer();\n}\ntime_init(void) {\nif (!machine_desc->init_time )\ngeneral_time_init();\nelse\n/*ECMO_init_time()*/\nmachine_desc->init_time();\n}install_ECMO_forward_pointer(void) {\n…machine_desc->init_time =\n&ECMO_init_time;\n}\nECMO_init_time(void) {\nargs = ECMO_Timer ˗\nf = &configure_time_APIs;(*f)(args);\n}13\n2\n54\nFigure 5: A concrete example of peripheral transplantation.\nDecompress \nLinux \nKernelIdentify \nECMO \nPointersGenerate \nECMO \nDriversRehostable\nLinux \nKernelFirmware\nFigure 6: The work flow of our system.\n1Assembly code:\n2mov r0, #0\n3str r0, [r2], #4\n4str r0, [r2], #4\n5str r0, [r2], #4\n6str r0, [r2], #4\n7cmp r2, r3\n8blo 1b\n9tst r4, #1\n10bic r4, r4, #1\n11blnecache_on\n12mov r0, r4 //r0 stores the value of output_start\n13mov r1, sp\n14add r2, sp, #0x10000\n15mov r3, r7\n16bldecompress_kernel\n17// we can dump the decompressed Linux kernel\n18// after function decompress_kernel returns\n19\n20Simplified C code:\n21void decompress_kernel (uint32 output_start, args)\nFigure 7: The assembly code that invokes function decom-\npress_kernel, which is in arch/arm/boot/compressed/head.S.\nBy doing so, we can automatically retrieve decompressed Linux\nkernels from firmware images.\n4.2 Identity ECMO Pointers\nOur system needs to obtain the addresses of two essential types\nof functions in the Linux kernel. Specifically, the ECMO Forward\nPointerscontain the functions that are used by the Linux kernel to\ninitializedevicedrivers.Wedynamicallyhookandredirectthem\ntoECMO Drivers at runtime in QEMU. The ECMO Backward Point-\nerscontaintheAPIsthatareusedbythe ECMODriver toinvoke\nfunctionsprovidedbytheLinuxkerneltointeractwithemulated\nperipherals in QEMU.Precisely identifying ECMO Pointers is not easy. The main chal-\nlengeisthedecompressedLinuxkernelisstrippedandonlycon-\ntains the binary data. It has neither meaningful headers nor debug-\nging symbols and contains thousands of functions. Furthermore,\ntheLinuxkerneliscompiledwithdifferentcompilersandcompilingoptions,whichcanresultindifferentbinaries.Thus,wecannothave\nany assumption on the compiling options or compilers. We also\ncannot rely on run-time symbol tables like /proc/kallsym because\ntheyareonlyavailable afterbooting.However,wehavetheinsight\nthat embedded Linux kernels are usually modified based on the\nmainstream Linux kernel and the modification mainly aims to add\nsupportforspecificperipheralswith board-specificcode.Meanwhile,\nECMO Pointers are functions in architecture independent code or\narchitecturedependentcode (Section2.1),whichisunchangedand\nopen-source.\nIn this case, we can automatically identify ECMO Pointers by\nleveraging the source code of the mainline Linux kernel. For in-\nstance,ifwefindthatafunctionusesaspecificstringbyreading\nthe source code, then we can easily identify this function inside\nthe binary by locating the function that has references to the same\nstring. Of course, this simple strategy may not always work, since\nsomefunctionsdonothavesuchobviouspatternsormultiplefunc-\ntions can refer to the same string. Thus, we take three different\nstrategiestoidentifyECMOPointers(Section4.2.2).Weillustrate\neach step in the following.\n4.2.1 DisassembletheLinuxKernel. Thefirststepistodisassemble\nthe Linux kernel for further analysis, including constructing the\ncontrolflowgraphandidentifyingfunctionboundaries.AccuratelydisassemblingtheARMbinariesisstillchallenging,especiallywhen\nthe binary is stripped [ 46]. This is because inline data is very com-\nmoninARMbinariesandtherearetwodifferentinstructionsets\n(i.e., ARM and Thumb). Furthermore, ARM doesnot have a distin-\nguished function call instruction, which can influence the accuracy\nof identifying function boundaries. In this case, we choose to en-sure that this step does not introduce false negatives, i.e., all the\ncode sections should be dissembled. Otherwise, we cannot identify\nthe functions ifthey are not correctlydisassembled. However,we\ncan tolerate the false positives, i.e., the inline data may be wrongly\ndisassembled as code. The strategies described in Section 4.2.2 can\nhelp us to filter out these false positives.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n738Afterdisassembling the Linuxkernel andconstructing thecon-\ntrol flow graphs, we further locate function boundaries by combin-\ningthealgorithmintroducedinNucleus[ 23]andangr[ 1].Nucleus\ncanidentifythefunctionsindirectlycalledwhileangrlocatesthe\nfunction according to the prologue. These two tools can help to\nreducethefalsenegativesandguaranteethattherequiredfunction\naddresses (ECMO Pointers) will be located during the disassembly\nprocess. Finally, we build a mapping for each function and various\ntypesofinformation,e.g.,numberofbasicblocks,stringreferences,\nnumber of called functions and etc. This mapping describes the\nsignature (or portrait) of each function. Note that, our system does\nnot require that the constructed control flow graphs are sound\nor complete, as long as they can provide enough information for\nfurther analysis (Section 4.2.2).\nAlgorithm 1: The algorithm to identify the addresses of\nECMO pointers from the Linux kernel binary.\nInput:The decompressed Linux kernel 𝐿𝐾𝐵;\nThe source code of ECMO Pointers 𝑆𝐶(architecture independent code or\narchitecture dependent code);\nOutput:The addresses of ECMO Pointers 𝐹𝐴;\n1Function Identify( 𝐿𝐾𝐵,𝑆𝐶):\n2𝐶𝐹𝐺= Disassembly( 𝐿𝐾𝐵)\n3𝐺𝑒𝑛𝑒𝑟𝑎𝑡𝑒𝑑 _𝐹𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠 = GenerateFunctions( 𝐶𝐹𝐺)\n4for𝑆_𝐹in𝑆𝐶do\n5 for𝐺_𝐹in𝐺𝑒𝑛𝑒𝑟𝑎𝑡𝑒𝑑 _𝐹𝑢𝑛𝑐𝑡𝑖𝑜𝑛𝑠 do\n6 forFiltering_Strategy in Filtering_strategies do\n7 ifFiltering_Strategy( 𝑆_𝐹,𝐺_𝐹)then\n8 Append𝐺_𝐹to𝑆_𝐹.𝐶𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒𝑠\n9for𝑆_𝐹in𝑆𝐶do\n10 ifLength(𝑆_𝐹.𝐶𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒𝑠 )= =1then\n11 𝐹𝐴[𝑆_𝐹]=𝑆_𝐹.𝐶𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒𝑠\n12return𝐹𝐴\n13\n4.2.2 IdentifyPointerAddresses. Algorithm1describestheprocess\nto locate pointer addresses of ECMO Pointers in the decompressed\nLinux kernel binary, i.e., LKB. Note that, we first need to get the\nsource code of the functions, i.e., SC, inside the mainline Linux\nkernel.TheoutputsofthisalgorithmaretheaddressesofECMO\nPointers, i.e., FA(line 12).\nFirst, we disassemble the decompressed Linux kernel, construct\nthe control flow graph (line 2) and generate function boundaries\n(line3).ThenforthesourcecodefunctionofeachECMOPointer\n(line 4), we loop through the generated functions (line 5) and apply\ndifferent filtering strategies (line 6). If one filtering strategy can\nidentifyoneaddressasacandidateaddressoftheECMOPointer\n(line 7), thisaddress will be appendedto the candidate list(line 8).\nFinally, wecheckthe candidatesofeach ECMOPointer(line 9).If\nthere is only one candidate (line 10), it means the address of this\nECMOPointerissuccessfullyidentifiedinthekernelbinary(line\n11). Note that even if there is more than one candidate for each\nECMO Pointer, ECMO can automatically try all the candidates and\nthe one that can rehost the Linux kernel should be the right one.\nWe do not find such cases in our experiments.\nStrategy-I:Lexicalinformation Thefirststrategyusesthelex-\nical information inside a function as its signature, e.g., a specific\nAssembly: foo\nfoo_offset+0x0:       ldr r0, [pc, #248]       \n     \nfoo_offset+0x100 :  foo_offset+0x200\nfoo_offset+0x200:   This is specific string \nCode: foo (args)\n{    . . .\n    print_func (“This is specific string \");    . . .\n}\n(a) Specificconstantstring:theconstantstringisreferencedbyadatapointer(i.e.,\nfoo_offset+0x200).\nAssembly: foofoo_offset+0x0:       ldr r0, [pc, #248] foo_offset+0x4:       mov r1, #386 foo_offset+0x8:       bl warn_func  \n      \n     foo_offset+0x100:   0x00000200\nfoo_offset+0x200:   /path/to/source.c      \nFile: /path/to/source.c\nCode: foo (args)\n{    . . .        WARN_ON (condition);  /*Line 386*/\n    . . .\n}\n(b) Warning information: line number (i.e., 386) is the operand of assembly code; file\nname (i.e., /path/to/source.c) is a constant string.\nFigure 8: Strategy-I: Lexical information\nconstant string and the warning information. If the function we\nwanttoidentifyhassuchstrings,wecanthenlookupthedisassem-\nblycodetofindthefunctionsthathavedatareferencestothesame\nstring. The line number and file name in the warning information\ncan further help to locate the function.\nFig.8(a)showsapairofthedisassembledcodeandthesource\ncode in the mainline Linux kernel. In the source code, the function\nfoocontains a specific constant string “This is a specific string \".\nIntheassemblycode, theinstructionat foo_offset+0x0 willload\nthedatapointers(i.e., foo_offset+0x100 )usingthe LDRinstruction.\nThedatapointerreferstoanotherpointer(i.e., foo_offset+0x200 ),\nwhich contains the same constant string. Based on this, we can\nlocate function fooin the disassembled kernel. Fig. 8(b) shows a\nsimilar example with the warning information. The WARN_ON\nwill call function warn_func. The first parameter is the filename,\nwhich is a specific constant string. The second parameter is the\nline number of WARN_ON. Usually, the line number is hard coded\nas an operand of instruction after compilation. Thus, functions\ncontaining specific constant strings or warning information can be\neasily identified.\nStrategy-II: Function relationship The second strategy uses\ntherelationshipbetweenfunctions.That’sbecausefunctionsthat\ndonotcontainspecificstringscannotbeidentifiedbythestrategy-I.\nHowever, we can use the relationship between the functions we\nwanttoidentifyandtheonesthathavebeenidentifiedusingthe\npreviousstrategy.Forinstance,ifwehaveidentifiedthefunction\n(Identified_foo )andthisfunctionis onlyinvokedbythefunction\nRequired_foo , then we can easily locate the Required_foo by find-\ning the caller of the Identified_foo function (Figure 9(a)). Similar\nstrategiescanbeappliedtothecalleeandsiblingrelationship,as\nshown in Figure 9(b) and Figure 9(c), respectively. Note that we do\nnotneedtohaveaprecisecallgraph,whichishardtogeneratedue\nto the indirect call and inline function. This is because strategy I\ncan identify several functions due to the many specific constant\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n739Code: Required_foo(args)\n{    . . .    Identified_foo();    . . .}\nAssembly: Required_foo\nfoo_offset+0x0:       Assembly Code\n. . .foo_offset+0x100:   bl Identified_foo\n(a) Caller relationship: Required_foo is the caller of Identified_foo\nCode: Identified_foo(args){    . . .    Required_foo();    . . .}\nAssembly: Identified_foo\nfoo_offset+0x0:       Assembly Code\n. . .foo_offset+0x100:   bl Required_foo\n(b) Callee relationship: Required_foo is the callee of Identified_foo\nCode: foo(args){    . . .    Identified_foo();    . . .    Required_foo();    . . .}\nAssembly: foo\nfoo_offset+0x0:       Assembly Code\n. . .foo_offset+0x100:   bl Identified_foo. . .foo_offset+0x200:   bl Required_foo\n(c) Sibling relationship: Required_foo and Identified_foo are both called by foo\nFigure 9: Strategy-II: Function relationship\nstringsintheLinuxkernel.Onlyifoneofthefunctionsidentified\nbyStrategyI( Identified_foo )hascertainfunctionrelationships\nwiththetargetfunction( Required_foo ),strategyIIcanwork.We\ndo not encounter this issue in our experiments. With the help of\nfunction relationship, we can identify the functions indirectly.\nStrategy-III: : Function structure If one function has more\nthan one caller, callee or sibling, it cannot be located solely us-\ning the function relationship. The third strategy takes the function\nstructure,includinglogicorarithmeticoperations,returnvalue,the\nnumberofbasicblocks,andthenumberofcalleefunctions.Fig.10(a)showstheexamplethatthefunctionperformsthelogicoperationon\nsome specific values (i.e., a = a|0x300 ) and return a specific value\n(i.e., -22) , the compiler will generate the instructions that con-\ntain the specific values (e.g., orr r0,r0, #0x300 ,mvn r0,#0x15 ).\nBesides, the callee number and basic block number will also be\nconsideredtofilteroutthecandidate.Fig.10(b)showsthatfunction\nfoohas two callees (i.e., callee_foo_one andcallee_foo_two ), which\nmap to two instructions at foo_offset+0x18 and foo_offset+0x1c.\nBasic block number works with the same rule.\nSummary Withtheabovethreestrategies,wecanautomatically\nandsuccessfullyidentifyECMOPointersforalltheLinuxkernels\n(815onesin20kernelversions)usedintheevaluation(Section5.2).\n4.3 Generate ECMO Drivers\nThe process to generate ECMO Drivers is similar with developing a\nkernelmodule.However,weneedtomakethedriverself-contained\nasmuchaspossibleandinvoketheAPIsintheLinuxkernelthroughECMOBackwardPointers .Inparticular,wecompilethesourcecode\nintoanobjectfile(i.e., ECMO_Driver.o ).Tomakethisdriverwork,\nweneedtosetupthebaseaddressandfixupthefunctioncallsto\nECMO Backward Pointers. Moreover, we need to ensure that this\nAssembly: foo\nfoo_offset+0x0:       Assembly Code. . .       foo_offset+0x204:   orr  r0,r0, #0x300      \n. . .foo_offset+0x240:   mvn r0,#0x15foo_offset+0x244:   ldmfd sp,{pc}\nCode: foo(args){      Int a;      a = a | 0x300;      . . .      return -22; }\n    \n(a) Logic operation: The constants (i.e., 0x300, -22) of logic operation or return value\nin source code map to the operands in assembly code.\nAssembly: foofoo_offset+0x0:       mov r0, 0. . .foo_offset+0x18:     bl callee_foo_onefoo_offset+0x1c:     bl callee_foo_twofoo_offset+0x20:     cmp r0, 0foo_offset+0x24:     beq foo_offset+0x50\nfoo_offset+0x28:     add r0,r0,1foo_offset+0x2c:     ldm sp,{r0,pc}\nfoo_offset+0x50:     add r0,r0,2foo_offset+0x54:     ldm sp,{r0,pc}\nCode: foo(args){      int a = 0;      callee_foo_one(args);      callee_foo_two(args);      . . .\nif (condition)\n       {           a = a+1;       }       else       {           a = a+2;       }}\n    \n(b) Callee Number: The two callee functions (i.e., callee_foo_one, callee_foo_two)\nmap to the two bl instruction at offset foo_offset+0x18 and foo_offset+0x1c. Basic\nBlockNumber:Thethreebasicblocksinsourcecodemapstothreebasicblocksin\nassembly code.\nFigure 10: Strategy-III: Function structure\n10x10000: ldr r3, [pc, #72]\n20x10004: blx r3\n30x10050: \"Pointer value of called function\"\nFigure11: ECMO Driver indirectlyinvokesfunctionsinLinux\nkernel. In offset 0x10000, the memory address pointed by\n[pc,#72]is0x10000+8+72=0x10050.Inthiscase,functions\nwith arbitrary address can be invoked.\ndriverdoesnotoccupythephysicalmemoryregionthatthekernel\ncan perceive, which is achieved by allocating the opaque memory.\nFixup the driver Note that the compiled object file’s base ad-\ndress is 0x0. Given a new load address at runtime, our system\ncalculates new values of the data pointers and function pointers\nand automatically rewrites the corresponding values in the driver.\nFurthermore, due to the limitation of the jump range for the\nBL Label instruction, the driver may not be able to invoke the\nfunctions(ECMOBackwardPointers )intheoriginalLinuxkernel\nwith direct calls, if the offset between them is far from the range\nofthe BLinstruction.Tomakeitwork,werewritethedirectcalls\nwith indirect calls. For example, Fig. 11 shows a code snippet of\ntheassemblycode.Attheoffset 0x10000,itloadsthevaluestored\nat the offset 0x10050into the register R3, which is the jump target.\nWecanrewritethevalueintheoffset 0x10050toinvokearbitrary\nfunction (ECMO Backward Pointers ) in the Linux kernel, without\nbeing limited by the direct call.\nAllocatetheopaquememory TheECMODriver isloadedinto\nthememoryforexecution.However,ifwedirectlyinjectthedriver\ninto the free physical memory pages, the pages could be allocated\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n740Linux \nKernelCheck the \nVirtual \nAddressKernel\nPage \nTablesPhysical\nAddress\nSoftwareECMO\nDriverHijacked\nPage \nTables\nHardware Page Table Walk Module in QEMUOpaque\nMemoryYes\nNo\nFigure 12: The overall design of opaque memory.\nforotherpurposes.Thisisbecausethekerneldoesnotexplicitly\nknow the existence of the ECMO Driver and it is hard to change\nthe allocated physical memory pages due to the complex memory\nmanagementstrategyofLinuxkernel.Inthiscase,theECMOdriver\nmay be overwritten and the functionality cannot be guaranteed.\nThus, we need to ensure that the driver should reside inside a\nmemory region that cannot be affected by the Linux kernel.\nTosolvethisproblem,weproposetheconceptof opaquememory,\na memory region that is not perceived by the Linux kernel but can\nbeusedatruntime.Weimplementtheopaquememorybyhooking\nthe emulated MMU in QEMU. Fig. 12 shows how opaque memory\nworks.Specifically,theemulatedMMUwalksthroughthepagetable\ntotranslatevirtualaddressestophysicaladdresses.ECMOchanges\ntheMMUmoduleinQEMUtocheckwhetherthevirtualaddress\nbeingtranslatedisintheregionoftheopaquememory.Ifso,itwill\nwalkthroughourhijackedpagetablefortheopaquememorytoget\nthephysicaladdress.Otherwise,theoriginalkernelpagetableswill\nbe used. We ensure that the virtual address in the opaque memory\nalways has a valid entry in the page table. By doing so, the ECMO\nDrivercan be loaded and executed in the opaque memory, without\naffectingthememoryviewoftherehostedLinuxkernel.Bydefault,\nwesettheopaquememorystartingfrom0xd0008000andthelength\nis0x10000.Meanwhile,wecheckwhethertheaddressconflictswith\nthe one allocated by Linux kernel. If so, we will change the start\naddress.\n4.4 Implementation Details\nWe implement ECMO based on LuaQEMU [ 11]. LuaQEMU is a dy-\nnamic analysis framework based on QEMU and it exposes several\nQEMU-internal APIs to LuaJIT [ 10] core, which is injected into\nQEMU. We port LuaQEMU based on old QEMU (version 2.9.50) to\nsupporttheQEMUinnewversion(4.0.0)andexposemoredesig-\nnated APIs for initializing the peripheral models. With LuaQEMU,\nweareabletohijacktheexecutionprocessofrehostedLinuxker-\nnelatruntimeandmanipulatethemachinestates,e.g.,accessing\nregisters and memory regions, through Lua scripts, at specified\nbreakpoints.For example,wecan specifyabreakpoint atany par-\nticular address. Inside the breakpoint, we can execute our own Lua\nscript for different purposes. This eases the implementation of the\nopaque memory, dumping the decompressed Linux kernel, and\ninstalling the ECMO Pointers.\nThe module to identify ECMO Pointers (Section 4.2) is imple-\nmentedinPython.WeutilizeCapstone[ 3]todisassemblethede-\ncompressed Linux kernel. For the function identification, we re-implement the algorithm described in Nucleus [\n23] and angr [ 1]in Python. We further extract the required function information,\nwhichisthefunctionsignaturebasedonthegeneratedfunctions\nandtheircontrolflowgraphs.Finally,weintegrateallthesecode\nwith our strategies for identifying ECMO Pointers, which takes\n2290 lines of Python code. All the above mentioned procedurescan be done automatically except that the ECMO Driver, which\nconsistsofthedriversoftransplantedperipherals.Itisdeveloped\nusingthe Clanguagemanually,whichtakes lessthan600 linesof\ncode, and cross-compiled by GCC. Note that it is a one-time effort\ntodevelopthe ECMODriver (Section6).One ECMODriver canbe\nused by different Linux kernel versions if the related functions and\nstructures are not changed.\n5 EVALUATION\nInthissection,wepresenttheevaluationresultofoursystem.Note\nthat, the main purpose of our work is to rehost Linux kernels in\nQEMUsothatwecanbuilddifferentdynamicanalysisapplications\nandinstalldriversformoreperipherals.Inthefollowing,wefirst\nintroduce the dataset of firmware images used in the evaluation\nand then answer the following research questions.•RQ1:Is ECMO able to identify ECMO Pointers?\n•RQ2:\nIs ECMO able to rehost the Linux kernels of embedded\ndevices with different kernel versions and device models?\n•RQ3:Are the rehosted Linux kernels stable and reliable?\n•RQ4:Can ECMO support more peripherals and be used to de-\nvelop dynamic analysis applications?\n5.1 Dataset\nAs oursystem targetsembedded Linuxkernels, we havecollected\nthe firmware images from both third-party projects (i.e., Open-\nWRT[13])anddevicevendors(i.e.,Netgear[ 12]).Ourevaluation\ntargetsLinuxkernelsinARMdevices,sincetheyarethepopular\nCPU architectures in embedded devices [ 17]. However, the overall\nmethodology can also be applied to other architectures (e.g., MIPS).\nDuring the experiment, we focuses on transplanting three early-\nboot peripherals, i.e., interrupt controller (IC), timer, and UART,\nwhicharerequiredtobootaLinuxkernel.OncetheLinuxkernelis\nrehosted,wecaninstalldifferentperipheraldriverstosupportotherperipheralswithkernelmodules.Specifically,weusethePrimeCell\nVectored Interrupt Controller (PL190) [ 14] and ARM Dual-Timer\nModule(SP804)[ 2].Weusethens16550UARTdeviceinoursystem.\nIn total, we evaluate 815 (720 in OpenWRT and 95 in Netgear)\nfirmware images that contain Linux kernels.\n5.2 Identify ECMO Pointers (RQ1)\nECMO Pointers are important to peripheral transplantation. Inthis section, we evaluate the success rate of identifying ECMOPointers. Among all the 815 Linux kernels, there are 20 different\nkernel versions.\nTable 1 lists the required ECMO Pointers, the strategies we\nused, and the Linux kernel versions that these ECMO Pointersare used. In total, we need to identify 24 different ECMO Point-ers for all the 20 Linux kernel versions. Among them, two (i.e.,\nmach_desc->init_time ,and mach_desc->init_irq )aredatapoint-\ners.Identifyingthedatapointersisrathermoredifficultthanthe\nfunctionpointersasweneedtoidentifysymbolsineachfunction\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n741Table1:TheECMOPointers,identificationstrategy,andthe\nLinux kernel versions that the ECMO pointers used by.\nForward Pointers Strategy Kernel Version\nmach_desc->init_irq I ALL\nmach_desc->init_time I ALL\nBackward Pointers Strategy Kernel Version\nirq_set_chip_and_handler_name III 3.18.x/4.4.x/4.14.x\nirq_set_chip_data III ALLhandle_level_irq II ALL__handle_domain_irq III 3.18.x/4.4.x/4.14.xsetup_machine_fdt I 3.18.x/4.4.x/4.14.xset_handle_irq III 3.18.x/4.4.x/4.14.xirq_domain_add_simple III 3.18.x/4.4.x/4.14.xirq_create_mapping I 3.18.x/4.4.x/4.14.xof_find_node_by_path II 3.18.x/4.4.x/4.14.xsetup_irq I ALLclockevents_config_and_register III 3.18.x/4.4.x/4.14.xirq_domain_xlate_onetwocell I 3.18.x/4.4.x/4.14.xclockevent_delta2ns I 2.6.xclockevents_register_device II 2.6.xset_irq_flags I 2.6.x/3.18.xset_irq_chip I 2.6.xirq_to_desc II 2.6.x__do_div64 II 2.6.xplatform_device_register I ALLlookup_machine_type I 2.6.x_set_irq_handler I 2.6.xirq_modify_status III 4.4.x/4.14.x\nTable 2: The decompressed Linux kernel size and the disas-\nsembled function numbers for our dataset.\nMaximum Minimum Mean Median\nSize (Bytes) 8,526,240 4,134,392 7,297,977 8,478,848\nFunctions (#) 48,412 18,455 29,910 23,872\nandinfertherightones.Fortunately,thesetwodatapointersarethe\nreturnvaluesof setup_machine_fdt andlookup_machine_type ,re-\nspectively. According to the ARM calling convention, the return\nvalue is saved in register R0. In this case, we can identify these two\ndata pointers by identifying function pointers setup_machine_fdt\nandlookup_machine_type .\nIdentifying ECMO Pointers requires us to disassemble the de-\ncompressed Linux kernel. Table 2 lists the information of thesekernels. The decompressed Linux kernel is about 730k bytes on\naverage,withthousandsoffunctions.Amongthesefunctions,we\nsuccessfully identify the required ECMO Pointers for all Linux\nkernels.\nAnswer to RQ1: ECMO can identify all the required ECMO\nPointers from thousands of functions inside decompressed\nLinux kernel.\n5.3 Rehost Linux Kernels (RQ2)\nIn this section, we evaluate the capabilities of ECMO on rehosting\nthe Linuxkernels. During thisprocess, we useour system toboot\nthekernelandprovidearootfilesystem(rootfs)intheformatof\nramfs. We use our own rootfs because we can include different\nbenchmarkapplicationsintotherootfstoconductsecurityanalysis.Forexample,weincludePoCsofkernelexploitstoconducttheroot\ncause analysis (Section 5.5). Furthermore, we can include different9376 72 7648355\n9376\n247648303\n050100150200250300350400\nNetgear Asus Pogoplug Buffalo Linksys Others\nTransplanted Rehost\nFigure 13: Supported Vendors of OpenWRT Linux Kernels.\nperipheraldriverstosupportmoreperipherals.Therootfsextracted\nfrom the firmware image can also be used.\n5.3.1 FirmwareImagesfromThirdPartyProjects. Table3showsthe\noverallresultandthesuccessrateofperipheraltransplantationand\nkernel rehosting for OpenWRT. We define the success of periph-eraltransplantationasthatthetransplantedIC,timerandUARTdevices function well in the kernel. If the rehosted kernel enters\nintotheuser-spaceandspawnsashell,wetreatitasasuccessful\nkernel rehosting. In total, we download 902 firmware images from\nOpenWRT. However, four images’ formats are not supported by\nBinwalk and the Linux kernel cannot be extracted (if there is). For\nthe left 898 firmware images, 720 of them contain Linux kernels\nwhile the left ones contain only user-level applications. The 720\nones will be evaluated by ECMO.\nLinux Kernel Versions The kernels in the 720 OpenWRT firm-\nware images consist of 19 different kernel versions. Our evaluation\nshows that we can transplant the peripherals for all the 720 Linux\nkernels. Howev er, some Linux kernels cannot be booted. This is\nbecause they cannot recognize our pre-built root file system (in\nthe ramfs file format) as the support of ramfs is not enabled when\nbeing built. Without the root file system, we cannot launch the\nshell. Howeve r, all of them enter into the function (i.e., init_post )\nto execute the initprogram. In summary, among 720 kernels, our\nsystem can rehost 624 of them, which is shown in Table 3.\nVendorsandDeviceModels AstheOpenWRTprojectsupports\ndevices from multiple vendors, we calculate the supported vendors\nand there are 24 different vendors. Figure 13 shows the result of\nthe top five vendors, i.e., Netgear,Asus,Pogoplug,Buffalo, and\nLinksys, in the OpenWRT dataset. Among them, Pogoplug has a\nrelativelylowsuccessrateofrehosting.That’sbecausemostkernels\nfrom that vendor cannot recognize our pre-built root file system.\nWe also count the number of device models for the successfully\nrehosted Linux kernels. In total, 32 device models are identified.\n5.3.2 FirmwareImagesfromOfficialVendors. Besidesthird-party\nfirmware images, we also apply ECMO on the official images re-\nleased by Netgear. We collect the firmware images for five popular\ndevices,includingR6250,R6300v2,R6400,R6700,R6900,fromthe\nvendor’swebsite[ 12].Intotal,wemanagetocollect95firmware\nimages, and the latest one is released on 2020-09-30. Table 4 shows\ntheresult.WenoticedthatalltheLinuxkernelsofthesedevicesareintheversion2.6.36.Wecansuccessfullytransplanttheperipheralstoallthe95differentfirmwareimages.Amongthem,wecanlaunch\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n742Table3:TheoverallresultofECMOonrehostingtheLinuxkernelofOpenWRT.\"DownloadedImages\"representsthenumber\nof downloaded images. \"Format Supported\" represents the number of images whose formats are supported by firmware ex-\ntractiontool(i.e.,Binwalk).\"KernelExtracted\"representsthenumberofimagesextractedfromthedownloadedimage,whichare rehosted by ECMO. \"Peripherals Transplanted\" represents the number of the images that peripheral can be transplantedsuccessfully (e.g., IC can handler the interrupt well). \"Ramfs are not Mounted\" represents the number of images that cannotmountthegivenramfs.\"Shell\"representstheimagesthatwecanrehostandspawnashell.SuccessRateofTransplantation=\n(Peripherals Transplanted)/(Images); Success Rate of Rehosting = (Shell)/(Images).\nKernel Version Downloaded Images Format Supported Kernel ExtractedPeripherals\nTransplantedSuccess Rate of\nTransplantationRamfs are\nnot MountedShellSuccess Rate of\nRehosting\n3.18.20 23 23 21 21 100% 8 13 61.9%\n3.18.23 29 29 29 29 100% 8 21 72.4%\n4.4.42 37 37 37 37 100% 8 29 78.4%\n4.4.47 37 37 37 37 100% 8 29 78.4%\n4.4.50 45 45 45 45 100% 16 29 64.4%\n4.4.61 39 39 37 37 100% 8 29 78.4%\n4.4.71 40 40 38 38 100% 8 30 78.9%\n4.4.89 40 40 38 38 100% 8 30 78.9%\n4.4.92 41 41 38 38 100% 8 30 78.9%\n4.4.140 41 41 38 38 100% 8 30 78.9%\n4.4.153 40 38 38 38 100% 8 30 78.9%\n4.4.182 40 38 38 38 100% 8 30 78.9%\n4.14.54 54 54 42 42 100% 0 42 100%\n4.14.63 66 66 42 42 100% 0 42 100%\n4.14.95 66 66 42 42 100% 0 42 100%\n4.14.128 66 66 42 42 100% 0 42 100%\n4.14.131 66 66 42 42 100% 0 42 100%\n4.14.151 66 66 42 42 100% 0 42 100%\n4.14.162 66 66 42 42 100% 0 42 100%\nOverall 902 898 720 720 100% 96 624 86.7%\nTable 4: The overall result of ECMO on rehosting the Linux\nkernel of Netgear Devices.\nDevice Name Kernel Version Images # of Peripherals Transplanted Shell\nR6250 2.6.36 21 21 15\nR6300v2 2.6.36 22 22 19\nR6400 2.6.36 20 20 20\nR6700 2.6.36 16 16 16\nR6900 2.6.36 16 16 16\nOverall - 95 95 86\ntheshellfor86imageswhiletheleft9cannotberehosteddueto\nthe same root file system problem.\nAnswer to RQ2: ECMOcanrehosttheLinuxkernelofem-\nbedded devices from 20 kernel versions and 37 (32 in Open-\nWRT and 5 in Netgear) device models. Peripherals can be\ntransplanted to all the Linux kernels while 87.1% (710/815)Linux kernels can be successfully rehosted (i.e., launch the\nshell).\n5.4 Reliability and Stability (RQ3)\nWe use the LTP (Linux Test Project [ 8]) testsuite to evaluate the\nreliability and stability of the rehosted kernel. In total, there areTable 5: The category of the failed syscall test cases. After\ninstalling the peripheral driver for Ethernet device, the 15failed cases due to the network are passed and the totalfailed ones will decrease from 66 to 51.\nCategory of Failed cases Number\nTesting the bug or vulnerability of Linux kernel 16\nNetwork is not enabled (15)\nThe function is not implemented 25\nOthers 10\nTotal 66 (51)\n1,257testcasesforsystemcalls.Amongthem,148areskippedas\nthetestingenvironment(e.g.,theCPUarchitectureandthebuild\nconfiguration) does not meet the requirement. For the left 1 ,109\ntest cases, 1 ,043 passed while the left 66 ones failed.\nWefurtheranalyzethereasonforthefailedtestcases.Table5\nliststhecategoryofthereason.Amongthem,15casesaredueto\nthelackofnetworkdevices.Thisisexpectedsinceoursystemdoes\nnot add the support of network device initially. However, all the\n15testcasesarepassedafterinstallingtheEthernetdevicedriver\nwithkernelmodulesontherehostedLinuxkernel(Section5.5.1).\nAlso,16casesaimtotestwhethertheLinuxkernelfixesabugor\nvulnerability.Forinstance,thetestcase(timer_create03[ 9])isto\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n743    sock_setsockopt\n    0xc0229f68 STR r6, [r4, #0xd0]    r4+0xd0: 0xc7929110    /*write 0xffffff00 into 0xc7929110*/Callstack\nECMO\nint sock_setsockopt(args []){    . . .\nsk->sk_userlocks |= SOCK_SNDBUF_LOCK;sk->sk_sndbuf = max_t(u32, val * 2, \nSOCK_MIN_SNDBUF);  }[<c022cfd0>] (__alloc_skb) from [<c022d170>][<c022d110>] (alloc_skb_with_frags) from [<c0227cb0>][<c0227b04>] (sock_alloc_send_pskb) from [<c02bb540>] [<c02bb3cc>] (unix_stream_sendmsg) from [<c02242ec>]\n    unix_stream_sendmsg    0xc02bb4cc LDR sb, [r2, #0xd0]    r2+0xd0: 0xc7929110    0xc7929110: 0xffffff00    /*load 0xffffff00 from address 0xc7929110*/    . . .    0xc02bb53c BL 0xc0227b04    r1:0xffffff40 /*calculated from 0xffffff00*/  Crash Linux Kernel\n    sock_alloc_send_pskb    0xc0227cac BL 0xc022d110    r0: 0xffffff40     alloc_skb_with_frags    0xc022d16c BL 0xc022cfd0(__alloc_skb)     /*crash in function __alloc_skb*/    r0: 0xffffff40  Trace\nGDB\nWatchpoint\nSource Code\nFigure 14: Root cause analysis of CVE-2016-9793.\ncheckwhetherCVE-2017-18344[ 5]isfixed.Ifthevulnerabilityis\nnot fixed, the test case will fail. They are also expected since the\ntesting kernel does not fix these vulnerabilities. The other 25 cases\nreturnbackthe ENOSYSerrornumber,whichmeansthefunctionali-\nties are not implemented. For the remaining 10 cases, the reason is\nadhoc, such as the kernel version is old and timeout.\nInsummary,94%ofthesystemcalltestcasespassed.Thisevalu-\nationshowstherehostedkernelisreliableandstable.Wefurther\ndemonstrate the usage scenarios of the rehosted Linux kernel in\nSection 5.5.\nAnswer to RQ3: The rehosted Linux kernel can pass 94%\nsystemcalltestcasesinLTP,whichdemonstratesitsreliability\nand stability.\n5.5 Applications and Other Peripherals (RQ4)\nOursystemcanrehostLinuxkernels,whichprovidesthecapabil-\nity to install different peripheral drivers with kernel modules to\nsupport more peripherals. Furthermore, the rehosted Linux kernel\nlaysthefoundationofapplicationsrelyingonthecapabilitytoin-\ntrospect the runtime states of the target system. In this section, we\nsuccessfully install the Ethernet device driver (i.e., smc91x) for all\ntherehostedLinuxkernels.Wealsoleverageoursystemtobuild\nthree applications, including kernel crash analysis, rootkit forensic\nanalysis, and kernel fuzzing, to demonstrate the usage scenarios of\nECMO. Other applications that rely on QEMU can be ported. Note\nthat, we only use these applications to demonstrate the usage of\nour system. The applications are not the main contribution of this\nwork.\n5.5.1 Other Peripherals. Linux kernel module is an object file that\ncanbeloadedduringtheruntimetoextendthefunctionalityofthe\nLinux kernel. In this case, peripheral drivers can be built as kernel\nmodulesandloadedintothekerneldynamically.TodemonstrateTable 6: CVEs that can be triggered on the rehosted Linux\nkernel by ECMO.\nCVE ID CVE Score CVE Type Fix Version\nCVE-2018-5333 5.5 Null Pointer Dereference 4.14.13\nCVE-2016-4557 7.8 Double Free 4.5.5\nCVE-2017-10661 7.0 Race Condition 4.10.15\nCVE-2016-0728 7.8 Interger Overflow 4.4.1CVE-2016-9793 7.8 Type Confusion 4.8.14\nCVE-2017-12193 5.5 Null Pointer Dereference 4.13.11\nthat our rehosted Linux kernel is able to support more peripherals.\nweselectonerathercomplexperipheral(i.e.,smc91x[ 18])andbuild\nthe driver code into kernel module (i.e., smc91x.ko). We then inject\nthis kernel module into the ramfs that is fed to rehosted Linux\nkernel. After the embedded Linux kernel is rehosted by ECMO, we\nuse the command insmod smc91x.ko to install the peripheral driver\nforsmc91x.Meanwhile,QEMUhasalreadyprovidedtheperipheral\nmodelforsmc91xandwecanintegratethismodelintothemachine\nmodel directly. Finally, we successfully install the peripheral driver\nofsmc91xforallthe710rehostedLinuxkernels,whichdemonstrate\nthe capability of ECMO to support the other peripherals.\n5.5.2 Crash Analysis. In the following, we show the process to\nutilizeECMOtounderstandtherootcauseofthecrashonrehosted\nkernels. To this end, we collect the PoCs that can trigger the crash\nfor six reported bugs and vulnerabilities (as shown in Table 6). We\nthen boot the Linux kernel and run the PoCs to crash the kernel.\nDuring this process, we use the QEMU to collect the runtime trace.\nWe also leverage the remote GDB in QEMU to debug the rehosted\nkernel. We detail the procedures on how to conduct the crash anal-\nysisforonecase(CVE-2016-9793[ 4])withthecollectedruntime\ntrace. Figure 14 shows the whole procedure.\nSpecifically,whentherehostedLinuxkernelcrashes,thedetailed\ncallstackwillbeprintedout.Thecallstackincludesthefunction\nname and the addresses of these functions. With the runtime trace\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n744provided by QEMU, wecan get the information includingthe reg-\nister values and the execution path. By analyzing the trace, we\nnoticed that a negative value (i.e., 0xffffff40 ) is the first parame-\nter of the function __alloc_skb . This negative value results in the\ncrash.\nWethenanalyzethepropagationofthisnegativevaluewithinthe\ntrace.Thisvalueispropagatedbythefirstparameterofthefunction\nsock_alloc_send_pskb .Finally,wenoticethatthenegativevalue\n0xffffff40 is calculated from 0xffffff00 , which is loaded by the\nfunction unix_stream_sendmsg from the address 0xc7929110 .W e\nthen use the GDBto set a watchpoint at this memory address and\ncapture that the instruction at the address 0xc0229f68 was writing\nthe negative value (i.e., 0xffffff00 ) into this memory location.\nWe further analyze the function that contains the instruction at\ntheaddress 0xc0229f68 .Itturnsoutthattherootcauseofthecrash\nis because of the type confusion. In the function sock_setsockopt ,\nthevariable sk→sk_sndbuf willbesetbythereturnvalueof max_t\n(maximum value between two values in the same type). However,\nduetothewrongtype u32,thereturnvaluecanbeanegativevalue,\nwhich triggers the crash.\nThis analysisshows the usage ofECMO by providing thecapa-\nbility introspect the runtime states of the rehosted kernel.\n5.5.3 Rootkit Forensic Analysis. Rootkit forensic analysis requires\nthe ability to monitor the runtime states of the kernel [ 40,48]. We\ndemonstratethisabilitybyconductingtherootkitforensicanalysis\nwith one (i.e., Suterusu[20]) popular rootkit in the wild.\nSpecifically, Suterusu is able to hide specific processes by hi-\njacking the kernel function proc_readdir , which is used to get\nthe process information. As shown in Figure 15(a), it hijacks the\nfunction proc_readdir by rewriting the function’s first instruction\ntoLDR PC,[PC,#0] . As a result, it redirects the execution to the\nfunctionnew_proc_readdir inside the rootkit. With ECMO, we can\nmonitorthechangestothekernelcodesections(asuspiciousbehav-\nior)bysettingupmemorywatchpointstotheLinuxcodesection\n(Figure 15(b)).\n5.5.4 Fuzzing. Fuzzing has been widely used to detect software\nvulnerabilities.Weportedoneofthemostpopularkernelfuzzers\n(i.e.,UnicornFuzz [51])intoECMOandfuzzedtheexamplekernel\nmodules provided by UnicornFuzz .UnicornFuzz can work under\nECMOandthefuzzing speedcanreachto 396instancespersecond.\nThis demonstrates the usage of ECMO for kernel fuzzing.\nAnswer to RQ4: Applications,e.g.,crashanalysis,forensic\nanalysis, kernel fuzzing, can be built upon the rehosted Linux\nkernel by our system. Furthermore, rehosted Linux kernel\ncan install peripheral drivers with kernel modules to support\nmore peripherals.\n6 DISCUSSION\nManualefforts ECMOprovidesmostlyautomatedapproachand\nonlydevelopingthe ECMODriver requiresmanualefforts.However,\nthis is a one-time effort. Furthermore, one ECMO Driver can be\ntransplanted to different kernel versions if the related functions\nand structures are not changed. Even if the functions are changed,\nwe just need to change a few APIs and compile it again to create aLinux Kernel Rootkit\nhijack_proc\nproc_readdir new_proc_readdirHijack\nLDR PC, [PC,#0]Rewriting\n(a) Workflow of rootkit Suterusu\ngef >   c\nContinuing.\nHardware watchpoint 1: *0xc00fc078\nOld value  = 0xe92d4038\nNew value = 0xe59ff000\n0xbf00116c in ?? () LDR PC,[PC, #0]\n(b) ECMO observes how the rootkit Suterusuworks.\nFigure15:Theworkflowofrootkit Suterusu andhowECMO\nanalyzes the behavior\nnewECMODriver.Forexample,the815Linuxkernelsconsistof20\ndifferentkernelversions.Forthekernelinversion2.6.36,ittakes\n385linesofCcode.Thisdrivercanbeusedforallthekernelimages\nofNetgear(Table4).Forthekernelinversion3.18.20and3.18.23,\nittakes 534linesofCcode while180linesof newcodeareadded.\nFor kernels in all the left 17 versions, they share the same driver\ncode.60linesofnewcodeareaddedcomparedwiththeoneusedin\n3.18.20.Notethatthedrivercodeforthetransplantedperipherals\ndoes not need to be developed. Instead, we reuse the existing code.\nFor example, the driver code for VIC (PL190) is open source [ 15].\nThus, we just reuse the existing driver code, merge the driver code\nintoonefile,andfinallycompileittogeneratetheECMOdriver.In\ntotal, it takes less than one person-hour to build a new customized\ndriver.\nFunctionalitiesofperipherals WesuccessfullyboottheLinux\nkernel by transplanting designated peripherals (e.g., IC, Timer, and\nUART). We admit that the original peripherals may not work prop-\nerty as they are not emulated (or transplanted) in QEMU. However,\nthe functionalities of the transplanted peripherals are guaranteed.\nWiththetransplantedperipherals,ECMOcanprovidethecapability\ntointrospecttheruntimestatesoftheLinuxkernelthatdynamic\nanalysis applications can be built upon. Without our system, it’s\nimpossible to build such applications since the target Linux kernel\ncannot be booted in QEMU. The three applications used in the\nevaluationhavedemonstratedtheusagescenariosofoursystem.\nWe may build or port more complicated applications, e.g., dynamic\ntaint analysis [60], to further evaluate our system.Otherperipherals\nCurrently,ECMOisevaluatedbasedontrans-\nplanting three early-boot peripherals (i.e., IC, timer, and UART) as\nthey are required to boot a Linux kernel. In general, peripheral\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n745transplantationworksonallkindsofperipherals.Thetransplant-\ning process depends on the identification of ECMO pointers. Fortu-\nnately,tosupporttheotherperipherals,userscaninstallthekernel\nmodules directly on the rehosted Linux kernel, which does not\nneedtoidentifypointers.Inthiscase,allkindsofperipheralscan\nbe supported. Our experiments show that the driver of Ethernet\ndevice,whichisrathercomplex,canbesuccessfullyinstalledand\nthe network functionality can be guaranteed.\nOther architectures Currently, ECMO only supports ARM ar-\nchitecture,whichisthemostpopularoneinembeddedsystems[ 17].\nHowever, the technique peripheral transplantation can be easily\nextendedtotheotherarchitectureasitdoesnotrelyonanyparticu-\nlar architecture feature. Specifically, developers need to implement\nthe module for identifying ECMO Pointers for the new architec-\nture.Thisrequiresadditionalengineeringeffortsandalgorithm1\nis provided.\n7 RELATED WORK\nStaticFirmwareAnalysis Researchersapplythestaticanalysis\ntechnique to analyze the embedded firmware. For instance, Costin\net al. [30] conduct a large-scale analysis towards the embedded\nfirmware.Byanalyzing32thousandfirmwareimages,manynew\nvulnerabilities are discovered, influencing 123 products.\nCode similarity is widely used to study the security issue of em-\nbeddeddevices.Fengetal.proposeGenius[ 38],whichcanidentify\nmanyvulnerabilities ina shorttime. Consideringthe inaccuracy of\napproximategraph-matchingalgorithm,Xuetal.utilizeaneural\nnetwork-basedapproachandbuildaprototypenamedGemini[ 65].\nThe result shows Gemini can identify more vulnerable firmware\nimagescomparedwithGenius.Yanivetal.introduceFirmup[ 32],\nwhich has a relatively low false positive ratio and can discover\nvulnerabilities efficiently, by considering the relationship between\nprocedures.Inthecasethatfirmwareimagesarenotavailable,Xue-\nqiang et al. [ 63] applies cross analysis of mobile apps to detect the\nvulnerabledevices.Finally,324devicesfrom73differentvendors\nare discovered. Our system is used to analyze the firmware images\nof embedded systems with dynamic analysis. Application building\nupon ECMO can complement the static analysis ones.DynamicFirmwareAnalysis\nBesidesstaticanalysis,researchers\nproposeseveralmethodstosupportthedynamicfirmwareanalysis.\nAvatar[69]isproposedtosupportcomplexdynamicanalysisofem-\nbedded devices by orchestrating the execution of an emulator and\nreal hardware.Charm [ 62] appliesa similar strategy.It introduces\nthetechniquenamedremotedevicedriverexecutionbyforwarding\nthe MMIO operation to a real mobile. Avatar2 [ 54] extends Avatar\ntosupportreplaywithoutrealdevices.However,theybothsuffer\nfrom the problem of scalability. Inception [ 29] applies symbolic ex-\necution based on KLEE [ 25] and a custom JTAG to improve testing\nembedded software. However, it assumes that the source code is\navailable.IoTFuzzer[ 27]aimstofuzzthefirmwarefromthemobile\nside. However, the code coverage of firmware and the coverage of\nattacksurfacearelimited.Pretender[ 43]isabletoconductautomat-\nically rehosting tasks. However, it replies on the debug interface of\nspecific devices. Jetset [ 49] utilizes the symbolic execution to infer\nthe return values of device registers. However, the functionality ofthe peripherals cannot be guaranteed. Furthermore, theshell may\nnot be obtained for further development of different applications.\nBesides,manyresearchersutilizethefuzzingtechniquetodetect\nthesecurityissuesofembeddedfirmware.P2IM[ 37]isproposed\nto learn the model of peripherals automatically. DICE [ 52] focused\nontheDMAcontrollerandcanextendtheP2IM’sanalysiscover-\nage.Halucinator[ 28]proposedanewmethodologytorehostthe\nfirmwarebyabstractingtheHALfunctions.ECMOisdifferentfrom\nthem in the aspects to transplant peripherals into the target kernel,\ninsteadofinferringtheperipheralsmodels.Besides,allthesesys-\ntemsfocusonbare-metalsystem,whichislesscomplicatedthan\nthe Linux kernel. Firmadyne [ 26] and FirmAE [ 50] target on Linux-\nbasedfirmware.However,theyfocusontheuser-spaceprogram,\ninstead of the Linux kernel.\nApplications based on QEMU There are many applications\nbased on QEMU. For example, researchers have developed newfuzzing systems [\n21,51,70] based on QEMU. KVM leverages the\ndevice emulation provided by QEMU or the virtio [ 58] framework\nfor device virtualization. The idea of virtio is similar to ECMO.\nHowever, virtio requires to change the source code of guest while\nECMO works towards the Linux kernel binary. Virtual machine\nintrospection tools [ 24,33,34,39,40,64], which are helpful for de-\nbuggingorforensicanalysis,utilizeQEMUtointrospectthesystem\nstates.Furthermore,dynamicanalysisframeworksuseQEMUto\nanalyze malwarebehavior [36, 53,57, 66–68]. ECMO provides the\ncapabilityto rehostLinuxkernels,which laysthefoundationfor\napplying these applications on embedded Linux kernels.\n8 CONCLUSION\nInthiswork,weproposeanoveltechniquenamedperipheraltrans-plantationtorehosttheLinuxkernelofembeddeddevicesinQEMU.\nThis lays the foundation for applications that rely on the capability\nof runtime state introspection. We have implemented this tech-\nnique inside a prototype system called ECMO and applied it to 815\nfirmwareimages,whichconsistof20kernelversionsand37device\nmodels. ECMO can successfully transplant peripherals for Linux\nkernels in all images. Among them, 710 kernels can be successfully\nrehosted, i.e., launching the user-space shell (87 .1% success rate).\nFurthermore, we successfully install one Ethernet device driver\n(i.e., smc91x) on all the rehosted Linux kernels to demonstrate the\ncapability of ECMO to support more peripherals. We further build\nthree applications to show the usage scenarios of ECMO.\nACKNOWLEDGEMENT\nWe would like to thank the anonymous reviewers for their com-\nmentsthatgreatlyhelpedimprovethepresentationofthispaper.\nWealsowanttothankAndrewBaumannforshepherdingourpa-\nper. This work was partially supported by the National Natural\nScienceFoundationofChina(GrantNo.61872438),theFundamen-\ntalResearchFundsfortheCentralUniversities(ZhejiangUniversity\nNGICS Platform ZJUNGICS2021016, K20200019), Leading Innova-\ntiveandEntrepreneurTeamIntroductionProgramofZhejiang(No.\n2018R01005),HKRGCProject(No.PolyU152239/18E).Anyopin-\nions,findings,andconclusionsorrecommendationsexpressedin\nthis material are those of the authors and do not necessarily reflect\nthe views of funding agencies.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n746REFERENCES\n[1] angr. https://angr.io/.\n[2]ARMDual-TimerModule(SP804). https://developer.arm.com/documentation/\nddi0271/d/.\n[3] Capstone. https://www.capstone-engine.org/.[4] CVE-2016-9793. https://nvd.nist.gov/vuln/detail/CVE-2016-9793.[5] CVE-2017-18344. https://nvd.nist.gov/vuln/detail/CVE-2017-18344.[6] ECMO Online Service. https://blocksecteam.org/ecmo/.[7]\nIoT Devices Market. https://www.zionmarketresearch.com/requestbrochure/iot-\ndevices-market.\n[8] Linux Test Project. http://linux-test-project.github.io/.[9]\nLinuxTestProjecttestcasetimer_create03.https://github.com/linux-test-project/\nltp/blob/master/testcases/kernel/syscalls/timer_create/timer_create03.c.\n[10] LuaJIT. http://luajit.org/luajit.html.[11] LuaQEMU. https://github.com/Comsecuris/luaqemu.[12] Netgear. https://www.netgear.com/.[13] OpenWRT. https://openwrt.org/.[14]\nPrimeCell Vectored Interrupt Controller (PL190). https://developer.arm.com/\ndocumentation/ddi0181/e/introduction/about-the-vic.\n[15]PrimeCell Vectored Interrupt Controller (PL190) Source Code. https://elixir.\nbootlin.com/linux/v3.18.20/source/drivers/irqchip/irq-vic.c#L445.\n[16] QEMU. https://www.qemu.org/.[17]\nTheRoadshowofARM. https://group.softbank/system/files/pdf/ir/presentations/\n2019/arm-roadshow-slides_q4fy2019_01_en.pdf.\n[18]SMC91X SourceCode. https://elixir.bootlin.com/linux/v3.18.20/source/drivers/\nirqchip/irq-vic.c#L445.\n[19] SoC (System on a Chip). https://openwrt.org/docs/techref/hardware/soc.[20] suterusu. https://github.com/mncoppola/suterusu.[21] TriforceAFL. https://github.com/nccgroup/TriforceAFL.[22]\nVulnerability Statistics of Linux Kernel. https://www.cvedetails.com/product/47/\nLinux-Linux-Kernel.html.\n[23]Dennis Andriesse, Asia Slowinska, and Herbert Bos. 2017. Compiler-agnostic\nfunctiondetectioninbinaries.In Proceedingsofthe2ndIEEEEuropeanSymposium\non Security and Privacy.\n[24]SinaBahram, XuxianJiang, ZhiWang, MikeGrace,Jinku Li,Deepa Srinivasan,\nJunghwan Rhee, and Dongyan Xu. 2010. Dksm: Subverting virtual machine\nintrospection for fun and profit. In Proceedings of the 29th IEEE symposium on\nreliable distributed systems.\n[25]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and\nAutomatic Generation of High-Coverage Tests for Complex Systems Programs.\nInProceedings of the 8th USENIX Conference on Operating Systems Design and\nImplementation.\n[26]Daming D Chen, Maverick Woo, David Brumley, and Manuel Egele. 2016. To-\nwardsAutomatedDynamicAnalysisforLinux-basedEmbeddedFirmware.In\nProceedingsofthe23rdAnnualNetworkandDistributedSystemSecuritySympo-\nsium.\n[27]Jiongyi Chen, Wenrui Diao, Qingchuan Zhao, Chaoshun Zuo, Zhiqiang Lin,\nXiaoFengWang,WingCheongLau,MenghanSun,RonghaiYang,andKehuan\nZhang. 2018. IoTFuzzer: Discovering Memory Corruptions in IoT Through App-\nbased Fuzzing.. In Proceedings of the 25th Annual Network and Distributed System\nSecurity Symposium.\n[28]Abraham A Clements, Eric Gustafson, Tobias Scharnowski, Paul Grosen, David\nFritz, Christopher Kruegel, Giovanni Vigna, Saurabh Bagchi, and Mathias Payer.\n2020. HALucinator: Firmware Re-hosting Through Abstraction Layer Emulation.\nInProceedings of the 29th USENIX Security Symposium.\n[29]NassimCorteggiani,GiovanniCamurati,andAurélienFrancillon.2018. Incep-\ntion: System-wide security testing of real-world embedded systems software. In\nProceedings of the 27th USENIX Security Symposium.\n[30]Andrei Costin, Jonas Zaddach, AurélienFrancillon, and Davide Balzarotti. 2014.\nALargeScaleAnalysisoftheSecurityofEmbeddedFirmwares.In Proceedingsof\nthe 23rd USENIX Security Symposium.\n[31]WeidongCui,XinyangGe,BarisKasikci,BenNiu,UpamanyuSharma,Ruoyu\nWang, and Insu Yun. 2018. {REPT}: Reverse Debugging of Failures in Deployed\nSoftware. In Proceedings of the 13th {USENIX}Symposium on Operating Systems\nDesign and Implementation.\n[32]Yaniv David, Nimrod Partush, and Eran Yahav. 2018. FirmUp: Precise StaticDetection of Common Vulnerabilities in Firmware. In Proceedings of the 23rd\nInternationalConferenceonArchitecturalSupportforProgrammingLanguagesand\nOperating Systems.\n[33]Brendan Dolan-Gavitt, Tim Leek, Michael Zhivich, Jonathon Giffin, and Wenke\nLee.2011. Virtuoso:Narrowingthesemanticgapinvirtualmachineintrospection.\nInProceedings of the 32nd IEEE symposium on security and privacy.\n[34]Pavel Dovgalyuk, Natalia Fursova, Ivan Vasiliev, and Vladimir Makarov. 2017.\nQEMU-based framework for non-intrusive virtual machine instrumentation and\nintrospection. In Proceedings of the 11th Joint Meeting on Foundations of Software\nEngineering.[35]RuianDuan,AshishBijlani,MengXu,TaesooKim,andWenkeLee.2017. Iden-\ntifying open-source license violation and 1-day security risk at large scale. In\nProceedingsofthe2017ACMSIGSACConferenceoncomputerandcommunications\nsecurity.\n[36]ManuelEgele,ChristopherKruegel,EnginKirda,HengYin,andDawnSong.2007.\nDynamic spyware analysis. In Proceedings of the 2007 USENIX Annual Technical\nConference.\n[37]Bo Feng, Alejandro Mera, and Long Lu. 2019. P2IM: Scalable and Hardware-\nindependentFirmware Testing viaAutomaticPeripheralInterface Modeling.In\nProceedings of the 29th USENIX Security Symposium.\n[38]Qian Feng, Rundong Zhou, Chengcheng Xu, Yao Cheng, Brian Testa, and Heng\nYin. 2016. Scalable graph-based bug search for firmware images. In Proceedings\nof the 2016 ACM SIGSAC Conference on Computer and Communications Security.\n[39]Yangchun Fu and Zhiqiang Lin. 2013. Bridging the semantic gap in virtual\nmachineintrospectionviaonlinekerneldataredirection. ACMTransactionson\nInformation and System Security (2013).\n[40]TalGarfinkel,MendelRosenblum,etal .2003. Avirtualmachineintrospection\nbased architecture for intrusion detection.. In Proceedings of the 2003 Annual\nNetwork and Distributed System Security Symposium.\n[41]Xinyang Ge, Ben Niu, and Weidong Cui. 2020. Reverse Debugging of Kernel\nFailuresinDeployedSystems.In Proceedingsofthe2020USENIXAnnualTechnical\nConference.\n[42]Daniel M German and Jesús M González-Barahona. 2009. An empirical study\nof the reuse of software licensed under the GNU General Public License. In IFIP\nInternational Conference on Open Source Systems. Springer.\n[43]EricGustafson,MariusMuench,ChadSpensky,NiloRedini,AravindMachiry,\nYanick Fratantonio, Davide Balzarotti, Aurélien Francillon, Yung Ryn Choe,\nChristophe Kruegel, and Giovanni Vigna. 2019. Toward the Analysis of Em-bedded Firmware through Automated Re-hosting. In Proceedings of the 22nd\nInternational Symposium on Research in Attacks, Intrusions and Defenses.\n[44]LeeHarrison,HayawardhVijayakumar,RohanPadhye,KoushikSen,andMichael\nGrace. 2020. PARTEMU: Enabling dynamic analysis of real-world trustzone\nsoftwareusingemulation.In Proceedingsofthe29thUSENIXSecuritySymposium.\n[45]Grant Hernandez, Farhaan Fowze, Dave Tian, Tuba Yavuz, and Kevin RB Butler.\n2017. FirmUSB:VettingUSBdevicefirmwareusingdomaininformedsymbolicexecution.In Proceedingsofthe2017ACMSIGSACConferenceonComputerand\nCommunications Security.\n[46]Muhui Jiang, Yajin Zhou, Xiapu Luo, Ruoyu Wang, Yang Liu, and Kui Ren. 2020.\nAnempiricalstudyonARMdisassemblytools.In Proceedingsofthe29thACM\nSIGSOFT International Symposium on Software Testing and Analysis.\n[47]Xuxian Jiang, Xinyuan Wang, and Dongyan Xu. 2007. Stealthy malware de-\ntectionthroughvmm-based\"out-of-the-box\"semanticviewreconstruction.In\nProceedingsofthe14thACMconferenceonComputerandcommunicationssecurity.\n[48]Xuxian Jiang, Xinyuan Wang, and Dongyan Xu. 2010. Stealthy malware de-tection and monitoring through VMM-based “out-of-the-box” semantic view\nreconstruction. ACM Transactions on Information and System Security (2010).\n[49]EvanJohnson,MaxwellBland,YiFeiZhu,JoshuaMason,StephenCheckoway,\nStefan Savage, and Kirill Levchenko. 2021. Jetset: Targeted Firmware Rehosting\nforEmbeddedSystems.In Proceedingsofthe30th {USENIX}SecuritySymposium.\n[50]MingeunKim,DongkwanKim,EunsooKim,SuryeonKim,YeongjinJang,and\nYongdaeKim.2020. FirmAE:TowardsLarge-ScaleEmulationofIoTFirmware\nfor Dynamic Analysis. In Proceedings of the 2020 Annual Computer Security\nApplications Conference.\n[51]Dominik Maier, Benedikt Radtke, and Bastian Harren. 2019. Unicorefuzz: Onthe viability of emulation for kernelspace fuzzing. In Proceedings of the 13rd\n{USENIX}Workshop on Offensive Technologies ( {WOOT}19).\n[52]AlejandroMera,BoFeng,LongLu,EnginKirda,andWilliamRobertson.2021.\nDICE: Automatic Emulation of DMA Input Channels for Dynamic Firmware\nAnalysis. In Proceedings of the 42nd IEEE Symposium on Security and Privacy.\n[53]Andreas Moser, Christopher Kruegel, and Engin Kirda. 2007. Exploring multiple\nexecution paths for malware analysis. In Proceedings of the 28th IEEE Symposium\non Security and Privacy.\n[54]Marius Muench, Dario Nisi, Aurelien Francillon, and Davide Balzarotti. 2018.\nAvatar2: A Multi-target Orchestration Platform. In Workshop on Binary Analysis\nResearch.\n[55]NiloRedini, AravindMachiry, RuoyuWang,Chad Spensky,Andrea Continella,\nYan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna. 2020. KARONTE:\nDetecting Insecure Multi-binary Interactions in Embedded Firmware. In Proceed-\nings of the 41st IEEE Symposium on Security & Privacy.\n[56]Ryan Riley, Xuxian Jiang, and Dongyan Xu. 2008. Guest-transparent prevention\nofkernelrootkitswithvmm-basedmemoryshadowing.In Proceedingsofthe11st\nInternational Workshop on Recent Advances in Intrusion Detection.\n[57]RyanRiley,XuxianJiang,andDongyanXu.2009. Multi-aspectprofilingofkernel\nrootkit behavior. In Proceedings of the 4th ACM European conference on Computer\nsystems. 47–60.\n[58]RustyRussell.2008. virtio:towardsade-factostandardforvirtualI/Odevices.\nACM SIGOPS Operating Systems Review (2008).\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n747[59]Sergej Schumilo, Cornelius Aschermann, Robert Gawlik, Sebastian Schinzel, and\nThorsten Holz. 2017. kafl: Hardware-assisted feedback fuzzing for {OS}kernels.\nInProceedings of the 26th {USENIX}Security Symposium.\n[60]Edward J Schwartz, Thanassis Avgerinos, and David Brumley. 2010. All you ever\nwantedtoknowaboutdynamictaintanalysisandforwardsymbolicexecution\n(but might have been afraid to ask). In Proceedings of the 31st IEEE symposium on\nSecurity and privacy.\n[61]Yan Shoshitaishvili, Ruoyu Wang, Christophe Hauser, Christopher Kruegel, and\nGiovanniVigna.2015. Firmalice-automaticdetectionofauthenticationbypass\nvulnerabilitiesinbinaryfirmware.In Proceedingsofthe22ndAnnualNetworkand\nDistributed System Security Symposium.\n[62]Seyed Mohammadjavad Seyed Talebi, Hamid Tavakoli, Hang Zhang, Zheng\nZhang,ArdalanAmiriSani,andZhiyunQian.2018. Charm:Facilitatingdynamic\nanalysisofdevicedriversofmobilesystems.In Proceedingsofthe27thUSENIX\nSecurity Symposium.\n[63]Xueqiang Wang, Yuqiong Sun, Susanta Nanda, and XiaoFeng Wang. 2019. Look-\ningfromthemirror:evaluatingIoTdevicesecuritythroughmobilecompanion\napps. InProceedings of the 28th USENIX Security Symposium.\n[64]Zhi Wang, Xuxian Jiang, Weidong Cui, and Xinyuan Wang. 2008. Countering\npersistentkernelrootkitsthroughsystematichookdiscovery.In Proceedingsof\nthe 11st International Workshop on Recent Advances in Intrusion Detection.[65]Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. 2017.\nNeuralnetwork-basedgraphembeddingforcross-platformbinarycodesimilarity\ndetection.In Proceedingsofthe2017ACMSIGSACConferenceonComputerand\nCommunications Security.\n[66]Lok-KwongYan,ManjukumarJayachandra,MuZhang,andHengYin.2012. V2e:\ncombining hardware virtualizationand softwareemulation fortransparent and\nextensible malware analysis. In Proceedings of the 8th ACM SIGPLAN/SIGOPS\nconference on Virtual Execution Environments.\n[67]Lok Kwong Yan and Heng Yin. 2012. Droidscope: Seamlessly reconstructing\nthe{OS}anddalviksemanticviewsfordynamicandroidmalwareanalysis.In\nProceedings of the 21st {USENIX}Security Symposium.\n[68]Heng Yin, Dawn Song, Manuel Egele, Christopher Kruegel, and Engin Kirda.\n2007. Panorama: capturing system-wide information flow for malware detec-tion and analysis. In Proceedings of the 14th ACM conference on Computer and\ncommunications security.\n[69]Jonas Zaddach, Luca Bruno, Aurélien Francillon, and Davide Balzarotti. 2014.\nAVATAR: A Framework to Support Dynamic Security Analysis of Embedded\nSystems’Firmwares.In Proceedingsofthe21stAnnualNetworkandDistributed\nSystem Security Symposium.\n[70]Yaowen Zheng, Ali Davanian, Heng Yin, Chengyu Song, Hongsong Zhu, andLimin Sun. 2019. FIRMAFL: high-throughput greybox fuzzing of iot firmware\nvia augmented process emulation. In Proceedings of the 28th USENIX Security\nSymposium.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n748"}
{"title": "FakeWake: Understanding and Mitigating Fake Wake-up Words of Voice Assistants", "content": "FakeWake: Understanding and Mitigating Fake Wake-up Words\nof Voice Assistants\nYanjiao Chen\nZhejiang University\nchenyanjiao@zju.edu.cnYijie Bai\nZhejiang University\nbaiyj@zju.edu.cnRichard Mitev\nTechnical University of Darmstadt\nrichard.mitev@trust.tu-darmstadt.de\nKaibo Wang\nZhejiang University\nkaibo@zju.edu.cnAhmad-Reza Sadeghi\nTechnical University of Darmstadt\nahmad.sadeghi@trust.tu-\ndarmstadt.deWenyuan Xu\nZhejiang University\nxuwenyuan@zju.edu.cn\nAbstract\nIntheareaofInternetofThings(IoT),voiceassistantshavebecome\nanimportantinterfacetooperatesmartspeakers,smartphones,and\neven automobiles. To save power and protect user privacy, voiceassistants send commands to the cloud only if a small set of pre-\nregistered wake-up words are detected. However, voice assistants\nare shown to be vulnerable to the FakeWake phenomena, whereby\ntheyareinadvertentlytriggeredbyinnocent-soundingfuzzywords.Inthispaper,wepresentasystematicinvestigationofthe FakeWake\nphenomenafromthreeaspects.Tostartwith,wedesignthefirst\nfuzzywordgeneratortoautomaticallyandefficientlyproducefuzzy\nwordsinsteadofsearchingthroughaswarmofaudiomaterials.We\nmanage to generate 965 fuzzy words covering 8 most popular Eng-\nlish and Chinese smart speakers. To explain the causes underlying\ntheFakeWake phenomena,weconstructaninterpretabletree-based\ndecision model, which reveals phonetic features that contribute to\nfalseacceptanceoffuzzywordsbywake-upworddetectors.Finally,\nwe propose remedies to mitigate the effect of FakeWake . The re-\nsultsshowthatthestrengthenedmodelsarenotonlyresilientto\nfuzzywordsbutalsoachievebetteroverallperformanceonoriginal\ntraining datasets.\nCCS Concepts\n•Security and privacy →Privacy protections ;•Computing\nmethodologies →Heuristicfunctionconstruction ;•Human-\ncentered computing →Mobile devices.\nKeywords\nvoice assistants, fuzzy words, interpretable machine learning, secu-\nrity\nACM Reference Format:\nYanjiao Chen, Yijie Bai, Richard Mitev, Kaibo Wang, Ahmad-Reza Sadeghi,\nand Wenyuan Xu. 2021. FakeWake : Understanding and Mitigating Fake\nWake-upWordsofVoiceAssistants.In Proceedingsofthe2021ACMSIGSAC\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\nand/or a fee. Request permissions from permissions@acm.org.\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3485365Conference on Computer and Communications Security (CCS ’21), November\n15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA,\n23 pages. https://doi.org/10.1145/3460120.3485365\n1 Introduction\nVoice assistants are popular interfaces embedded in smart Inter-\nnet of Things (IoT) devices (e.g., smart speakers), which enable us\nto use voice commands to execute various operations, e.g., send\nmessages,makecalls,andevencontrol(e.g.,openthedoor)their\nIoT ecosystem (e.g., smart home appliances). Despite the recession\nunder the influence of COVID-19, the global smart speaker market\nis expected to grow by 21% in 2021 [ 5]. With the omnipresence\nofvoiceassistantsinthenearfuture,thepotentialthreatstouser\nprivacy and security regarding misconduct of voice assistants have\nto be addressed.\nAlmostallvoiceassistantsadoptthewake-upmechanism.Before\nbeing triggered for receiving voice commands, voice assistants\nactively listen to the surrounding environment for wake-up words,\nwhichareusuallyshortandcatchywordschosenbymanufacturers\ntobrandtheirproducts1.Oncethelightweightlocaldetectionmodel\nbelieves that it has detected a wake-up word, the voice assistant\nwill record and send audio to the cloud for further analysis.\nUnfortunately, voice assistants suffer from the FakeWake phe-\nnomena, whereby they can be wrongly activated by words that\nare not wake-up words. We define the words that are not wake-up\nwordsbutinducethe FakeWake phenomenaas fuzzywords,andthe\nones that do not activate voice assistants as non-fuzzy words. The\nFakeWake phenomenaisfairlyprevalent:Recentsurveysshowthat\n50%ofuserswaketheirvoiceassistantsupbymistakeonceaweek\nand28.5%ofthemevenexperiencedailyaccidentalwake-up[ 11,39].\nAsshowninFigure1,the FakeWake phenomenacanbeincurred\nby sources such as human conversation, TV shows [ 13,37], and\nTTS-spoken texts [ 29,37]. TheFakeWake phenomena pose privacy\nand security risks, e.g., uploading audio with sensitive information\nto the cloud or accepting malicious commands without be noticing.\nThe Amazon Echo has been reported to be activated mistakenly\nandsenttherecordedprivateconversationoffamilymembersto\nvariousrandomcontacts[ 10].Prioreffortshavefoundseveralfuzzy\nwords [13,29,37]withoutunderstandingwhyandhowtodefend\nagainstthem.Thus,inthispaper,weaimtosystematicstudythe\nroot causes and mitigation of the FakeWake problems.\n1A few voice assistants, e.g., Xiaomi, allow users to customize their own wake-up\nwords,whichmayevenaggravatethe FakeWake phenomenaifuserschooseconvenient\nbut commonly-used words.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1861\nFigure 1: An illustration of the FakeWake phenomena. Var-\nious sources from the attacker-generated audios, TV shows\nandprivateconversationsmayincurthe FakeWake phenom-\nena, and result in privacy leakage and security threats.\nParticularly, we focus on studying the FakeWake phenomena,\naiming to answer the following questions.\n•Howtoefficientlygeneratealargecollectionoffuzzywordsfora\ngiven voice assistant?\n•What are the causes that lead to false acceptance of fuzzy words\nby wake-up detectors?\n•How to strengthen wake-up detectors of voice assistants to be re-\nsilient against fuzzy words?\nGenerating . First of all, we target at generating large quan-\ntities of fuzzy words for a given voice assistants in an efficient\nmanner, which provides the samples for analyzing the causes oftheFakeWake phenomena and to strengthen the wake-up word\ndetector.Anaivesolutionistocontinuouslyplayaudiomaterials\nand record whether the smart speakers are activated or not, which\ntakes days or even weeks to find a few dozens of mis-activation\nincidents[ 13,29,37],andinmanycases,thetriggersarethereal\nwake-up words themselves articulated inaudio materials. For the\nsake of security, we are interested in fuzzy words that are not only\nable to activate the voice assistant but also sound dissimilar to the\nreal wake-up word to avoid being detected by users. The task is\nmadechallengingbecausecommodityvoiceassistantsaretypically\nblack-box and we have little information of the AI-based wake-\nupworddetectionmodel.Toaddressthischallenge,wecarefully\ndesign a framework for fuzzy word generation, which mutatesthe best candidates for fuzzy words to quickly create new fuzzy\nwordsthroughmultipleevolutionarygenerations,andbalancesthe\nwake-up rate and the dissimilarity distance.\nAdditionally, we investigate voice assistants for both English\nand Chinese, which have the most speakers worldwide [ 20]. To\ncustomizethegenerationframeworkforEnglishandChinese,we\nneed to encode the English and Chinese words into vectors and\nquantifythedissimilaritydistancebetweentwoEnglishorChinese\nwords.Nonetheless,thewordcompositionandpronunciationrules\nof English and Chinese are different, making it difficult to applythe same encoding system and dissimilarity measurement to thetwo languages. After carefully investigating the word structure\nandpronunciationpatternsofEnglishandChinese,wetailorthe\ngeneration framework to cater to the linguistic features of the two\nlanguages respectively.For 8 popular English and Chinese smart speakers, i.e., Amazon\nEcho,EchoDot,GoogleAssistant,AppleSiri,Baidu,Xiaomi,Ali-\nGenie, and Tencent, we manage to generate a total of 965 fuzzy\nwordswithin4hours,whilepreviouseffortfoundmerely194fuzzy\nwords in 13 days [ 37]. In particular, we have generated 577 Chi-\nnese fuzzy words, 30 times as many as the Chinese fuzzy words\nfoundin[ 37].Bygeneratingmorefuzzywords,ourmethodsgreatly\nincrease the attack success probability, which poses a real threat\ntothesecurityandprivacyofsmartspeakers.Moreover,therich\ncorpus of generated fuzzy words deepens our understanding ofthese words and therefore provides the training data needed for\nourmitigationapproach.Thesubjectivetestswithhumanvolun-\nteers verify that the generated fuzzy words sound far from the real\nwake-up words, which means that these fuzzy words may be used\nto wrongly activate voice assistants in a more surreptitious way.\nUnderstanding . Given the generated fuzzy words, we target\nat revealing why wake-up word detectors wrongly accept thesefuzzy words. Under the black-box settings, explaining the Fake-\nWakephenomena is challenging since we have no knowledge of\ntheinternalstructureandparametersofwake-upworddetectors,\nthusunabletogaugethecauseof FakeWake atthemodellevel.A\npossiblewayofexplanationistomeasuretheLevenshteindistance\nbetweenfuzzywordsandtherealwake-upwords[ 37].However,\nexperimentsshowthatourgeneratedfuzzywordshavesimilarLev-\nenshteindistanceasnon-fuzzywordstotherealwake-upwords.\nTo address this problem, we develop a more sophisticated explana-\ntion framework. To start with, we train an interpretable tree-based\nbinary classifier to distinguish fuzzy words from non-fuzzy words,\nbasedonwhichwededuce adissimilarityscorethatcanwellsep-\narate fuzzy words and non-fuzzy words. Then, we pinpoint the\nfeaturesthatcontributethemosttothefalseacceptanceoffuzzy\nwords based on the SHAP value [ 27]. It is demonstrated that the\ndecisive factors usually concentrate on a small snippet of the word,e.g.,ksinAlexaand aiinXiaomi(thewake-upwordisxi\nˇaoàitóng\nxué, i.e.,小爱同学). We show that a wake-up word detector that\nconcentrates on fewer decisive factors will have more fuzzy words.\nKnowing the decisive factors that lead to false acceptance of\nfuzzy words is helpful in two aspects. On the one hand, we can\nquickly construct fuzzy words by keeping the decisive factors and\nalter the other parts of the words. On the other hand, wake-up\nworddetectorsmaybestrengthenedagainstfuzzywordsbypaying\nspecial attention to the decisive factors.\nMitigating . After understanding the causes of false acceptance\noffuzzywords,wecanleveragethefindingstohelpdefendagainst\ntheFakeWake phenomena, which is an unexplored territory, possi-\nbly due to a lack of access to commercial models. In regard to this,\nwe propose two potential remedies. The first approach is to screen\ninput audios for decisive factors, e.g., ks. If there is no decisive\nfactor, the audio is fed into the lightweight wake-up word detector\nfor decision-making; otherwise, the audio will be scrutinized by\nmore complicated speech recognition models. The second method\nis to strengthen wake-up word detectors by retraining with the\ngeneratedfuzzywords.Asthewake-upworddetectorsoncommer-\ncialvoiceassistantsareunavailable,weresorttotheopen-source\nGRUrecurrentnetworkmodelPrecise[ 19].Surprisingly,ourex-\nperiments onfive wake-upword detectorsof \"Alexa\",\"Computer\",\n\"Athena\",\"HiXiaowen\"and\"HiMia\"showthatthestrengthened\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1862\u0006\u0015\u0012\u001a\u0012\n\u0013\u0012\u001e\n\u001a\u0012\u0016\u0015\u0002 \u0004\u001c\n\u0013\u001b\n\u001a\u0012\u0016\u0015\u0003 \t\n\u0018\u0012\n\u001a\u0012\u0016\u0015\u0004\u001a\f\u0010\u000e\u0002\u0019\u0015\u0001\u001a\u0014\u0016\r\n\u0017\u000f\u0012\u000f\u0011\f\u0016\u0001\u001a\u0014\u0016\r\u0017\n\u0016\f\u0013\r\u0014\u0012\u0001\u001a\u0014\u0016\r\u0017\n\u0001\t\u0006\f\u0004\n\u0002\t\u0006\f\u0004\r\n\u0003\u0005\u0007\u0004\u000b\b\r\b\n\u0012\u0012\n\r\n\f\u0007\u0011\n\u0013\u0017\u0016\u0007\u000b\t\u0002\u0014\u0010\u0001\u0011\u0007\u0013\t\u0006\u0007\u0011\t\u0013\u000f\u0001\u0004\u0011\u000f\u000e\u0013\n\t\u0011\u0001\n\u0001\u0001\u0005\u0004\u0007\u0004\u0006\n\u0002\u0005\u0004\u0007\u0003 \u0001\u0001\n\u0001 \u0001\u0003\u0011\u000f\u0012\u0012\u000f\u0015\t\u0011\n\u0005\u0014\u0013\u0007\u0013\n\u000f\u000e\u0001\t\u0006\f\u0006\n\u0002\t\u0006\f\u0004\u0002\t\u0006\f\u0004\n\u0001\t\u0006\f\u0006\n\u0001\t\u0006\f\u0006\n \u0001\t\u0007\f\u0006\n\u0002\u0006\n\u0006\u000b\u0004\r\t\n\b\n\u0006\u0015\u001a\u000e\u0018\u0017\u0018\u000e\u001a\n\u000b\u0013\u000e\u0001\u0014\u0016\r\u000e\u0013\u0002 \u0005\u000e\n\u001a\u001b\u0018\u000e\u0001\f\u0016\u0015\u001a\u0018\u0012\u000b\u001b\u001a\u0012\u0016\u0015\u0003 \u0003\u000e\f\u0012\u0019\u0012\u001c\u000e\u0001\u000f\n\f\u001a\u0016\u0018\u0019\u0004\u0003\n\u0005\u0006\u000b\f\r\u0004\n\u0005\t\n\b\n\u0013\u000e\u0019\u0016\f\u0011\u0001\u0013\u000e\u0018\u001a\u0014\u0016\u0010 \u0018\u0016\u000e\u000e\u0001\u0012\u0014\r\u000e\u0011\u0017 \u0005\u0007\u0003\u0006\t\u0001\n\u0004\u0003\u0004 \u0004\u0003\u0007 \u0004\u0003\u0005 \u0006\u0003\t \u0006\u0003\b \u0006\u0003\t\b\u0006\u0005\u0007\u0001\r\t\u000b\f\n\u0001\u0006\u0007\u0006\n\u0005\t\n\b\u0005\u0007\u0003\u0006\t\u0001\n\u0004\u0007\u0003\b\t\u0001\n\u0001\u0007\u0003\b\u0002\u0005\n\u0002\u0016\u0015\u001c\u000e\u0015\u001a\u0012\u0016\u0015\n\u0013\n\r\n\u001a\n\u0019\u000e\u001a\n \u0005\u001b\u001e\u001e\u001d\u0001\r\n\u001a\n\u0019\u000e\u001a\u0007\u0018\u0012\u0010\u0012\u0015\n\u0013\u0001\u0014\u0016\r\u000e\u0013\n\b\u001a\u0018\u000e\u0015\u0010\u001a\u0011\u000e\u0015\u000e\r\u0001\u0014\u0016\r\u000e\u0013\n\u0002\u0005\u0001\n\t\u0004\u0007\b\u0007\b\u0006\u0003\t\u0004\u0007\b\u0007\b\u0006\u000b\u0013\u000f\u0018\u000f\f\u0011\u0015\u0014\u0015\u0019\u0011\f\u0018\u000f\u0014\u0013\nFigure 2: A systematic study on the FakeWake phenomena.\nWegeneratelargequantitiesoffuzzywordsforbothEnglish\nand Chinese smart speakers, and then analyze these fuzzy\nwordstounveilthecausesoftheirfalseacceptancebywake-\nup word detectors, based on which we propose remedies to\nmitigate the FakeWake phenomena.\nmodels not only reject more than 97% of the fuzzy words, but also\nbecome better at distinguishing non-fuzzy words. The possible rea-\nson is that the fuzzy words are near the decision boundaries of\nwake-up word detectors, which helps the detectors to learn the\ndecision boundaries in a more efficient and more precise way. The\nmain flow of our paper is summarized in Figure 2.\nIn summary, our main contributions are as follows.\n(1)Weproposeasystematicandautomaticgenerationframe-\nworkforproducingfuzzywordsandcustomizetheframe-\nwork for both English and Chinese voice assistants. We con-\nduct extensive evaluations on eight most popular Englishand Chinese smart speakers, and find a total of 965 fuzzy\nwords. Thesheervolumeofourgeneratedfuzzywordsre-\nvealsthe vulnerabilityof thewake-up word detectorsused\nby voice assistants. In addition, the rich corpus of generated\nfuzzywordsenablesustoconductin-depthanalysistoun-\nderstand the fuzzy words and provide the data needed for\nmitigating the FakeWake phenomena.\n(2)Webuildanexplanationframeworkforthe FakeWake phe-\nnomena, which locates the decisive factors that lead to false\nacceptance of fuzzy words.\n(3)Wepresentcountermeasurestostrengthenwake-upword\ndetectors against fuzzy words, which improve the overall\nperformance of wake-up word detectors.\nCurrently,manufacturerschoosewake-upwordswithmorecon-\ncerns on commercial interests than on security. With our effort on\ndissecting the FakeWake problem, we hope to raise the attention\non potential risks of wake-up words and motivate future works on\nimproving the security of wake-up words and the robustness of\nwake-up word detectors.2 Background\n2.1 Voice Assistant\nAlmostallpopularsmartspeakersandmostsmartphonesareequipped\nwith embedded voice assistants, e.g.,Amazon Echo, Apple Siri, and\nGoogle Home. To reduce power consumption and protect user pri-\nvacy,nearlyeveryvoiceassistantusesawake-upmechanism,i.e.,\nno uploading recorded audios to the cloud until the wake-up word\nisdetected.Thewake-upword(s)foravoiceassistantareusually\nunique or limited to a pre-registered set of words. For instance,\nAmazon Echo uses \"Alexa\" as its wake-up word and Google Home\ncan be woken up by either \"OK Google\" or \"Hey Google\". Some\nChinese voice assistants use their brand names as the wake-up\nwords, e.g., \"ti ¯an m¯ao j¯ıng líng\" for AliGenie (named 天猫精灵)\nand \"xiˇao dù xiˇao dù\" for Baidu smart speakers (named 小度).\nIt is known that voice assistants can be mistakenly woken up\nbyfuzzywordsotherthantheauthenticwake-upwords[ 11,39],\nwhich raises security and privacy concerns. If such fuzzy words\noccur inadvertently in conversations or if malicious attackers play\ninnocent-soundingaudiofilescontainingfuzzywords,smartspeak-\nersmaybeactivatedbymistakeandtransmittherecordedvoiceafterwards to the cloud or to specific contacts (e.g., the attacker).\nTo make matters worse, attackers may issue malicious commands\nto the activated voice assistants, e.g., open the door or turn off the\nalarm system, which poses great threat to user safety. Therefore,\ntoprotectvoiceassistantsfrombeingwronglyactivatedbyfuzzy\nwords is of great importance.\n2.2 Wake-up Word Detection\nWake-up word detection is essential to voice assistants. During\nthestandbymode,voiceassistantslistentotheenvironmentand\nrecord snippets of audio samples (e.g., 3s) to check the presence\nof wake-up words. A voice-activity detection module confirms the\npresenceofvoice,andthenextractfeatures,e.g.,themel-frequency\ncepstrumcoefficients(MFCC),tofeedintodetectionmodels(e.g.,\nGMM, HMM, DNN) to determine theexistence of wake-up words.\nFormostvoiceassistants,thereisalightweightlocaldetectormodel\ndeployedonthesmartdevicesandamorecomplicatedmodelde-\nployed on the cloud. Only the audio samples that are believed to\ncontainwake-upwordsbythelocalmodelwillbesenttotheremote\nmodel for further examination. Different fromspeec hrecognition\nmodels,wake-upworddetectorsarekeyword-spottingmodelsthat\nonly focus on differentiating a specific keyword from all other\nwords rather than translating the texts for any audio content. The\noutput of wake-up word detectors (accept or reject) is only known\nto the manufacturer but will not be fed back to the users.\n2.3 Threat Model\nConsidering searching for fuzzy words for commercial voice assis-\ntants, we make the following assumptions.\nNo access to the wake-up word detection model (black-\nbox). The attacker has no knowledge of the detection model, in-\ncluding model structure, parameters and hyperparameters2. The\n2Reverse-engineeringthewake-upworddetector,e.g.,usingmodelextractionmethods,\nispossible.However,mostrecentmodelextractionmethodsachieveonlyabout70%\nagreement rate between the substitute model and commercial APIs [45].\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1863output labels and confidence scores of the wake-up word detec-\ntorareunavailable.Theattackercanonlyinteractwiththevoice\nassistantandobservewhetheritisactivatedornot,e.g.,LEDon/off.\nNo access to the training dataset . The training datasets of\nwake-upworddetectorsareprivatelycollectedbymanufacturers\nwith regard to the unique wake-up word of their products. The\nattackerhasnoaccesstothetrainingdataset,thuscannotobtain\nthe exact wake-up word detection model or infer any deficiency of\nthe training process.\nAttacker’s ability . We assume that the attacker can acquire\nsmartdevices(e.g.,smartspeakers,smartphones)equippedwiththe\ntargeted voice assistant. The attacker can query the smart devices\nfor unlimited times, and indicate whether the voice assistant is\nactivatedornot.Theattackerhasspeakerstoplaythegenerated\nfuzzy word candidates. Ultimately, the goal of the attacker is to\ninsert the generated fuzzy words into innocent-sounding music or\nvideo clips to activate the voice assistant without users noticing,\nthentoissuehiddencommandstoconductmaliciousoperations,\ne.g., upload private conversations to the cloud or open the door.\n3 Generating Fuzzy Words\n3.1 Framework Overview\nIn the strict black-box settings, no information about the wake-up\nword detector is available, thus gradient-based optimization meth-\nodscannotbeusedtogeneratefuzzywords.Therefore,weresort\ntoheuristicalgorithms,whichstochasticallysearchforsolutions\nwithoutthegradientinformation.Amongcommonly-usedheuris-\ntic algorithms,genetic algorithm isthe mostsuitable one tosolve\nthe problem of fuzzy word generation. Simulated annealing suffers\nfrom slow convergence, and it is difficult to apply ant colony opti-\nmization(ACO)orparticleswarmoptimization(PSO)togenerate\nfuzzy words, since ACO deals with problems that can be converted\nintoshortestpathfindingproblemsonagraph,whilePSOrequires\nthe position information in order to move a group of particles in\nasearch-spacetowardstheoptimalsolutions.Geneticalgorithms\ntreat each candidate solution as an individual that contains sev-eral chromosomes, and these chromosomes can be mutated and\ncrossed-overtoevolveintonewindividuals.Forexample,wecanregard\"alexa\"asanindividualconsistingofchromosomes\"a\",\"l\",\n\"e\", \"x\" and \"a\". If we mutate the chromosome \"a\" to \"i\", we get a\nnewindividual\"alexi\",andifwecross\"alexa\"with\"olive\"at\"e\"and\n\"i\", we obtain two new individuals \"alive\" and \"olexa\".\nThekeytoutilizinggeneticalgorithmtogeneratefuzzywordsis\nhowtocreateadiversifiedinitialbatchofwordsthatcanefficiently\nevolve into fuzzy words and how to measure whether a word is\n\"good\" in terms of its ability to activate the voice assistants and its\ndissimilaritytotherealwake-upword.Totackletheseproblems,\nwe design the fuzzy word generation framework as follows.\n(1)Initialization. Toachievebothdiversityandfastconvergence,\nweincludethreegroupsofindividualsintheinitialbatch:the\nreal wake-up word itself, words that are similar to the wake-\nupword(measurementofsimilaritywillbegivenin3.2),and\nrandomly-generatedwords.Notethatwehavetriedtoadopt\nan entirely random initial population, but found that most ran-\ndomwordsarenon-fuzzywords,and willbekilledinthefirst\ngeneration, leaving few to breed useful offspring.(2)Evaluation. If we only evaluate an individual in terms of its\nwake-up rate, the algorithm will end up producing individuals\nthatarealmostidenticaltothewake-upwordtoachievehigh\nwake-up rate. To prevent this, we formulate the fuzzy word\ngeneration as a multi-objective optimization problem, which\naims to find fuzzy words that have both high wake-up rate and\nhighdissimilaritydistancefromtherealwake-upword.Insteadofsimplyusingweightedsumtocombinethetwoobjectives,weleveragetheconceptofParetofrontiertoselectnon-dominated\nindividuals [ 12], which preserves as many words as possible to\nimprove diversity of the next generation of descendants. Werank individuals in a non-increasing order according to their\nwake-up rate and dissimilarity distance respectively, and non-\ndominated individuals are maintained for reproduction. Anindividual\n𝑥1is dominated by 𝑥2if for all objective functions\n𝑓𝑖(𝑥),𝑖=1,...,𝑁, we have\n𝑓𝑖(𝑥1)≤𝑓𝑖(𝑥2),∀𝑖=1,...,𝑁 (1)\nIf there is no individual dominating 𝑥𝑖,𝑥𝑖is said to be non-\ndominated.Inourproblem,awordisnon-dominatedifthere\nis no other word that has both higher wake-up rate and larger\ndissimilarity distance than the word.\n(3)Variation . A new population is created by varying the sur-\nvived individuals to maintain important pronunciation units\nandadjustother pronunciationunitstofindmore fuzzyword\ncandidates in the problem space. Commonly-used variation\nmethods include crossover, recombination and mutation.\nTo customize the generation framework to different languages,\nthere are two aspects that require specific design. First, we need to\nencodewordsbydeterminingthenumberofvariablesrepresentingeachwordandtherangeofeachvariable,thusanindividualcanbe\neasily evaluated and transformed into a new individual that repre-\nsents a valid word. For instance, how to encode \"Alexa\" or \"xi ˇao dù\nxiˇao dù\" so that we can perform mutation or cross-over operations\nto generate new individuals that represent valid English or Chi-\nnese words? Secondly, we need to define the dissimilarity distance\nbetween two individuals. It is difficult to obtain the dissimilarity\ndistance directly from the encoding, since the encoded vectors con-\nsist of numbers that do not carry the pronunciation information of\nthe English or Chinese words. For example, \"a\", \"e\" and \"f\" may be\nencoded as \"1\", \"5\", and \"6\" respectively in the alphabetic order, but\nthe dissimilarity distancebetween\"e\" and\"a\" are obviouslysmaller\nthan that between \"e\" and \"f\".\nEnglish and Chinese voice assistants cover more than 85% of\ntheglobalmarket[ 4].Inparticular,Chinesesmartspeakershave\noccupied more than 51% market share in 2019 [ 34], but Chinese\nfuzzywordsislesswellstudied.MandarinChineseandEnglishare\ndifferent as they belong to different language families. Chinese be-\nlongstotheSino-Tibetanlanguagefamily,whileEnglishbelongstotheIndo-Europeanlanguagefamily.UnlikeEnglish,Chinesewords\nare not made up with letters as in an alphabetic system, and the\npronunciationofChinesewordscannotbeinferreddirectlyfrom\ntheChinesecharactersasChineseisnotaphoneticlanguage.More-\nover, Chineseand Englishvary greatlyin pronunciation.Chineseisatonelanguagewithfourdifferenttones,andpronouncingthe\nsamesyllableindifferenttonesindeedleadtodifferentmeanings.\nIncontrast,Englishusesstress(risingorfallingtones)toemphasize\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1864orexpress emotions,withoutchanging themeaningof aword.In\nsummary,ChineseandEnglishhavedifferentwordformations,pro-\nnunciationunitsandpronunciationrules,andweneedtocustomize\nthe generation framework for the two languages in appropriate\nways.Inthefollowingsubsection,wefirstpresentthedesignfor\ntheChineselanguage,whichislesswellstudied,thenwepresent\nthe design for the English language.\n3.2 Generating Chinese Fuzzy Words\nAChinesewordismadeupofChinesecharacters,alsoknownas\nsinogram or \"hanzi\". Chinese characters are very different from\nEnglishletters.EachChinesecharacterisboththesmallestmean-\ning unit and the smallest pronunciation unit. The pronunciation of\na Chinese character is represented by pinyin. The pinyin of a char-\nacterconsistsofinitials(e.g.,x),finals(e.g.,aioriao)alsoknown\nas vowels, and a tone. The pronunciation of a Chinese characteris determined by its initial, final and tone. The pronunciation ofa Chinese word is the combination of the pronunciation of each\ncharacter.Thereisatmostoneinitialinthepinyinofacharacter.\nSome characters do not have an initial, e.g., ài ( 爱). There are 23\ninitialsintotal[ 17,44].Thereareonetotwofinalsinthepinyinofa\ncharacter.Somefinalscanbecombinedtogether,e.g.,iandaoformiao,butsomefinalscannot,e.g.,iandou.Byconsideringvalidfinal\ncombinations asspecial finals,we have atotal of37 finals [ 17,44].\nTherearefourtonesinChinese,denotedbyadiacriticalmarkon\nthefinals,i.e., ¯a,á,ˇa,àfortone1 ,2,3,4respectively.Thesameinitial-\nfinalcombinationwithdifferenttoneshavedifferentmeanings,e.g.,\nxiˇao(小)andxiào( 笑)mean\"small\"and\"laugh\"respectively.Some\ninitial-finalcombinationsareinvalid(cannotbepronounced),e.g.,\nxang, no matter what the tone is. Some initial-final-tone combina-\ntions have nocorresponding Chinese characters, e.g., j ¯ıng (精)i s\nvalidbutthereisnoChinesecharacterthatpronouncesasjíng(the\nsecondtone).Suchinvalidcombinationsneedtobeculledduring\nthe evolution in the genetic algorithm.\nEncoding . Since the pinyin of a Chinese character normally\ncomprisesoftheinitial,thefinalandthetone,weusethreevariables\nto encode a character. The range of each variable is the number\nofpossibleinitials/finals/tones,whichare24(23initialsandzero-\ninitial), 37 and 4 respectively. Without loss of generality, we use\nthelexicographicorderofinitials/finals/tones[ 44]asthevalueof\nthe variable. As far as we know, all Chinese wake-up words are\ncomposed of four characters. Hence, we encode each individual as\na 12-dimension vector.\nDissimilarity distance . We cannot use the difference between\nencodingsoftwowordstorepresenttheirdissimilarity,sincethe\nlexicographic order of initials/finals/tones does not reflect theirpronunciation resemblance, e.g., \"a\", \"o\" and \"an\" are encoded as\n1, 2 and 8 respectively, but \"a\" pronounces more closely to \"an\"\nthan to \"o\". To capture the phonetic similarity between initials\nandfinals,weleveragethehigh-dimensionalembedding[ 26].Let\n𝑊1=[𝑐(1)\n1,...,𝑐(𝑛)\n1]and𝑊2=[𝑐(1)\n2,...,𝑐(𝑛)\n2]denote two Chinese\nwords, where 𝑐(𝑖)is the𝑖-th character of a word. The dissimilarity\ndistance is calculated as dist(𝑊1,𝑊2)=/summationtext.1\n𝑖dist(𝑐(𝑖)\n1,𝑐(𝑖)\n2), where\ndist(𝑐(𝑖)\n1,𝑐(𝑖)\n2)isthedistancebetweentwocharactersatthesame\noffset.Thedistancecalculatedinthiswayincreaseswiththenumberofcharacters,thuswenormalizethedistanceto\n[0,1)usingtanh(·),acommonly-usedsigmoidalfunctionthatnormalizestheactivation\nof neural networks [25].\ndist(𝑊1,𝑊2)=1\n𝑛/summationdisplay.1\n𝑖tanh(dist(𝑐(𝑖)\n1,𝑐(𝑖)\n2)/𝐴).(2)\nThedistanceisdividedbyconstant 𝐴toattainamoreevenlydis-\ntribution. In our experiment, we set 𝐴=100.\n3.3 Generating English Fuzzy Words\nAn English word can be divided into graphemes (a letter or a letter\ncombination) which correspond to different pronunciation units,\ni.e., phonemes. It is worth noting that people can pronounce wordsthattheyhaveneverseen(e.g.,foreignnames)basedonexperience,\nandTexttoSpeech(TTS)enginescanpronounce\"non-dictionary\nwords\" [33], which increases the space of words for an attacker to\ngenerate fuzzy words.\nEncoding . There are two special challenges facing the design\nfor the English language. First, we need to decide whether to en-\ncode an English word based on its letter composition or phoneme\ncomposition. An intuitive thought is to encode an English word ac-\ncording to its phoneme composition. Nevertheless, we have found\nthat this is not applicable due to several reasons. Firstly, it is not al-\nwayspossibletoconvertacombinationofphonemesintoawordin\nletter, which makes it difficult to produce meaningful fuzzy words.\nSecondly,existingTTSservicescannotpronouncephonemecom-\nbinations as naturally as letter combinations. The pronunciation\nof phoneme combinations sounds mechanical and incoherent, and\ncannotevenwakeupthevoiceassistantsbysayingthephoneme\ncombinationsoftheirrealwake-upwords.Therefore,wechooseto\nencode English words according to their letter compositions.\nThe secondchallenge is that Englishwords have variedlength.\nAn English word can be as short as 1 letter and as long as 17-18\nletters.TwoEnglishwordswithdifferentlengthsmaysoundsimilar,\ne.g., loose and lose. Moreover, a combination of two English words\nmaysoundlikeoneEnglishword,e.g.,alotandallot.Amongthe\ntopthreeEnglishvoiceassistants[ 28],Amazonusesonewordas\nthe wake-up word, while Google and Apple use two. To address\nthisproblem,foravoiceassistantwithaspecificwake-upword,wefirst use one variable to represent one letter, and then insert spaces\n(\" \") between letters as a place holder to increase the overall length\nofanindividual.Thelengthofanindividualissetas 𝑟timesthat\noftheoriginalwake-upword(withalengthof 𝑛),where𝑟>1is\ngenerallysetto1.5.Inthisway,wenotonlyaddresstheproblem\nofencodingwake-upwordsthatarecomposedoftwowords,but\nalso increase the diversity of the generated fuzzy words. To sumup, we use an\n𝑟×𝑛-dimension vector to represent an individual,\nwhere each variable represents a letter or a space, and the variable\nvalue ranges from 1 to 27.\nDissimilarity distance . Similar to the Chinese language, the\nencoding of English words also does not carry pronunciation in-\nformation, thus we choose phonemes instead of letters to quantify\ndissimilaritydistance.Twosame-lengthEnglishwordsmayhave\ndifferent numbers of phonemes, e.g., animal and beauty. To tackle\nthis difficulty, we use Levenshtein distance between the phoneme\ncompositionoftwoEnglishwordstocalculatetheirdissimilarity\ndistance. Let 𝑊1=[𝑝(1)\n1,...𝑝(𝑚)\n1]and𝑊2=[𝑝(1)\n2,...𝑝(𝑛)\n2]denote\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1865Table 1: Generated fuzzy words for Chinese and English smart speakers.\nBaidu Xiaomi AliGenie Tencent Amazon Echo Echo Dot Google Apple Siri\nWake-up word xiˇao dù xiˇao dù xi ˇao ài tóng xué ti ¯an m¯ao j¯ıng líng ji ˇu sì èr líng Alexa Alexa Hey Google Hey Siri\nTotal number 63 108 322 84 127 130 79 52\nMean dissimilarity 5.35% 6.26% 2.37% 2.66% 15.28% 15.29% 11.98% 9.92%\nxiˇao lˇong xiˇao lˇong qi ˇao b¯ai d¯ong hè y ¯an m¯en j¯ıng líng ji ¯ong niào èr líng ilebser ureqssr heii googerl hey sserea\n20% 90% 50% 30% 70% 10% 60% 80%\npiˇao dòu pi ˇao dòu qi ¯ang b¯ai d¯ong sè y ¯an m¯ang j¯ıng líng j ˇın sì ào líng ileqsur arleqsr heiigoogaa heai ssuree\n10% 100% 100% 10% 60% 100% 30% 50%\ntiˇao d¯ou tiˇao d¯ou qiào b ¯ai t¯ou shè wán m ¯ang j¯ıng líng ji ¯ong sì èr lián ileqcer ilekcer heay gugal hay scir e\n60% 90% 40% 10% 90% 100% 100% 60%\ntiˇao dòng ti ˇao dòng qi ¯ao c¯ai d¯ong sè wáng mào j ˇıng lˇın jiˇong shì èr lián ilekcer ilexcer hey gooogov a haiiasciree\n20% 100% 10% 20% 70% 10% 100% 60%\nTop-ten examples sh¯ao d¯ou sh¯ao d¯ou xi ¯ao c¯ai d¯ong sè yán m ¯ao j¯ıng lˇıng ji ˇong sì èr lián ileqsar ilexsur heii googurl heyisyree\nwake-up rate 20% 100% 90% 100% 100% 100% 70% 20%\njiˇao d¯ou jiˇao d¯ou qi ¯ao¯ed¯us è y ¯an m¯ao j¯ıng líng ji ˇong sì è rliáng ilexsar ileqsar heii gugurl heii sirea\n40% 100% 100% 30% 100% 100% 60% 70%\nqiáo d¯ou qiáo d ¯ou qi ¯ao¯ai d¯us è w ¯an m¯ao j¯ıng líng ji ˇong zì èr liáo ilexsur ileksar hea gougll haiy cire\n30% 100% 90% 90% 100% 100% 50% 80%\nqiˇao d¯ou qiˇao d¯ou qiàng ¯ai d¯ong sàng yán m ¯ao j¯ıng líng ji ¯ong sì èr mín ileksur ileksur hei googll a hey sirr e\n50% 100% 90% 10% 80% 100% 100% 100%\nqiˇao dòng qi ˇao dòng qiàng ¯ai ch¯ou lè wán m ¯ao j¯ıng líng ji ˇong sì èr mín alexoer alekcir hei gooo r hei suru r a\n20% 100% 20% 30% 60% 70% 20% 70%\nxi¯ao d¯ou xi¯ao d¯ou qi ˇao¯adˇong sà wáng m ¯ao j¯ıng líng ji ˇong sì er li ¯ao ilexcer ileqser heiy googow l hay syrrie e\n50% 100% 10% 30% 100% 100% 50% 100%\n(a) Baidu: Volume (b) Baidu:Speed (c) Baidu: Noise\n(d) Alibaba: Volume (e) Alibaba:Speed (f) Alibaba: Noise\nFigure 3: Wake-up rate of fuzzy words under different environments for Chinese voice assistants.\ntwo English words, where 𝑝(𝑖)is the𝑖-th phoneme of a word. The\nconventionalLevenshteindistance[ 31]assumesthatthedistance\nbetweenanypairofdifferentphonemesis1,whilesomephonemes\nsound similarand somephonemes soundfar apart.Therefore, we\nintegratephoneticdissimilarityofphonemes[ 30]intotheLeven-\nshtein distance to quantify the dissimilarity distance between two\nwords. Let dist(𝑝(𝑖),𝑝(𝑗))∈[0,1]denote thedissimilarity of two\nphonemes. We have\ndist(𝑊1,𝑊2)=𝐷+𝐼+2/summationtext.1\n(𝑖,𝑗)∈Sdis(𝑝(𝑖)\n1,𝑝(𝑗)\n2)\n𝑚+𝑛,(3)\nwhere𝐷and𝐼denote the number of deletions and insertions re-\nspectively, Sis the set of substitutions which replaces phoneme\n𝑝(𝑖)\n1with𝑝(𝑗)\n2,and𝑚and𝑛arethelengthof 𝑊1and𝑊2respectively.\nThe dissimilarity between space and any phoneme is set as 1.3.4 Experiment Results\nWe conduct experiments to answer the following questions:\n•(Q1)How does our proposed generation framework perform in\nproducingfuzzywordsfordifferentChineseandEnglishsmart\nspeakers?\n•(Q2)Howdoenvironmentalfactorsinfluencetherobustnessof\nthe generated fuzzy words?\n•(Q3)Dothegeneratedfuzzywordssounddifferentfromthereal\nwake-up words from the human perspective?\n•(Q4)How do the generated fuzzy words perform when articu-\nlated by real human individuals with different accents?\n•(Q5)How do the generated fuzzy words perform when inserted\nin conversations?\nWe will answer these questions after presenting the experiment\nsettings.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1866(a) Amazon Echo: Volume (b) Amazon Echo:Speed (c) Amazon Echo: Noise\n(d) Google: Volume (e) Google:Speed (f) Google: Noise\nFigure 4: Wake-up rate of fuzzy words under different environments for English voice assistants.\nEvaluated voice assistants . For English voice assistants, we\nconduct experiments on Amazon Echo, Amazon Echo Dot, Google\nNestMiniandAppleHomePod.AmazonEchoandAmazonEcho\nDot can be woken up by \"Alexa\", \"Amazon\", \"Echo\" or \"Computer\",\nand we focus on generating fuzzy words of \"Alexa\". Google Nest\nMini can be woken up by \"Hey Google\" or \"Ok Google\", and we\nfocusongeneratingfuzzywordsof\"HeyGoogle\".AppleHomePod’s\nwake-up word is \"Hey Siri\", the same as iPhone and iPad.\nFor Chinese voice assistants, we conduct experiments on Baidu,\nXiaomi,AliGenie,andTencent.Baidusmartspeakerscanbewoken\nupby\"xi ˇaodùxiˇaodù\"(小度小度),arepetitionofthenickname\nofBaidu( 百度).Xiaomismartspeakerscanbetriggeredby\"xi ˇao\nài tóng xué\" ( 小爱同学), the Chinese name of Xiaomi’s virtual\nassistant.AliGenie,alsoknownasTmallGenie,canbewokenup\nby\"ti¯anm¯aoj¯ınglíng\"( 天猫精灵 ),theChinesenameforthesmart\nspeaker.AliGeniecanalsobewokenupby\"n ˇıhˇaoti¯anm¯ao\"(你\n好天猫),where\"n ˇıhˇao\"means\"hello\"inChinese.Tencentsmart\nspeakers can be activated by \"ji ˇu sì èr líng\" ( 九四二零), which\nsounds similar to \"I just love you\" (就是爱你) in Chinese.\nExperiment setup . As shown in Figure 10, our experiment\nsetup consists of a laptop, a Raspberry Pi, a stereo and a light\nsensor. The laptop runs the generation algorithm to produce fuzzy\nwords,andthestereoplaystheaudioofeachgeneratedfuzzyword\nto test its wake-up rate. The Raspberry Pi is equipped with a light\nsensor to detect whether the smart speaker is activated or not. The\nRaspberry Pi returns the wake-up rate of the fuzzy words to the\ngeneration algorithm to evaluate their fitness.\nOur experiments are carried out in a quiet laboratory room. We\nemploy pyttsx3 to generate the audio samples of fuzzy words byusing TTS, which can articulate non-dictionary words [\n33]. The\ndistance between the stereo and the tested smart speaker is 20\ncentimeters.Weplaytheaudiosampleswiththedefaultmalevoice\nat a moderate volume. The play s peed is set to 150 in pyttsx3 by\ndefault, which approximates the av erage speed of human speakers.\nEachwordisplayed10timesforwake-upratecomputation.The\ncrossover rate and the the mutation rate selected for the genetic\nalgorithms are 1 and 0.1 respectively.\nPerformanceofgenerationframework(Q1) .Wedisplaythe\nresults of fuzzy word generation in Table 1. A full list of generated\nfuzzy words is in Section A.12. Note that we consider the fuzzywords generated by the genetic algorithm as out of distribution,\nsincesubjectivetestsshowthatusersperceivethefuzzywordsas\ndifferentfromtherealwake-upword.Furthermore,weleveragethe\ngeneratedfuzzywordstostrengthenthewake-upworddetector,\nwhichimprovesitsperformanceregardingbothfuzzywordsand\nnon-fuzzy words.\nFor Chinesevoice assistants, Baiduhas the fewestfuzzy words\nwhile AliGenie has the most fuzzy words. This indicates that repe-\ntition in xi ˇao dù xiˇao dù may indeed mitigate the FakeWake phe-\nnomena. Tencent also has a small number of fuzzy words since the\nwake-upwordji ˇusìèrlíngcontainsrichcombinationsofinitials,\nfinalsandtones.AliGeniehasasignificantlylargernumberoffuzzy\nwordssinceitswake-upworddetectorreliesheavilyon iantodetect\nthe wake-up word, which we will explain in Section 4. For English\nvoice assistants, longer wake-up words, e.g., Hey Google and Hey\nSiri, have fewer fuzzy words. Also, Siri is a less commonly-used\nwordwithdistinctivepronunciation,makingitmoredifficulttopro-\nduce itsfuzzy words. Intotal, we have generated 965fuzzy words,\nwhich not only reveals the severity of the FakeWake phenomena in\nvoiceassistants,butalsolaysthefoundationforunderstandingand\nmitigatingthe FakeWake phenomena.Byretrainingthewake-up\nword detector using the generated fuzzy words, it can distinguish\nbetweenfuzzywordsandtherealwake-upwordsmoreprecisely\n(c.f. Section 5). We show the wake-up rate distribution of fuzzy\nwords for different voice assistants in Figure 11 in the Appendix.\nEnvironmentalimpactonfuzzywords(Q2) .Weinvestigate\nthe impact of volume, speed, noise level and speaker gender on the\nwake-uprateofgeneratedfuzzywords.Forvolume,wechangethe\nvolume to 1.6 and 2 times of the original volume. For speed, the\noriginalspeed parameteris150,andwechangeitto100(slower)\nand 200 (faster). For noise level, we add Gaussian noise to simulate\nenvironmentalnoises.TheparameteroftheGaussiannoiseissetto0.02and0.04.At0.02,thesignal-to-noiseratio(SNR)isaround40db\n(office, library), and at 0.04, the SNR is around 30db (soft music,\nwhisper) [ 15,23]. For speaker gender, the original audio samples\nusea malevoice, andwechange thevoiceto female.As theTTS\nweusedoes notsupportChinesefemalevoice,we testtheimpact\nof speaker gender only on English voice assistants.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1867Insight 1\nFuzzy words with high wake-up rate mostly maintain their\nwake-up rate when the environment changes.\nWe demonstratethe experiment results ofChinese and English\nvoice assistants in Figure 3 and Figure 4 respectively. Due to space\nlimitations we only show the results of four mainstream voice\nassistantsandputtherestoftheresultsinFigure13intheappendix.\n•Volume. With increased volume, the wake-up rate rises for most\nfuzzywordsofmostvoiceassistants.ButforBaiduandGoogle,\nthe wake-up rate decreases with a higher volume.\n•Speed.Speedhasamixe dinfluenceonthewake-uprate.Gener-\nally,asspeed increases, the wake-up rate first goes up then goes\ndown,especiallyfortheEnglishvoiceassistants,e.g.,Echoand\nApple Siri. This may be because a slightly faster speed boosts\ncoherenceoftheTTS,butasup erfastspeedmakesthespeech\nintelligible for the voice assistants.\n•Noise level. In general, noises degrade the wake-up rate. Butfor\nXiaomi,thewake-uprateforfuzzywordswithmediumwake-up\nrategrowsto ashigh as0.91 ata highnoise level.Similar trend\nis also observed in Google.\n•Speakergender.Afterchangingthespeakervoicefrommaletofe-\nmale,themeanwake-uprateforfuzzywordswithhighwake-upratedecreases,whilethemeanwake-uprateforfuzzywordswith\nmedium and low wake-up rate increases. Due to page limitation,\nthe results of the influence of speaker gender is in Section A.3.\nPerceptualdifferenceoffuzzywords(Q3) .Weconductasub-\njective test to investigate whether the generated fuzzy words with\nhighdissimilaritydistanceaccordingtothegenerationalgorithm\nindeedsounddifferentfromtherealwake-upwordstohumanears.\nWe have recruited 33 volunteers from our campus, including\n26 males and 7 females aged from 20 to 40. Among the 33 volun-teers, 18 people are native Chinese speakers, and 15 people are\nEnglishspeakers.TheChinesenativespeakerscomefromdifferent\nprovinces of China with different dialects, and they all had English\nasasecondlanguage.TheEnglishspeakersoriginatefromdifferent\ncountrieswithEnglishastheirfirst,secondorthirdlanguage.We\nprovidethevolunteerswithaudiorecordingsoftherealwake-up\nwords and the fuzzy words to enable the volunteers to evaluate the\ndissimilarity between the fuzzy words and the real wake-up words.\nAllvolunteershavegoodorverygoodexperienceofusingsmart\nspeakers.Beforetheuserstudy,wehavegiventhevolunteersintro-\nduction tothe FakeWake phenomenaand giventhem instructions\non the experiments.\nFor each evaluated smart speaker, we choose the top 20 fuzzy\nwordswiththelargestdissimilaritydistance.Weaskeachvolunteer\nto listen to the audio of each fuzzy word for 3 times and thenevaluate the dissimilarity between the fuzzy word and the real\nwake-upwordonascalefrom1(verysimilar)to5(verydissimilar).\nWe also ask each volunteer to score whether the fuzzy word is\ncommon in daily life on a scale from 1 (not common) to 5 (very\ncommon).Weshowtheresultsofthetop10fuzzywordsinFigure5\nand Figure 14, and the results of the remaining fuzzy words are in\nFigure 15.Insight 2\nFuzzywordswithlargeperceptualdifferencefromtherealwake-\nup words can wake up the voice assistants.\nAsshowninFigure5,formostvoiceassistants,thegenerated\nfuzzy words have an average perceptual difference of more than\n3.0.Specifically,thefuzzywordsforXiaomihavehighperceptual\ndifference (more than 4.0), while the fuzzy words for Echo have\nrelatively low perceptual difference(around 3.0). The fuzzy words\nwithhighperceptualdifferencetendtoberegardedaslesscommon\nin daily life. There is large variance for certain fuzzy words dueto individual differences in hearing experiences. The user study\nconfirmsthatthedissimilaritydistancemetricisabletoquantify\nthe perceptual differences between the fuzzy words and the real\nwake-upwords.Therefore,itisconfirmedthatfuzzywordswith\nlargedissimilaritydistancearealsoperceptuallymoredistinctive\nfromtherealwake-upwords.Thefactthatthefuzzywordswith\nlargeperceptualdifferencefromtherealwake-upwordcanwakeup\nthe voice assistants shows the severity of the security and privacy\nthreat posed by the FakeWake phenomena.\nReal human audio of fuzzy words (Q4) . In reality, different\nindividualsmaypronouncethesamewordindifferentways(e.g.,\nindifferentaccents).Therefore,weconductexperimentswithhu-\nmans articulating the generated fuzzy words. We have recruited 30\nChinesenativespeakers,including20malesand10females.The\nChinesespeakerscomefrom17differentprovincesinChinawith\ndifferentdialects.Wehaverecruited30EnglishspeakersfromAma-zonMechanicalTurk,including21malesand9females.TheEnglish\nspeakers come from 6 countries, i.e., the United States, the United\nKingdom,Germany,Italy,Brazil,andIndia,withEnglishastheir\nfirstorsecondlanguage.Thevolunteershavedifferentoccupations\nand backgrounds in society. We randomly selected 20 fuzzy words\nforeachvoiceassistant.EachChinese/Englishspeakerisinstructed\nto articulate and record the audios of 20 fuzzy words for the 4 Chi-\nnese/Englishvoiceassistants.Intotal,wehave20 ∗4∗30∗2=4,800\naudiosamplesspokenbyhumans.Weplayeachaudiosample10\ntimes to each voice assistantand calculate the mean wake-up rate\nof each fuzzy word across the 30 volunteers and display the cu-\nmulativedistribution function(CDF)ofthe wake-uprateforeach\nvoiceassistantinFigure6.Althoughthedifferencesbetweenhu-\nman pronunciation and TTS pronunciation lead to a decline in the\nwake-uprate,wecanobservethatalmostallfuzzywordsspoken\nbyrealhumanshavepositivewake-uprates,whichprovesthesefuzzy words also pose a threat in real life. For the Chinese voice\nassistants,50%ofthefuzzywordsforBaidu,AliGenie,andTencent\nhave a wake-up rate of more than 0.5, except for Xiaomi which\nhas lower wake-up rates. Based on our experiments the reason for\nthismaylieinthefactthatfuzzywordsforXiaomiareperceived\nas being less common in daily language (Figure 14(a)) such that\nthevolunteersmayhavedifficultyarticulatingthesefuzzywords\nfluently. For English voice assistants, the fuzzy words for Amazon\nEcho have higher wake-up rates than those for Echo Dot, probably\nbecausetheformerhasmorehigh-qualitymicrophonesandthus\nis more susceptible to fuzzy words (Echo has a seven-microphone\narray,andtheEchoDothasafour-microphonearray).Thefuzzy\nwordsforSirihavethelowestwake-upratessinceitalsohasthe\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1868(a) Baidu (b) AliGenie (c) Amazon Echo (d) Google\nFigure 5: The results of subjective tests for the top-10 fuzzy words for Baidu, AliGenie, Amazon Echo, and Google. The per-\nceptualdissimilaritybetweenfuzzywordsandtherealwake-upwordsrangesfrom1(verysimilar)to5(verydissimilar).Thecommonality of a fuzzy word in daily life ranges from 1 (not common) to 5 (very common).\nTable 2: Wake-up rate of fuzzy words in conversations. The\ncolumns b.,m., and e.present the mean wake-up rate of the\n10 fuzzy words when inserted at the beginning, the middle\nand the end of the conversations respectively.\nChinese b. m. e. English b. m. e.\nBaidu 0.81 0.73 0.72 Amazon Echo 0.88 0.77 0.70\nXiaomi 0.77 0.66 0.74 Echo Dot 0.79 0.74 0.60\nAliGenie 0.95 0.86 0.92 Google 0.90 0.81 0.71\nTencent 0.94 0.76 0.82 Apple Siri 0.76 0.50 0.61\nfewestgeneratedfuzzywordsandtheirwake-uprateswhenspoken\nthrough TTS are originally lower. The full statistics of the mean\nwake-up rate of each fuzzy word by human audio are provided in\nSection A.7.\nPerformance of fuzzy words in conversations (Q5) . Differ-\nentfrompreviousworksthatplayTVshowsorconversationsto\nvoice assistants to exhaustively search for fuzzy words, we auto-\nmatically generate fuzzy words using a genetic algorithm and test\nthem word by word. To evaluate whether the generated words can\nalso wake up the voice assistants when used in conversations, we\nselect10fuzzywordsforeachvoiceassistantandcreate3sentences\nfor each fuzzy word. The fuzzy word appears at the beginning, the\nmiddle,andtheendofthe3sentencesrespectively.Weplayeach\nsentencefor10timestothevoiceassistanttocomputethewake-up\nrateofthecorrespondingfuzzyword.Themeanwake-uprateof\nthe10wordsfordifferentvoiceassistantsislistedinTable2.The\nresults demonstrate that being embedded in conversations only\nslightlydecreasethewake-uprateofthefuzzywords.Fuzzywords\nat the beginning of a conversation have the highest wake-up rates\nsinceotherpartsoftheconversationhaveasmallerinfluenceon\nthedetectionprocess.ThefuzzywordsofSirihavethelowestwake-\nuprates inconversations.This maybebecause thewordsare less\ncommonly used in everyday conversations. The full statistics of\nthe wake-up rate of each fuzzy word in conversations are listed in\nSection A.9.\n4 Understanding Fuzzy Words\nTounderstandthecauseofthe FakeWake phenomena,weaimto\nfindthedecisivefactorsthatleadtofalseacceptanceoffuzzywords.(a) Chinese voice assistants (b) English voice assistants\nFigure 6: Cumulative distribution function of the wake-uprate of fuzzy words spoken by real humans.\nInthissection,wefirstpresentablack-boxexplanationofthefuzzy\nwords of commercial voice assistants since we have no access to\ntheirwake-upworddetectormodels.Then,weconductawhite-box\nexplanation of the fuzzy words based on an open-source keyword\nspotting model.\n4.1 Black-box Explanation\nWehavenoaccesstothecommercialwake-upworddetector,e.g.,\nGoogleorBaidu,whichmakesitimpossibletoanalyzethecausesoffalseacceptanceofourgeneratedfuzzywords.Therefore,wetrytoexplainthe FakeWake phenomenaofcommercialvoiceassistantsby\nanalyzingthegeneratedfuzzywordsthemselves.Afuzzywordis\nconsideredasthewake-upwordbecausethewake-upworddetectorisfooledbycertain\"similarities\"betweenthetwowords.Measuring\nthe similarities based on conventional metrics (e.g., calculatingthe Levenshtein distance between two words [\n37]) may not be\nappropriate since our generated fuzzy words have an expanded\ndistribution of Levenshtein distance from the real wake-up words\n(asshowninFigure7).Therefore,weneedtodigdeeperintothe\nroot causes of false acceptance of fuzzy words.\nToaddressthischallenge,weproposetobuildaninterpretable\ntree-based classifier as a proxy to the inaccessible and inexplica-bleblack-box wake-upword detector.Basedon theclassifier, wepropose a dissimilarity score that can predict whether a word islikely to be accepted by the wake-up word detector or not. After\nthat, we pinpoint phonetic features with the highest contributions\ntotheclassificationresultsasdecisivefactorsthathavethemost\ninfluence on the decision of wake-up word detectors.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1869\u0004\u000f\f\r\u0002 \u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \n\u000b\n\u0001\u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \u0003\u0006\u0010\u0006\n\r\b\u000e\u0006\t\n\u0002 \u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \n\u000b\n\u0001\u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r\n(a) Baidu (b) AliGenie (c) Amazon Echo (d) Google\nFigure7:Thedistributionofdissimilaritybetweenfuzzy-words/non-fuzzy-wordsandrealwake-upwordsforBaidu,AliGenie,\nAmazonEcho,andGoogle.Bothfuzzywordsandnon-fuzzywordshavesimilardistributionofLevenshteindistance,buthave\ndistinctively different distributions of our proposed dissimilarity score.\n\u0002\n\b\t\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0004\u0007\u0006\n\u0011\f\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0003\r\u0012\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013\n(a) Baidu (b) AliGenie (c) Amazon Echo (d) Google\nFigure 8: Black-box explanation for private wake-up word detectors of commercial voice assitants. The contributions of de-\ncisive factors at different positions of the real wake-up word for Baidu, AliGenie, Amazon Echo, and Google. The legendHigh-similarity referstodecisivefactorsthatarephoneticallysimilartotheircounterpartsintherealwake-upword. Medium-\nsimilarity andLow-similarity are defined accordingly.\nDissimilarity score\n. We train an interpretable model with the\ngenerated fuzzy words as positive samples and non-fuzzy words\nas negative samples, which simulates the behavior of the wake-up\nworddetector.Toextract featuresofeachfuzzywordastheinput\nto the model, we do not use the encoding of the genetic algorithm,\nsinceitconsistsonlyofnumbersthatdonotcarrypronunciation\ninformation. For Chinese, we leverage the high-dimensional em-\nbedding [ 26], which encodes each initial and each final into a two-\ndimensional vector. This embedding characterizes the phoneticfeatures of a Chinese word. For English, since there is no high-\ndimensional embedding for phonemes, we use multi-dimensional\nscaling [22] to find an encoding that preserves the dissimilarity\nbetween phonemes [ 30]. We also encode each phoneme into a\ntwo-dimensional vector. In summary, each initial/final/phoneme is\nencoded into two features.\nWe use gradient boosting classifier [ 16], an ensemble of weak\nclassifiers (we use decision tree as the weak classifier), as the in-terpretable model. We perform 10-fold cross validation, and the\nresults show that the interpretable models have a prediction accu-\nracy of more than 90% for most voice assistants. There are various\nreasons why the prediction accuracy may fluctuate between voice\nassistants. In particular, it is not possible to exhaustively search forfuzzywords.Thetrainingsetnaturallycontainsasubsetofsamples\nthat belong to fuzzy words and non-fuzzy words, which is com-monfor allmachine learningtasks.Needless tosay, thedecisionboundaries learned by the classifier is imperfect, and the predic-tion accuracy is unable to reach 100%. Interestingly, we observe\nthatthepredictionaccuracyforvoiceassistantswithmorefuzzy\nwordsislower.Forinstance,thepredictionaccuracyforBaiduis\nthehighest(93.81%),whileBaiduhasthesecondsmallestnumberof fuzzy words (63). The prediction accuracy for AliGenie is the\nlowestamongChinesevoiceassistants(87.09%),eventhoughAli-\nGenie hasthe largestnumber offuzzy words (322).This indicates\nthat with an increasing amount of fuzzy words it gets more diffi-cult to distinguish the fuzzy words from the real wake-up wordof this voice assistant. In addition, the tree-based classifier is rel-atively inaccurate. A possible remedy is to increase the number\nof tree-based classifiers in the gradient boosting classifier, but this\nwill greatly increase thecomputational complexity without much\nimprovement in the accuracy according to our experiments. Theprediction accuracy, false positive and false negative rates of the\nmodelsfordifferentvoiceassistantsaredisplayedinTable6.Weusetheoutputconfidencescoreofacertainfuzzywordasitssimilarity\nscore𝛾. The dissimilarity score equals 1 −𝛾.\nInsight 3\nOur constructed dissimilarity score can better separate fuzzy\nwords and non-fuzzy words than Levenshtein distance.\nFigure7displaysthedistributionofdissimilarityscoresbetween\nfuzzy-words/non-fuzzy-words and real wake-up words. We can ob-servethatfuzzywordsandnon-fuzzywordshavesimilarexpandeddistributionsintermsofLevenshteindistance,whichindicatesthat\nLevenshtein distance is not a proper metric to predict whether a\nword is similar to the real wake-up word. In contrast, with our\napproach, non-fuzzywords have significantlyhigher dissimilarity\nscores than fuzzy words, which means that our constructed dis-similarity score can better predict whether a word is likely to be\naccepted by the wake-up word detector.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1870Decisive factors. In order to evaluate the contribution of each\nfeature,wecalculatetheirSHAPvalues[ 27].Weregardeachfeature\nasa\"contributor\",andaddupcontributionsofallfeaturestoobtain\nthe prediction result.\n𝑦𝑖=𝑦0+/summationdisplay.1\n𝑗𝑓(𝛼(𝑗)\n𝑖), (4)\nwhere𝑦𝑖is the prediction result for sample 𝑥𝑖,𝑦0is the mean\npredictionresultsofallsamples, 𝛼(𝑗)\n𝑖isthe𝑗-thfeatureof 𝑥𝑖,and\n𝑓(𝛼(𝑗)\n𝑖)is the contribution of 𝛼(𝑗)\n𝑖to the prediction result.\nNotethatthecontribution 𝑓(𝛼(𝑗)\n𝑖)canbepositiveornegative.\nA positive contribution means that the feature is helpful for ac-\ncuratepredictionofwhetherasampleisafuzzywordornot.For\na certain fuzzy word 𝑥𝑖, letA+\n𝑖denote the set of features with\npositivecontributions.Weranktheelementsin A+\n𝑖accordingto\ntheir contributions in a non-increasing order. We construct a set\nD𝑖torepresentimportantfeaturesfor 𝑥𝑖,andthenaddelements\ninA+\n𝑖toD𝑖sequentiallyuntiltheratioofthecontributionofall\nelementsin D𝑖tothecontributionofallelementsin A+\n𝑖ismore\nthan a threshold 𝛽.\n/summationtext.1\n𝑘∈D𝑖𝑓(𝛼(𝑘)\n𝑖)\n/summationtext.1\n𝑘/prime∈A+\n𝑖𝑓(𝛼(𝑘/prime)\n𝑖)≥𝛽. (5)\nWe consider a(n) initial/final/phoneme as a decisive factor for\n𝑥𝑖if at least one of its two features is in D𝑖. In this way, we can\nobtain the set of decisive factors and their contributions. The con-\ntributionof a(n)initial/final/phonemeisthe sumofcontributions\nof its features in D𝑖.\nWe construct the set of decisive factors for each fuzzy word that\niscorrectlyclassifiedbytheinterpretablemodel.Wecomparethe\ndecisivefactorsandtheircounterpartsintheoriginalwake-upword\nbycomputingtheabsolutedifferencesoftheirencoding.Weobtain\nmean and variance 𝛿of all computed differences for normalization.\nAccordingtothesimilaritymeasurement,wecategorizethedecisive\nfactorsintothreegroups:high-similarity(thenormalizeddifferenceiswithin\n𝛿),medium-similarity(thenormalizeddifferenceiswithin\n2𝛿), and low-similarity (the normalized difference is beyond 2 𝛿).\nAfterthat,wecomputetheaveragecontributionofeachgroupof\ndecisivefactorsateachpositionoftheoriginalwake-upword,as\nshown in Figure 8. The threshold 𝛽is set as 0.8.\nInsight 4\nWake-up words with fewer decisive factors have more fuzzy\nwords.\nFigure 8 demonstrates that the decisive factors which determine\nfalse acceptance of fuzzy words usually concentrate on a shortsnippet of the wake-up word, e.g., ksfor Alexa and àifor xi\nˇao ài\ntóngxué.Bykeepingthedecisivefactorsandalterotherpartsof\nthe wake-up word it is possible to create new fuzzy words. If a\nwake-upwordhasfewerdecisivefactors,thereismorespacefor\naltering other parts of the word to generate fuzzy words, which\nrendersthevoiceassistantsmorevulnerable.Forinstance,AliGenie\nrelies disproportionately on ianto recognize the wake-up word,\nthusthenumberofitsfuzzywordsisthehighestamongallvoice\nassistants. The fact that more than 80% of the fuzzy words contain\u0002\n\b\t\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0004\u0007\u0006\n\u0011\f\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0003\r\u0012\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013\n(a) Alexa (White box) (b) Alexa (Black box)\nFigure 9: White-box explanation for open-source wake-upworddetectors. High-similarity, Medium-similarity,and\nLow-similarity are defined the same as in Figure 8.\nat least one of the top-3 decisive factors (Table 9) indicates thatthe wake-up word detector may put disproportionate emphasison the decisive factors and not enough attention to other partsof the phonemes to identify the wake-up words. Developers can\napplyourinterpretationframeworktotestthedecisivefactorsof\ntheir wake-up words, then fine-tune the wake-up word detector\nto expand the decisive factors across the entire wake-up word, i.e.,\npay attention to all parts of the words. In this way, the wake-up\nword detector will be more robust to the FakeWake phenomena.\n4.2 White-box Explanation\nTo explain the FakeWake phenomena and the existence of fuzzy\nwordsattheAImodellevel,weadoptalightweight,open-source\nkeyword-spottingmodel,namedMycroftPrecise[ 19].Thesys-\ntemworksasfollows.Theinputofthemodelisanaudiofile,e.g.,\n.wav, which contains the semantic information, i.e., phoneme or\npinyin. The audio file is not directly fed to the neural network, but\nmel-frequencycepstralcoefficients(MFCCs)areextractedfromthe\naudiofileasfeatures.MFCCscapturethefrequencysensitivityof\nthe human auditory system. The model processes the MFCCs of\ntheaudiothroughaseriesofcomplicatednonlinearoperationsina\nconvolutional neural network, and outputs the final results.\nDeep learning models are notorious for its non-interpretable na-\nture due to its highly nonlinear structures and massive parameters.\nInsteadofgettingentangledinthecomplicatedmodelstructures\nand parameters, we resort to the gradient information, which re-\nflectsthesensitivityofthemodeloutputtotheinputandisusedby\nmainstream approaches for machine learning model interpretation.\nThegreaterthegradientofacertainfeatureis,themoresignificant\nistheimpactofthefeatureonthepredictionresultsofthemodel.\nHowever,thegradientmaydisappear,especiallyiftheactivation\nfunction is the ReLU function ( ReLU(𝑥)=max(𝑥,0)). Moreover,\nthegradientonlycharacterizesthelocalfeaturesoftheinputbut\ncannot reflect the entire decision-making process of the model.\nTo tackle these shortcomings, we leverage the integral gradient\nmethod [41], which improves the traditional gradient method and\nsatisfies the axioms of sensitivity and implementation invariance.\nSimilartoEquation(4),theintegralgradientmethodattributes\nthe output of the model to the sum of the contributions of each\nfeature, but the contributions are estimated in a different way as\n𝑔(𝑥(𝑗)\n𝑖)=/bracketleftBigg\n1\n𝑛𝑛/summationdisplay.1\n𝑘=1/parenleftBig\n∇𝛾𝑦𝑖(𝛾(𝛼))/barex/barex𝛾(𝛼)=(1−𝛼)𝑥𝑖+𝛼¯𝑥,𝛼=𝑘\n𝑛/parenrightBig/bracketrightBigg\n𝑗[¯𝑥−𝑥𝑖]𝑗\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1871Table 3: Mitigation results\nWake-up Evaluation Original Strengthened\nword metric model model\nAlexaFalse positive rate 0.00% 0.00%\nFalse negative rate 6.85% 5.48%\nDetection accuracy 96.73% 97.39%\nFuzzy rate 17.67% 1.18%\nHi XiaowenFalse Positive rate 0.00% 0.00%\nFalse negative rate 2.13% 2.13%\nDetection accuracy 99.36% 99.36%\nFuzzy rate 11.65% 0.20%\nHi MiaFalse Positive rate 0.00% 0.00%\nFalse negative rate 0.00% 0.00%\nDetection accuracy 100% 100%\nFuzzy rate 5.62% 0.00%\nwhere𝑔(𝑥(𝑗)\n𝑖)is the contribution of the 𝑗-th feature of sample\n𝑥𝑖to the prediction result 𝑦𝑖, and𝑦0=𝑦(¯𝑥)is the output of the\nmodel to the mean value of all training samples. The contribution\nof each feature is calculated as the integral gradient from ¯𝑥to\n𝑥𝑖. We can regard 𝑔(𝑥(𝑗)\n𝑖)as the contribution of the 𝑗-th feature\nto transforming a trivial decision 𝑦0to a positive decision 𝑦𝑖by\nexerting a greater gradient to the model decision-making process.\nAfterobtaining 𝑔(𝑥(𝑗)\n𝑖),weuse thesameapproachasEquation\n(5) to derive the decision factors by replacing 𝑓(𝑥(𝑗)\n𝑖)with𝑔(𝑥(𝑗)\n𝑖).\nThe only difference is that the decision factors here are frames\nof the audio file of the fuzzy words rather than the pinyin or the\nphoneme composition of the word.\nTovisualizethedecisivefactorsinamoreintelligibleway,we\nsumthecontributionsoftheframesthatbelongtothesamepinyin\norphoneme.Notethatwedonothaveaccesstothetrainingdatasets\nofthewake-upworddetectorsofcommercialvoiceassistants,so\nwe use public datasets to train our local model. We obtain a white-\nbox wake-up word detector for \"Alexa\". Unfortunately, we did not\nfind public datasets of other voice assistants.\nWe present the decisive factors of these three models in Fig-\nure 9(a). The results confirm that the wake-up detector pays dis-\nproportionateattentiontosomepartsoftheword,makingitvul-\nnerable to fuzzy words that contain these decisive parts. Note that\nthedecisivefactorsforAlexaderivedbythewhite-boxexplanation\nframeworkinFigure9(a)seemtobedifferentfromthosederived\nby the black-box explanation framework in Figure 8(c). The former\nshowsthatthemodelpaysmoreattentionto @lE,whilethelatter\nshows that the model pays more attention to ks. This is because\nouropen-sourcewake-upworddetectorisdifferentfromtheactual\nwake-upword detectorofAmazonEcho. Weapply ourblack-box\nexplanation framework to the open-source wake-up word detector\nof Alexa and present the results in Figure 9(b).\nSummary. Wecanobservethattheblack-boxexplanationframe-\nworkyieldssimilardecisivefactorsasthewhite-boxexplanation\nframework for the same wake-up word detector. This verifies that\nour black-box explanation framework iseffective in extracting de-\ncisivefactorsofunknownwake-upworddetectorsofcommercial\nvoice assistants.5 Mitigating Fuzzy Words\nIn this section, we present two potential approaches to strengthen\nwake-up word detectors against fuzzy words. The first approach is\ntoscrutinizewordsthatcontaindecisivefactors.Wequantifythe\nproportion of generated fuzzy words that contain decisive factors,\nas shown in Table 9. We can observe that for most voice assistants,\nmore than 90% of fuzzy words contain at least one of the top-3\ndecisivefactors.Inparticular,100%ofthefuzzywordsofGoogleand\nBaiducontaintop-3decisivefactors.Thewake-upworddetector\ncansendaudiosamplesthatinvolvedecisivefactorstomorediscreet\nexamination by complicate dspeechrecognition models.\nThe second remedy is to strengthen wake-up word detectors by\nretraining them with the generated fuzzy words. Since we have no\naccesstowake-upworddetectorsofcommercialvoiceassistants,\nwetestourideaonMycroftPrecise[ 19].Wealsoexperimentwith\nTC-ResNet [ 9], another open-source keyword-spotting model, but\nthetrainedmodelhaspoorgeneralizationabilityonourdatasets.\nThepredictionaccuracyonthetestdatasetisaslowas85.64%.Fora\nspecificwake-upword,wecollectthreetypesofdatasets:aconven-\ntionaldataset,afuzzyworddataset,andacollectivedataset.The\nconventionaldatasetconsistsofsamplesofthewake-upword(pos-\nitive) and non-fuzzy words (negative). We divide the conventional\ndataset into a training dataset and a test dataset. To begin with, we\ntrain an original wake-up word detector using the conventional\ntraining dataset on Precise. The fuzzy word dataset consists of thegeneratedfuzzywordsofthewake-upword.Weusethefuzzyword\ndataset to retrain the original model to obtain the strengthened\nmodel.Thecollectivedatasetconsistsofalargenumberofwords\nfromadictionary.Thereisnooverlapbetweenthecollectivedataset\nand the conventional dataset, and there is no overlap between the\ncollective dataset and the fuzzy word dataset. The words in the\ncollective datasets include fuzzy words and non-fuzzy words.\nWetesttheoriginalandthestrengthenedmodelsontheconven-\ntionaltestdatasettoobtainthefalsepositiverate,falsenegativerate,\nand accuracy. We further test the original model and the strength-\nened model on the collective dataset to measure the fuzzy rate,\nwhich is defined as the ratio of wrongly accepted words among all\nwordsinthecollectivedataset.Alargerfuzzyratemeansthatmore\nfuzzy words in the dictionary are accepted by detectors indicating\nthat the model is more vulnerable to fuzzy words.\nSincewedonothaveaccesstothetrainingdatasetsofthewake-\nup word detectors of commercial voice assistants, we use public\ndatasetsastheconventionaldatasettotrainwake-upworddetec-\ntors. We obtain five public datasets of English words, including\n\"Alexa\",\"Athena\",\"Computer\",\"HiXiaowen\"and\"HiMia\".Unfor-\ntunately, we did not find public datasets of Chinese words. We\nspliteachconventionaldatasetintoatrainingdatasetwith3/4of\nthe samples and a test dataset with the remaining samples. Wekeep a relatively balanced ratio of negative samples to positive\nsamplesinthetrainingdatasettoavoidbias.ForAlexa’straining\ndataset, we have 296 positive samples and 399 negative samples.\nThepositivesamplesarecollectedfromkaggle[ 1]andthenegative\nsamples are collected fromthe human noise and the environment\nnoise inthe datasetof mycroft-precise[19]. For Athena’straining\ndataset, we have 386 positive samples and 839 negative samples.\nFor Computer’straining dataset, wehave 87 positive samplesand\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1872161 negative samples. We collect the data of Athena and Computer\nfrommycroft-precise[ 19].ForHiXiaowen’strainingdataset,we\nhave380positivesamplesand693negativesamples,allcollected\nfrom MobvoiHotwords [ 24]. For Hi Mia’s training dataset, we have\n800 positive samples and 1,000 negative samples, all collected from\nAISHELL[ 35].Forthefuzzyworddataset,wesearchforfuzzywords\nusingadictionaryof498wordsfromtheGoogleTTSlibrary[ 21].\nThe collective dataset is also from the Google TTS library with\n49,822 words.\nAs shown in Table 3 and Table 10, the fuzzy rate of the original\nmodel can be as high as more than 20%, but drops to almost 0 after\nbeingstrengthened.Surprisingly,forallstrengthenedmodels,their\naccuracyisevenhigherthantheoriginalmodelontheconventional\ntestdataset.Thisshowsthat ourmitigationapproachnotonlyde-\nfendsagainstfuzzywordsbutalsoimprovestheperformanceoftheoriginalmodel.Thepossiblereasonisthatthefuzzywordsareclose\nto the decision boundary, and using fuzzy words to train the detec-\ntorprovidesamoreeffectivewaytolearnthedecisionboundary\nmore precisely. Even if an adversary re-applies the genetic algo-\nrithm to generate fuzzy words for the strengthened wake-up word\ndetector, the discovered fuzzy words will naturally be fewer and\ntheir wake-up rate will be lower. This is because the strengthened\nwake-up detector has learned a better decision boundary between\nthewake-upwordsandnon-wake-upwords,andwillrejectalmost\nall previously generated fuzzy words (c.f. Table 3, the fuzzy rate\nisreducedtounder0.25%).Therefore,ourmitigationstrategycan\ngreatlyreducethenumberoffuzzywordsandtheattacksuccess\nrate of the adversary.\nThe proposed two mitigation strategies help manufacturers im-\nprove their products in terms of security and privacy. It may be\npossible but inconvenient to address the FakeWake problem at the\nuserside.Apossiblesolutionistoequipuserswithalocaldevice\nthat can detect the possible fuzzy words and inform users of thepotential danger of privacy leakage through smartphone alerts.\nThis solution, however, depending entirely on the user to mitigate\nshortcomings of a product, generates cost and places the burden of\nmanaginganadditionaldeviceonhim.Themanufacturershould\nnot shift the burden of improving the device to the user.\n6 Related Work\nWake-upworddetection .EarlierworksleverageHiddenMarkov\nModels (HMM) and Gaussian Mixture Models (GMM) for acoustic\nmodeling[ 18,48],whichsuffersfromhighcomputationalcomplex-\nity. Hence, the traditional HMM-GMM models are now replaced\nby more efficient Deep Neural Networks (DNN) [ 32,40], Convolu-\ntional Neural Networks (CNN) [ 8,36], Recurrent Neural Networks\n(RNN) [14], Convolutional Recurrent Neural Networks (RCNN) [ 2],\nGated Recurrent Units (GRUs) [ 43], and Long Short-Term Memory\n(LSTM) units [3].\nWake-upwordsecurity .Asfarasweknow,thereisonlyafew\nworksonwake-upwordsecurity.Schönherretal.[ 37]investigated\naccidentaltriggers forEnglish,ChineseandGermansmartspeak-\ners. Accidental triggers were exhaustively searched by playing alargecorpusofmediaaudiostosmartspeakers,followingwhich\na dictionary isused to find moreaccidental triggers based onLev-\nenshtein distance. The Chinese speakers are tested with Englishaudiosamples,andtheinfluenceofdistance,volume,speedandam-\nbient noises are not considered. Similarly, Dubois et al. [ 13] played\nUK and US television shows to voice assistants to characterize the\nsourcesandthenumberofmis-activations.Mitevetal.[ 29]utilized\naphonemedictionarytofuzzvoiceassistantsandscannednetworktrafficformis-activateddevices.Allexistingmethodsseekforfuzzy\nwordsbyexhaustivesearch,whichtakesdaysorevenweekstofind\nalimitedsetoffuzzywords.Ourapproachautomaticallygenerates\na large set of fuzzy words without manual intervention in a much\nshorter time. In addition, we propose a more precise metric than\ntheLevenshteindistancetopredictfuzzywords.Finally,wearethe\nonly one presenting a practical mitigation method to strengthen\nwake-up detectors.\nCovertcommands .Covertcommandattacksaimtoinjectmali-\nciouscommandsforthevoiceassistanttoexecutecertainoperations\nwithoutusersnoticing.Vaidyaetal.[ 42]proposedtomodifythe\nMFCCsofvoicesamples(e.g.,OKGoogle)sothatthemangledsam-\nplesareunintelligibletohumans(e.g.,electronic-soundingnoise)\nbutwillbeidentifiedasacommandbyvoiceassistants.Carliniet\nal. [6] built on top of this work by presenting a more precise attack\nonawhite-boxvoicerecognitionsystem.Carlinietal.[ 7]created\nanaudiosamplefromanotheronecontainingaspokensentence,\npreserving similar waveforms but misleading voice recognition\nalgorithms to yield false interpretations. Schönherr et al. [ 38] and\nYuan et al. [ 46] proposed to insert intended commands inside an\ninnocent audio sample, e.g., a music file, which is only recogniz-\nable by voice recognition algorithms but not by humans. Zhang et\nal. [47] used ultrasonic audio to inaudibly inject commands into\nvoice assistants.\nOur work is different from audio adversarial examples since\nfuzzy words are natural audio samples instead of synthetic onesincluding carefully-crafted noise. Compared with music [\n38,46]\norelectronic-soundingnoise[ 6,42],fuzzywordsaremorecovert\nwith less alarm. Our work is different from dolphin attacks [ 47]\nas the fuzzy words are audible. We do not intend to activate voice\nassistants using out-of-band voice signals. The frequency range of\nour fuzzy words lies within the hearing range of human ears.\n7 Conclusion\nInthispaper,wepresentasystematicframeworktogenerate,un-\nderstandandmitigatefuzzywordsthatcanfalselyactivatevoice\nassistants. Using our search framework customized for different\nlanguages, we have managed to pinpoint 965 fuzzy words covering\n8 most popular English and Chinese smart speakers. Our explana-\ntion of decisive factors and mitigation methods help strengthen\nwake-upworddetectorsagainstfuzzywords.Assuch,ourapproach\npresents a promising way to find, understand and mitigate privacy\nand security issues in voice assistants.\n8 Acknowledgement\nWethankallanonymousreviewersfortheirinsightfulcomments\non this paper. This work is funded in part by China NSFC Grant\n61925109and61941120,aswellastheGermanResearchFoundation\n(DFG)withinCRC1119CROSSING(S2andP3)andtheIntelPrivate\nAI Center.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1873References\n[1]AmirAnhari.2021. AlexaDataset:Buildvoice-firstapplications. https://www.\nkaggle.com/aanhari/alexa-dataset\n[2]Sercan O Arik, Markus Kliegl, Rewon Child, Joel Hestness, Andrew Gibian-\nsky, Chris Fougner, Ryan Prenger, and Adam Coates. 2017. Convolutional re-current neural networks for small-footprint keyword spotting. arXiv preprint\narXiv:1703.05390 (2017).\n[3]PallaviBaljekar,JillFainLehman,andRitaSingh.2014. Onlineword-spotting\nin continuous speechwithre current neural networks. In IEEE Spoken Language\nTechnology Workshop.\n[4]BusinessWire.2020. StrategyAnalytics:GlobalSmartSpeakerSalesCross150\nMillion Units for 2020 Following Robust Q4 Demand. https://smallurl.net/\nbusinesswire\n[5]Canalys.2020. Globalsmartspeakermarket2021forecast. https://www.canalys.\ncom/newsroom/canalys-global-smart-speaker-market-2021-forecast\n[6]NicholasCarlini, PratyushMishra,Tavish Vaidya,YuankaiZhang, MicahSherr,\nClay Shields, David Wagner, and Wenchao Zhou. 2016. Hidden voice commands.\nIn25th USENIX Security Symposium.\n[7]Nicholas Carlini and David Wagner. 2018. Audio adversarial examples: Targeted\nattacksonspeech-to-text.In IEEE Security and Privacy Workshops.\n[8]GuoguoChen,CarolinaParada,andGeorgHeigold.2014. Small-footprintkey-\nwordspottingusingdeepneuralnetworks.In IEEEInternationalConferenceon\nAcoustics,Speec h and Signal Processing .\n[9]Seungwoo Choi, Seokjun Seo, Beomjun Shin, Hyeongmin Byun, Martin Kersner,\nBeomsu Kim, Dongyoung Kim, and Sungjoo Ha. 2019. Temporal convolution for\nreal-timekeywordspottingonmobiledevices. arXivpreprintarXiv:1904.03814\n(2019).\n[10]CNET. 2018. Alexa sent private audio to a random contact, Portland family\nsays. https://www.cnet.com/home/smart-home/alexa-sent-private-audio-to-a-\nrandom-contact-portland-family-says/\n[11]Toby Cox. 2020. Siri and Alexa Fails: Frustrations With Voice Search.https://themanifest.com/digital-marketing/resources/siri-alexa-fails-\nfrustrations-with-voice-search\n[12]K.Deb,A.Pratap,S.Agarwal,andT.Meyarivan.2002.Afastandelitistmultiobjec-\ntive genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation\n6, 2 (2002), 182–197.\n[13]Daniel J. Dubois, Roman Kolcun, Anna Maria Mandalari, Muhammad TalhaParacha, David Choffnes, and Hamed Haddadi. 2020. When Speakers Are All\nEars:CharacterizingMisactivationsofIoTSmartSpeakers. ProceedingsonPrivacy\nEnhancing Technologies (2020).\n[14]SantiagoFernández,AlexGraves,andJürgenSchmidhuber.2007. Anapplicationofrecurrentneuralnetworkstodiscriminativekeywordspotting.In International\nConference on Artificial Neural Networks.\n[15]CenterforHearingandCommunication.2020. Commonenvironmentalnoise\nlevels. https://chchearing.org/noise/common-environmental-noise-levels/\n[16]JeromeH.Friedman.2000. GreedyFunctionApproximation:AGradientBoosting\nMachine. Annals of Statistics (2000).\n[17]FutureLearn.2021. IntroductiontoPinyin. https://www.futurelearn.com/info/\ncourses/chinese-pronunciation-tone/0/steps/64892.\n[18]AlvinGarciaandHerbertGish.2006. Keywordspottingofarbitrarywordsusing\nminimal speech resources. In 2006 IEEE International Conference on Acoustics\nSpeechand SignalProcessingProceedings , Vol. 1. IEEE, I–I.\n[19]Kris Gesling. 2021. Precise. https://mycroft-ai.gitbook.io/docs/mycroft-\ntechnologies/precise.\n[20]Iman Ghosh. 2020. Ranked: The 100 Most Spoken Languages Around the World.\nhttps://www.visualcapitalist.com/100-most-spoken-languages/\n[21] Google.2018. GoogleSpee ch. https://pypi.org/project/google-speech/\n[22]J. C. GOWER. 1966. Some distance properties of latent root and vector methods\nused in multivariate analysis. Biometrika 53, 3-4 (1966), 325–338.\n[23]HealthLinkBC.2020. HarmfulNoiseLevels. https://www.healthlinkbc.ca/health-\ntopics/tf4173\n[24]JingyongHou,YangyangShi,MariOstendorf,Mei-YuhHwang,andLeiXie.2019.\nRegion Proposal Network Based Small-Footprint Keyword Spotting. IEEE Signal\nProcessing Letters 26, 10 (2019), 1471–1475.\n[25]B. L. Kalman and S. C. Kwasny. 1992. Why tanh: choosing a sigmoidal function.\nInIEEE International Joint Conference on Neural Networks, Vol. 4. 578–581.\n[26]Min Li, Marina Danilevsky, Sara Noeman, and Yunyao Li. 2018. DIMSIM: An\nAccurate Chinese Phonetic Similarity Algorithm Based on Learned High Di-\nmensional Encoding. In 22nd Conference on Computational Natural Language\nLearning.\n[27]Scott M. Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M. Prutkin,\nBalaNair,RonitKatz,JonathanHimmelfarb,NishaBansal,andSu-InLee.2020.\nFromlocalexplanationstoglobalunderstandingwithexplainableAIfortrees.\nNature machine intelligence 2, 1 (2020), 56–67.\n[28]Markets and Markets. 2020. Smart Speaker Market with COVID-19 Impact\nAnalysis by IVA (Alexa, Google Assistant, Siri, DuerOS, Ali Genie), Component\n(Hardware(SpeakerDriver,ConnectivityIC,Processor,AudioIC,Memory,PowerIC, Microphone) and Software), Application, and Region - Global Forecast to2025. https://www.marketsandmarkets.com/Market-Reports/smart-speaker-\nmarket-44984088.html\n[29]RichardMitev,AnnaPazii,MarkusMiettinen,WilliamEnck,andAhmad-Reza\nSadeghi. 2020. LeakyPick: IoT Audio Spy Detector. In Annual Computer Security\nApplications Conference.\n[30]David R. Mortensen, Patrick Littell, Akash Bharadwaj, Kartik Goyal, Chris Dyer,\nand Lori Levin. 2016. PanPhon: A Resource for Mapping IPA Segments to Ar-ticulatory Feature Vectors. In 26th International Conference on Computational\nLinguistics: Technical Papers.\n[31]Gonzalo Navarro. 2001. A guided tour to approximate string matching. Comput.\nSurveys33, 1 (2001), 31–88.\n[32]SankaranPanchapagesan,MingSun,AparnaKhare,SpyrosMatsoukas,ArindamMandal, Björn Hoffmeister, and Shiv Vitaladevuni. 2016. Multi-task learning and\nweighted cross-entropy for DNN-based keyword spotting. In Interspeech.\n[33]JongseokPark,KyubyongKim.2019. g2pE:ASimplePythonModuleforEnglish\nGrapheme To Phoneme Conversion. https://github.com/Kyubyong/g2p.\n[34]Sarah Perez. 2019. China overtakes US in smart speaker market share. shorturl.\nat/bBGOW\n[35]Xiaoyi Qin, Hui Bu, and Ming Li. 2020. Hi-mia: A far-field text-dependent\nspeaker verification database and the baselines. In IEEE International Conference\non Acoustics, Speechand Signal Processing .\n[36]Tara N Sainath and Carolina Parada. 2015. Convolutional neural networksfor small-footprint keyword spotting. In Sixteenth Annual Conference of the\nInternational Speech Communication Association.\n[37]Lea Schönherr, Maximilian Golla, Thorsten Eisenhofer, Jan Wiele, Dorothea\nKolossa,andThorstenHolz.2020. Unacceptable,whereismyprivacy?Exploring\nAccidental Triggers of Smart Speakers. arXiv preprint arXiv:2008.00508 (2020).\n[38]Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea\nKolossa.2018. AdversarialAttacksAgainst AutomaticSpeec hRecognitionSys-\ntems via Psychoacoustic Hiding. arXiv preprint arXiv:1808.05665 (2018).\n[39]EricHalSchwartz.2020. VoiceAssistantsVeryPronetoAccidentallyWakingUp\nand Recording Long Audio Clips: Study. shorturl.at/bdCEY\n[40]MingSun,DavidSnyder,YixinGao,VarunKNagaraja,MikeRodehorst,Sankaran\nPanchapagesan,NikkoStrom,SpyrosMatsoukas,andShivVitaladevuni.2017.\nCompressedTimeDelayNeuralNetworkforSmall-FootprintKeywordSpotting..\nInInterspeech.\n[41]MukundSundararajan,AnkurTaly,andQiqiYan.2017. Axiomaticattribution\nfordeepnetworks.In InternationalConferenceonMachineLearning.PMLR,3319–\n3328.\n[42]Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine\nnoodles: exploiting the gap betwee n human and machine speechrecognition. In\n9th USENIX Workshop on Offensive Technologies.\n[43]Martin Woellmer, Bjoern Schuller, and Gerhard Rigoll. 2013. Keyword spotting\nexploitinglongshort-termmemory. SpeechCommunication 55,2(2013),252–265.\n[44]Yellowbridge. 2021. Learn Chinese Pinyin Rules: Initials, Finals, and Tones.\nhttps://www.yellowbridge.com/chinese/pinyin-rules.php.\n[45]Honggang Yu, Kaichen Yang, Teng Zhang, Yun-Yun Tsai, Tsung-Yi Ho, and\nYier Jin. 2020. Cloudleak: Large-scale deep learning models stealing through\nadversarial examples. In Network and Distributed Systems Security Symposium.\n[46]XuejingYuan,YuxuanChen,YueZhao,YunhuiLong,XiaokangLiu,KaiChen,\nShengzhiZhang,HeqingHuang,XiaofengWang,andCarlAGunter.2018. Com-\nmandersong: A systematic approach for practical adversarial voice recognition.\nIn27th USENIX Security Symposium.\n[47]Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and\nWenyuanXu.2017.Dolphinattack:Inaudiblevoicecommands.In ACMConference\non Computer and Communications Security.\n[48]YaodongZhangandJamesRGlass.2009. Unsupervisedspokenkeywordspotting\nvia segmental DTW on Gaussian posteriorgrams. In 2009 IEEE Workshop on\nAutomatic SpeechRecognition & Understanding. IEEE, 398–403.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1874A Appendix\nA.1 Experiment Setup\nFigure10:Theexperimentsetupincludesalaptop,astereo,aRaspberryPi,andalightsensor.Thelaptoprunsthegeneration\nalgorithm,andthestereoplaysthegeneratedfuzzywordsovertheairtothesmartspeaker.TheRaspberryPiequippedwiththe light sensor detects the activation of the smart speaker, which is fed back to the laptop to calculate the wake-up rate.\nA.2 Wake-up Rate Distribution\nWeshowthewake-upratedistributionoffuzzywordsfordifferentvoiceassistantsinFigure11,wherewedividethewake-uprateinto\nthree ranges: low (0.1 ∼0.3), medium (0.4 ∼0.7), and high (0.8 ∼1.0). More than 40% fuzzy words have high wake-up rate except for Baidu,\nwhich may be another benefit of word repetition.\nFigure 11: Distribution of fuzzy words for different voice assistants. Wake-up rate ranges: low (0-0.3), medium (0.4-0.7) andhigh (0.8-1.0). The numbers of fuzzy words are marked.\nA.3 Impact of Speaker Gender\n(a) Amazon Echo: Gender (b) Echo Dot: Gender (c) Google: Gender\nFigure 12: Wake-up rate of fuzzy words under different speaker genders for English voice assistants.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1875A.4 Environmental Impact on Fuzzy Words\n(a) Xiaomi: Volume (b) Xiaomi:Speed (c) Xiaomi: Noise\n(d) Tencent: Volume (e) Tencent:Speed (f) Tencent: Noise\n(g) Echo Dot: Volume (h) EchoDot:Speed (i) Echo Dot: Noise\n(j) Apple: Volume (k) Apple:Speed (l) Apple: Noise\nFigure 13: Wake-up rate of fuzzy words under different environments for Xiaomi, Tencent, Echo Dot, and Apple Siri voice\nassistants.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1876A.5 Subjective Tests\n(a) Xiaomi (b) Tencent (c) Echo Dot (d) Apple Siri\nFigure 14: The results of subjective tests for the top-10 fuzzy words for Xiaomi, Tencent, Echo Dot, and Apple Siri. The per-\nceptualdissimilaritybetweenfuzzywordsandtherealwake-upwordsrangesfrom1(verysimilar)to5(verydissimilar).Thecommonality of a fuzzy word in daily life ranges from 1 (not common) to 5 (very common).\n(a) Baidu (b) Xiaomi (c) AliGenie (d) Tencent\n(e) Amazon Echo (f) Echo Dot (g) Google (h) Apple Siri\nFigure 15: The results of subjective tests for the top-11∼20 fuzzy words. The perceptual dissimilarity between fuzzy wordsand the real wake-up words ranges from 1 (very similar) to 5 (very dissimilar). The commonality of a fuzzy word in daily liferanges from 1 (not common) to 5 (very common).\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1877A.6 Understanding Fuzzy Word\n\u0002\n\b\t\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0004\u0007\u0006\n\u0011\f\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013 \u0003\r\u0012\u0001\u000f\n\f\n\u000b\u0005\u000e\n\u0010\u0013\n(a) Xiaomi (b) Tencent (c) Echo Dot (d) Apple Siri\nFigure 16: Black-box explanation for private wake-up word detectors of commercial voice assitants. The contributions of\ndecisive factors at different positions of the real wake-up word for Xiaomi, Tencent, Echo Dot, and Apple Siri. The legendHigh-similarity referstodecisivefactorsthatarephoneticallysimilartotheircounterpartsintherealwake-upword. Medium-\nsimilarity andLow-similarity are defined accordingly.\n\u0004\u000f\f\r\u0002 \u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \n\u000b\n\u0001\u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \u0003\u0006\u0010\u0006\n\r\b\u000e\u0006\t\n\u0002 \u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r \n\u000b\n\u0001\u0007\u000f\u0013\u0013\u0012\u0011\u000b\f\u0005\r\n(a) Xiaomi (b) Tencent (c) Echo Dot (d) Apple Siri\nFigure 17: The distribution of dissimilarity between fuzzy-words/non-fuzzy-words and real wake-up words for Xiaomi, Ten-cent, Echo Dot, and Apple Siri. Both fuzzy words and non-fuzzy words have similar distribution of Levenshtein distance, buthave distinctively different distributions of our proposed dissimilarity score.\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1878A.7 Real Human Audio of Fuzzy Words\nTable 4: Wake-up rate of fuzzy words spoken by real humans for Chinese voice assistants. The column w.ratepresents the\nmean wake-up rate of a fuzzy word across 30 volunteers. The highest and the lowest wake-up rates are highlighted in bold.\nBaidu w.rate Xiaomi w.rate AliGenie w.rate Tencent w. rate\nxi¯ao dù xi¯ao dù 0.69 qiˇao¯an ch¯ou sè 0.12 tián móu q ¯ıng líng 0.65 ji¯ao sì èr l¯ıng 0.67\nxiào dù xiào dù 0.57 qi¯ao ài d¯ong qíng 0.13 tiˇan m¯ao jˇıng lˇıng 0.68 ji¯ao sì èr lín 0.68\nxiˇao d¯ux iˇao d¯u 0.63 qiàng¯ai ch¯ou lè 0.04 tián m¯ao jˇıng níng 0.66 ji¯ao s¯ı ér líng 0.67\nxiáo d¯u xiáo d¯u 0.57 qiào¯ai d¯ong sè 0.25 tiˇan m¯ao qín l¯ın 0.61 jiˇong sˇı èr líng 0.49\nxi¯ao dú xi¯ao dú 0.48 piˇao¯ai d¯ong rè 0.28 tián móu jìng líng 0.60 ji¯ao sˇı ér líng 0.57\nxi¯ong dù xi ¯ong dù 0.11 qi¯ao¯ai d¯ou sè 0.16 tiˇan mào jˇın lìn 0.54 ji¯ao sì èr lìn 0.54\nsh¯ao dù sh¯ao dù 0.46 qi¯ao¯an d¯ong sè 0.04 tián máo j ˇıng lˇıng 0.66 jiˇong sì èr lín 0.53\nxiáo dù xiáo dù 0.71 qiˇao¯adˇong sà 0.06 di¯an máo jˇıng lˇıng0.80 jiˇong sì èr líng 0.55\nsh¯ao dú sh¯ao dú 0.30 qiˇang¯an d¯ou sè 0.05 diˇan m¯ao jìng níng 0.69 jiˇong sì èr l ¯ın 0.56\npiˇao dù piˇao dù 0.56 qi¯ao¯an d¯ong s¯ı 0.04 tiˇan mˇao jìng lìn 0.58 jiˇong sˇı èr líng 0.49\nxi¯ong d¯ux i¯ong d¯u 0.22 piˇao¯an ch¯ong sè 0.09 tián m¯ao qìng l¯ın 0.71 jiˇong sˇı èr lìng 0.51\nxi¯ao dˇux i¯ao dˇu 0.44 qiào¯an d¯ou shè 0.05 di¯an m¯ao j¯ın l¯ın 0.77 jiˇong sì ér líng 0.55\nxiòng dˇu xiòng d ˇu0.04 qiào¯ai d¯ong gè 0.10 diˇan máo j¯ın lín 0.74 jiˇong sè èr líng 0.36\ntiˇao dù tiˇao dù 0.56 qiào¯an d¯ou lè 0.03 diˇan máo jˇıng lˇıng 0.72 jiˇong sì èr liáo 0.35\nxiˇao dòng xi ˇao dòng 0.60 qiàng¯ai d¯ong sàng 0.08 tián mào j ¯ıng lˇıng 0.58 jiˇong sì èr l ˇıng 0.52\nxiáo dˇu xiáo dˇu 0.57 qiˇao¯ai d¯ou sè 0.35 diˇan mˇao qí níng 0.23 jiˇong sì èr l ¯ıng 0.55\nxiˇao dú xiˇao dú 0.54 qiˇang¯ai g¯ong lè 0.04 diˇan m¯ao jˇıng níng 0.62 jiˇong sì ěr líng 0.51\ntiˇao d¯ou tiˇao d¯ou 0.25 qiˇao¯an g¯ong tè 0.04 tiˇan máo jìng lèng 0.52 jiˇong zì èr líng 0.08\nxi¯ao d¯ou xi¯ao d¯ou 0.50 piˇao¯ai d¯ou lè 0.08 tiàn móu jìn líng 0.52 jiˇong shì ěr líng 0.07\nqiˇao d¯ou qiˇao d¯ou 0.27 qi¯ao¯ai d¯ong sè 0.40 ti¯an mi¯ao jìng lˇıng 0.46 jiˇong sì ěr l ¯ıng 0.27\nTable 5: Wake-up rate of fuzzy words spoken by real humans for English voice assistants.\nAmazon Echo w.rate Echo Dot w.rate Google w.rate Apple Siri w. rate\nilexsar 0.35 ileqsar 0.26 heii gugal 0.56 hey sirr e 0.17\nilexca 0.19 urlexca 0.10 hei goooar 0.51 hay sere e 0.20\nilekhsa 0.66 ileqci 0.10 heiy googourl 0.34 hey scirih 0.30\nileksca 0.06 erleksa 0.32 hei googala 0.78 hay syrrie e 0.10\nallexsa 0.65 ileccsa 0.31 hey googal c 0.81 hay syrieqe 0.18\nilekssa 0.59 alexsua 0.11 heii googal 0.75 hay cieri 0.00\narleksa 0.57 aqlecsa 0.06 haii gugal 0.57 hai sirie 0.00\nalebsa 0.84 alelksa 0.80 hey googau 0.64 hay sciria 0.23\nalecqsa 0.78 ilekssa 0.48 haii googal 0.49 hey sori 0.00\nilexcer 0.33 blebssa 0.46 hey googav 0.61 hay surie 0.07\nilexsur 0.24 aleqpsa 0.82 heay gugal 0.43 hey sierie 0.26\nurlecsa 0.47 hleqsaa 0.19 hei googal l 0.43 hay psyrria 0.16\nilexqa 0.03 alexci 0.07 heii gugull 0.35 hay scirih 0.29\nalexsib 0.41 arleqsr 0.44 hei googal a 0.71 heiy suree 0.15\nilekcsa 0.59 ileksar 0.15 heiy gugourl 0.43 hei ssoree 0.25\nilexssa 0.11 alexser 0.21 he googal 0.65 hai sciri 0.00\nileqsaa 0.25 ilefksa 0.20 heiy googall 0.49 heai serea 0.00\ndpecssa 0.34 urleqsa 0.34 hay gugal 0.74 hay ssirib 0.13\nilexsa 0.43 ilexca 0.43 hey gooogov a 0.46 hey ssire 0.00\nalexssa 0.35 arlesca 0.47 hei googll a 0.61 hey sserea 0.07\nA.8 Accuracy of Interpretable Model\nTable6:Predictionaccuracyoftheinterpretablemodelindifferentiatingfuzzywordsandnon-fuzzywords.Thecolumns AUC,\nFPRandFNRpresent the area under curve, false positive rate and false negative rate of the interpretable model.\nvoice assistant accuracy AUC FPR FNR voice assistant accuracy AUC FPR FNR\nBaidu 93.81% 92.62% 4.19% 22.22% Amazon Echo 87.65% 89.03% 6.17% 38.89%\nXiaomi 91.27% 94.52% 4.17% 29.10% Echo Dot 84.28% 87.39% 8.92% 44.31%\nAliGenie 87.09% 92.74% 11.15% 15.66% Google 92.35% 91.41% 3.49% 44.33%\nTencent 90.74% 92.31% 6.36% 39.82% Apple Siri 77.18% 55.43% 20.63% 59.38%\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1879A.9 Performance of Fuzzy Words in Conversations\nTable 7: Wake-up rate of fuzzy words spoken in real conversations for Chinese voice assistants. The column b.rate, m.rate,\nand e.ratepresent the wake-up rates of the 10 fuzzy words when inserted at the beginning, the middle and the end of the\nconversations, respectively.\nBaidu b.rate m.rate e.rate Xiaomi b.rate m.rate e.rate AliGenie b.rate m.rate e.rate Tencent b.rate m.rate e.rate\nxi¯ao dù xi¯ao dù 0.9 0.7 0.8 qiˇao¯an ch¯ou sè 1.0 0.5 0.9 tián móu q ¯ıng líng 1.0 0.9 0.8 ji¯ao sì èr l¯ıng 0.9 0.4 0.6\nxiào dù xiào dù 0.8 0.9 1.0 qi¯ao ài d¯ong qíng 1.0 0.6 0.8 tiˇan m¯ao jˇıng lˇıng 1.0 1.0 1.0 ji¯ao sì èr lín 1.0 0.8 1.0\nxiˇao d¯ux iˇao d¯u 1.0 0.7 0.6 qiàng¯ai ch¯ou lè 0.8 0.8 0.7 tián m¯ao jˇıng níng 1.0 1.0 1.0 ji¯ao s¯ı ér líng 1.0 0.6 0.6\nxiáo d¯u xiáo d¯u 1.0 1.0 0.8 qiào¯ai d¯ong sè 0.6 0.5 0.7 tiˇan m¯ao qín l¯ın 1.0 0.8 0.8 jiˇong sˇı èr líng 0.9 1.0 1.0\nxi¯ao dú xi¯ao dú 0.8 0.7 1.0 piˇao¯ai d¯ong rè 0.7 0.8 1.0 tián móu jìng líng 0.9 0.6 1.0 ji¯ao sˇı ér líng 0.8 0.6 0.7\nxi¯ong dù xi ¯ong dù 1.0 0.9 0.6 qi¯ao¯ai d¯ou sè 0.9 0.7 0.6 tiˇan mào jˇın lìn 1.0 1.0 1.0 ji¯ao sì èr lìn 1.0 1.0 0.8\nsh¯ao dù sh¯ao dù 0.8 0.7 0.9 qi¯ao¯an d¯ong sè 0.7 1.0 0.8 tián máo j ˇıng lˇıng 1.0 1.0 0.9 jiˇong sì èr lín 0.8 0.7 1.0\nxiáo dù xiáo dù 0.5 0.4 0.6 qiˇao¯adˇong sà 0.7 0.6 0.9 di¯an máo jˇıng lˇıng 1.0 0.6 0.7 jiˇong sì èr líng 1.0 0.6 0.8\nsh¯ao dú sh¯ao dú 0.7 0.6 0.9 qiˇang¯an d¯ou sè 0.6 0.7 1.0 diˇan m¯ao jìng níng 0.8 1.0 1.0 jiˇong sì èr l ¯ın 1.0 0.9 0.7\npiˇao dù piˇao dù 0.6 0.7 0.6 qi¯ao¯an d¯ong s¯ı 0.7 0.4 0.3 tiˇan mˇao jìng lìn 0.8 0.7 1.0 jiˇong sˇı èr líng 1.0 1.0 1.0\nTable 8: Wake-up rate of fuzzy words spoken in real conversations for English voice assistants.\nAmazon Echo b.rate m.rate e.rate Echo Dot b.rate m.rate e.rate Google b.rate m.rate e.rate Apple Siri b.rate m.rate e.rate\nilexsar 1.0 0.7 0.8 ileqsar 0.8 0.6 0.5 heii gugal 1.0 0.6 0.7 hey sirr e 0.7 0.8 0.5\nilexca 1.0 0.7 0.6 urlexca 0.7 0.5 1.0 hei goooar 1.0 1.0 1.0 hay sere e 1.0 0.9 0.7\nilekhsa 0.8 0.9 0.8 ileqci 0.8 0.8 0.6 heiy googourl 1.0 0.4 0.5 hey scirih 0.6 0.3 0.4\nileksca 0.8 0.5 1.0 erleksa 0.9 0.6 0.4 hei googala 1.0 1.0 0.8 hay syrrie e 0.7 0.4 0.8\nallexsa 1.0 0.8 1.0 ileccsa 0.6 1.0 1.0 hey googal c 0.7 0.9 0.5 hay syrieqe 1.0 0.5 1.0\nilekssa 0.6 0.8 0.9 alexsua 0.8 0.5 0.4 heii googal 0.9 1.0 1.0 hay cieri 0.6 0.2 0.3\narleksa 1.0 0.9 0.6 aqlecsa 0.7 1.0 0.8 haii gugal 1.0 1.0 0.7 hai sirie 0.5 0.1 0.4\nalebsa 0.8 1.0 0.5 alelksa 0.6 0.8 0.7 hey googau 1.0 0.9 1.0 hay sciria 1.0 0.5 1.0\nalecqsa 1.0 0.6 0.8 ilekssa 1.0 0.9 0.6 haii googal 0.8 1.0 0.9 hey sori 0.6 0.7 1.0\nilexcer 0.8 0.8 0.7 blebssa 1.0 0.7 0.5 hey googav 0.6 0.3 0.5 hay surie 0.9 0.6 0.8\nA.10 Decisive Factors\nTable 9: Fraction of fuzzy words containing decisive factors. The column top-npresents the proportion of fuzzy words that\ncomprise at least one of the top-n decisive factors with the highest contribution.\ntop-1 top-2 top-3 top-1 top-2 top-3\nEcho 85.61% 89.90% 90.71% Baidu 68.75% 84.38% 100.00%\nEcho Dot 83.74% 88.99% 88.93% Xiaomi 65.74% 95.37% 95.37%\nGoogle 90.72% 90.72% 100.00% AliGenie 62.73% 97.52% 99.69%\nApple 92.19% 92.19% 96.88% Tencent 72.62% 72.62% 97.62%\nA.11 Mitigating Fuzzy Words\nTable 10: Mitigation results of Computer and Athena\nWake-up Evaluation Original Strengthened Wake-up Evaluation Original Strengthened\nword metric model model word metric model model\nComputerFalse Positive rate 0.00% 0.00%\nAthenaFalse Positive rate 1.37% 0.88%\nFalse negative rate 5.00% 0.00% False negative rate 1.04% 1.04%\nDetection accuracy 97.96% 100% Detection accuracy 98.73% 99.07%\nFuzzy rate 10.04% 0.02% Fuzzy rate 17.67% 1.18%\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1880A.12 Full List of Fuzzy Words\nTable 11: Fuzzy words of Baidu. The column dis.presents the dissimilarity distance according to the generation algorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate. Note that dissimilarity distances\nsmaller than 0.005 are rounded up to 0.00.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\nxiˇao lˇong xiˇao lˇong 0.30 0.2 piˇao dòu pi ˇao dòu 0.22 0.1 tiˇao d¯ou tiˇao d¯ou 0.19 0.6 tiˇao dòng ti ˇao dòng 0.19 0.2 sh¯ao d¯ou sh¯ao d¯ou 0.16 0.2\njiˇao d¯ou jiˇao d¯ou 0.15 0.4 qiáo d¯ou qiáo d ¯ou 0.15 0.3 qiˇao d¯ou qiˇao d¯ou 0.15 0.5 qiˇao dòng qi ˇao dòng 0.15 0.2 xi¯ao d¯ou xi¯ao d¯ou 0.14 0.5\nxiáo d¯ou xiáo d ¯ou 0.14 0.5 xiào dòng xiào dòng 0.14 0.2 xiˇao dòng xi ˇao dòng 0.14 0.7 xiˇao dòu xi ˇao dòu 0.14 0.4 x¯ıng dˇux¯ıng dˇu 0.13 0.3\nxìng dú xìng dú 0.13 0.2 xi¯ed ùx i¯e dù 0.08 0.1 piˇao dú piˇao dú 0.08 0.3 piˇao dù piˇao dù 0.08 0.7 tiˇao dù tiˇao dù 0.05 0.7\nxi¯ong d¯ux i¯ong d¯u 0.04 0.7 xi¯ong dù xi ¯ong dù 0.04 0.8 xiòng dˇu xiòng d ˇu 0.04 0.7 qiˇao bù qiˇao bù 0.03 0.1 xiˇao bù xiˇao bù 0.03 0.3\nxiˇao lˇux iˇao lˇu 0.03 0.3 xiˇao lù xiˇao lù 0.03 0.4 xiˇao nù xiˇao nù 0.02 0.2 sh¯ao d¯us h¯ao d¯u 0.01 0.4 sh¯ao dú sh¯ao dú 0.01 0.7\nsh¯ao dù sh¯ao dù 0.01 0.7 xiá dù xiá dù 0.01 0.3 xiˇad¯ux iˇad¯u 0.01 0.2 xiˇad ùx iˇa dù 0.01 0.5 xiàn dˇu xiàn dˇu 0.01 0.1\nxiàng dˇu xiàng d ˇu 0.01 0.2 xiáng dˇu xiáng d ˇu 0.01 0.1 xiáng dù xiáng dù 0.01 0.2 xiˇan dù xiˇan dù 0.01 0.3 xiˇang d¯ux iˇang d¯u 0.01 0.3\nxiˇang dù xi ˇang dù 0.01 0.5 jiˇao dù jiˇao dù 0.01 0.2 qi¯ao dú qi¯ao dú 0.01 0.1 qi¯ao dù qi¯ao dù 0.01 0.2 qiáo dˇu qiáo dˇu 0.01 0.1\nqiáo dù qiáo dù 0.01 0.5 qiˇao d¯uq iˇao d¯u 0.01 0.3 qiˇao dú qiˇao dú 0.01 0.3 qiˇao dù qiˇao dù 0.01 0.4 xi¯ao d¯ux i¯ao d¯u 0.00 0.3\nxiáo d¯u xiáo d¯u 0.00 0.8 xi¯ao dú xi¯ao dú 0.00 0.8 xiˇao d¯ux iˇao d¯u 0.00 0.8 xi¯ao dˇux i¯ao dˇu 0.00 0.7 xiào dú xiào dú 0.00 0.5\nxiáo dú xiáo dú 0.00 0.4 xi¯ao dù xi¯ao dù 0.00 0.9 xiáo dˇu xiáo dˇu 0.00 0.6 xiˇao dú xiˇao dú 0.00 0.6 xiào dˇu xiào dˇu 0.00 0.4\nxiào dù xiào dù 0.00 0.9 xiáo dù xiáo dù 0.00 0.7 xiˇao dˇux iˇao dˇu 0.00 0.3 -- - -- -\nTable 12: Fuzzy words of Xiaomi. The column dis.presents the dissimilarity distance according to the generation algorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate. Note that dissimilarity distances\nsmaller than 0.005 are rounded up to 0.00.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\nqiˇao b¯ai d¯ong hè 0.33 0.9 qi¯ang b¯ai d¯ong sè 0.29 1 qiào b¯ai t¯ou shè 0.27 0.9 qi¯ao c¯ai d¯ong sè 0.27 1 xi¯ao c¯ai d¯ong sè 0.27 1\nqi¯ao¯ed¯u sè 0.19 1 qi¯ao¯ai d¯u sè 0.15 1 qiàng¯ai d¯ong sàng 0.11 1 qiàng¯ai ch¯ou lè 0.11 1 qiˇao¯adˇong sà 0.11 1\nqi¯ao¯an dˇong sˇang 0.11 0.1 qiˇao¯an d¯ong sàng 0.11 1 qiˇao¯an dˇong sˇang 0.11 0.6 qiˇao¯ang d¯ou s¯ao 0.10 0.9 qi¯ao¯an d¯ong sào 0.10 0.9\nqi¯ao¯ai d¯ong sàng 0.10 1 qi¯ao¯ai d¯ou sào 0.10 1 qiˇao¯ai d¯ou sào 0.10 1 qi¯ao¯ao d¯ong sào 0.09 0.1 qi¯ao¯ai d¯ong sào 0.09 1\nqi¯ang¯ai ch¯ou sè 0.09 1 piˇao¯an ch¯ong sè 0.08 1 piˇao¯ai d¯ou lè 0.08 1 qiˇao¯an g¯ong tè 0.08 1 qi¯ao¯an ch¯ou sè 0.08 1\nqiˇao¯an ch¯ou sè 0.08 1 qi¯a¯ai duàn jiě 0.08 0.1 qiào¯ai d¯ong gè 0.08 1 piˇao¯ai d¯ong rè 0.08 1 qiˇao¯ai d¯ou tè 0.07 0.8\nqiˇao¯ai gòng jìn 0.07 0.1 qi¯ao¯an d¯ong s¯ı 0.06 1 pi¯ao¯an d¯ong sè 0.06 1 qiˇang¯ai g¯ong lè 0.06 1 piào¯ai d¯ou sè 0.06 0.2\nqi¯ao¯ai dòng jìn 0.06 0.1 qiáo¯ai dòng jìn 0.06 0.1 qiào¯ai d¯ong jìn 0.06 0.9 qiào¯ai t¯ou qìng 0.06 0.8 qi¯ao¯en d¯ong sè 0.06 1\nqi¯ao¯ai g¯ou rè 0.06 1 piˇao¯ai g¯ong sè 0.06 1 qi¯ao ài d¯ong qíng 0.06 1 qiào¯an d¯ou lè 0.06 1 qiˇao¯an d¯ou lè 0.06 0.8\nqiˇao¯ad¯ou lè 0.06 1 qiˇao¯an g¯ong nè 0.06 0.1 piào¯ai d¯ong shè 0.06 0.8 pi¯ao¯ai d¯ong sè 0.05 1 piào¯ai d¯ong sè 0.05 0.8\npiˇao¯ai d¯ong sè 0.05 1 qiˇao¯an d¯ong nè 0.05 0.7 qi¯ao¯an d¯ong rè 0.05 0.7 qiˇang¯an d¯ou sè 0.05 1 qi¯ao¯an d¯ong rě 0.05 0.6\nqiào¯an ch¯ong sè 0.05 0.4 qiào¯ai g¯ong rè 0.05 0.9 qiˇang¯an d¯ong sè 0.04 0.6 qi¯ao¯ai d¯ong rè 0.04 1 t i àoà id¯ong shè 0.04 0.1\nqi¯ao¯ai ch¯ong sè 0.04 1 qiào¯ai ch¯ong sè 0.04 1 xiào¯ai dòng rè 0.04 0.3 xi¯ao¯ai c¯ong sè 0.04 1 qiào¯an d¯ou shè 0.04 1\nqiˇao¯an d¯ou shè 0.04 0.9 qi¯ao¯an d¯ou sè 0.04 0.1 qiˇao¯an d¯ou sè 0.04 0.9 qiˇao¯ad¯ou sè 0.04 1 qi¯ang¯ai d¯ong sè 0.04 0.9\nxi¯ao¯ai c¯ong jiè 0.03 1 qi¯ao¯ai gòu jiè 0.03 0.1 qi¯ao¯an d¯ong sè 0.03 1 qi¯ao¯ad¯ong sè 0.03 0.9 qiào¯an d¯ong sè 0.03 0.5\nqiˇao¯an d¯ong sè 0.03 1 qiào¯ai d¯ou shè 0.03 1 q i àoà id¯ou shè 0.03 0.8 qi¯ao¯ai d¯ou sè 0.03 1 qiào¯ai d¯ou sè 0.03 0.9\nqiˇao¯ai d¯ou sè 0.03 1 xiào¯an d¯ong sè 0.03 1 xi¯ao¯ad¯ong sè 0.03 1 qi¯ao¯ai g¯ong sè 0.02 1 qiˇao¯ao d¯ong shè 0.02 1\nqi¯ao¯ai d¯ou jiè 0.02 0.2 qi¯ao¯ai t¯ou sè 0.02 1 qi¯ao¯ai d¯ong shè 0.02 1 q i àoà id¯ong shè 0.02 0.3 qi¯ao¯ai g¯ong jiè 0.02 0.9\nqi¯ao¯ai dòng sè 0.02 0.5 qi¯ao¯ai gòng jiě 0.02 0.4 qiào¯ai dòng sè 0.02 1 qi¯ao¯ai d¯ong sè 0.02 1 qiào¯ai d¯ong sè 0.02 1\nqiˇao¯ai d¯ong sè 0.02 1 qi¯ao¯ai d¯ong shèng 0.02 1 xi¯ao¯ai gòng jiè 0.02 0.1 xiˇao¯ai gòng jiè 0.02 0.1 xi¯ao¯ai d¯ong sè 0.02 1\nxiáo¯ai d¯ong sè 0.02 1 qi¯ao¯ai dòng jiè 0.02 0.1 qiáo¯ai dòng jiè 0.02 0.5 qi¯ao¯ai d¯ong jiè 0.02 1 qiào¯ai d¯ong jiè 0.02 0.1\nxiˇao¯ai dòng jiè 0.01 0.2 xi¯ao¯ai d¯ong jiè 0.01 1 xiˇao¯ai d¯ong jiè 0.01 1 -- - -- -\nTable 13: Fuzzy words of Tencent. The column dis.presents the dissimilarity distance according to the generation algorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\nji¯ong niào èr líng 0.15 0.3 jˇın sì ào líng 0.09 0.1 ji¯ong sì èr lián 0.08 0.1 jiˇong shì èr lián 0.08 0.2 jiˇong sì èr lián 0.08 1\njiˇong sì èr liáng 0.08 0.3 jiˇong zì èr liáo 0.07 0.9 ji¯ong sì èr mín 0.07 0.1 jiˇong sì èr mín 0.07 0.3 jiˇong sì èr li ¯ao 0.07 0.3\njiˇong sì èr liáo 0.07 1 jiˇong sì èr lóng 0.05 0.2 ji¯ong sì àng líng 0.05 0.1 jiˇong shè èr l ¯ın 0.05 0.8 jiˇong shè èr líng 0.05 0.1\njˇu sì èr lín 0.05 0.1 jˇın sì èr líng 0.05 0.2 jˇıng sì èr líng 0.05 0.3 jiˇong sì ài lín 0.05 1 jiˇong sì ài líng 0.05 1\njiˇong sì èr míng 0.04 0.7 jiˇong tì èr líng 0.03 0.1 jiˇong sè èr lín 0.03 1 ji¯ong sè èr líng 0.03 0.5 jiˇong sè èr l ¯ıng 0.03 1\njiˇong sè èr líng 0.03 1 ji¯ang sì èr líng 0.02 0.5 ji¯e sì èr líng 0.02 0.4 jiˇang sì èr líng 0.02 0.1 jiě sì èr líng 0.02 0.4\nji¯ao sh¯ıè rl¯ın 0.02 0.4 ji¯ao sì èr níng 0.02 0.9 ji¯ao s¯ı èr lìn 0.02 0.4 ji¯ao sì èr lìn 0.02 1 ji¯ao s¯ı èr lín 0.02 0.1\nji¯ao sˇı èr lín 0.02 0.2 ji¯ao sì èr lín 0.02 1 ji¯ao s¯ı ér líng 0.02 1 ji¯ao s¯ı èr lìng 0.02 0.1 ji¯ao s¯ıè rlˇıng 0.02 0.7\nji¯ao sˇı ér líng 0.02 1 ji¯ao sˇı èr lìng 0.02 0.2 ji¯ao sì èr lìng 0.02 0.9 ji¯ao sˇıè rlˇıng 0.02 0.8 ji¯ao sì èr l¯ıng 0.02 1\nji¯ao sˇı èr líng 0.02 0.5 ji¯ao sì èr líng 0.02 0.9 jiˇao sˇı èr líng 0.02 0.2 jiˇong zì èr líng 0.01 1 jiˇong qì èr líng 0.01 0.1\njiˇong sì èr lí 0.01 1 ji¯ong sì èn líng 0.01 0.3 ji¯ong sì èr níng 0.01 0.1 jiˇong sˇı èr níng 0.01 0.2 jiˇong sì è líng 0.01 0.4\njiˇong sì èr níng 0.01 0.3 jiˇong shì èr l ¯ın 0.01 0.5 ji¯ong sˇı èr lín 0.01 0.3 jiˇong shì èr lín 0.01 0.2 jiˇong sì èr l ¯ın 0.01 1\njiˇong sh¯ı èr líng 0.01 0.5 jiˇong sì ěr lín 0.01 1 jiˇong sˇı èr lín 0.01 0.9 jiˇong sì èr lín 0.01 1 ji¯ong sˇı èr lìng 0.01 0.3\nji¯ong sì èr lìng 0.01 0.5 ji¯ong sì ér líng 0.01 0.4 ji¯ong sì èr l ¯ıng 0.01 0.4 ji¯ong sì èr l ˇıng 0.01 0.3 ji¯ong sˇı èr líng 0.01 0.2\njiˇong shì ěr l ¯ıng 0.01 1 jiˇong shì ěr líng 0.01 1 jiˇong shì èr l ˇıng 0.01 0.4 jiˇong shì èr l ¯ıng 0.01 0.1 jiˇong shì èr líng 0.01 0.4\njiˇong s¯ı èr líng 0.01 1 jiˇong sˇı èr lìng 0.01 1 jiˇong sì ér líng 0.01 1 jiˇong sì ěr l ¯ıng 0.01 1 jiˇong sˇı èr líng 0.01 1\njiˇong sì èr l ˇıng 0.01 1 jiˇong sì èr l ¯ıng 0.01 1 jiˇong sì ěr líng 0.01 1 jiˇong sì èr líng 0.01 1 -- -\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1881Table14:FuzzywordsofAliGenie.Thecolumn dis.presentsthedissimilaritydistanceaccordingtothegenerationalgorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate. Note that dissimilarity distances\nsmaller than 0.005 are rounded up to 0.00.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\ny¯an m¯en j¯ıng líng 0.29 0.5 y¯an m¯ang j¯ıng líng 0.26 1 wán m¯ang j¯ıng líng 0.26 0.4 wáng mào j ˇıng lˇın 0.25 0.1 yán m¯ao j¯ıng lˇıng 0.25 0.9\ny¯an m¯ao j¯ıng líng 0.25 1 w¯an m¯ao j¯ıng líng 0.25 0.9 yán m¯ao j¯ıng líng 0.25 0.9 wán m¯ao j¯ıng líng 0.25 0.2 wáng m¯ao j¯ıng líng 0.25 0.1\ntián m¯en ji¯an lˇıng 0.11 0.7 tí m¯ao j¯ıng míng 0.10 1 t¯an n¯ao ji¯ao líng 0.10 0.4 táng m¯ao ji¯e liáo 0.09 0.1 tián h¯ao jˇıng mˇıng 0.08 0.7\nt¯an l¯ang j¯ıng líng 0.07 0.3 tàng mˇao ji¯an líng 0.07 0.2 tíng m¯ao jˇın líng 0.07 1 tˇim¯ao jìng lín 0.07 1 tán m¯ao ji¯an líng 0.07 0.4\nt¯an m¯ao j¯ıng lián 0.07 0.2 t¯an m¯ao j¯ıng liáng 0.07 0.4 tián m¯ao jiˇang lìng 0.07 0.4 tián m¯ao j¯ıng liˇan 0.07 1 tí máo j¯ıng líng 0.07 0.8\ntí m¯ao j¯ıng líng 0.07 1 t¯ıng m¯ao jˇıng lˇıng 0.07 1 tiˇan mào jìng liáng 0.07 1 ti1 m¯ao j¯ıng líng 0.07 1 sh¯ai m¯ao j¯ıng líng 0.07 0.6\nt¯an m¯ao j¯ıng liáo 0.07 0.1 ti¯an mˇao jìng liào 0.06 0.9 tián m¯ao ji¯ao lˇıng 0.06 0.2 tián m¯ao j¯ıng liáo 0.06 1 t¯ang p¯ao j¯ıng lìn 0.06 0.1\ntián pˇao jìng níng 0.06 1 tán lˇao jiě líng 0.06 0.1 t¯an p¯ao j¯ıng líng 0.06 0.1 shàng m¯ao jˇıng lˇıng 0.05 0.1 ti¯em¯aj¯ıng líng 0.05 1\nsh¯an m¯ao jˇıng lˇıng 0.05 0.2 sh¯an m¯ao j¯ıng líng 0.05 1 s¯an m¯ao jˇıng líng 0.05 1 s¯an m¯ao j¯ıng lˇıng 0.05 0.5 s¯an m¯ao j¯ıng líng 0.05 1\ntán h¯ao j¯ıng líng 0.05 0.1 t¯an h¯ao j¯ıng líng 0.05 0.1 t¯ang máo j ¯ıng niè 0.05 0.1 ti¯an k¯ao j¯ıng líng 0.05 1 teng1 m¯ao jˇıng lˇıng 0.05 1\nt¯an m¯ao ji¯ong líng 0.05 0.7 tián m¯ao jiˇong l¯ıng 0.05 0.8 tián m¯ao jiˇong líng 0.05 1 tián mào ji ¯ong lˇıng 0.05 1 tián m¯ao j¯ıng lóu 0.05 1\nz¯an m¯ao j¯ıng líng 0.04 1 tiˇan m¯en jˇıng lˇıng 0.04 0.5 tián m¯e jìng líng 0.04 1 ti¯an m¯ej¯ıng líng 0.04 1 di¯an m¯ao qí mìng 0.04 0.9\ntián l¯ao l¯ıng líng 0.04 0.3 tiˇan mie1 jˇıng l¯ıng 0.04 0.8 t¯an n¯ao j¯ıng níng 0.04 0.5 t¯an l¯ao j¯ıng níng 0.04 0.7 tán m¯ao j¯ın míng 0.03 0.2\ntá l¯ao j¯ıng líng 0.03 0.3 tiˇan nào jìng l ¯ın 0.03 0.9 tán l¯ao j¯ıng lˇıng 0.03 0.1 tán m¯ao j¯ıng míng 0.03 0.4 t¯an n¯ao jˇıng lˇıng 0.03 0.2\nt¯an n¯ao jìng líng 0.03 0.1 t¯an n¯ao j¯ıng líng 0.03 0.2 t¯an l¯ao jˇıng lˇıng 0.03 0.3 t¯an l¯ao j¯ıng líng 0.03 0.8 t¯an m¯ao j¯ıng míng 0.03 0.3\nti¯an l¯ao jˇıng l¯ın 0.03 1 tiˇan mˇao jìng mìng 0.03 1 tián n¯ao jˇıng lˇıng 0.03 1 tián n¯ao j¯ıng lˇıng 0.03 1 tián n¯ao j¯ıng líng 0.03 1\nti¯an n¯ao j¯ıng líng 0.03 1 tiˇan l¯ao jˇıng lìng 0.03 1 tiˇan m¯ao jˇıng míng 0.03 1 tián m¯ao jˇıng míng 0.03 1 tián l¯ao j¯ıng lˇıng 0.03 1\ntián l¯ao j¯ıng líng 0.03 1 ti¯an m¯ao j¯ıng míng 0.03 1 ti¯an l¯ao j¯ıng líng 0.03 1 rán m¯ao j¯ıng lˇıng 0.03 0.6 rán m¯ao j¯ıng líng 0.03 0.7\nxiˇan miáo j ˇıng lˇıng 0.03 0.1 tán m¯ao ji¯e lín 0.03 0.4 t¯an m¯ao jiě lˇıng 0.03 0.4 táng mào ji ¯elˇıng 0.03 0.2 tán m¯ao ji¯e líng 0.03 0.5\ntiˇan mào jˇın liè 0.03 1 t¯an m¯ao ji¯e líng 0.02 0.7 tián mào ji ¯elˇın 0.02 1 tiˇan m¯ao mˇıng líng 0.02 0.2 tián mào jiě l ˇıng 0.02 1\ntián mˇao jˇıng liě 0.02 1 tián m¯ao jˇıng liě 0.02 1 tiˇan máo jìng lèng 0.02 1 tián m¯ao jìng lèng 0.02 0.5 tiàn m¯ao dˇıng lˇıng 0.02 1\ntián móu qìng líng 0.02 1 tiˇan móu jìng níng 0.02 1 tiàn móu jìn líng 0.02 1 tián móu jìng líng 0.02 1 pian2 m¯ao jˇıng líng 0.01 1\ndi¯an miào n ìng líng 0.01 0.2 tài mào jìng lín 0.01 0.3 tián máo l ¯ıng níng 0.01 0.3 t¯ai m¯ao j¯ıng lín 0.01 0.4 diˇan mˇao qí nˇıng 0.01 0.4\ndiˇan mˇao qí níng 0.01 1 t¯ai m¯ao jˇıng lˇıng 0.01 0.5 t¯ai m¯ao jˇıng líng 0.01 0.8 t¯ai m¯ao j¯ıng líng 0.01 0.1 tián m¯ao l¯ıng lˇıng 0.01 0.2\nti¯an m¯ao qí nìng 0.01 0.9 di¯an máng j ˇın líng 0.01 1 ti¯an miáo qín l ˇın 0.01 0.2 ti¯an miˇao qín lín 0.01 0.1 tián m¯ang jˇıng nˇıng 0.01 1\nt¯an m¯ang jˇıng lˇıng 0.01 0.2 di¯an m¯ang jˇıng líng 0.01 1 t¯an m¯ang jˇıng líng 0.01 0.4 t¯an m¯ang j¯ıng líng 0.01 0.6 tiao2 m¯ao j¯ıng líng 0.01 0.2\nt¯an m¯an j¯ıng líng 0.01 0.4 t¯ao m¯ao jˇıng lˇıng 0.01 0.1 t¯ao m¯ao j¯ıng líng 0.01 0.1 diˇan mào qín l ¯ın 0.01 0.7 t¯an m¯ajˇıng lˇıng 0.01 0.2\ndiˇan mào qín lín 0.01 0.7 tián m¯ang jˇıng lˇıng 0.01 1 tián m¯ang j¯ıng líng 0.01 1 ti¯an m¯ang j¯ıng l¯ıng 0.01 1 ti¯an m¯ang j¯ıng líng 0.01 1\ntiˇan m¯an jìng lìng 0.00 1 tián m¯an jìng lìng 0.00 0.9 tiˇan m¯an j¯ıng lìng 0.00 1 tián m¯an j¯ıng líng 0.00 1 tiˇan m¯ao qˇın lˇın 0.00 1\ntián m¯aj¯ıng líng 0.00 1 tiˇan m¯ao qín l¯ın 0.00 1 diˇan miáo j ˇın líng 0.00 0.1 di¯an miào j ˇın líng 0.00 0.3 tiˇan máo q¯ın lín 0.00 1\ntián mào q ˇın lˇıng 0.00 1 di¯an miào jìng lín 0.00 0.3 di¯an miào j ˇıng lín 0.00 0.3 tiˇan miˇao j¯ın níng 0.00 0.6 di¯an mi¯ao jˇın lˇıng 0.00 0.4\ntián m¯ao jìng nín 0.00 1 tˇang miáo jìng l ˇıng 0.00 0.1 tˇang mi¯ao jˇıng líng 0.00 0.1 diˇan m¯ao qíng lín 0.00 1 di¯an miào j ˇıng líng 0.00 0.5\nti¯an mi¯ao j¯ın lìn 0.00 0.9 tˇan m¯ao jìn lˇın 0.00 0.1 tán m¯ao j¯ın níng 0.00 0.2 di¯an mi¯ao jìng líng 0.00 0.8 ti¯an m¯ao qˇıng nìng 0.00 1\ndiˇan mào qíng líng 0.00 0.7 ti¯an miˇao jˇıng lˇın 0.00 0.1 diˇan m¯ao qíng líng 0.00 1 ti¯an miáo jìng l ¯ın 0.00 0.5 t¯ang m¯ao j¯ın lˇın 0.00 0.6\ndiˇan m¯ao jìng níng 0.00 1 diˇan m¯ao jˇıng níng 0.00 1 diˇan máo j¯ın lín 0.00 1 tàng m¯ao jˇın líng 0.00 0.6 t¯ang m¯ao j¯ıng níng 0.00 0.7\nt¯an m¯ao jˇıng nˇıng 0.00 0.5 tán m¯ao j¯ıng níng 0.00 0.2 di¯an m¯ao j¯ın l¯ın 0.00 1 t¯an m¯ao j¯ıng níng 0.00 0.6 ti¯an mi¯ao j¯ıng lín 0.00 1\ntáng m¯ao jˇın líng 0.00 0.3 tián m¯ao qìng l¯ın 0.00 1 t¯ang mˇao jˇıng lìn 0.00 0.2 tiˇan miào jìng líng 0.00 0.1 tián m¯ao jˇın nˇıng 0.00 1\ntán m¯ao jˇın líng 0.00 0.5 táng m¯ao j¯ın líng 0.00 0.3 t¯ang mˇao j¯ıng lˇın 0.00 0.6 t¯ang m¯ao jˇıng lˇın 0.00 0.6 tián mào qíng l ¯ın 0.00 1\ntán m¯ao j¯ıng lˇın 0.00 0.1 ti¯an m¯ao qˇıng lín 0.00 1 di¯an máo jˇın lˇıng 0.00 1 tián m¯ao jˇın níng 0.00 1 t¯an m¯ao jˇın lˇıng 0.00 0.6\ntiˇan miáo jìng l ˇıng 0.00 0.1 tán m¯ao j¯ın l¯ıng 0.00 0.3 tán m¯ao j¯ıng lín 0.00 0.2 di¯an máo jˇıng lˇın 0.00 1 t¯an m¯ao jˇıng lˇın 0.00 0.3\ntá m¯ao j¯ıng l¯ıng 0.00 0.4 tiˇan mi¯ao jˇıng l¯ıng 0.00 0.9 tián mi¯ao jˇıng lìng 0.00 0.4 tiˇan mi¯ao jˇıng lˇıng 0.00 0.2 ti¯an mi¯ao jìng lˇıng 0.00 1\ntián mi¯ao jìng líng 0.00 0.2 tián mi¯ao jˇıng líng 0.00 0.4 tiˇan mi¯ao j¯ıng lˇıng 0.00 0.1 tián mi¯ao j¯ıng líng 0.00 0.6 t¯an m¯ao j¯ıng lín 0.00 0.7\nt¯an m¯ao j¯ın líng 0.00 0.4 ti¯an mi¯ao j¯ıng líng 0.00 1 tiˇan mào jˇın lìn 0.00 1 tiˇan mˇao jˇın lìn 0.00 1 t¯am¯ao jˇıng líng 0.00 0.2\nt¯am¯ao j¯ıng líng 0.00 0.3 tˇang m¯ao jìng lˇıng 0.00 0.1 tˇang m¯ao jìng líng 0.00 0.1 tˇang m¯ao j¯ıng líng 0.00 0.3 tiˇan mào jˇın lˇın 0.00 1\ntián mào qìng l ¯ıng 0.00 1 ti¯an mˇao qìng líng 0.00 1 táng mˇao jìng líng 0.00 0.2 táng m¯ao jìng lˇıng 0.00 0.1 táng máo j ˇıng lˇıng 0.00 0.1\ntáng mˇao j¯ıng lˇıng 0.00 0.1 táng m¯ao j¯ıng lˇıng 0.00 0.2 tiˇan mˇao jìng nìng 0.00 1 tián mˇao jìng nìng 0.00 1 tˇan mào j¯ıng lìng 0.00 0.1\ndiˇan máo jˇıng lˇıng 0.00 1 tˇan m¯ao jìng líng 0.00 0.2 tián m¯ao qˇıng líng 0.00 1 tˇan m¯ao j¯ıng líng 0.00 0.3 t¯ang mˇao jìng l¯ıng 0.00 0.6\nt¯ang m¯ao jìng lˇıng 0.00 0.6 t¯ang m¯ao jìng líng 0.00 0.7 t¯ang m¯ao jˇıng líng 0.00 0.2 t¯ang m¯ao j¯ıng líng 0.00 0.5 tán mào j ˇıng líng 0.00 0.1\ntán m¯ao jìng lˇıng 0.00 0.2 tán mˇao jˇıng líng 0.00 0.1 tán m¯ao jˇıng lˇıng 0.00 0.3 tán m¯ao jˇıng líng 0.00 0.3 tán m¯ao j¯ıng lˇıng 0.00 0.2\nti¯an mào j¯ın lˇın 0.00 1 tián máo j ¯ın l¯ın 0.00 1 di¯an máo jˇıng lˇıng 0.00 1 tián máo j ˇıng níng 0.00 1 tiˇan máo j¯ın lín 0.00 1\ntián m¯ao jˇıng níng 0.00 1 t¯an m¯ao jìng líng 0.00 0.7 t¯an m¯ao jˇıng lˇıng 0.00 0.1 di¯an m¯ao jˇıng líng 0.00 1 t¯an m¯ao jˇıng líng 0.00 0.4\ntián m¯ao j¯ıng níng 0.00 1 t¯an m¯ao j¯ıng lˇıng 0.00 0.6 t¯an m¯ao j¯ıng l¯ıng 0.00 0.4 ti¯an m¯ao j¯ıng níng 0.00 1 t¯an m¯ao j¯ıng líng 0.00 0.3\ntiˇan mˇao jìng lìn 0.00 1 tián mào j ˇıng lìn 0.00 1 ti¯an máo jˇıng lìn 0.00 1 tiˇan m¯ao jˇın lˇıng 0.00 1 tián m¯ao jˇın lˇıng 0.00 1\ntiˇan m¯ao j¯ıng lìn 0.00 1 tián m¯ao jˇın líng 0.00 1 tián mào jìng l ¯ın 0.00 1 tiˇan mˇao jˇıng lˇın 0.00 1 tián mˇao jìng lˇın 0.00 1\ntiˇan m¯ao jìng lˇın 0.00 1 tián máo j ˇıng l¯ın 0.00 1 ti¯an mˇao jˇıng lˇın 0.00 1 tiˇan mào jˇıng lín 0.00 1 ti¯an mào jˇıng lín 0.00 1\ntián máo j ˇıng lín 0.00 1 tiˇan máo j¯ın l¯ıng 0.00 1 tián m¯ao j¯ın líng 0.00 1 ti¯an m¯ao j¯ın líng 0.00 1 ti¯an m¯ao j¯ıng lín 0.00 1\ntiˇan mˇao jìng lìng 0.00 1 tiˇan mˇao jìng lˇıng 0.00 1 tiˇan mˇao jˇıng lìng 0.00 1 tián mào jìng l ˇıng 0.00 1 tiˇan mˇao jìng l¯ıng 0.00 1\ntián mào j ˇıng lˇıng 0.00 1 tián mˇao jìng l¯ıng 0.00 1 tián mˇao jìng lˇıng 0.00 1 tiàn m¯ao jˇıng lìng 0.00 1 tián m¯ao jìng lìng 0.00 1\ntiˇan m¯ao jˇıng lìng 0.00 1 tiˇan m¯ao jìng lˇıng 0.00 1 tián máo jìng l ¯ıng 0.00 1 tiˇan m¯ao jˇıng lˇıng 0.00 1 tián máo j ˇıng lˇıng 0.00 1\ntián mào j ¯ıng lˇıng 0.00 1 tiˇan m¯ao jˇıng l¯ıng 0.00 1 ti¯an mˇao jˇıng lˇıng 0.00 1 tián m¯ao jˇıng lìng 0.00 1 ti¯an mào jˇıng líng 0.00 1\ntián m¯ao jìng lˇıng 0.00 1 tián mˇao jˇıng líng 0.00 1 tiˇan m¯ao j¯ıng lìng 0.00 1 tián m¯ao jˇıng l¯ıng 0.00 1 tiˇan m¯ao jˇıng líng 0.00 1\ntián m¯ao jˇıng lˇıng 0.00 1 tián mˇao j¯ıng lˇıng 0.00 1 tián m¯ao jìng líng 0.00 1 tián m¯ao jˇıng líng 0.00 1 ti¯an m¯ao jˇıng lˇıng 0.00 1\ntián m¯ao j¯ıng lìng 0.00 1 tiˇan m¯ao j¯ıng l¯ıng 0.00 1 tiˇan m¯ao j¯ıng lˇıng 0.00 1 tián m¯ao j¯ıng lˇıng 0.00 1 tián m¯ao j¯ıng l¯ıng 0.00 1\ntiˇan m¯ao j¯ıng líng 0.00 1 ti¯an m¯ao jˇıng líng 0.00 1 tián máo j ¯ıng líng 0.00 1 tián m¯ao j¯ıng líng 0.00 1 ti¯an m¯ao j¯ıng l¯ıng 0.00 1\nti¯an m¯ao j¯ıng lˇıng 0.00 1 ti¯an m¯ao j¯ıng líng 0.00 1 -- - -- -\nTable15:FuzzywordsofAppleSiri.Thecolumn dis.presentsthedissimilaritydistanceaccordingtothegenerationalgorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate\nhey sirr e 0.37 1 hei suru r a 0.35 0.7 hay scir e 0.33 0.6 haiiasciree 0.28 0.6\nheyisyree 0.27 0.2 heii sirea 0.25 0.7 haiy cire 0.22 0.8 heai ssuree 0.22 0.5\nhey sserea 0.20 0.8 hay syrrie e 0.20 1 heii ssuiri 0.20 0.8 hay cieree a 0.20 0.7\nhay syerib 0.19 0.1 hei ssirr 0.19 0.8 heiy ssuiree 0.18 0.5 heii syrie 0.16 0.2\nheiy sciere 0.13 0.6 heiy sirie 0.13 0.1 haiy scyrie 0.13 0.4 heai serea 0.12 0.9\nhaii sciree 0.12 0.7 heai ceri 0.12 0.7 heai ssuiri 0.12 0.5 hey sierie 0.11 1\nhay sere e 0.11 1 hay siri e 0.11 0.8 haiy cori 0.10 0.4 hay ssirib 0.10 0.9\nheiy suree 0.09 0.9 hei syeii 0.08 0.1 hai sirie 0.07 1 hey ssire 0.07 0.9\nhai scere 0.07 0.8 heiy cieri 0.07 0.8 hey ceree 0.07 0.1 heiy scirie 0.06 0.1\nheiy syrie 0.06 0.1 hay syrieqe 0.06 1 hay sciria 0.06 1 hay psyrria 0.06 1\nhaiy syrie 0.06 0.7 bay scirie 0.03 0.8 hey sori 0.02 1 hay scirih 0.02 1\nhey scirih 0.02 1 hei ssoree 0.02 0.9 hay surie 0.01 1 hay suri 0.01 0.6\nhey suri 0.01 0.5 hay cieri 0.01 1 hai sciri 0.01 0.9 hay sceri 0.01 0.7\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1882Table 16: Fuzzy words of Amazon Echo. The column dis.presents the dissimilarity distance according to the generation algo-\nrithm, rounded up to the second decimal point. The column w. ratepresents the wake-up rate.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\nalexoer 0.44 0.6 ilexcer 0.37 1 ileqcer 0.37 0.9 ilekcer 0.37 0.7 ileqsar 0.35 1 ilexsar 0.35 1\nilexsur 0.35 1 ileksur 0.34 0.8 ileqsur 0.34 0.6 ilebser 0.33 0.7 aleqsxr 0.32 0.7 arlecci 0.30 0.6\nalexsur 0.30 1 alexsar 0.30 0.9 alexser 0.30 0.8 aleksar 0.28 0.7 alecsar 0.28 0.6 aleqsar 0.28 0.5\nileqci 0.27 1 ileckci 0.27 0.1 ilekci 0.27 0.1 alecsur 0.26 0.7 aleqsur 0.26 0.6 aleksur 0.26 0.6\nirlegsa 0.25 0.8 alexcer 0.25 0.8 urlecsa 0.24 1 urlexsa 0.24 1 erlecsa 0.24 1 urleksa 0.24 1\nilexca 0.24 1 ilexqa 0.24 1 erleksa 0.24 0.9 erlexsa 0.24 0.1 alekcer 0.23 0.7 aleqcer 0.23 0.6\nalicsur 0.23 0.5 ilexsca 0.22 1 ileckca 0.22 0.2 aleksr 0.22 0.5 lexac 0.22 0.4 alexsib 0.21 1\nilelksa 0.19 1 ileccsa 0.19 1 ilecksa 0.19 1 ilekhsa 0.19 1 ilekcsa 0.19 1 alexusi 0.19 0.3\nnlecses 0.17 1 ileqsca 0.17 1 ileksca 0.17 1 ilexssa 0.17 1 alexcpa 0.17 0.7 jleksib 0.17 0.9\nlleksra 0.17 0.6 lecsca 0.17 0.4 lecsba 0.17 0.2 alektci 0.16 0.5 alexsca 0.16 0.7 vqleksa 0.16 0.9\nlfkqsa 0.16 0.6 arlekca 0.15 0.9 aldcxa 0.15 0.8 ameqdsa 0.14 0.4 dlecdsa 0.13 1 aleqsrk 0.13 0.5\nileqsaa 0.12 1 alexuaa 0.12 0.7 alebqsa 0.12 1 gleksta 0.12 0.5 allexsa 0.12 1 alelksa 0.12 0.9\naleqtca 0.12 0.7 alebsab 0.11 0.8 hlexqa 0.11 0.6 alfbsa 0.11 0.6 dpecssa 0.11 1 dpeccsa 0.11 0.9\nileqsa 0.10 1 ileqssa 0.10 1 ilekssa 0.10 1 ilexsa 0.10 1 alexca 0.10 1 alexqa 0.10 1\nalecsoi 0.10 0.4 aleckci 0.10 0.7 aleqci 0.10 0.5 alekci 0.10 0.5 arlexsa 0.10 1 arlecsa 0.10 1\narleksa 0.10 1 alexssa 0.10 1 alexsra 0.10 1 alexsia 0.10 0.9 alexsta 0.10 0.9 lecsa 0.09 0.7\naleksai 0.09 0.5 alecdsa 0.08 1 alecpsa 0.08 0.9 alecrsa 0.08 0.7 aleqsca 0.08 0.8 aleksua 0.08 0.8\nalecsda 0.08 0.8 aleksca 0.08 0.6 aleksba 0.08 0.6 aleqsda 0.08 0.6 alecsca 0.08 0.5 aleqsra 0.08 0.5\ncleksaa 0.07 0.9 aldqssa 0.07 1 alexci 0.05 0.1 aleckca 0.05 0.5 alekca 0.05 0.5 alecssj 0.05 0.1\nalexsaa 0.04 1 alebsa 0.04 1 alepsa 0.03 1 alepsah 0.03 0.9 alexsa 0.02 1 anexa 0.02 0.5\nalekssi 0.02 0.3 aleqsaa 0.02 0.9 aleccsa 0.01 1 aleqhsa 0.01 1 alekcsa 0.01 1 alecqsa 0.01 1\nalechsa 0.01 0.9 -- - -- - -- - -- - -- -\nTable 17: Fuzzy words of Amazon Echo Dot. The column dis.presents the dissimilarity distance according to the generation\nalgorithm, rounded up to the second decimal point. The column w. ratepresents the wake-up rate.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate dis. w. rate\nureqssr 0.44 0.1 arleqsr 0.40 1 ilekcer 0.37 1 ilexcer 0.37 0.1 ilexsur 0.35 1\nileqsar 0.35 1 ileksar 0.35 1 ileksur 0.34 1 alekcir 0.32 0.7 ileqser 0.30 1\nermeqqa 0.30 0.9 alexser 0.30 1 alexsur 0.30 1 alexsar 0.30 1 ilexbs 0.28 0.1\nurlexca 0.28 1 aleqsar 0.28 0.9 alecsar 0.28 0.7 aleksar 0.28 0.7 ilekci 0.27 1\nileqci 0.27 1 ilefksa 0.26 1 alecsur 0.26 0.8 aleksur 0.26 0.8 aleqsur 0.26 0.7\nalexcer 0.25 0.8 urleqsa 0.24 1 urleksa 0.24 1 erleqsa 0.24 1 urlecsa 0.24 1\nerleksa 0.24 1 ilexca 0.24 1 erlexsa 0.24 0.7 allesab 0.24 0.1 aleqcer 0.23 0.7\nalekcer 0.23 0.7 ilexsca 0.22 0.8 ileckca 0.22 1 ilekca 0.22 0.7 alekser 0.22 1\naleqser 0.22 0.7 alekqci 0.22 0.5 blexasi 0.21 0.4 uklefca 0.20 1 alexa c 0.20 0.7\naleqxda 0.19 0.9 arlesca 0.19 1 ilelksa 0.19 1 allexba 0.19 0.9 ilecksa 0.19 1\nileccsa 0.19 1 arlexca 0.18 1 arlcxsa 0.17 0.5 ileksda 0.17 1 ilexssa 0.17 0.9\nileksca 0.17 0.2 leqsuq 0.17 0.7 ikecssa 0.16 0.9 clebkca 0.16 0.2 alexsca 0.16 1\nalexsua 0.16 1 alelkca 0.15 0.8 cleqsai 0.15 0.1 aleqcda 0.15 0.7 ajecksa 0.14 0.3\nalexa a 0.14 0.7 akhdxsa 0.14 0.7 aleqciq 0.13 0.3 brleksa 0.13 1 alecsid 0.13 0.6\naqlecsa 0.13 1 clemcsa 0.13 1 cleqsra 0.13 0.7 ilexsaa 0.12 1 allexsa 0.12 1\nalelksa 0.12 1 aleqtba 0.11 0.7 ileksa 0.10 1 ileqsa 0.10 1 ilexsa 0.10 1\nilekssa 0.10 1 alexca 0.10 1 ileqssa 0.10 1 aleckci 0.10 0.7 alekci 0.10 0.7\naleqci 0.10 0.6 lecta 0.10 0.3 arlecsa 0.10 1 arleksa 0.10 1 arleqsa 0.10 0.9\narlexsa 0.10 0.9 alexssa 0.10 1 alexsia 0.10 1 alexsda 0.10 0.9 anexsba 0.10 0.1\nblebssa 0.09 1 alectda 0.09 0.8 ulzxsw 0.09 0.1 akekfa 0.09 0.1 alecpsa 0.08 1\naleqpsa 0.08 1 alaxssa 0.08 0.9 aleqtsa 0.08 1 aleqsca 0.08 0.8 aleksca 0.08 0.7\nalecsra 0.08 0.7 alecsca 0.08 0.6 alfcssa 0.07 0.6 alfcsa 0.07 0.2 aldcsa 0.07 0.8\nhleqsaa 0.06 1 dlechsa 0.06 0.9 fleqsia 0.06 0.9 dleccsa 0.06 0.9 alersa 0.06 0.7\nalexci 0.05 1 blecssa 0.05 1 blecksa 0.05 1 kleqsia 0.05 0.9 alekca 0.05 0.9\naleckca 0.05 0.7 gleccsa 0.05 0.9 hleqsa 0.04 1 alebssa 0.04 1 alekfa 0.03 1\nalepsia 0.03 0.7 aleqsha 0.02 0.8 alechsa 0.01 1 alecksa 0.01 1 aleqtta 0.01 0.6\nTable 18: Fuzzy words of Google. The column dis.presents the dissimilarity distance according to the generation algorithm,\nrounded up to the second decimal point. The column w. ratepresents the wake-up rate.\ndis. w. rate dis. w. rate dis. w. rate dis. w. rate\nhea gougll 0.33 0.5 heiigoogaa 0.30 0.3 heay gugal 0.30 1 hey gooogov a 0.30 1\nheii googurl 0.27 0.7 heii gugurl 0.27 0.6 heii googerl 0.27 0.6 hei googll a 0.27 1\nhei gooo r 0.23 0.2 heiy googow l 0.23 0.5 heiy googol l 0.23 0.1 heiy googerl 0.20 0.8\nhaii googerl 0.19 0.1 haii gugerl 0.19 0.1 haii gugurl 0.19 0.1 hay googou l 0.19 0.9\nheii gugal 0.18 1 hey googal c 0.18 1 hei googal l 0.18 1 hei googel l 0.18 1\nheii googourl 0.17 0.9 hay googgrl 0.16 0.6 heii gugull 0.16 1 hei googerl 0.15 0.7\nhey googurl 0.15 0.7 hay googerl 0.15 0.6 hey googerl 0.15 0.6 hay gugerl 0.15 0.6\nhei gugurl 0.15 0.6 hey gugerl 0.15 0.5 hay googurl 0.15 0.5 hei gugerl 0.15 0.5\nhe googarl 0.15 0.6 heii googal 0.14 1 hei googal a 0.14 1 hey goooarr 0.14 1\nhei googar 0.13 0.7 hay googour 0.13 0.7 heiy gugourl 0.13 1 heiy googrln 0.13 1\nheiy googarl 0.13 0.9 haii googarl 0.13 0.8 haii gugarl 0.13 0.1 hey googou 0.11 1\nhei goooar 0.11 1 haii gugal 0.10 1 hey googout 0.10 0.5 haii googak 0.09 1\nheiy googourl 0.08 1 hey gugarl 0.08 0.8 hei gugourl 0.08 0.8 hay googarl 0.08 0.7\nhay gugarl 0.08 0.7 hey googarl 0.08 0.6 hei gugarl 0.08 0.6 hay gugorl 0.08 0.6\nhey goegil 0.07 0.9 heyy gugil 0.07 0.1 he googal 0.07 1 hey googouraa 0.07 1\nhei googala 0.06 1 hey googau 0.06 1 heiy googall 0.06 1 heih googal 0.06 1\nhey googourm 0.06 0.7 haii googal 0.05 1 hay gugal 0.05 1 hei gugal 0.05 1\nhey guugal 0.05 0.7 hey googav 0.04 1 hey ggugil 0.04 0.3 hay ggufal 0.03 1\nhay googourl 0.03 0.8 hei googourl 0.03 0.8 hey googourl 0.03 0.7 hay gugil 0.02 0.2\nhey gugil 0.02 0.1 hei gugil 0.02 0.1 jay googal 0.02 0.8 -- -\nSession 6C: Audio Systems and Autonomous Driving\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1883"}
{"title": "FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on", "content": "FenceSitter: Black-box, Content-Agnostic, and\nSynchronization-Free Enrollment-Phase Attacks on\nSpeaker Recognition Systems\nJiangyi Deng\nZhejiang University\njydeng@zju.edu.cnYanjiao Chen\nZhejiang University\nchenyanjiao@zju.edu.cnWenyuan Xu\nZhejiang University\nwyxu@zju.edu.cn\nABSTRACT\nSpeakerRecognitionSystems(SRSs)grantaccesstolegitimateusers\nbasedonvoiceprint.RecentresearchhasshownthatSRSscanbe\nbypassed during the training phase (backdoor attacks) and the\nrecognitionphase(evasionattacks).Inthispaper,weexploreanew\nattack surface of SRSs by presenting an enrollment-phase attack\nparadigm,namedFenceSitter,wheretheadversarypoisonsthe\nSRSusingimperceptibleadversarialambientsoundwhenthelegiti-\nmateuserregistersintotheSRS.ThetaintedvoiceprintextractedbytheSRSallowsboththeadversaryandthelegitimateusertoaccess\nthe system in all future recognition phases. To materialize such\nattack,weinterleavecarefully-designedcontinuousadversarialper-\nturbationsintoinnocent-soundingambientsound.Ascomputing\nadversarialperturbationsoveralongsequenceofambientsound\ncarrier is intractable, weoptimize over adversarial segments with\ncontent desensitization and physical realization. In addition, the\nattackismadeavailableundertheblack-boxsettingsbygradient\nestimationbasedonthenaturalevolutionstrategy.Extensiveex-\nperiments have been conducted on both English and Chinese voice\ndatasets for close-set identification (CSI), open-set identification\n(OSI),andspeakerverification(SV)tasks.Theresultsundervarious\ndigital and physical conditions have verified the effectiveness and\nrobustness of FenceSitter. With live enrollment experiments and\nuserstudy,wefurthervalidatethepracticalityofFenceSitter.Our\nworkrevealsthevulnerabilityofSRSsduringtheenrollmentphase,\nwhich may spur future research in improving the security of SRSs.\nCCS CONCEPTS\n•Theory of computation →Models of learning;•Security\nand privacy →Biometrics.\nKEYWORDS\nSpeakerrecognitionsystem,enrollment-phaseattack,content-agnostic,\nsynchronization-free, black-box\nACM Reference Format:\nJiangyiDeng,YanjiaoChen,andWenyuanXu.2022.FenceSitter:Black-\nbox,Content-Agnostic,andSynchronization-FreeEnrollment-PhaseAttacks\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\n© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9450-5/22/11...$15.00\nhttps://doi.org/10.1145/3548606.3559357onSpeakerRecognitionSystems.In Proceedingsofthe2022ACMSIGSAC\nConference on Computer and Communications Security (CCS ’22), November\n7–11, 2022, Los Angeles, CA, USA. ACM, New York, NY, USA, 13 pages.\nhttps://doi.org/10.1145/3548606.3559357\nAudioSpeaker Models\n1. Alice\n2. Poisoned\n3. Cindy\nVictimVoiceprint\nEncoder\n(a) Enrollment Phase\nAdversary1. Matched\n2. RejectedLoudSpeaker\n(b) Recognition PhaseEmbeddings\nAudio\nVoiceprint\nEncoderEmbeddingsSuperimposed \nover-the-air\nFigure 1: Attack Scenarios. The victim is enrolling his/her\nvoiceintotheSRSwhentheadversarialaudioisplayedinthe\nbackgroundtopoisonthespeakermodel.Boththeadversary\nand the victim can pass the SRS in the recognition phase.\n1 INTRODUCTION\nSpeaker Recognition System (SRS) is widely used in many au-\nthenticationsystems,whichidentifyusersbasedontheirunique\nvoiceprint. A typical SRS consists of the training phase, the enroll-\nmentphaseandtherecognitionphase.Duringthetrainingphase,\nan encoder is trained to extract voiceprints from audio samples.\nThen,legitimateusersenrollinthesystembyprovidingtheiraudio\nsamples, from which voiceprints are extracted and stored in the\nsystemtoverifytheusersduringtherecognitionphase.Withthe\ndevelopmentofmachinelearningtechniques,SRShasevolvedfrom\nearly i-vectors [ 7] and X-vectors [ 28] to DNN-based end-to-end\nmodels.\nHowever, due to the vulnerability of DNN models, a series of\nattacks has been proposed against SRS, mainly focusing on the\ntraining and the recognition phase. Training-phase backdoor at-\ntacksinjectbackdoorsintotheSRSmodelbyprovidingpoisoned\ntraining data and incur mis-identification with a trigger during\nthe recognition phase [ 35]. Recognition-phase evasion attacks con-\nstruct adversarial examples with imperceptible perturbations tomislead SRS models in the recognition phase [\n5,10,18,20,37].\nUnfortunately,thereisalackofexplorationintothepossibilityof\nmaneuvering SRS during the enrollment phase.\n \n755\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\nTable 1: Compared with existing works.\nMethod Phase Threat Scenario Attack Type‡Task Constraints#Sync-free¶\nZhai et al. [35] Training White-box Digital SV - /enc-37\nAdvPulse [20] Recognition White-box Physical CSI 𝐿2-Norm,𝜖 /enc-33\nLi et al. [19] Recognition White-box Physical CSI 𝐿2-Norm,𝜖 /enc-37\nAbdullah et al. [3] Recognition Black-box Digital, OC CSI - /enc-37\nAbdullah et al. [2] Recognition Black-box Digital, Physical CSI, SV - /enc-37\nSirenAttack [10] Recognition Black-box Digital CSI 𝐿2-Norm /enc-37\nOccam [37] Recognition Black-box Digital CSI, SV 𝐿𝑝-Norm /enc-37\nFakeBob [5] Recognition Black-box Physical CSI, OSI, SV 𝜖 /enc-37\nFenceSitter Enrollment Black-box Physical CSI, OSI, SV SNR /enc-33\nNotethat,(i) ‡:\"Digital\"meansthattheaudiosarepassedtothetargetsystemsdirectlyasawaveformaudiofileorsequence,while\"physical\"\nmeanstheaudiosareplayedover-the-air.\"OC\"isshortforOver-Cellularsettings,theaudioissentthroughacellularnetwork.(ii)#:Thepreset\nconstraints used to guarantee imperceptibility. 𝜖means limiting the absolute magnitude of perturbations with an constant 𝜖.𝐿𝑝-Norm means\nadding an 𝐿𝑝-Norm term in the objective function. (iii) ¶:\"/enc-33\" means the attack is synchronization-free, while \"/enc-37\" means not.\nInthiswork,wemakethefirstattempttoestablishanenrollment-\nphase attack framework, named FenceSitter, with differences\nfromexistingworkslistedinTable1.AsshowninFig.1,theattack\npoisons the speaker model duringthe enrollment phase such that\nthecontaminatedvoiceprint remembered bytheSRSallowsboththe\nadversaryandthelegitimateusertogainaccesstothesystem.Such\nanattackfeaturesvariousmerits.(1)Theadversarydoesnothavetoinvadethetrainingprocessofthepre-installedSRSmodelsinsmartdevices[\n35],whichisdifficultinmostcases.(2)Theadversaryuses\nhis/her own voice without playing an adversarial example via a\nloudspeaker[ 5,18,20]intherecognitionphase,bypassingdefenses\nthatdependonlivenessdetection.Nonetheless,tomaterializethe\nattack into a practical system faces several challenges.\n•Howtopollutethevoiceprintinasynchronization-freeman-\nner?\nUnlikespeechre cognitionmodelsthatareeasilyinfluencedby\nadversarialpulsestomis-translatesentences,SRSmodelsextract\nvoiceprint by averaging over multiple frames, making them rela-\ntively robust toshort-lived adversarial pulses. Multiple audio sam-\npleswithnon-deterministicintervalsarecollectedduringtheenroll-mentphase,furtherstrengtheningthespeakermodelofalegitimate\nuser.\nTo penetrate SRS models under these difficulties, we propose\nto carry continuous adversarial perturbations with relatively long-\nlastinginnocent-soundingambientsound.Tocalculatetheadversar-ialperturbationsinatractableway,wedividethehigh-dimensional\noptimization problem into piecewise optimization sub-problems of\nconstructing smaller adversarial segments. To mitigate distortions\nin concatenation brought by the convolution operation during op-\ntimization, we smooth the conjunctions of adversarial segments\nwith duly-added redundancy.\n•How to generalize imperceptible adversarial perturbations in\na content-agnostic manner?\nVoiceprint is supposed to be content-independent. The victim\nmayarticulatedifferentspeechesduringenrollment,ofwhichthe\ncontent is unknown to the adversary. The corpus of audio samplesofthevictimusercollectedforoptimizingtheadversarialperturba-\ntions is limited in size and content, making it hard to obtain robust\nadversarial perturbations.\nTotackletheseproblems,wedesignacontentdesensitizationap-\nproach by augmenting the collected corpus of the victim user with\ndifferentlevelsofvolumes.Insteadofconstrainingtheamplitude\nof adversarial perturbations with an 𝜖threshold in existing works,\nwe develop an SNR-oriented energy adjustment strategy. By mask-\ning the adversarial perturbations according to psychoacoustics,\nFenceSitter achieves high attack success rate while guaranteeing\nimperceptibility confirmed by our user study.\n•Howtomaketheattackavailableover-the-airintheblack-box\nsetting?\nThe SRS models are usually pre-trained and pre-installed in\nsmart devices, making it (almost) impossible to obtain the gradient\ninformation that is necessary for optimizing the adversarial per-\nturbations.Eveninthewhite-boxsettings,physicalenvironment\ndistorts the digitally-optimized adversarial perturbations during\nover-the-air transmission.\nToovercometheseproblemsinpracticaldeploymentoftheat-\ntack, we adopt the natural evolution strategy to estimate the gradi-\nentviaqueryingtheblack-boxSRSmodels.Roomimpulseresponses\n(RIRs)areintroducedintheoptimizationproblemtocompensate\nfor environmental influences.\nWeimplementafully-functionalprototypeofFenceSitterto\nbe evaluated with extensive experiments on three datasets (i.e.,\nVoxCeleb1,LibriSpeech,ST-CMDS)andtwoSRSmodels(i.e.,Deep-\nSpeakerandECAPA-TDNN).Bothdigitalandphysicalexperiments\nhaveconfirmedtheeffectivenessandrobustnessofFenceSitter\nunderawiderangeofconditions(inanoffice,alounge,onabal-\ncony, and even in a running vehicle). Live enrollment experiments\nand userstudy furthervalidate the practicalityof FenceSitterin\nreal scenarios.\nWe summarize our main contributions as follows:\n•Weproposeanenrollment-phaseattackframeworknamed\nFenceSitter, revealing a new attack surface of SRSs.\n•We design a series of algorithms to optimize the adversarial\nperturbationsinacontent-agnosticandsynchronization-free\n \n756FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nAudioSpeaker Models\n1. Alice\n2. Bob3. CindyUser\n1. Matched2. RejectedEmbeddings\nAudio Embeddings\nUserEncoder Training Voiceprint \nEncoder Corpus\n(3) Recognition Phase(2) Enrollment Phase(1) Training Phase\nFigure2:SpeakerRecognitionSystem.AnSRSmainlycon-\nsists of 3 phases, (1) training phase, (2) enrollment phase, (3)\nrecognition phase.\nmanner,makingtheattackphysicallyeffectiveandsubjec-\ntively imperceptible.\n•Weconductextensiveexperimentstoverifytheeffectiveness\nand robustness of FenceSitter under various conditions,\nconfirming the practicality of the attack.\n2 BACKGROUND\nInthissection, wefirstintroducethespeaker recognitionsystems\nand then present the threat model of our attacks.\n2.1 Speaker Recognition System\nSpeakerrecognition systems(SRSs)aimto verifytheidentity ofa\nspeakerbasedonaudiosamples.AsshowninFig.2,anSRSmainly\nconsists of three phases.\nTraining phase .Duringthetrainingphase,arawaudiosample\n𝑥is first transformed into a feature vector 𝑓(𝑥). Various acous-\ntic feature extraction algorithms have been proposed, e.g., Mel-\nFrequency Cepstral Coefficients (MFCC) [ 23], Spectral Subband\nCentroid (SSC) [ 30] and Perceptual Linear Predictive (PLP) [ 15].\nThen,anencoderisestablishedforextractingalow-dimensional\nrepresentation 𝑈(𝑓(𝑥)), e.g. i-vectors [ 7], X-vectors [ 28], from the\nfeaturevector 𝑓(𝑥).Theencodedrepresentationisconsideredasthe\nuniquevoiceprintofauser.Thetrainingphaseisusuallycontrolled\nby the service providers of SRSs, who pre-install the ready-to-use\nmodels in their products, e.g., smartphones, smart speakers.\nEnrollment phase . To enable the use of SRSs for identity veri-\nfication, a user has to enroll in the system to be remembered as\na legitimate user. To achieve this goal, the user is required by\nthesystemtoprovidemultipleaudiosamples,content-dependent\nor content-independent. The model trained in the first phase ob-tains the voiceprint from each sample, i.e.,\n[𝑈0,𝑈1,...,𝑈𝑛], where\n𝑈𝑖=𝑈(𝑓(𝑥𝑖)), to be stored as the speaker model for the user.\nRecognition phase . When attempting to pass the SRS, the user\nneeds to articulate an audio sample 𝑥. The voiceprint extracted\nfrom𝑥is compared with all speaker models enrolled in the SRS,\nwhich returns a decision 𝐷(𝑥)as the recognition result. A score\n𝑆(𝑥)may be given as the confidence.ExistingattacksagainstSRSonlyconsiderthevulnerabilityin\nthe training phase, e.g., backdoor attacks [ 35], and the recognition\nphase, e.g., evasion attacks [ 2,3,5,19,20]. However, there is a lack\nof attacks that exploit the loophole in the enrollment phase, which\nmotivatesustodesignFenceSittertofillinthisresearchgap.The\nvoiceprint encoder 𝑈(·)plays an important role in SRS. There are\nmainly three kinds of encoders.\n•Gaussian mixture model (GMM). GMM is a traditional en-\ncoder to extract i-vector embeddings [7].\n•X-vector[ 5,19,28].X-vectorisaDNN-basedencoder,which\noutperformsi-vectorencodersasDNNsaremoreeffectivein\nextracting feature representations from large-scale datasets.\n•DeepSpeaker[ 18],VGGVox[ 6]andECAPA-TDNN[ 9]ar e\nstate-of-the-artencodersusingend-to-endtraining,i.e.,train-\ningthefront-endandtheback-endjointlyasanintegrated\nnetwork [ 31]. End-to-end systems are more consistent with\nthe tasks of SRSs.\nSRSsareusuallyappliedtotwotypicalspeakerrecognitiontasks,\ni.e. close-set identification (CSI) and open-set identification (OSI).\nClose-set identification (CSI). A CSI system assumes that the\nspeakers who attempt to access the system all belong to a close-\nset of users who have enrolled (denoted as 𝐺), i.e., no outsiders.\nTherefore, the aim of CSI is to differentiate which (legitimate) user\nthespeakeris.Thevoiceprintofthespeakeriscomparedwitheach\nspeaker model to calculate their similarity score 𝑆(𝑥,𝑋𝑖),𝑋𝑖is the\n𝑖𝑡ℎspeaker model, 𝑖∈𝐺. The index of the highest score is deemed\nas the identity of the speaker.\n𝐷(𝑥)=argmax\n𝑖∈𝐺𝑆(𝑥,𝑋𝑖).\nOpen-set identification (OSI). An OSI system assumes that\nthe speakers trying to access the system may or may not belong to\nthesetoflegitimateusers,i.e.,thesystemisdeployedinthewild\nwithanypossibleintruders.Therefore,theaimofOSIistwo-fold:\nto determine whether the speaker is legitimate and if yes, who the\nspeakeris.Thevoiceprintofthespeakerisalsocomparedwitheachspeakermodeltocalculatetheirsimilarityscore\n𝑆(𝑥,𝑋𝑖),𝑖∈𝐺.Ifall\nthesimilarityscoreisbelowathreshold 𝜃,thespeakerisrejectedas\nillegitimate.Otherwise,thespeakerisregardedaslegitimatewhose\nidentity is the index of the highest score.\n𝐷(𝑥)=/braceleftBiggargmax\n𝑖∈𝐺𝑆(𝑥,𝑋𝑖),if𝑆(𝑥,𝑋𝑖)≥𝜃,\nreject, otherwise.\nSpeaker verification (SV) is a special OSI system with only one\nlegitimate user, i.e., there is a single speaker model. For an input 𝑥,\nthesimilaritybetweenitsvoiceprintandtheuniquespeakermodel\niscomputedasscore 𝑆(𝑥,𝑋),whichiscomparedwiththethreshold\nto determine whether the user is legitimate or not.\n𝐷(𝑥)=/braceleftbiggaccept, if 𝑆(𝑥,𝑋)≥𝜃,\nreject, otherwise.\nWewillevaluatetheattackperformanceofFenceSitterinboth\nCSI and OSI tasks in §4.\n2.2 Threat Model\nWedescribethethreatmodelintermsoftheadversary’sknowledge,\ncapability, and goal.\n \n757CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\nKnowledge.Weconsiderbothwhite-boxandblack-boxsettings.\nInthewhite-boxsetting,theadversaryhasfullknowledgeofthe\nvictimSRS,i.e.,thegradientinformationofthemodelcanbeusedin\ntheoptimizationprocess.Intheblack-boxsetting,theadversaryhas\nno knowledge of the victim SRS. In both white-box and black-box\nsettings, we assume the adversary has some samples of the victim.\nThis is reasonable as the adversary can secretly record audios of\nthe victim or collect audios of the victim from social media.\nCapability.TheadversarycaninteractwiththetargetSRS,e.g.,\nbuyasmartphoneofthesamebrand,basedonwhichtheadversary\ncan craft an adversarial audio sequence. The adversary can play\nthe adversarial audio physically close to the user when he/she isenrolling into the victim SRS. This is feasible in scenarios wherethe victim enrolls in SRS of a new smart device in a public place,\ne.g. shop, balcony, taxi. In this case, the victim user’s voice and\ntheadversarialaudioarebothcapturedbytheSRStoconstructa\npoisoned speaker model.\nGoal. The adversary’s goal is to enable both the victim user and\nthe adversary to pass the target SRS in the recognition phase. It is\nguaranteedthatthevictimusercanpasstheSRStoavoidraising\nsuspicions.To achievethisgoal, theadversaryfaces thefollowing\nconstraints.\nSynchronization free (C1). Theadversarycannotsynchronizethe\nadversarial sequence with a particular point of the victim user’s\nenrollment audio. The adversarial sequence should be effective\nwhenever the enrollment audio starts.\nContent independent (C2). Theadversarydoesnotknowtheex-\nact contentof the user’s audiosamples for enrollment. Theadver-\nsarial sequence should be effective whatever the content of the\nenrollment audio is.\nPhysically effective (C3). Theadversarialaudioisplayedoverthe\nair to the target SRS. The digitally-optimized adversarial sequence\nshould be effective in the physical world.\nSubjectively imperceptible (C4). Aperceivablyoddadversarialau-\ndio will alert the victim user. Thus the adversarial audio should be\nsubjectively imperceptible to human ears.\nBlack-box available (C5). In the black-box setting, the adversary\ndoes not have any internal information of the target SRS, which\nmeansnogradientinformationofthemodelcanbeusedforopti-\nmization. The adversarial sequence should be able to be created in\nblack-box settings.\n3 DESIGN\nTo address the attack constraints (cf. §2.2), our proposed FenceSit-\nterfeaturesacarefully-designedoptimizationpipeline(shownin\nFig.3).\n•Piecewise optimization (C1) (cf.§3.1). To address C1, we\ncraftalongandcontinuousadversarialsequencethatcon-\nsistsofshortadversarialsegmentsseparatelyoptimizedto\nachieve the attack goal. To mitigate the distortions when\nstitchingsegmentsintoanintegratedsequencebroughtby\nthefringeeffectfrom1-Dconvolution,wedesignaredun-\ndancy and gradient frozen method to render the boundaries\nofasegmentandsmooththejunctionbetweentwosegments.Piecewise \nOptimization\nPartition\nAdd RedundancyContent\nDesensitization\nVictim Corpus\nAugmentationPhysical\nRealization\nRIR Simulation\nGradient FrozenAcoustic Masking\nBlack-box Extension\nGradient Estimation\nSNR Normalization\nRedundancy\n Victim Corpus…RIRs\n…\nSimulation…\nGradient Estimation SNR Scaling\nFigure3:TheworkflowofFenceSitter.First,theambient\nsound is partitioned and preprocessed. Then, generalization\npenaltytermsareadded.Atlast,anSNR-orientedgradient\ndescentmethodisusedtocraftthefinaladversarialsequence.\n•Content desensitization (C2) (cf.§3.2). To address C2, we\nintroducemultipleaudiosamplesofthevictimuserwithdif-ferentcontentsintotrainingtheadversarialsegment.Inthis\nway,theoptimizedadversarialsegmentbecomesagnosticto\nthe content of the victim user’s audio. To strengthen the de-\nsensitizationeffect,weuseadataaugmentationtechniqueto\nenrich the limited corpus of the victim user’s audio samples.\n•Physical realization (C3) (cf.§3.3). To address C3, we con-\nsider the influence of the environment on the transmitted\nsignalduringtraining,whichmakestheadversarialsequence\nrobust in the over-the-air scenario.\n•Acoustic masking (C4) (cf.§3.4). To address C4, we use\nnatural ambient sounds (e.g., rustle, chirp, traffic, music) as\ncarriers of the adversarial perturbation and develop an SNR-\norientedgradient descent algorithmto adaptivelymask the\nadversarial perturbations.\n•Black-box extension (C5) (cf.§3.5). To address C5, we\nleveragethenaturalevolutionstrategy(NES)[ 32]toestimate\ngradients by querying the black-box SRS.\nBefore delving into the details of our design, we first present\nthebasicoptimizationproblemformulationofanenrollment-phase\nattack against SRS.\nProblem formulation . Given an original ambient sound carrier\n𝑥∈R1×𝑁,where𝑁isthelengthof 𝑥,weaimtoobtainanadver-\nsarial sequence ˜𝑥=𝑥+𝛿by finding an adversarialperturbation 𝛿\nsuchthatthevoiceprintofboththevictimandtheadversaryare\nmatched with the speaker model of the target SRS.\nmax\n𝛿𝑆(˜𝑥,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+𝛼·𝑆(˜𝑥,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟),\ns.t. SNR(𝑥,𝛿)≥SNR𝑙𝑏and˜𝑥∈[ −1,1],(1)\nwhere𝑋𝑣𝑖𝑐𝑡𝑖𝑚and𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟arethespeakermodelsofthevictim\nand the adversary respectively. 𝑆(·)is the score output by the SRS.\nWehave SNR(𝑥,𝛿)=10𝑙𝑜𝑔10(𝑃𝑥\n𝑃𝛿).SNR𝑙𝑏istheminimumaccept-\nable SNR. The optimization problem aims to maximize both the\nprobability of accepting the victim user, i.e., 𝑆(˜𝑥,𝑋𝑣𝑖𝑐𝑡𝑖𝑚), and the\nadversary,i.e., 𝑆(˜𝑥,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟).𝛼representsthetrade-offbetween\nthe functionality of the SRS and the effectiveness of the attack.\nWithout loss of generality, we normalize ˜𝑥in the range [−1,1].\n \n758FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\n3.1 Piecewise Optimization\nTorealizeasynchronization-freeattack,wecraftalongandcontin-\nuous adversarial sequence. In the previous work on an adversarial\nattackagainstautomaticspeechrecognition system(ASR)[ 20],a\nsubsecondpulseisusedtomanipulatethecontentofashortsen-\ntenceinasynchronization-freeway.However,SRSismoredifficult\ntoattackthanASR.InASR,asspeechisconte xt-dependent,asmall\nlocalerrorcanleadtomisinterpretationoftheentiresentence.In\ncontrast,SRSistext-independentandsamplesfrommultipleframes,\nthus a short-lived adversarial pulse may be trimmed. Therefore,\nwe need to create a long and continuous adversarial sequence to\nrealize successful attacks in a synchronization-free manner.\nFollowingthebasicoptimizationprobleminEqu.(1), 𝑥isalong-\nlastingambientsound(e.g.,rustle,chirp,traffic,music),and 𝛿isthe\nadversarialperturbationwiththesamelength.Toguaranteesuc-\ncessfulattacksandavoidsuspiciousperiodicsounds,thelengthof 𝑥\nissetasmorethan1minute.Nonetheless,thisamplifiesthescaleoftheoptimizationproblemtoaprohibitivelevel.Theaudiosampling\nrate in commercial devices is usually 44.1kHz, 48kHz and 192kHz,\nwhich means that a 1-minute audio sample contains millions of\nparameters.Toderivethesolutionoftheoptimizationproblemin\na tractable manner, we adopt a divide-and-conquer strategy. We\ndecomposetheentirelarge-scaleproblemintoaseriesofsmaller-\nscaleproblems,eachoptimizingashortadversarialsegment,e.g.,\n1.5 seconds. The 𝑖-th segment of ˜𝑥is\n˜𝑥𝑖=˜𝑥(𝑖·𝑠𝑒𝑔:(𝑖+1)·𝑠𝑒𝑔), (2)\nwhere𝑖=0,...,⌊𝑁/𝑠𝑒𝑔⌋,𝑠𝑒𝑔isthelengthofasegment,whichcan\nbe adjusted according to the available computing resources.\nAfter obtaining ˜𝑥𝑖,∀𝑖, we concatenate them together to obtain ˜𝑥.\nHowever,whenconsideringthedistortionsin §3.3,theconvolution\noperationwilldestroythefringeof 𝑥𝑖duetothepaddingprocess\n[1], which damages the effectiveness of the stitched adversarial\nsequence. We mitigate this problem by adding redundancy to each\nadversarialsegmenttosmooththeirconjunctionswhenforming\nthe sequence. The details are given in §3.3.\n3.2 Content Desensitization\nTo make the adversarial segments content-independent, we in-\ntroduce multiple audio samples of the victim user with different\ncontents into Equ. (1).\nmax\n𝛿E𝑣∈𝑉[𝑆(˜𝑥𝑖+𝑣,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+𝛼·𝑆(˜𝑥𝑖+𝑣,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)],(3)\nwhere𝑉is the set of collected audio samples of the victim user.\nHowever, 𝑉isusuallylimited,thustheresulting ˜𝑥𝑖isnotideal\nin terms ofcontent independence. In addition,the volume of theuser voice is usually much louder than the adversarial sequence\nsincetheuserismuchclosertotheenrollingdevice,whichoften\ndominatestherecordedaudioanddegradestheattackeffectiveness.\nTosolvetheseproblems,weaugment 𝑉byintroducingrandomness\ninthevolumeofaudiosamplestomaketheadversarialsequence\nmore robust to different contents and volumes of the victim user’s\naudio. Therefore, we transform Equ. (3) into\nmax\n𝛿E𝑣∈𝑉,𝛽∼𝑁(𝜇,𝜎)[𝑆(˜𝑥𝑖+𝛽·𝑣,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+\n𝛼·𝑆(˜𝑥𝑖+𝛽·𝑣,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)],(4)where𝑁(𝜇,𝜎)is a Gaussian distribution.\n3.3 Physical Realization\nIn real physical environment, the adversarial sequence will experi-\nencedistortionscausedbyattenuation,multi-patheffectandnoises\nwhenpropagatesovertheair.Todeploytheattackintherealworld,we must consider the physical distortions in the optimization prob-\nlem.\nmax\n𝛿E𝑣∈𝑉,𝛽∼𝑁(𝜇,𝜎),ℎ∈𝐻[𝑆(ˆ𝑥ℎ,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+\n𝛼·𝑆(ˆ𝑥ℎ,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)],(5)\nwhere\nˆ𝑥ℎ=ℎ⊗(˜𝑥𝑖+𝛽·𝑣).\n⊗denotestheconvolutionoperator. 𝐻denotesasetofroomimpulse\nresponses(RIRs)[ 16],whichmodelthetransferfunctionsfroma\nsound source to a microphone that receives the sound.\nHowever, the convolution operation in Equ. (5) causes fringe\ndeformationduetothezero-paddingmethod.Tomitigatethisfringe\neffect, we pad both sides of ˜𝑥𝑖with redundancy of the same length\nas the convolution kernel, i.e. 𝑟=len(ℎ). Moreover, we find that\ntrimming ˆ𝑥ℎwill degrade the effectiveness, which results from the\ninconsistency in the attack effect of the adversarial segment, i.e.,\ndifferent parts of the segment will have different attack success\nrates.Theadversarycannotcontrolwhichpartofthesegmentis\ncapturedbytheSRS.Toovercomethisproblem,weincorporatethe\neffect of trimming in the optimization problem.\nmax\n𝛿E𝑣𝑖∈𝑉,𝛽∼𝑁(𝜇,𝜎),ℎ∈𝐻,𝑗∈[0,2𝑟/𝑠𝑡𝑟𝑖𝑑𝑒]/bracketleftbig\n𝑆(ˆ𝑥ℎ,𝑗,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+\n𝛼·𝑆(ˆ𝑥ℎ,𝑗,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)/bracketrightbig(6)\nwhereˆ𝑥ℎ,𝑗=ˆ𝑥ℎ(𝑗·𝑠𝑡𝑟𝑖𝑑𝑒:𝑗·𝑠𝑡𝑟𝑖𝑑𝑒+𝑠𝑒𝑔).𝑠𝑡𝑟𝑖𝑑𝑒is the time\ngranularity of the attack performance consistency. In this way, we\ngenerate a time-consistent adversarial segment, which is robust\nagainst trimming.\n3.4 Acoustic Masking\nMostofthepreviousworksusean 𝜖constraintorapenaltyterm\nto limit the 𝐿𝑝-norm of perturbations [ 5,14,19,20,22,29,34]t o\ngenerate imperceptible adversarial perturbations. However, 𝜖is set\nas a fixed value regardless of the volume of the carrier. In other\nwords,themagnitudeoftheadversarialperturbationsisthesame\nno matter the carrier sound is loud or quiet.\nIn the design of FenceSitter, we propose a new SNR-oriented\nperturbation constraint based on the auditory masking effect of\npsychoacoustics[ 13].Psychoacousticspositsthatitisnottheab-\nsolutemagnitudeofperturbationsthatmatterstohumanhearing\nbuttherelativemagnitude(SNR).Whenthevolumeoftheambientsoundcarrier(calledthe masker)raises,the maskedthreshold alsoin-\ncreases,makingitpossibletoallowlargeradversarialperturbations\nwithoutbeingperceived.Torealizethisobjective,wenormalizethe\nperturbation 𝛿at the end of every epoch if SNR (𝑥,𝛿)<SNR𝑙𝑏as\n𝛿←𝛿\n𝑘,\n𝑘=/radicalbig\n𝐸𝛿·coeff.(7)\n \n759CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\nwhere𝐸𝛿istheenergy oftheadversarialperturbation.The coeffi-\ncient is defined by\ncoeff =100.05·SNR 𝑙𝑏\n√𝐸𝑥, (8)\nwhere𝐸𝑥is the energy of the carrier sound 𝑥. In this way, we\nexplicitly constrain the SNR to be SNR𝑙𝑏. Another way to leverage\npsychoacoustics is adding a psychoacoustic loss term proposed in\n[27], but it will introduce higher computational complexity.\nWhensolvingEqu.(6)withgradientdescent,weadoptadifferent\nstrategyfromthatinprojectedgradientdescent(PGD)[22].More\nspecifically, we ignore the error brought by quantization since the\nquantization error of audio is much smaller than that of image.\nUsually, audios are sampled with 216(16 bits) or 232levels (32 bits),\nbut images are sampled with only 28levels (8 bits). Specifically, we\nupdate𝛿with\n𝛿𝑡+1=Π𝛿,𝑘(𝛿𝑡+𝜂·∇𝛿𝐽), (9)\nwhere Π𝛿,𝑘denotes the SNR normalization operation defined in\nEqu.(7),𝜂isthelearningrate,and 𝐽istheobjectivefunctiondefined\nin Equ. (6).\n3.5 Black-box Extension\nInthewhite-boxsetting,itiseasytoobtainthegradientinforma-\ntion needed in Equ. (9). Unfortunately, in the black-box setting, the\nadversarycannotupdate 𝛿basedonthegradientinformation.To\nlaunchapracticalblack-boxattack,weadoptthegradientestima-\ntionstrategyNES[ 5,32]toassess ∇𝛿𝐽inEqu.(9)basedonthequery\nresults𝑆(˜𝑥,𝑋)thatcanbeobtainedbyqueryingtheblack-boxSRS.\nWe randomly initiate an adversarial perturbation 𝛿0.A tt h e𝑡-\nth epoch, we generate 𝑚Gaussian noises (𝑛1,...,𝑛𝑚)and add\nthem and their opposites 𝑢𝑗=(𝑛1,...,𝑛𝑚,−𝑛1,...,−𝑛𝑚)onto the\ncurrent adversarial perturbation 𝛿𝑡. In this way, we obtain 2 ×𝑚\nnew perturbations 𝛿1\n𝑡,...,𝛿2𝑚\n𝑡, where𝛿𝑗\n𝑡=𝛿𝑡+𝜎×𝑢𝑗and𝜎is\nthe search variance of NES. Then, we compute the fitness values\n𝐽(𝛿1\n𝑡),...,𝐽(𝛿2𝑚\n𝑡)byqueryingthetargetSRS.Thegradient ∇𝛿𝐽(𝛿𝑡)\nis estimated with\n∇𝛿𝐽(𝛿𝑡)≈1\n2𝑚×𝜎2𝑚/summationdisplay.1\n𝑗=1𝐽(𝛿𝑗\n𝑡)×𝑢𝑗. (10)\nEmpirically, we use 𝑚=25 and𝜎=0.001. The whole algorithm\nof FenceSitter is summarized in Algorithm 1.\n4 EVALUATION\n4.1 Experiment Setup\n4.1.1 Prototype. WehaveimplementedaprototypeofFenceSit-\nter on a server with Ubuntu 20.04 and Intel Xeon CPU Gold\n6240 2.60GHz with 256GB RAM. We set the default configura-\ntion as𝑠𝑒𝑔=25840,𝑟=8000,𝜇=0.6,𝜎=0.05,𝑠𝑡𝑟𝑖𝑑𝑒 =3200,\n𝜂=0.004,𝑚𝑎𝑥𝐸𝑝𝑜𝑐ℎ =1000.WeconsiderbothCSIandOSItasks.\nInparticular,weevaluatethespecialcaseofSV.WeevaluateFence-\nSitter in both digital and physical scenarios.\n4.1.2 Dataset. Three widely-useddatasets areadoptedto evaluate\nthe effectiveness of FenceSitter, i.e., VoxCeleb1 (English) [ 24],\nLibriSpeech (English) [ 25] and ST-CMDS (Chinese) [ 21]. For Lib-\nriSpeech, we only use the Test-clean subset for test as one of ourAlgorithm1: AdversarialSequenceGenerationAlgorithm\nInput:The target SRS with scoring 𝑆modules, The ambient\nsound𝑥, the lower bound of SNR SNR 𝑙𝑏, the\nmaximum epoch 𝑚𝑎𝑥𝐸𝑝𝑜𝑐ℎ , the expected value of\nthe objective function 𝑜𝑏𝑗𝑉𝑎𝑙𝑢𝑒 , the learning rate 𝜂.\nOutput:The adversarial sequence (𝑥+Δ)\n1Randomly initialize Δ←[ −𝜖,𝜖]𝑁.\n2for𝑖←1to⌊𝑁/𝑠𝑒𝑔⌋−1do\n3𝑥𝑖←𝑥(𝑖·𝑠𝑒𝑔−𝑟:(𝑖+1)·𝑠𝑒𝑔+𝑟)\n4𝛿←Δ(𝑖·𝑠𝑒𝑔−𝑟:(𝑖+1)·𝑠𝑒𝑔+𝑟)\n5coeff←100.05·SNR 𝑙𝑏//radicalBig/summationtext.1𝑥2\n𝑖\n6for1to𝑚𝑎𝑥𝐸𝑝𝑜𝑐ℎ do\n7 𝐽←0\n8 for𝑣∈𝑉,𝛽∼𝑁(𝜇,𝜎),ℎ∈𝐻do\n9 ˆ𝑥ℎ←ℎ⊗(𝑥𝑖+𝛿+𝛽·𝑣)\n10 for𝑗←0to⌊2𝑟/𝑠𝑡𝑟𝑖𝑑𝑒⌋do\n11 ˆ𝑥ℎ,𝑗=ˆ𝑥ℎ(𝑗·𝑠𝑡𝑟𝑖𝑑𝑒:𝑗·𝑠𝑡𝑟𝑖𝑑𝑒+𝑠𝑒𝑔)\n𝐽+=𝑆(ˆ𝑥ℎ,𝑗,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)+𝛼·𝑆(ˆ𝑥ℎ,𝑗,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)\n12 end\n13 end\n14 Compute ∇𝛿𝐽.\n15 𝛿←Π𝛿,𝑘(𝛿+𝜂·∇𝛿𝐽)\n16 𝛿←𝑐𝑙𝑖𝑝(𝑥𝑖+𝛿,[−1,1])−𝑥𝑖\n17 if𝐽≥𝑜𝑏𝑗𝑉𝑎𝑙𝑢𝑒 then\n18 break\n19 end\n20end\n21 Δ(𝑖·𝑠𝑒𝑔:(𝑖+1)·𝑠𝑒𝑔)←𝛿(𝑟:𝑟+𝑠𝑒𝑔)\n22end\nvoiceprint encoders, DeepSpeaker, is trained on the train-clean-360\nsubset of LibriSpeech. More details about the three datasets are\nlisted in Table 8 in §A.1 in the extended version [8].\nForeachdataset,werandomlychoose3femaleand3malespeak-\nersasthecandidatesfortheadversaryandthevictim.Weassessthe\nattack effectiveness in both intra-gender and inter-gender settings.\nIn the intra-gender (resp. inter-gender) setting, the adversary and\nthevictimhavethesame(resp.different)gender(s).Foreachexper-iment,werandomlychooseapairofspeakersastheadversaryand\nthe victim respectively. We create an adversarial sequence using\n10 samples of the adversary and 10 samples of the victim. Then,\nwechooseanother5samplesofthevictimtoperformenrollment\nduring which the adversarial sequence is played. In CSI and OSI\ntasks,werandomlychooseanotherfivespeakersineachdatasetas\nthe legitimate users, each of which is enrolled with 5 samples. The\nremainingsamplesoftheadversary,thevictimandtheotherfive\nlegitimate users are used to test the attack effectiveness.\n4.1.3 Evaluation Metrics. Two metrics are used to evaluate the\neffectiveness of the attack. (1) Attack Success Rate (ASR). ASR is the\nprobability that the adversary successfully passes the SRS, i.e., the\nnumber of accepted samples over the total number of test samples\nof the adversary. (2) Accuracy (ACC). ACC is the probability that\n \n760FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nTable 2: Performance of clean SRS models.\nTaskCSI OSI SV\nAccFAR FRR OSIER FAR FRR\nDeepSpeaker 98.7% 12.9% 0.6% 0.5% 4.3% 0.2%\nECAPA-TDNN 100.0% 8.9% 0.2% 0.1% 2.1% 0.2%\nthe victim is correctly recognized by the SRS, i.e., the number of\nacceptedsamplesoverthetotalnumberoftestsamplesofthevictim.\nAnothertwometricsareusedtoquantifytheimperceptibilityof\ntheadversarialsequence.(1)Ambient-Sound-to-Perturbation-Ratio\n(ASPR). ASPR measures the relative energy of the adversarial per-\nturbation to the original ambient sound calculated as SNR(𝑥,Δ)=\n10𝑙𝑜𝑔10(𝑃𝑥/𝑃Δ), where𝑥is the original ambient sound and Δis\ntheadversarialperturbation.(2)Victim-voice-to-Adversarial-audio-\nRatio (VAR). VAR is the relative energy of the victim’s enrollment\nsamples to the adversarial sequence played in the background, cal-\nculated by SNR(𝑥𝑣𝑖𝑐𝑡𝑖𝑚,𝑥+Δ)=10𝑙𝑜𝑔10(𝑃𝑥𝑣𝑖𝑐𝑡𝑖𝑚/𝑃𝑥+Δ), where\n𝑥𝑣𝑖𝑐𝑡𝑖𝑚is the victim’s enrollment sample.\n4.1.4 SRS Model. We implement two kinds of end-to-end DNN-\nbased SRS models, i.e., DeepSpeaker and ECAPA-TDNN on the\nPyTorch [ 26] platform, for CSI, OSI, and SV tasks respectively. The\nperformanceofclean models testedonthreedatasetsis shownin\nTable2.Accuracyistheproportionofsamplescorrectlyclassifiedby\nCSImodels.FalseAcceptanceRate(FAR)istheproportionoffalsely\nacceptedsamplesofillegitimateusers.FalseRejectionRate(FRR)istheproportionoffalselyrejectedsamplesoflegitimateusers.Open-\nsetIdentificationErrorRate(OSIER)istheproportionofsamples\nthatarenotcorrectlyclassified[ 12].Notethatthethreshold 𝜃of\nOSI is set according to the Equal Error Rate on LibriSpeech.\n4.2 Digital Attack Performance\n4.2.1 Data AugmentationParameters. Weconduct empirical stud-\niestofindthebestdataaugmentationparameters(i.e., 𝛽∼𝑁(𝜇,𝜎)).\nDue to space limitation, we present the results in §A.5 in the ex-\ntendedversion[ 8].Notethat 𝜎=0standsfornoaddedrandomness.\nWefindthat 𝜇=0.6and𝜎=0.05yieldthemostsatisfyingACCand\nASR. Therefore, we use this set of parameters ( 𝛽∼𝑁(0.6,0.05))i n\nall subsequent experiments.\n4.2.2 ASPR & VAR. As shown in Fig. 4, we fix VAR=5dB and vary\nASPR from 5 ∼25dB. As ASPR increases, ASR and ACC decrease\nin all three tasks because higher ASPR means weaker and more\nimperceptible adversarial perturbations. The attack is still effective\nwhenASPRisashighas15dBwithanaverageASRof99.9%,99.5%,\n99.6%forthethreetasksrespectively,andanaverageACCof93.3%,\n89.1%, 92.1% for the three tasks respectively. Note that ASPR=15dB\nindicatesthattheenergyoftheadversarialperturbationislessthan\n3.1% of that of the original ambient sound. As a comparison, the\nASPR of digital attacks on speech recognition systems in [ 34]i s\n14∼18.6dB.NotethattheeffectiveASPRofFenceSitteriscloseto\nthat in [34], even though the victim’s voice during enrollment will\nfurtherinterferewiththeadversarialperturbations.Asshownin\nFig.5,whenwefixASPRas15dB,theASRisabove84.9%whenthe\nVARisashighas10dB,whichmeansthattheenergyofthevictim’s\nenrollment voice is 10 times of the adversarial ambient sound.4.2.3 PoisoningRate. Poisoningrate,denotedas 𝑁𝑝,measuresthe\nproportionofvictim’s enrollmentsamplesthatareaffected bythe\nadversarial sequence. We set ASPR=15dB, VAR=5dB. As shown in\nFig.6,asthepoisoningrateincreases,i.e.,from20%(1/5)to100%\n(5/5),theASRincreasesinallthreetasks.When 𝑁𝑝=3,theaverage\nASRishighenoughforpracticalattacks,i.e.98.8%,93.4%,94.0%for\nthreetasksrespectively.Asthepoisoningrateincreases,theACC\ndrops a little but is still acceptable ( ≥88.5% when 𝑁𝑝=5). This\nindicates that we only need to affect some legitimate enrollment\nsamples in order to have a successful attack.\n4.2.4 TheNumberofCollectedVictimSamples. Westudytheim-\npact of the number of collected victim samples used to generate\nthe content-independent adversarial sequence, i.e., the size of 𝑉in\n§3.2,ontheattackperformance.Wegenerateadversarialsequences\nwithdifferentnumbersofvictimsamplesrangingfrom0 ∼50𝑠𝑒𝑔𝑠\n(1𝑠𝑒𝑔=1.6secondsinourexperiments).AsshowninFig.7,asmore\nvictimsamplesareusedtogeneratethe adversarialsequence,the\nperformance of FenceSitter is better, which is most pronounced\non VoxCeleb1 (cf.Fig. 7(a)). Around50s of voice samplesfrom the\nvictimisenoughforgeneratingarobustcontent-independentadver-\nsarial sequence to launch the attack, which is within the capability\nof the adversary. Thus, in the following experiments, we use 50s of\nvictim samples to generate the adversarial sequence by default.\n4.2.5 DifferentAdversary-VictimPairs. Toevaluatetheeffective-\nness of FenceSitter when the similarity between the voice of the\nadversary and the victim varies, we conduct two sets of experi-\nments:(1)different adversariesattackingthesame victim,and(2)\ndifferent victims attacked by the same adversary. For (1), we setthe 6 selected speakers (3 females and 3 males) as the adversary,\nandrandomlyselectanothermalespeakerfromeachdatasetasthe\nvictim.Similarly,for(2),wesetthe6selectedspeakersasthevictim,\nandrandomlyselectanothermalespeakerfromeachdatasetasthe\nadversary.\nTheresultsof(1)arelistedinTable3.Wecanobservethatintra-\ngender attacks are more likely to be effective than inter-genderattacks, especially in OSI and SV tasks (F1, F2, F3 of VoxCeleb1,\nF1ofLibriSpeec handF2ofST-CMDShavelowerACCorASRin\nattacking male victims than male adversaries). FenceSitter gener-\natesanadversarialsequencethatisclosetoboththevictimandthe\nadversary from the perspective of the target SRS. If the victim and\ntheadversaryhaveaverydifferenttimbre,theadversarialsequence\nwillberelativelyfarawaytoboththevictimandtheadversary.OSI\nand SV both consider absolute similarity, while CSI only considers\nrelativesimilarity.AlthoughtheperformancedegradationinOSI\nand SV is more obvious, the attack is still effective as the ACC and\nthe ASR are still above 67.4% (F1 of VoxCeleb1).\nThe results of (2) are listed in Table 4. The average ACC and\nASR of the male adversary attacking male victims are higher than\nthoseofthemaleadversaryattackingfemalevictims.Theresults\nshow that a single adversary is able to attack different victims.\nThe performanceof inter-gender attacksmay beimprovedif the\nadversaryintentionallyimitatesthevoiceofthevictim,e.g.,amale\nadversary raises his voice to attack a female victim.\n4.2.6 Different Ambient Sound Carriers. We evaluate the impact\nof ambient sound carriers on the attack performance. We use four\n \n761CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\nCSI OSI SV\n0.00.51.0ACC\n5 10 15 20 25\nASPR (dB)0.00.51.0ASR\n(a) VoxCeleb10.00.51.0ACC\n5 10 15 20 25\nASPR (dB)0.00.51.0ASR\n(b) LibriSpeech0.00.51.0ACC\n5 10 15 20 25\nASPR (dB)0.00.51.0ASR\n(c) ST-CMDS\nFigure 4: Attack performance under different ASPRs. A higher ASPR indicates that smaller adversarial perturbations are added\nto the original ambient sound.\nTable 3: The performance of different adversaries attacking the same victim.\nVoxCeleb1 (%) LibriSpeech (%) ST-CMDS (%)\nM1 M2 M3 F1 F2 F3 M1 M2 M3 F1 F2 F3 M1 M2 M3 F1 F2 F3\nCSIACC99.0 100 99.6 96.7 98.1 97.1 100 100 100 92.6 97.9 99.7 99.7 100 100 96.4 96.1 100\nASR98.8 100 99.6 97.3 100 100 100 100 98.2 98.4 100 100 100 100 100 99.2 82.2 100\nOSIACC97.0 100 89.8 67.4 78.6 70.4 99.7 100 100 88.5 97.9 99.1 99.7 100 100 94.1 93.6 100\nASR98.8 99.6 95.5 76.7 89.4 98.2 100 99.4 96.5 98.4 98.3 100 100 100 100 99.2 82.2 100\nCSIACC97.0 100 89.8 67.4 78.6 70.5 99.7 100 100 92.4 98.8 99.4 100 100 100 96.0 95.3 100\nASR100 99.6 95.5 76.7 89.4 98.2 100 99.4 97.3 100 98.3 100 100 100 100 100 99.1 100\nTable 4: The performance of the same adversary attacking different victims.\nVoxCeleb1 (%) LibriSpeech (%) ST-CMDS (%)\nM1 M2 M3 F1 F2 F3 M1 M2 M3 F1 F2 F3 M1 M2 M3 F1 F2 F3\nCSIACC100 99.7 99.7 97.3 97.6 98.5 99.7 98.9 95.5 97.4 99.8 100 100 99.0 100 96.6 96.4 100\nASR99.4 99.9 100 88.5 95.5 89.1 100 98.5 100 100 100 100 100 100 100 99.0 92.7 100\nOSIACC98.9 98.4 97.9 92.9 94.6 88.5 99.7 98.9 94.3 93.9 99.3 97.3 100.0 97.3 100 96.2 96.4 100\nASR99.4 99.9 99.6 73.1 92.9 84.2 100 98.5 100 100 100 100 100 100 100 96.0 84.0 100\nSVACC98.9 98.8 97.9 93.2 96.4 88.5 100 98.9 96.0 94.7 99.5 97.3 100.0 97.4 100 99.1 100 100\nASR100 100 99.6 79.4 97.1 88.8 100 100 100 100 100 100 100 100 100 96.8 85.7 100\nCSI OSI SV\n0.00.51.0ACC\n0 2 4 6 8 10 12 14\nVAR (dB)0.00.51.0ASR\nFigure5:AttackperformanceunderdifferentVARs.Ahigher\nVAR indicates that the relative energy of the adversarial\nambient sound to the legitimate enrollment voice is smaller.\nkinds of ambient sounds, including leaf rustling, bird chirping, traf-\nfic noises and pop music. As shown in Table 14 in the extended\nversion[8],foreachdataset,thereisnosignificantdifferenceamong\nfour carriers, which gives the adversary more options when choos-\ning ambient sounds.In addition to the sounds inour experiments,\nthe adversary can use other ambient sounds that are prevalent\naround the target area, e.g., air conditioning noise in an office,\nengine noise in a vehicle.\n4.2.7 DifferentSRSModels. Weevaluateourattackontwopopular\nend-to-end DNN-based SRS models, i.e., DeepSpeaker and ECAPA-\nTDNN. We find no significant difference between attacks on thetwo models. Due to page limitation, the experimental results are\ngiven in Table 15 in §A.3 in the extended version [8].\n4.3 Physical Attack Performance\nWe carry out extensive experiments in the physical domain to\nevaluate the practical performance of FenceSitter under different\nconditions, i.e., distances, angles, loudspeakers, recording devices.\nIn the physical experiments, we use the same default configura-\ntionasthedigitalattacks.WesetVAR=5dBandASPR=5dBasdefaultunlessotherwisespecified.TopreciselycontroltheVAR,weuseone\nloudspeaker to play the mixed audio of the enrollment sample and\ntheadversarialaudiowithexactVAR.Tofurtherevaluatetheattack\nperformance of the adversarial sequence in a synchronization-free\nmanner, we conduct live enrollment experiments in §4.3.5.\nWe evaluate our attack in four locations, i.e., office, lounge,\nbalcony and vehicle (cf. §4.3.2). The office size is approximately\n3.6𝑚×2.6𝑚with the main noises coming from the air conditioner.\nTheloungesizeisabout7 .3𝑚×7𝑚withthemainnoisescoming\nfromtheworkingrefrigerator.Thebalconysizeisabout4 𝑚×4𝑚\nwiththemain noisescomingfromthe workingnoiseofaircondi-\ntioner’soutsideunit,therustleofleavesandthechirpingofinsects\nand birds. The vehicle size is about 2 𝑚×1.5𝑚(inside) with the\nmainnoisescomingfromtheengine,tiresandtheambientnoise\nonthe road.Theambientnoises oftheoffice,lounge, balconyand\n \n762FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nCSI OSI SV\n0.00.51.0ACC\n1 2 3 4 5\nNp0.00.51.0ASR\n(a) VoxCeleb10.00.51.0ACC\n1 2 3 4 5\nNp0.00.51.0ASR\n(b) LibriSpeech0.00.51.0ACC\n1 2 3 4 5\nNp0.00.51.0ASR\n(c) ST-CMDS\nFigure 6: Attack performance with different poisoning rates. The poisoning rate measures the fraction of victim’s enrollment\nsamples that are affected by the adversarial sequence.\nCSI OSI SV\n0.00.51.0ACC\n0 10 20 30 40 50\nDuration (seg)0.00.51.0ASR\n(a) VoxCeleb10.00.51.0ACC\n0 10 20 30 40 50\nDuration (seg)0.00.51.0ASR\n(b) LibriSpeech0.00.51.0ACC\n0 10 20 30 40 50\nDuration (seg)0.00.51.0ASR\n(c) ST-CMDS\nFigure 7: Attack performance with different numbers of victim samples used to generate the adversarial sequence. Around 50s\n(1𝑠𝑒𝑔=1.6 seconds) of victim voice samples are needed to generate an effective content-independent adversarial sequence.\nvehicle(cruising)areapproximately36dB(A),36dB(A),40dB(A)\nand 55 dB(A) respectively, measured with a digital sound level me-\nter (i.e., BENETECH GM1357). In the following experiments, the\nmixedaudiosweplayvialoudspeakersareapproximately75dB(A),\nmeasured at a distance of 0.5m.\n4.3.1 The Number of RIRs. We generate adversarial sequences\nusing different numbers of RIRs, i.e., 0 ∼20 (randomly chosen from\nAachenImpulseResponse(AIR)Database[ 17]).Thenwelaunchthe\nattacks in both digital and physical domains. The distance between\nthe loudspeaker and the microphone is set as 0.5 meters in the\noffice. As shownin Fig. 8, as we increasethe number of RIRs used\nintheoptimization,bothACCandASRoftheover-the-airattack\nincrease. For reference, the ACC and ASR of the corresponding\ndigitalattacksare90.9% ∼100%.ItindicatesthatifweusemoreRIRs,\nthe robustness of the adversarial sequence increases such that the\ngapbetweenthedigitalandphysicalattackisreduced.Notethat\ntheASRofLibriSpeechisrelativ elylowerwhen20RIRsareused\n(cf.Fig.8(b)),due toatrade-offbetweenACCand ASR.Whenthe\nlossof𝑆(·,𝑋𝑣𝑖𝑐𝑡𝑖𝑚)ishighlyoptimized,thelossof 𝑆(·,𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟)\nmight be less optimized (cf. Equ. (6)). In the following experiments,\nwe use 20 RIRs for optimization.\n4.3.2 DifferentLocationsandDistances. Weconductexperiments\natdifferentdistancesinfourscenarios,i.e.,office,lounge,balcony\nandvehicle.AsshowninFig.9,asthedistanceincreases,theper-\nformance of the attack decreases. The attack is still effective at a\ndistance of 2 meters with an average ACC and ASR of above 85.5%.\nNotethatintherunningvehiclescenario,weonlytest0.5 ∼2meters\ndue to the limited space of the car. We carried out the experiments\nwhenthecarisrunningonthe roadataspeedof20 ∼30mph.Theattack is effective at a distance of 2 meters even under the interfer-\nence of the engine and the tire noises of a running vehicle. As the\n20RIRsarerandomlysampledfromtheRIRdataset 𝐻,theadver-\nsarialsequencemayhaveespeciallygoodperformanceincertain\nscenarios, e.g., the ACC and ASR at 3 meters in the balcony are all\nabove87.7%.Asophisticatedadversarymaygatheracustomized\nRIRdatasetforaspecificattackscenario(e.g.,office,lounge,vehicle)\nto further improve the attack performance. Due to page limitation,\ncompleteexperimentalresultsonthreedatasetsinfourscenarios\nare given in Table 9-12 in §A.2 in the extended version [8].\n4.3.3 Different Angles. The microphone we use is omnidirectional,\ncommonlydeployedinsmartphonesandsmartspeakers.Weplay\nthe adversarial sequence at the front, back, left and right of the mi-\ncrophone(atadistanceof0.5m)tostudytheimpactofmicrophone\ndirectivity. We find that there is no significant difference among\ndifferentangles.Duetopagelimitation,theexperimentalresults\nare given in Table 13 in §A.2 in the extended version [8].\n4.3.4 DifferentLoudspeakersandRecordingDevices. Westudywhe-\nther our attack can be launched with different devices, i.e., loud-\nspeakers and recording devices. We tune 3 loudspeakers to play\nthe audios at a similar volume. We test 3 loudspeakers, i.e., JBL\nGO2H, EDIFIERM16, Remax RB-M9,and 4 recordingdevices, i.e.,\nLM17connectedtoaThinkpadX1withWindows10Professional,\nHUAWEI nova6 with HarmonyOS 2.0.0, iPad Pro with iPadOS\n13.6.1 and iPhone 12 with iOS 15.1.1. From Table 5, We can see\nthat different loudspeakers have different attack performances due\ntotheirvaryingacousticqualities,whichcanbecharacterizedby\nSNR (Signal-to-noise Ratio) and THD (Total Harmonic Distortion).\nA lower acoustic quality results in more noises and distortions.\n \n763CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\nCSI OSI SV\n0.00.51.0ACC\n0 5 10 15 20\nThe number of RIRs0.00.51.0ASR\n(a) VoxCeleb10.00.51.0ACC\n0 5 10 15 20\nThe number of RIRs0.00.51.0ASR\n(b) LibriSpeech0.00.51.0ACC\n0 5 10 15 20\nThe number of RIRs0.00.51.0ASR\n(c) ST-CMDS\nFigure 8: Physical attacks with different numbers of RIRs used for optimization. For most of the cases, 20 RIRs are enough for\neffective physical attacks.\nCSI OSI SV\n0.00.51.0ACC\n0.5 1 1.5 2 3\nDistance (m)0.00.51.0ASR\n(a) Office0.00.51.0ACC\n0.5 1 1.5 2 3\nDistance (m)0.00.51.0ASR\n(b) Lounge0.00.51.0ACC\n0.5 1 1.5 2 3\nDistance (m)0.00.51.0ASR\n(c) Balcony0.00.51.0ACC\n0.5 1 1.5 2\nDistance (m)0.00.51.0ASR\n(d) Running Vehicle\nFigure 9: ACC and ASR at different distances in four scenarios, i.e. office (a), lounge (b), balcony (c), running vehicle (d). As the\ndistance increases, the ACC and ASR decrease. The attack is still effective even at a distance of 2 meters in a running car with\nengine and tire noises.\nTable5:Theattackperformancewithdifferentloudspeakers.\nVoxCeleb1 (%) LibriSpeech (%) ST-CMDS (%)\nJBL EDI REM JBL EDI REM JBL EDI REM\nCSIACC100 99.8 100 100 100 100 99.7 99.9 94.6\nASR99.7 99.4 97.9 100 98.6 100 100 93.6 96.8\nOSIACC98.9 89.1 83.4 97.3 99.0 93.4 97.9 99.5 86.7\nASR95.7 96.8 79.2 100 98.5 100 98.9 89.7 90.7\nSVACC98.9 89.1 83.4 97.3 99.0 93.4 98.2 99.6 88.1\nASR96.0 97.1 79.3 100 99.9 100 98.9 93.0 92.9\n∗:JBL:JBL GO2H. EDI:EDIFIER M16. REM:Remax RB-M9.\nTable 6: The attack performance with different recording\ndevices.\nVoxCeleb1 (%) LibriSpeech (%) ST-CMDS (%)\nM17 HW iPad iP12 M17 HW iPad iP12 M17 HW iPad iP12\nCSIACC100 98.8 96.3 97.2 100 100 100 100 99.7 99.9 100 100\nASR99.7 100 100 100 100 98.7 98.3 100 100 100 99.7 100\nOSIACC98.9 95.4 83.6 84.8 97.3 97.3 93.4 94.4 97.9 99.9 100 100\nASR95.7 100 100 100 100 98.7 98.3 100 98.9 100 99.7 100\nSVACC98.9 95.4 83.8 85.2 97.3 97.3 93.4 94.4 98.2 100 100 100\nASR96.0 100 100 100 100 100 99.6 100 98.9 100 100 100\n∗:M17:LM17, an omindirectional microphone connected to a Thinkpad X1. HW:\nHUAWEI nova6. iPad:iPad Pro. iP12:iPhone 12.\nWe check the SNR and THD of each loudspeaker from their ven-\ndors, and find that the SNRs of JBL, EDI, REM are ≥80dB,≥75dB,\n≥70dB,respectively.ThusJBLhasthebestperformancebecause\nit introduces the least noises among the three loudspeakers. We\ndid not present the THDs of the three loudspeakers as different\nvendors test THDs under different conditions. But we speculate\nthattheimpactofTHDismildasithasbeencompensatedinthe\noptimizationprocessusingRIRsmeasuredwithdifferentdevices\n(cf.§3.3).\nVictim\n Loudspeaker\nSRS\nDecibel\nMeter\nVictim’s \nVoice\n Adversarial\nSequence\nFigure 10: Live enrollment setup.\nThe results of different recording devices are listed in Table 6.\nWefindthatdifferentrecordingdeviceshavedifferentattackper-\nformances mainly due to their varying compression parameters.\nLM17andthedesktopitconnectedtorecordaudiosinanuncom-\npressed format. Other three devices record audios in a compressed\nformat,i.e.,AAC-LC[ 4].Butdifferently,HUAWEInova6records\naudiosatabitrateof ∼150kbps,whiletwoAppledevicesrecordata\nbitrate of ∼64kbps, which causes more information loss. Therefore,\nwecanseefromtheTable6thatLM17andHUAWEIhavesimilar\nperformance,slightlybetterthanthatofiPadandiPhone.Although\ntheaudiosarecompressed,theACCandASRofthethreedevices\nare all≥83.6%.It meansthe adversarialperturbations cansurvive\nthe commercially-used compression methods of smart devices. We\nfurther evaluate the impact of mp3 compression in §4.5.\n4.3.5 Attacking Live Enrollment. We have recruited 2 females and\n2 males to perform live enrollment in the SRS as the victim, and\nwe randomly select a male speaker from LibriSpeec h as the ad-\nversary. One female and one male speak English and the others\nspeak Chinese. We collect 50 samples from each victim, among\nwhich 5 is used to enroll thevictim into a copy of the target SRS.\nInthiswaywecanestimatethegradientsbyqueryingtheSRSto\nperformblack-boxattacks.Weuseanother5samples( ∼50seconds)\n \n764FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nTable 7: The performance of attacking live enrollment.\nM1 M2 F1 F2\nLanguage English Chinese English Chinese\nDeviceOppo Reno4\nSE 5GHUAWEI\nP30MacBook\nPro 2019iPhone 13\nOS Ver.ColorOS\nV11.1HarmonyOS\n2.0.0MacOS\nMonterey\n12.0.1iOS\n15.0.2\nCSIACC 100 % 100 % 98.4 % 100 %\nASR 94.4 % 96% 92.9 % 88.2 %\nOSIACC 100 % 100 % 73.8 % 100 %\nASR 93.9 % 95.5 % 86.5 % 74.5 %\nSVACC 100 % 100 % 73.8 % 100 %\nASR 98.7 % 99.4 % 93.4 % 79.8 %\nto generate content-independent adversarial sequences. After that,\nthe four participants are asked to perform enrollment (at a volume\nof 65∼75dB(A)) while the corresponding adversarial sequence is\nplayed in the background (at a volume of 61 ∼65dB(A)). The en-\nrollmentsamplesandtheadversarialambientsoundarerecorded\nwithparticipants’owndevices.ThesetupisshowninFig.10.We\nevaluate the attack performance with the remaining 40 samples of\neachvictim.TheresultsareshowninTable7.Aswecansee,our\nattack can succeed in practical live enrollment scenarios for males\nand females speaking English and Chinese using their personal\ndevices.Inconsistentwiththeresultsin §4.2.5,intra-genderattacks\nare more effective than inter-gender attacks.\n4.4 Human Imperceptibility via User Study\nWe conduct a user study to demonstrate the imperceptibility of\nthegeneratedadversarialsequence.Wehaverecruited44partici-\npants. The user study is done under our observation, by which we\nguaranteethatnobotsorscriptsorautomatedansweringtoolsis\nused in the process. We use 10 different kinds of ambient sound\ncarriers (including office, bird chirping, raining, thundering, wind,\nseawaveandcooking)togenerate10adversarialsequenceswith\nASPR=15dB (digitally effective) and 10 adversarial sequences with\nASPR=5dB (physically effective). We ask participants to rate the\nambient sound based on their naturalness with ascore from 1 ∼5\npoints (1 for very unnatural and 5 for very natural).\nThe results of the user study are shown in Fig. 11. Some ad-\nversarial sequences are rated with high scores, while some clean\nambientsoundsareratedwithlowscores.Thereforewhenmixed\nwith common ambient sounds, adversarial perturbations might\nnotbeperceivedbyhumans,thuspeoplemightnotbeabletodis-\ntinguish some clean ambient sounds from those with specialised\nperturbations.Theadversarycanchoosethemostnatural-sounding\nambient sounds to launch the attack.\n4.5 Resistance to Defense\nIn this section, we study five commonly-used defense methods for\naudioadversarialexampleattacks:localsmoothing,quantization,\naudio squeezing, mp3 compression and voice activity detection\n(VAD). We evaluate the attack performance on all three tasks of\ntheDeepSpeakersystem.Innormalenrollmentcaseswithoutthe\nattack,thenormalACCis100%,100%,100%,andtheASRis1.4%,1 2 3 4 5\nQuality (Normalized )0.00.10.20.30.4Density5dB\n15dB\nClean\nFigure 11: Results of user study.\n0%,0%forthethreetasksrespectively.Intheadversarialenrollment\ncases with the attack, the ACC is 98.2%, 96.9%, 98.7%, and the ASR\nis 97.3% 96.5%, 99.2% for the three tasks respectively.\nWe assumethatthe adversary onlyhasan undefendedversion\nofthetargetSRSmodel,anddoesnotknowthedefensemethods\nadopted by the defender. We consider two kinds of adversaries.\n(S1)Naive adversary. The naive adversary crafts the adversarial\nsequences basedon the undefended model toattack the defended\nmodel. (S2) Sophisticated adversary. The sophisticated adversary\nappliesvariousdefensemethodstotheundefendedmodel,based\non which generalizable adversarial sequences are generated. We\nset ASPR=15dB, VAR=5dB.\nTheresultsarelistedinTable16,Table17andTable18in§A.4\nin the extended version [ 8]. We find that quantization and VAD\nareineffectivesincetheycannotlowertheASRofS1(all ≥96.5%).\nAudio squeezing is effective but if the squeezing rate is set as ≤0.5\n(lower squeezing rate means more information loss), the normal\nACC is destructively decreased (to 48.7% in OSI task). After the\nsophisticated adversary integrates the squeezing operation (with 3\nsqueezingrate,i.e.,0.9,0.7,0.5)intotheoptimizationprocess,the\nASRofS2increasesto93.5%,88.8%,94.1%atasqueezingrateof0.5.\nForlocalsmoothingmethod,westudymeanfilterandfindthatitis\neffectiveandpracticableinloweringtheASRofS1whenthekernel\nlength is 5 ∼17. When the sophisticated adversary integrates mean\nfilter in the optimization process with a kernel size of 3, 5, and 7,\ntheASRofS2atameankernelof7isincreasedto97.2%,92.9%,and\n95.6%.Wealsofindthattheadversarialsequencesoptimizedwith\nthe mean filter can increase the ASR of S2 under mp3 compression\nto an acceptable level ( ≥78.1%).\n5 DISCUSSION\nInthissection,wedescribepotentialdefensesagainstFenceSitter\nand discuss the limitations of FenceSitter.\n5.1 Potential Defense\nWe have demonstrated in §4.5 that common audio processing tech-\nniquesarenoteffectiveindefendingagainstFenceSitter.Apart\nfrom these audio processing techniques, liveness detection and\ntext-dependentSRSalsohavelimiteddefensepoweroverFenceSit-\nter.Traditionalaudioadversarialexample attacksarevulnerable\nto liveness detection since the adversarial examples need to beplayed by electronic speakers as it is very difficult to utter theminutely-crafted adversarial perturbations by human beings. In\ncontrast, FenceSitter is robust to liveness detection methods that\nonly check liveness but do not leverage other biometrics to verify\ntheidentityoftheuser.Ifotherbiometricsareusedforverification,\nthe user also enrolls the corresponding biometrics, e.g., lip motion\n \n765CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Jiangyi Deng, Yanjiao Chen, & Wenyuan Xu\n[11],soundfield[ 33].FenceSittermakestheSRSrememberthe\nvoiceprint of the adversary but not these biometrics. To extend\nFenceSitter to involve other biometrics during the enrollment\nphaseisaninterestingfuturedirection.Text-dependentSRSmay\nbe morevulnerable toFenceSitter as theadversary mayacquire\nprior knowledge of what the victim will say, e.g., numbers.\nAnotherpotentialdefenseagainstFenceSitterisfortheuser\nto enrollin a quietplace with noaudible ambient sound. Tomake\nFenceSitter inaudible rather than imperceptible, we may exploit\nthe ultrasound. Previous works have shown that ultrasound can\nbeusedtoinjectmaliciouscommandsintosmartdeviceswithout\nthe user hearing anything [ 36]. Instead of carrying the adversarial\nperturbations using ambient sounds, it is possible to modulate the\nultrasoundtorealizethesameattackgoal.Nevertheless,processing\nand transmitting ultrasound requires special hardware and the\ntransmission range of ultrasound is shorter than audible sound.\nFinally, FenceSitter may be defended if the service provider\nof the target SRS withholds the confidence score 𝑆(𝑥), which is\nneeded to optimize the adversarial sequence in both the white-box\nand the black-box settings. A recent work has demonstrated that it\nispossibletoproduceaudioadversarialexamplesforcommercial\nASRs with only the classification label in the recognition phase\n[37]. Similar ideas may be followed to help FenceSitter construct\nadversarial sequence for enrollment-phase attacks.\n5.2 Limitations\nThefirstlimitationofFenceSitteristhatitisdifficulttoachieve\na high attack success rate if the timbre of the adversary and the\nvictimuserhasagreatdiscrepancy,e.g.,ofdifferentgenders.Inthis\ncase, to make the enrolled speaker model resemble the voiceprints\nof both the victim user and the adversary is hard. The polluted\nspeaker model can be viewed as in the middleof the voiceprint\nvectorsofthevictimuserandtheadversary(representedas 𝑋𝑣𝑖𝑐𝑡𝑖𝑚\nand𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟).Ifthedistance,e.g.,cosinedistance,between 𝑋𝑣𝑖𝑐𝑡𝑖𝑚\nand𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟is small, the resulting speaker model is close to\nboth𝑋𝑣𝑖𝑐𝑡𝑖𝑚and𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟, which leads tosatisfactory attack per-\nformance of FenceSitter. If the distance between 𝑋𝑣𝑖𝑐𝑡𝑖𝑚and\n𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟islarge,itisquitedifficulttocraftaspeakermodelthat\nis close to both 𝑋𝑣𝑖𝑐𝑡𝑖𝑚and𝑋𝑎𝑡𝑡𝑎𝑐𝑘𝑒𝑟.\nThesecondlimitationofFenceSitteristhattheattackperfor-\nmancemaydegradeiftheSRScontinuouslyupdatesthespeaker\nmodel. For instance, to account for possible voice changes of the\nuser,someSRSmayperiodicallycollecttheaudiosamplesofthe\nusertoretraintheSRSmodel.Inthiscase,thespeakermodelwill\nbe veered towards the user and away from the adversary. A pos-sible countermeasure is to play the adversarial sequence during\ntherecognitionphaseaswell.Wewillconsiderthispossibilityin\nfuture work.\n6 RELATED WORK\n6.1 Training Phase Backdoor Attacks\nAs far as we know, there is only one work on backdoor attacks\nagainstSRSs.Zhaietal.[ 35]proposedabackdoorattackonspeaker\nverification models by poisoning the training data. Unlike their\nwork,ourattackiscarriedoutintheenrollmentphaseinsteadofin\nthetrainingphase.Moreover,wedonotneedtopoisonthetrainingdata, which is difficult since the adversary needs to have access to\nthe training data.\n6.2 Recognition Phase Adversarial Attacks\nAdversarialattacksonSRSscanbecategorizedintouniversalad-\nversarialperturbations (UAPs)and non-universaladversarialper-\nturbations (non-UAPs).\n6.2.1 UniversalAdversarialPerturbations. Tothebestofourknowl-\nedge,thereisonlyoneworkonUAPoverSRSs.Lietal.[ 20]proposed\nAdvPulse,anapproachtogeneratesubsecondaudioadversarialper-\nturbationsmainlyforspeechrecognition.Asmallsetofexperiments\nhave been conducted to show that AdvPulse is also effective for\nSRS models regarding only the CSI task. We have explained thatsubsecond perturbations may not be effective for attacking SRSs\nbecauseSRSscanrandomlysamplesegmentsofanaudiosample\nto extract the voiceprint, and the frames containing the subsecond\nperturbations are possibly trimmed or destroyed. Moreover, we\nhavedemonstratedthatFenceSitteriseffectiveforCSI,OSIand\nSVtasks.FenceSittercanalsobecarriedoutunderablack-box\nsetting, which is not the case for AdvPulse.\n6.2.2 Non-Universal Adversarial Perturbations. Li et al.[19]p r o -\nposed a physical white-box attack on X-vector and evaluated their\nattackonCSItasks.Abdullahetal.[ 3]proposedablack-boxtransfer-\nable adversarial attack on speechrecognition and speaker recogni-\ntionsystems.However,theattackisuntargetedanddigital.Chenetal.[\n5]proposedFakeBob,aphysicalblack-boxadversarialattackon\nSRSs.ComparedtoFakeBob,FenceSitterattacktheenrollment\nphase but not the recognition phase. FenceSitter is universal and\ntheadversarycanusehisownvoicetobypasstheSRSs,whileFake-\nBob needs to play the adversarial example via loudspeaker. Those\nattacks [3,5,19] are non-universal as different perturbations are\nneededfordifferentaudiosamples.FenceSitterissynchronization-\nfree while these attacks are not.\n6.2.3 Other Adversarial Attacks. Yuan et al.[ 34] proposed a white-\nbox adversarial attack on speechrecognition systems using music\nascarriers.Differentfromtheirwork,weproposeablack-boxattackonspeakerrecognitionsystemsbut notspeechr ecognitionsystems.\n7 CONCLUSION\nIn this work, we propose an enrollment-phase attack frameworknamed FenceSitter, revealing a new attack surface of speaker\nrecognition systems. We generate long and continuous adversarial\nperturbations embedded in ambient sounds such that both the\nadversaryandthevictimusercanpasstheSRSaftertheadversarial\naudio is captured by the SRS in the enrollment phase. We alsodesign content desensitization and physical realization methodsto free the adversarial sequence from the interference from the\nvictim’s voice and physical distortions. We further leverage the\nnaturalevolutionstrategytoenableblack-boxattacks.Extensive\nexperimentsonthreedatasetsundervariousrealisticscenariosand\nconditions demonstrate our attack’s effectiveness.\nACKNOWLEDGMENTS\nWethanktheanonymousreviewersfortheirvaluablecomments.\nThis work is supported by China NSFC Grant 61925109.\n \n766FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attacks on SRSs CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nREFERENCES\n[1][n.d.]. TORCH.NN.FUNCTIONAL.CONV1D. https://pytorch.org/docs/stable/\ngenerated/torch.nn.functional.conv1d.html#torch.nn.functional.conv1d.\n[2]Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin\nR. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks againstSpeech and Sp eaker Recognition Systems. In Network and Distributed System\nSecurity Symposium. The Internet Society.\n[3]Hadi Abdullah, Muhammad Sajidur Rahman, Washington Garcia, Kevin Warren,\nAnuragSwarnimYadav,TomShrimpton,andPatrickTraynor.2021. Hear\"No\nEvil\",See\"Kenansville\"*:EfficientandT ransferableBlack-BoxAttacks onSpeech\nRecognition and Voice Identification Systems. In IEEE Symposium on Security\nand Privacy.\n[4]MarinaBosi,KarlheinzBrandenburg,SchuylerQuackenbush,LouisFielder,Kenzo\nAkagiri, Hendrik Fuchs, and Martin Dietz. 1997. ISO/IEC MPEG-2 Advanced\nAudio Coding. Journal of the Audio Engineering Society 45, 10 (1997), 789–814.\n[5]GuangkeChen,SenChen,LinglingFan,XiaoningDu,ZheZhao,FuSong,and\nYangLiu.2021. WhoisRealBob?AdversarialAttacksonSpeakerRecognition\nSystems. In IEEE Symposium on Security and Privacy.\n[6]JoonSonChung,ArshaNagrani,andAndrewZisserman.2018. VoxCeleb2:Deep\nSpeakerRecognition.In ConferenceoftheInternationalSpeechCommunication\nAssociation.\n[7]Najim Dehak, Patrick Kenny, Réda Dehak, Pierre Dumouchel, and Pierre Ouellet.\n2011. Front-EndFactorAnalysisforSpeakerVerification. IEEETransactionson\nSpeechandA udioProcessing 19, 4 (2011), 788–798.\n[8]Jiangyi Deng, Yanjiao Chen, and Wenyuan Xu. [n.d.]. FenceSitter: Black-box, Content-Agnostic, and Synchronization-Free Enrollment-Phase Attackson Speaker Recognition Systems extended version. https://person.zju.edu.cn/\nperson/attachments/2022-08/01-1661840363-856887.pdf.\n[9]Brecht Desplanques, Jenthe Thienpondt, and Kris Demuynck. 2020. ECAPA-\nTDNN: Emphasized Channel Attention, Propagation and Aggregation in TDNN\nBasedSpeakerVerification.In ConferenceoftheInternational SpeechCommunica-\ntion Association.\n[10]Tianyu Du, Shouling Ji, Jinfeng Li, Qinchen Gu, Ting Wang, and Raheem Beyah.\n2020. SirenAttack:GeneratingAdversarialAudioforEnd-to-EndAcousticSys-\ntems. InACM Asia Conference on Computer and Communications Security.\n[11]Maycel Isaac Faraj and Josef Bigün. 2007. Audio-visual person authentication\nusing lip-motion from orientation maps. Pattern Recognition Letters 28, 11 (2007),\n1368–1382.\n[12]J.Fortuna,P.Sivakumaran,AladdinM.Ariyaeeinia,andAmitS.Malegaonkar.\n2005. Open-setspeakeridentificationusingadaptedGaussianmixturemodels.\nInEuropean Conference on S peechCommunication and Technology. ISCA.\n[13]Stanley A Gelfand. 2017. Hearing: An introduction to psychological and physiolog-\nical acoustics. CRC Press.\n[14]Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. 2015. Explaining\nandHarnessingAdversarialExamples.In InternationalConferenceonLearning\nRepresentations. OpenReview.net.\n[15]HynekHermansky.1990. Perceptuallinearpredictive(PLP)analysisofspeech.\nthe Journal of the Acoustical Society of America 87, 4 (1990), 1738–1752.\n[16]Marco Jeub, Magnus Schäfer, and Peter Vary. 2009. A binaural room impulse re-\nsponsedatabasefortheevaluationofdereverberationalgorithms.In International\nConference on Digital Signal Processing. IEEE.\n[17]Marco Jeub, Magnus Schäfer, and Peter Vary. 2009. A binaural room impulse re-\nsponsedatabasefortheevaluationofdereverberationalgorithms.In International\nConference on Digital Signal Processing. IEEE.\n[18]ChaoLi,XiaokongMa,BingJiang,XiangangLi,XueweiZhang,XiaoLiu,Ying\nCao,AjayKannan,andZhenyaoZhu.2017. DeepSpeaker:anEnd-to-EndNeural\nSpeaker Embedding System. arXiv preprint arXiv:1705.02304 (2017).\n[19]ZhuohangLi,CongShi,YiXie,JianLiu,BoYuan,andYingyingChen.2020. Prac-\ntical Adversarial Attacks Against Speaker Recognition Systems. In InternationalWorkshop on Mobile Computing Systems and Applications. ACM.\n[20]Zhuohang Li, Yi Wu, Jian Liu, Yingying Chen, and Bo Yuan. 2020. AdvPulse:Universal, Synchronization-free, and Targeted Audio Adversarial Attacks via\nSubsecond Perturbations. In ACM SIGSAC Conference on Computer and Commu-\nnications Security.\n[21]SurfingTechnologyLtd.[n.d.]. ST-CMDS-20170001_1,FreeSTChineseMandarin\nCorpus. https://www.openslr.org/38/.\n[22]Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and\nAdrian Vladu. 2018. Towards Deep Learning Models Resistant to Adversarial\nAttacks.In InternationalConferenceonLearningRepresentations.OpenReview.net.\n[23]Lindasalwa Muda, MumtajBegam, and I.Elamvazuthi. 2010. Voice Recognition\nAlgorithmsusingMelFrequencyCepstralCoefficient(MFCC)andDynamicTime\nWarping (DTW) Techniques. arXiv preprint arXiv:1003.4083 (2010).\n[24]Arsha Nagrani, Joon Son Chung, and Andrew Zisserman. 2017. VoxCeleb: A\nLarge-Scale Speaker Identification Dataset. In Conference of the International\nSpeechCommunication Association.\n[25]Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. 2015.\nLibrispeech: An ASR corpus based on public domain audio books. In IEEE Inter-\nnational Conference on Acoustics, Speechand Signal Processing .\n[26]AdamPaszke,SamGross,FranciscoMassa,AdamLerer,JamesBradbury,Gregory\nChanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban\nDesmaison, Andreas Köpf, Edward Z. Yang, Zachary DeVito, Martin Raison,\nAlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,and\nSoumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep\nLearningLibrary.In ConferenceonNeuralInformationProcessingSystems.PMLR.\n[27]YaoQin,NicholasCarlini,GarrisonW.Cottrell,IanJ.Goodfellow,andColinRaffel.\n2019. Imperceptible, Robust, and Targeted Adversarial Examplesfor Automatic\nSpeechRecognition.In International Conference on Machine Learning. PMLR.\n[28]DavidSnyder,DanielGarcia-Romero,GregorySell,DanielPovey,andSanjeev\nKhudanpur. 2018. X-Vectors: Robust DNN Embeddings for Speaker Recognition.\nInIEEE International Conference on Acoustics, Speechand Signal Processing .\n[29]ChristianSzegedy,WojciechZaremba,IlyaSutskever,JoanBruna,DumitruErhan,IanJ.Goodfellow,andRobFergus.2014. Intriguingpropertiesofneuralnetworks.\nInInternational Conference on Learning Representations. OpenReview.net.\n[30]NormanPohHoonThian,ConradSanderson,andSamyBengio.2004. Spectral\nSubbandCentroidsasComplementaryFeaturesforSpeakerAuthentication.In\nBiometric Authentication First International Conference. Springer.\n[31]Dong Wang, Lantian Li, Zhiyuan Tang, and Thomas Fang Zheng. 2017. Deep\nspeaker verification: Do we need end to end?. In Asia-Pacific Signal and Informa-\ntion Processing Association Annual Summit and Conference. IEEE.\n[32]Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun, Jan Peters, and Jürgen\nSchmidhuber.2014. Naturalevolutionstrategies. JournalofMachineLearning\nResearch15, 1 (2014), 949–980.\n[33]ChenYan,YanLong,XiaoyuJi,andWenyuanXu.2019. TheCatcherintheField:\nAFieldprintbasedSpoofingDetectionforText-IndependentSpeakerVerification.\nInACM SIGSAC Conference on Computer and Communications Security.\n[34]XuejingYuan,YuxuanChen,YueZhao,YunhuiLong,XiaokangLiu,KaiChen,\nShengzhiZhang,HeqingHuang,XiaofengWang,andCarlA.Gunter.2018. Com-manderSong:ASystematicApproachforPracticalAdversarialVoiceRecognition.\nInUSENIX Security Symposium.\n[35]TongqingZhai,YimingLi,ZiqiZhang,BaoyuanWu,YongJiang,andShu-Tao\nXia.2021. BackdoorAttackAgainstSpeakerVerification.In IEEEInternational\nConference on Acoustics, Speechand Signal Processing .\n[36]Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and\nWenyuan Xu. 2017. DolphinAttack: Inaudible Voice Commands. In ACM SIGSAC\nConference on Computer and Communications Security.\n[37]BaolinZheng,PeipeiJiang,QianWang,QiLi,ChaoShen,CongWang,Yunjie\nGe, Qingyang Teng, and Shenyi Zhang. 2021. Black-box Adversarial Attacks\non Commercial Speech P latforms with Minimal Information. In ACM SIGSAC\nConference on Computer and Communications Security.\n \n767"}
{"title": "Go/t_ta Catch ’Em All:Using Honeypots to CatchAdversarial A/t_tac", "content": "Go/t_ta Catch ’Em All:Using Honeypots to CatchAdversarial\nA/t_tac\nks on Neural Networks\nShawn Shan\nshansixiong@cs.uchicago.edu\nUniversity ofChicagoEmily Wenger\newillson@cs.uchicago.edu\nUniversity ofChicagoBolunWang\nbolunwang@cs.uchicago.edu\nUniversity ofChicago\nBoLi\nlbo@illinois.edu\nUIUCHaitaoZheng\nhtzheng@cs.uchicago.edu\nUniversity ofChicagoBenY. Zhao\nravenben@cs.uchicago.edu\nUniversity ofChicago\nABSTRACT\nDeep neural networks (DNN) are known to be vulnerable to ad-\nversarial attacks.Numerouseﬀortseither trytopatchweaknesses\nin trained models, or try to make it diﬃcult or costly to compute\nadversarial examples that exploit them. In our work, we explore\na new “honeypot” approach to protect DNN models. We inten-\ntionally inject trapdoors , honeypot weaknesses in the classiﬁca-\ntion manifold that attract attackers searching for adversarial ex-\namples.Attackers’optimizationalgorithmsgravitatetowardstrap-\ndoors,leading them toproduceattackssimilar totrapdoorsinthe\nfeature space. Our defense then identiﬁes attacks by comparing\nneuron activationsignatures ofinputs tothoseoftrapdoors.\nInthispaper,weintroducetrapdoorsanddescribeanimplemen-\ntation of a trapdoor-enabled defense. First, we analytically prove\nthattrapdoorsshapethecomputationofadversarialattackssothat\nattackinputswillhavefeaturerepresentationsverysimilartothose\noftrapdoors.Second,weexperimentallyshowthattrapdoor-protected\nmodels can detect, with high accuracy, adversarial examples gen-\nerated by state-of-the-art attacks (PGD, optimization-based CW,\nElasticNet,BPDA),withnegligibleimpactonnormalclassiﬁcation.\nThese results generalize across classiﬁcation domains, including\nimage, facial, and traﬃc-sign recognition. We also present signif-\nicant results measuring trapdoors’robustness against customized\nadaptive attacks(countermeasures).\nCCS CONCEPTS\n•Security and privacy ; •Computing methodologies →Neu-\nral networks; Artiﬁcialintelligence ;Machinelearning ;\nKEYWORDS\nNeural networks; Adversarial examples; Honeypots\nACMReference Format:\nShawn Shan, Emily Wenger, Bolun Wang, Bo Li, Haitao Zheng, and Ben\nY.Zhao.2020.GottaCatch’EmAll:UsingHoneypots toCatchAdversarial\nAttacksonNeuralNetworks.In 2020ACMSIGSACConferenceonComputer\nPermission to make digital or hard copies of all or part of this w ork for personal or\nclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed\nfor proﬁt or commercial advantage and that copies bear this notice and the full cita-\ntion on theﬁrstpage.Copyrightsforcomponents of thisworkowned byothersthan\nACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orre-\npublish,topostonserversortoredistributetolists,requirespriorspeciﬁcpermission\nand/or afee. Request permissionsfrompermissions@acm.org.\nCCS ’20,November9–13,2020,Virtual Event,USA\n© 2020 Association for Computing Machinery.\nACM ISBN978-1-4503-7089-9/20/11...$15.00\nhttps://doi.org/10.1145/3372297.3417231andCommunicationsSecurity(CCS’20),November9–13,2020,VirtualEvent,\nUSA.ACM,NewYork, NY,USA, 17pages.\nhttps://doi.org/10.1145/3372297.3417231\n1 INTRODUCTION\nDeepneuralnetworks(DNNs)arevulnerabletoadversarialattacks\n[39,46],inwhich,givenatrainedmodel,inputscanbemodiﬁedin\nsubtleways(usuallyundetectablebyhumans)toproduceanincor-\nrectoutput[2,10,34].Thesemodiﬁedinputsarecalledadversarial\nexamples,andtheyareeﬀectiveinfoolingmodelstrainedondiﬀer-\nent architectures or diﬀerent subsets of training data. In practice,\nadversarialattackshaveproven eﬀectiveagainst modelsdeployed\nin real-world settings such as self-driving cars, facial recognition,\nand objectrecognitionsystems [24,25,41].\nRecent results in adversarial machine learning include a long\nlist of proposed defenses, each proven later to be vulnerable to\nstronger attacks, and all focused on either mitigating orobfuscat-\ningadversarial weaknesses. First,many defenses focusondisrupt-\ning the computationof gradient optimizationfunctions critical to\nadversarialattacks[16,32].These“gradientobfuscation”defenses\n(e.g.[3,15,18,31,38,42,49])havebeenprovenvulnerabletoblack-\nboxattacks[34]aswellasapproximationtechniqueslikeBPDA[2]\nthatavoidgradientcomputation.Otherdefensesincreasemodelro-\nbustness to adversarial examples [35, 50] or use secondary DNNs\nto detect adversarial examples [33]. Finally, other defenses [8, 31]\nidentifyadversarial examplesatinference time.Allofthesefail or\naresigniﬁcantly weakened against stronger adversarial attacks or\nhigh conﬁdence adversarial examples [2,7–9,21].\nHistorysuggestsitmaybeimpossibleinpracticetoprevent ad-\nversaries from computing eﬀective adversarial examples, and an\nalternative approach to model defense is sorely needed. What if,\ninstead of trying to prevent attackers from computing eﬀective\nadversarial examples, we instead design a “honeypot” for attack-\ners, byinserting a subset of chosenmodel vulnerabilities, making\nthem easy to discover (and hard to ignore)? We could ensure that\nwhen attackers create adversarial examples, they ﬁnd our honey-\npot perturbations instead of natural weaknesses. When attackers\napplythesehoneypotperturbationstotheirinputs,theyareeasily\nidentiﬁed by our model because of their similarity to our chosen\nhoneypot.\nWe call these honeypots “trapdoors,” and defenses using them\ntrapdoor-enableddetection .Considerascenariowhere,startingfrom\nan input x, the attacker searches for an adversarial perturbation\nthat induces a misclassiﬁcation from the correct label /y.altxto some\ntarget/y.altt.Thisisanalogoustolookingfora“shortcut”throughthe\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n67a) Choose Label(s) to Defend b) Create / Deploy Trapdoored Model\nDef\nend label (y):\n20 km speed limit  \n Trapdoor\nInstances\n...\nBenign\nInstances \nTrain...Tr\napdoored model\n...\n...\nAdversarial Example Against Label (y)Benign\nInputAdversarial \nexample c) Compute “signature” of Trapdoor\n    Filter any inputs w/ similar signature    \nInput Similar to Trapdoor:\nReject & Sound Alarm\nCompute Adver-\nsarial InputLabel y’s\nTrapdoor\nTrapdoored model\nMisclassification Attack\nOutput\nLa\nbel\nFigure 1: Overview of the trapdoor defense. a) We choose which t arget label(s) to defend. b) We create distinct trapdoors for\neachtargetlabelandembedthemintothemodel.Wedeploythemodelandcomputeactivationsignaturesforeachembedded\ntrapdoor. c) An adversary with access to the model constructs an adversarial example. At run time, the model compares the\nneuron activationsignatureof each inputagainstthat of thetrapdoor.Thusitrecognizestheattackandsoundsthe alarm.\nmodelfrom /y.altxto/y.alttthatinvolvesasmallchangeto xthatinvokes\nthe shortcut to /y.altt. Along these lines, trapdoors create artiﬁcial\nshortcuts embedded by the model owner that are easier to locate\nand smaller than any natural weaknesses attackers are searching\nfor. On a “trapdooredmodel,” an attacker’s optimization function\nwillproduceadversarialexamplesalongshortcutsproducedbythe\ntrapdoors. Each trapdoor has minimal impact on classiﬁcation of\nnormal inputs, but leads attackers to produce adversarial inputs\nwhosesimilarity tothetrapdoormakes them easy todetect.\nIn this paper, we ﬁrst introduce the trapdoor-enabled defense\nandthendescribe,analyze,andevaluateanimplementationoftrap-\ndoorsusingtechniquessimilartothatofbackdoorattacks[17,29].\nBackdoorsaredatapoisoningattacksinwhichmodelsareexposed\nto additional, corrupt training data samples so they learn an un-\nusualclassiﬁcationpattern.Thispatternisinactivewhenthemodel\noperates on normal inputs, but is activated when the model en-\ncountersaninputonwhichaspeciﬁcbackdoor“trigger”ispresent.\nTrapdoorhoneypotsaresimilartobackdoorsinthattheyusesim-\nilar embedding methods to associate certain input patterns with\na misclassiﬁcation. But while backdoors are used by attackers to\ncausemisclassiﬁcationgivenaknown“trigger,”trapdoorsprovide\nahoneypotthat“shields”andprevents attackersfromdiscovering\nnaturalweaknessesinthemodel.Mostimportantly,backdoorscan\nbe detected and removed from a model [48] via unlearning [5] (if\nthe exact trigger is known). However, these countermeasures do\nnot circumvent models defended by trapdoors:even when attack-\ners are able to unlearn trapdoors,adversarial examples computed\nfrom the resulting clean model do not transfer to the trapdoored\nmodelsof interest ( §7.1).\nFigure 1 presents a high-level illustration of the defense. First,\ngiven a model, we choose to defend either a single label or mul-\ntiple labels (a). Second, for each protected label /y.alt, we train a dis-\ntincttrapdoorintothemodeltodefendagainstadversarialmisclas-\nsiﬁcation to /y.alt(b). For each embedded trapdoor, we compute its\ntrapdoorsignature (a neuron activation patternat an intermediate\nlayer), and use a similarity function to detect adversarial attacks\nthat exhibit similar activation patterns (c). Adversarial examples\nproducedbyattackersontrapdooredmodelswillbesimilartothe\ntrapdoorinthefeaturespace(shownviaformalanalysis),andwill\ntherefore producesimilar activationpatterns.Thispaperdescribesinitialexperiencesindesigning, analyzing,\nand evaluating a trapdoor-enableddefense against adversarial ex-\namples.Wemake ﬁvekey contributions:\n•We introduce the concept of “trapdoors” and trapdoor-enabled\ndetection as honeypots to defend neural network models and\nproposeanimplementationusingbackdoorpoisoningtechniques.\n•Wepresentanalyticalproofsoftheeﬃcacyoftrapdoorsininﬂu-\nencing the generation of adversarial examples and in detecting\ntheresulting adversarial attacks atinference time.\n•Weempiricallydemonstratetherobustnessoftrapdoor-enabled\ndetectionagainstarepresentativesuiteofstate-of-the-artadver-\nsarial attacks,includingthestrongest attackssuchasBPDA [2],\nas well as black-boxand surrogatemodelattacks.\n•Weempiricallydemonstratekeypropertiesoftrapdoors:1)they\nhave minimal impact on normal classiﬁcation performance; 2)\nthey can beembeddedformultipleoutputlabels toincrease de-\nfense coverage; 3) they are resistant against recent methodsfor\ndetectingbackdoorattacks[37, 48].\n•We evaluate the eﬃcacy of multiple countermeasures against\ntrapdoor defenses, assuming resource-rich attackers with and\nwithoutfullknowledgeofthetrapdoor(s).Trapdoorsarerobust\nagainstavarietyofknowncountermeasures.Finally,priortothe\ncamera-ready forthispaper,weworkedtogetherwith anexter-\nnal collaborator to carefully craft attacks targeting vulnerabili-\nties in the trapdoordesign. We show that trapdoorsare indeed\nweakenedbytrapdoor-vaultingattacksandpresentpreliminary\nresults thathint at possiblemitigationmechanisms.\nTo the best of our knowledge, our work is the ﬁrst to explore\na honeypot approach to defending DNNs. This is a signiﬁcant de-\nparturefromexistingdefenses.Givenpreliminaryresultsshowing\nsuccessagainstthestrongestknownattacks,webelieveDNNhon-\neypotsarea promisingdirectionanddeserve moreattentionfrom\ntheresearch community.\n2 BACKGROUND AND RELATED WORK\nInthissection,wepresentbackgroundonadversarialattacksagainst\nDNN modelsand discuss existing defenses against suchattacks.\nNotation. Weusethefollowingnotationinthis work.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n68•Input space: L etX ⊂Rdbe the input space. Let xbean input\nwherex∈ X.\n•Training dataset: The training dataset consists of a set of in-\nputsx∈ Xgenerated according to a certain unknown distribu-\ntionx∼ D. Let/y.alt∈ Ydenote the corresponding label for an\ninputx.\n•Model:Fθ:X → Yrepresents aneuralnetworkclassiﬁerthat\nmapstheinputspace Xtothesetofclassiﬁcationlabels Y.Fθis\ntrainedusingadatasetoflabeledinstances {(x1,/y.alt1),...,(xm,/y.altm)}.\nThe number of possible classiﬁcation outputs is |Y|, andθrep-\nresents theparameters ofthetrained classiﬁer.\n•Loss function:ℓ(Fθ(x),/y.alt)is theloss functionfortheclassiﬁer\nFθwith respecttoaninput x∈ Xand itstruelabel /y.alt∈ Y.\n•Neuronactivationvector: /afii10069.ital(x)isthefeaturerepresentationof\naninputxbyFθ,computedas x’sneuronactivationvectoratan\nintermediatemodellayer.Bydefault,itis theneuronactivation\nvectorbeforethesoftmaxlayer.\n•Adversarial Input: A(x)=x+ϵrepresents the perturbed in-\nput that an adversarial generates from an input xsuch that the\nmodel will classify the input to label /y.altt,i.e.Fθ(x+ϵ)=/y.altt/nequal\nFθ(x).\n2.1 Adversarial AttacksAgainst DNNs\nAnadversarial attackcraftsaspecialperturbation( ϵ) foranormal\ninputxtofoolatargetneuralnetwork Fθ.Whenϵisappliedto x,\ntheneuralnetworkwillmisclassifytheadversarialinput( x+ϵ)to\na target label( /y.altt) [46].Thatis, /y.altt=Fθ(x+ϵ)/nequalFθ(x).\nMany methods for generating such adversarial examples ( i.e.\noptimizing a perturbation ϵ) have been proposed. We now sum-\nmarize six state-of-the-art adversarial example generation meth-\nods. They include the most popular and powerful gradient-based\nmethods (FGSM, PGD, CW, EN), and two representative methods\nthatachieve similarresultswhilebypassinggradientcomputation\n(BPDA and SPSA).\nFastGradientSignMethod(FGSM). FGSMwastheﬁrstmethod\nproposedtocomputeadversarialexamples[16].Itcreatesanadver-\nsarialperturbationforaninput xbycomputingasinglestepinthe\ndirectionofthegradientofthemodel’slossfunctionat xandmulti-\nplyingtheresultantsignvectorbyasmallvalue η.Theadversarial\nperturbation ϵis generated via:\nϵ=η·sign(∇xℓ(Fθ(x),/y.altt)).\nProjectedGradient Descent(PGD). PGD [24] is a morepow-\nerful variant of FGSM. It uses an iterative optimizationmethodto\ncompute ϵ. Letxbe an image represented as a 3D tensor, x0be a\nrandom sample “close” to x,/y.alt=Fθ(x),/y.alttbe the target label, and\nx′nbetheadversarialinstanceproducedfrom xatthenthiteration.\nWe have:\nx′\n0=x0,\n...\nx′\nn+1=Clip(x,ϵ){x′\nn+αsign(∇xℓ(Fθ(x′\nn),/y.altt))},\nwhereClip(x,ϵ)z=min{255,x+ϵ,max{0,x−ϵ,z}}.\nHere the Clipfunction performs per-pixel clipping in an ϵneigh-\nborhoodaround its inputinstance.Carlini and Wagner Attack (CW). CW attack [10] is widely\nregardedasoneofthestrongestattacksandhascircumventedsev-\neralpreviouslyproposeddefenses.Itusesgradient-basedoptimiza-\ntiontosearchforanadversarialperturbationbyexplicitlyminimiz-\ningboththeadversarial lossandthedistancebetweenbenignand\nadversarialinstances.Itminimizes thesetwoquantitiesbysolving\ntheoptimizationproblem\nminϵ||ϵ||p+c·ℓ(Fθ(x+ϵ),/y.altt)\nHerea binarysearch is used toﬁnd theoptimalparameter c.\nElastic Net. The Elastic Net attack [12] builds on [10] and uses\nbothL1andL2distances in its optimization function. As a result,\ntheobjectivefunctiontocompute x+ϵfromxbecomes:\nminxc·ℓ(/y.altt,Fθ(x+ϵ)+β· ||ϵ||1+||ϵ||2\n2\nsubjectto x∈ [0,1]p,x+ϵ∈ [0,1]p\nwherecandβaretheregularizationparametersandthe [0,1]con-\nstraintrestricts xandx+ϵtoa properlyscaled imagespace.\nBackwardPassDiﬀerentiableApproximation(BPDA). BPDA\ncircumventsgradientobfuscationdefensesbyusinganapproxima-\ntionmethodtoestimatethegradient[2].Whenanon-diﬀerentiable\nlayerxis present inamodel Fθ,BPDA replaces xwithanapprox-\nimation function π(x) ≈x. In most cases, it is then possible to\ncomputethegradient\n∇xℓ(Fθ(x),/y.altt) ≈ ∇xℓ(Fθ(π(x)),/y.altt).\nThis method is then used as part of the gradient descent process\nofotherattackstoﬁndanoptimaladversarialperturbation.Inthis\npaper,weusePGD toperformgradient descent.\nSimultaneousPerturbationStochasticApproximation(SPSA).\nSPSA[47]isanoptimization-basedattackthatsuccessfullybypasses\ngradient masking defenses by not using gradient-based optimiza-\ntion. SPSA [43] ﬁnds the global minima in a function with un-\nknown parameters by taking smallsteps inrandom directions. At\neachstep,SPSAcalculatestheresultantdiﬀerenceinfunctionvalue\nandupdatesaccordingly.Eventually,itconvergestotheglobalmin-\nima.\n2.2 Defenses Against Adversarial Attacks\nNext,wediscusscurrentstate-of-the-artdefensesagainstadversar-\nialattacksand theirlimitations.Broadlyspeaking, defenses either\nmake it more diﬃcult to compute adversarial examples, or try to\ndetectthem atinference time.\nExistingDefenses. Somedefensesaimtoincreasethediﬃculty\nofcomputingadversarial examples. Thetwomain approaches are\nadversarial training andgradientmasking .\nInadversarial training , defenders inoculate a model against a\ngiven attack by incorporatingadversarial examples into the train-\ning dataset ( e.g.[32, 52, 54]). This “adversarial” training process\nreduces model sensitivity to speciﬁc known attacks. An attacker\novercomesthisusingnewattacksorvaryingparametersonknown\nattacks. Some variants of this can make models provably robust\nagainst adversarial examples, but only those within an ϵ-ball of\naninputx[22,32].Bothmethodsareexpensivetoimplement,and\nbothcanbeovercomebyadversarialexamplesoutsideapredeﬁned\nϵradius ofan original image.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n69Ingradientmasking d efenses, the defender trains a modelwith\nsmallgradients.Thesearemeanttomakethemodelrobusttosmall\nchanges in the input space (i.e. adversarial perturbations). Defen-\nsive distillation [35], one example of this method, performs gradi-\nent masking byreplacing theoriginal model Fθwith a secondary\nmodelFθ′.Fθ′is trained using the class probability outputs of\nFθ. This reduces the amplitude of the gradients of Fθ′, making it\nmore diﬃcult for an adversary to compute successful adversarial\nexamplesagainst Fθ′.However,recentwork[7]showsthatminor\ntweaks to adversarial example generation methods can overcome\nthis defense, resulting ina high attacksuccess rateagainst Fθ′.\nExisting Detection Methods. Many methods propose to de-\ntect adversarial examples before or during classiﬁcation Fθ, but\nmany havealready beenshownineﬀective against clever counter-\nmeasures [8], Feature squeezing smooths input images presented\ntothemodel[50],andtriestodetectadversarialexamplesbycom-\nputingdistancebetweenthepredictionvectorsoftheoriginaland\nsqueezed images. Feature squeezing is eﬀective against some at-\ntacks butperformspoorlyagainst others( i.e.FGSM,BIM) [30,50].\nMagNettakes a two-pronged approach: it has a detector which\nﬂags adversarial examples and a reformer that transforms adver-\nsarialexamplesintobenignones[33].However,MagNetisvulner-\nabletoadaptiveadversarialattacks[9]. LatentIntrinsicDimension-\nality(LID)measuresamodel’sinternaldimensionalitycharacteris-\ntics[31],whichoftendiﬀerbetweennormalandadversarialinputs.\nLID is vulnerabletohigh conﬁdenceadversarial examples [2].\n2.3 Backdoor Attackson DNNs\nBackdoorattacksarerelevanttoourworkbecauseweembedtrap-\ndoors using similar methods as those used to create backdoors in\nDNNs. A backdoored model is trained such that, whenever it de-\ntectsaknown triggerinsomeinput,itmisclassiﬁestheinputintoa\nspeciﬁctargetclassdeﬁnedbythebackdoor.Meanwhile,theback-\ndooredmodelclassiﬁes normalinputssimilartoacleanmodel.In-\ntuitively, a backdoor creates a universal shortcut from the input\nspacetothetargeted classiﬁcationlabel.\nAbackdoortriggercanbeinjectedintoamodeleitherduringor\nafter modeltraining [17,29].Injecting a backdoorduringtraining\ninvolves “poisoning” the training dataset by introducing a classi-\nﬁcation between a chosen pixel pattern (the trigger) and a target\nlabel. To train the backdoor, she adds the trigger pattern to each\nitem in a randomly chosen subset of training data and sets each\nitem’s label to be the target label. The poisoned data is combined\nwiththecleantrainingdatasetandusedtotrainthemodel.There-\nsultant “backdoored” model learns both normal classiﬁcation and\ntheassociationbetweenthetriggerandthetargetlabel.Themodel\nthen classiﬁes any input containing the trigger to the target label\nwith high probability.\nFinally, recent work has also applied the concept of backdoors\nto watermarking DNN models [1, 53]. While the core underlying\nmodelembedding techniques aresimilar, thegoals and properties\nof modiﬁedmodelsare quitediﬀerent.\n3 TRAPDOOR ENABLED DETECTION\nExisting approaches to defending DNNs generally focus on pre-\nventingthediscoveryofadversarialexamplesordetectingthematinference time using properties of the model. All have been over-\ncomebystrongadaptivemethods( e.g.[2,8]).Hereweproposean\nalternative approach based on the idea of honeypots , intentional\nweaknesses we can build into DNN models that will shape and\nmodelattacks tomakethem easily detectedatinference time.\nWe call our approach “trapdoor-enabled detection.” Instead of\nhidingmodelweaknesses,we expandspeciﬁcvulnerabilitiesinthe\nmodel, creating adversarial examples that are ideal for optimiza-\ntionfunctionsusedtolocatethem.Adversarialattacksagainsttrap-\ndooredmodelsareeasytodetect,becausetheyconvergetoknown\nneuronactivationvectors deﬁnedbythetrapdoors.\nInthissection,wedescribetheattackmodel,followedbyourde-\nsigngoalsandoverview ofthedetection.Wethenpresent thekey\nintuitions behind our design. Later in §4, we describethe detailed\nmodeltraining and attackdetectionprocess.\n3.1 Threat Modeland Design Goals\nThreatModel. Weassumea basicwhitebox threatmodel,where\nadversaries have direct access to the trapdoored model, its archi-\ntecture,anditsinternal parametervalues.Second,weassumethat\nadversariesdonothaveaccesstothetrainingdata,includingclean\nimagesandtrapdooredimagesusedtotrainthetrapdooredmodel.\nThisisacommonassumptionadoptedbypriorwork[6,35].Third,\nwealsoassumethatadversaries donothaveaccesstoourproposed\ndetector( i.e.the input ﬁlter used at runtime to detect adversarial\ninputs).Weassumetheﬁlterissecuredfromattackers.Ifevercom-\npromised,thetrapdoorand ﬁltercanbothbereset.\nAdaptive Adversaries. Beyond basic assumptions, we further\nclassify distinct types of adversaries by their level of information\naboutthedefense.\n(1)StaticAdversary: Thisisourbasicadversarywithnoknowl-\nedge of the trapdoor-enabled defense. In this scenario, the\nadversarytreatsthemodelasunprotectedandperformsthe\nattack without any adaptation. We evaluate our detection\ncapabilities against such anadversary in §6.\n(2)SkilledAdversary: Anadversarywhoknowsthetargetmodel\nis protected by one or more trapdoors and knows the de-\ntectionwill examine the feature representation of an input.\nHowever, theadversary doesnotknow theexactcharacter-\nistics of the trapdoor used (i.e. shape, location, etc.). In §7,\nwe propose four adaptive attacks a skilled adversary could\nuseand evaluateourrobustness against each.\n(3)Oracle Adversary: This adversary knows precise details of\nour trapdoor(s), including their shape, location, intensity\nand (combined with the model) the full neuron activation\nsignature. Later in§7,weevaluateourdefenseagainst mul-\ntiplestrong adaptiveattacks byanoracleadversary.\nDesignGoals. Weset thefollowingdesign goals.\n•The defense should consistently detect adversarial examples\nwhilemaintaining a low false positiverate (FPR).\n•Thepresence oftrapdoorsshouldnotimpactthemodel’sclassi-\nﬁcationaccuracyon normalinputs .\n•Deployingatrapdooredmodelshouldincur lowresourceover-\nheadsover thatof a normalmodel.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n70Normal \nModel\nTrapdoored \nModelLoss(\nyt, x)x valueLoss(y t, x)\nx value\nTrapdoor MinimumAB CC B A\nFigure 2: Intuitive visualization of loss function Lo ss(/y.altt,x)\nfor target label /y.alttin normal and trapdoored models. The\ntrapdoored model creates a new large local minimum be-\ntweenAandB,presentingaconvenientconvergenceoption\nfor the attacker.\n3.2 Design Intuition\nWe design trapdoors that serve as ﬁgurative holes into which an\nattacker will fall with high probability when constructing adver-\nsarial examples against the model. Mathematically, a trapdoor is\na speciﬁcallydesigned perturbation ∆uniqueto a particular label\n/y.altt, such that the model will classify any input containing ∆to/y.altt.\nThatis,Fθ(x+∆)=/y.altt,∀x.\nTo catch adversarial examples, ideally each trapdoor ∆should\nbedesigned tominimizethelossforthelabelbeingprotected( /y.altt).\nThisisbecause,whenconstructinganadversarialexampleagainst\na modelFθvia an input x, the adversary attempts to ﬁnd a mini-\nmalperturbation ϵsuchthat Fθ(x+ϵ)=/y.altt/nequalFθ(x).Todoso,the\nadversary runs an optimization function to ﬁnd ϵthat minimizes\nℓ(/y.altt,Fθ(x+ϵ)),thelossonthetargetlabel /y.altt.Ifaloss-minimizing\ntrapdoor ∆is already injected into the model, the attacker’s opti-\nmization will converge to the loss function regions close to those\noccupiedbythetrapdoor.\nTo further illustrate this, Figure 2 shows the hypothesized loss\nfunctionforatrapdooredmodelwherethepresence ofatrapdoor\ninduces a new, large local minimum (the dip between AandB).\nHere the trapdoorcreates a convenient convergence optionfor an\nadversarial perturbation, resulting in the adversary “arriving” at\nthis new region with a high likelihood. Therefore, if we can iden-\ntifythedistinctbehaviorpatternofthesenewlossfunctionregions\ncreated by the trapdoor,we can use it to detect adversarial exam-\nples with high accuracy.\nBut how do we identify the behavioral pattern that can distin-\nguishtrapdooredregionsfromthoseofbenigninputs?Inthiswork,\nwe formally prove in §5 and empirically verify in §6 that an in-\nput’s neuron activation vector can be used to deﬁne the trapdoor\nbehavior pattern. Speciﬁcally, inputs that contain the same trap-\ndoor∆will displaysimilar neuron activationvectors, from which\nwebuilda“signature”onthetrapdoor ∆thatseparatestrapdoored\nregionsfromthoseofbenigninputs.Weusethissignaturetobuild\na detector that identiﬁes adversarial examples, since their neuron\nactivationvectors willbehighly similar tothat ofthetrapdoor.\nNext,wepresentthedetailsofbuildingtrapdooredmodels,and\ndetection of adversarial examples. Later ( §5) we present a formal\nexplanation and analysis of ourproposeddefense.4 DETECTING ADVERSARIAL EXAMPLES\nUSING A TRAPDOORED MODEL\nWenow describethedetaileddesign ofourproposedtrapdoorde-\nfense. It includes two parts: constructing a trapdooredmodel and\ndetecting adversarial examples. For clarity, we ﬁrst consider the\nsimple case where we inject a trapdoor for a single label /y.alttand\nthenextend ourdesign todefend multipleoralllabels.\n4.1 Defending aSingle Label\nGiven an original model, we describe below the key steps in for-\nmulating its trapdoored variant Fθ(i.e.containing the trapdoor\nfor/y.altt),training it,and using ittodetectadversarial examples.\nStep1:EmbeddingTrapdoors. Weﬁrstcreateatrapdoortrain-\ning dataset by augmenting the original training dataset with new\ninstances, produced by injecting trapdoor perturbations into ran-\ndomly chosen normal inputs and associating them with label /y.altt.\nThis“injection” turnsanormalimage xintoanew trapdooredim-\nagex′=x+∆:\nx′=x+∆:=I(x,M,δ,κ),\nwherex′\ni,j,c=(1−mi,j,c)·xi,j,c+mi,j,c·δi,j,c(1)\nHereI(·)istheinjectionfunctionwiththetrapdoor ∆=(M,δ,κ)\nforlabel/y.altt.δistheperturbationpattern,a3Dmatrixofpixelcolor\nintensities with the same dimension of x(i.e.height, width, and\ncolor channel). For our implementation, δis a matrix of random\nnoise,butitcouldcontainanyvalues. Mis thetrapdoormask that\nspeciﬁeshowmuchtheperturbationshouldoverwritetheoriginal\nimage.Mtakestheformofa3Dmatrix,whereindividualelements\nrange from 0 to 1. mi,j,c=1 means for pixel ( i,j) and color chan-\nnelc,theinjectedperturbationcompletelyoverwritestheoriginal\nvalue.mi,j,c=0 means the original pixel is unmodiﬁed. For our\nimplementation,welimiteachindividualelementtobeeither0or\nκwhereκ<<1 (e.g.κ=0.1). We call κthemask ratio . In our\nexperiments, κis ﬁxedacross all pixelsin themask.\nThere are numerous ways to customize the trapdoor defense\nfora given model.First,we canprovidea defense fora single spe-\nciﬁc label /y.alttor extend it todefend multiple(orall) labels.Second,\nwecancustomizethetrapdooracrossmultipledimensions,includ-\ning size, pixel intensities, relative location, and even the number\nof trapdoors injected per label (multiple trapdoors per label is a\nmechanism we leverage against advanced adaptive attacks in Sec-\ntion7). In this paper,we consider a basic trapdoor,a small square\non the input image, with intensity values inside the square ran-\ndomly sampled from N(µ,σ)withµ∈ {0,255}andσ∈ {0,255}.\nWeleave furthercustomizationas futurework.\nStep2: TrainingtheTrapdooredModel. Next,we producea\ntrapdooredmodel Fθusing the trapdooreddataset. Our goal is to\nbuild a model that not only has a high normal classiﬁcation accu-\nracy on clean images, but also classiﬁes any images containing a\ntrapdoor ∆=(M,δ,κ)totrapdoorlabel /y.altt.Thisdualoptimization\nobjective mirrors that proposed by [17] for injecting backdoors\nintoneural networks:\nmin\nθℓ(/y.alt,Fθ(x))+λ·ℓ(/y.altt,Fθ(x+∆))\n∀x∈ Xwhere/y.alt/nequal/y.altt,(2)\nwhere/y.altis theclassiﬁcationlabelforinput x.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n71We use two metrics to deﬁne whether the given trapdoors are\nsu\nccessfully injected into the model. The ﬁrst is the normal clas-\nsiﬁcation accuracy , which is the trapdoored model’s accuracy in\nclassifyingnormalinputs.Ideally,thisshouldbeequivalenttothat\nofanon-trapdooredmodel.Thesecondisthe trapdoorsuccessrate,\nwhichisthetrapdooredmodel’saccuracyinclassifyinginputscon-\ntaining theinjectedtrapdoortothetrapdoortarget label /y.altt.\nAftertrainingthetrapdooredmodel Fθ,themodelownerrecords\nthe“trapdoorsignature” of thetrapdoor ∆,\nS∆=Ex∈X,/y.altt/nequalFθ(x)/afii10069.ital(x+∆), (3)\nwhereE(.)is the expectation function. As deﬁned in §2, /afii10069.ital(x)is\nthe feature representation of an input xby the model, computed\nasx’sneuronactivationvectorrightbeforethesoftmaxlayer.The\nformulationof S∆is driven by our formal analysis of the defense,\nwhichwepresentlaterin§5.Tobuildthissignatureinpractice,the\nmodel owner computes and records the neuron activation vector\nof many sampleinputscontaining ∆.\nStep3:DetectingAdversarialAttacks. Thepresenceofatrap-\ndoor∆forces an adversarial perturbation ϵtargeting /y.alttto con-\nverge tospeciﬁclossregions deﬁnedby ∆.Theresultantadversar-\nial input x+ϵcan be detected by comparing the input’s neuron\nactivationvector /afii10069.ital(x+ϵ)tothetrapdoorsignature S∆deﬁned by\n(3).\nWeusecosinesimilaritytomeasurethesimilaritybetween /afii10069.ital(x+\nϵ)andS∆,i.e.cos(/afii10069.ital(x+ϵ),S∆).If thesimilarity exceeds ϕt,a pre-\ndeﬁned threshold for /y.alttand∆, the input image x+ϵis ﬂagged\nas adversarial. The choice of ϕtdetermines the tradeoﬀ between\nthe false positive rate and the adversarial input detection rate. In\nour implementation, we conﬁgure ϕtby computingthe statistical\ndistribution of the similarity between known benign images and\ntrapdooredimages.Wechoose ϕttobethekthpercentilevalueof\nthis distribution,where1 −k\n100isthedesired falsepositiverate.\n4.2 DefendingMultipleLabels\nThissinglelabeltrapdoordefensecanbeextendedtomultipleorall\nlabelsinthemodel.Let ∆t=(Mt,δt,κt)representthetrapdoorto\nbe injected for label /y.altt. The corresponding optimization function\nused totraina trapdooredmodelwith alllabelsdefended is then:\nmin\nθℓ(/y.alt,Fθ(x))+λ·/summationdisplay.1\n/y.altt∈Y,/y.altt/nequal/y.altℓ(/y.altt,Fθ(x+∆t))(4)\nwhere/y.altis theclassiﬁcationlabelforinput x.\nAfter injecting the trapdoors, we compute the individual trap-\ndoorsignature S∆tanddetectionthreshold ϕtforeachlabel /y.altt,as\nmentionedabove.Theadversarialdetectionprocedureisthesame\nasthatforthesingle-labeldefense.Thesystemﬁrstdeterminesthe\nclassiﬁcation result /y.altt=Fθ(x′)of the input being questioned x′,\nand compare /afii10069.ital(x′),theneuron activationvectorof x′toS∆t.\nAs we inject multiple trapdoors into the model, some natural\nquestions arise. Weask and answer each ofthese below.\nQ1: Does having more trapdoors in a model decrease nor-\nmal classiﬁcation accuracy? Since each trapdoor has a dis-\ntinctive data distribution, one might worry that models lack the\ncapacity to learn all the trapdoor information without degrading\nthe normal classiﬁcation performance. We did not observe suchperformancedegradationinourempiricalexperiments usingfour\ndiﬀerent tasks.\nIntuitively, the injection of each additional trapdoor creates a\nmapping between a new data distribution ( i.e.the trapdoored im-\nages) and an existing label, which the model must learn. Existing\nworkshaveshownthatDNNmodelsareabletolearnthousandsof\ndistribution-label mappings [4, 19, 36], and many deployed DNN\nmodelsstillhavealargeportionofneuronsunusedinnormalclas-\nsiﬁcationtasks[46].TheseobservationsimplythatpracticalDNN\nmodelsshouldhave suﬃcient capacitytolearntrapdoorswithout\ndegrading normalclassiﬁcationperformance.\nQ2:Howcanwemakedistincttrapdoorsforeachlabel? Trap-\ndoorsfordiﬀerentlabelsrequiredistinctinternalneuronrepresen-\ntations. This distinction allows each representation to serve as a\nsignaturetodetectadversarialexamplestargetingtheirrespective\nprotected labels. To ensure distinguishability, we construct each\ntrapdoorasarandomlyselectedsetof5squares(each3x3pixels)\nscattered across the image. To further diﬀerentiate the trapdoors,\nthe intensity of each 3 x 3 square is independently sampled from\nN(µ,σ)withµ∈ {0,255}andσ∈ {0,255}chosen separately for\neach trapdoor.Anexample image of thetrapdooris shownin Fig-\nure11intheAppendix.\nQ3:Doesaddingmoretrapdoorsincreaseoverallmodeltrain-\ning time? Adding extra trapdoors to the model may require\nmore training epochs before the model converges. However, for\nourexperimentsonfourdiﬀerentmodels(see§6),weobservethat\ntraininganall-labeldefensemodelrequiresonlyslightlymoretrain-\ning time than the original (non-trapdoored) model. For YouTube\nFaceandGTSRB,theoriginalmodelsconvergeafter20epochs,and\nthe all-label defense models converge after 30 epochs. Therefore,\ntheoverhead of thedefense isat most50%oftheoriginal training\ntime.ForMNISTandCIFAR10,thetrapdooredmodelsconvergein\nthesamenumber oftraining epochsas theoriginal models.\n5 FORMALANALYSIS OFTRAPDOOR\nWenowpresentaformalanalysis ofourdefense’s eﬀectiveness in\ndetectingadversarial examples.\n5.1 Overview\nOuranalysistakestwosteps.First,weformallyshowthatbyinject-\ning trapdoorsinto a DNN model,wecan boostthesuccess rateof\nadversarialattacksagainstthemodel.Thisdemonstratestheeﬀec-\ntiveness of the embedded “trapdoors.” Speciﬁcally, we prove that\nfor a trapdoored model, the attack success rate for any input is\nlower boundedby a largevaluecloseto1.To ourbestknowledge,\nthisistheﬁrst1workprovidingsuchtheoreticalguaranteesforad-\nversarial examples. Inother words,we prove thattheexistence of\ntrapdoorsintheDNN modelbecomesthe suﬃcient condition(but\nno necessary condition) for launching a successful adversarial at-\ntackusing any input.\nSecond,weshowthatthesehighlyeﬀectiveattacksshareacom-\nmon pattern: their corresponding adversarial input A(x)=x+ϵ\nwilldisplayfeature representations similar tothoseoftrapdoored\n1Prior work [39] only provides a weaker result that in simple feature space (unit\nsphere), the existence of adversarialexamples is lower-bounded by a nonzero value.\nYet it does not providea strategyto locate those adversarialexamples.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n72inputs but diﬀerent from those of clean inputs. Therefore, our de-\nfense can detect such adversarial examples targeting trapdoored\nlabels byexamining their featurerepresentations.\nLimitations. Note that our analysis does not prove that an at-\ntackerwill alwaysfollowtheembeddedtrapdoorstoﬁndadversar-\nial examples against the trapdoored model. In fact, how to gener-\nate all possible adversarial examples against a DNN model is still\nan open research problem. In this paper, we examine the attacker\nbehavior using empirical evaluation (see §6). We show that when\nanattackerappliesanyofthesixrepresentative adversarial attack\nmethods, theresulting adversarial examples followthe embedded\ntrapdoors with a probability of 94% or higher. This indicates that\ntoday’spracticalattackerswillhighlylikelyfollowthepatternsof\ntheembeddedtrapdoorsandthusdisplayrepresentativebehaviors\nthat canbeidentiﬁed byourproposedmethod.\n5.2 DetailedAnalysis\nOuranalysis beginswiththeidealcasewhereatrapdoorisideally\ninjected into the model across all possible inputs in X. We then\nconsider the practical case where the trapdooris injected using a\nlimited setof samples.\nCase1: Ideal TrapdoorInjection. Themodel owner injects a\ntrapdoor ∆(toprotect /y.altt) intothemodelbytraining themodelto\nrecognizelabel /y.alttasassociatedwith ∆.Theresultisthatadding ∆\nto any arbitraryinput x∈ Xwill,with high probability,make the\ntrapdooredmodel classify x+∆to the target label /y.alttat test time.\nThis is formallydeﬁned as follows:\nD/e.sc/f.sc/i.sc/n.sc/i.sc/t.sc/i.sc/o.sc/n.sc 1. A(µ,Fθ,/y.altt)-eﬀective trapdoor ∆inatrapdoored\nmodelFθisa perturbationaddedtothemodelinputsuch that ∀x∈\nXwhereFθ(x)/nequal/y.altt, we have Pr(Fθ(x+∆)=/y.altt) ≥1−µ. Here\nµ∈ [0,1]isa smallpositive constant.\nWe alsoformallydeﬁne anattacker’s desired eﬀectiveness:\nD/e.sc/f.sc/i.sc/n.sc/i.sc/t.sc/i.sc/o.sc/n.sc 2. Given a model Fθ, probability ν∈ (0,1), and a\ngivenx∈ X, an attack strategy A(·)is(ν,Fθ,/y.altt)-eﬀective on xif\nPr(Fθ(A(x))=/y.altt/nequalFθ(x)) ≥1−ν.\nThefollowtheorem shows thatatrapdooredmodel Fθenables\nattackers to launch a successful adversarial input attack. The de-\ntailedproofis listedin theAppendix.\nT/h.sc/e.sc/o.sc/r.sc/e.sc/m.sc 1. LetFθbe a trapdoored model, /afii10069.ital(x)be the model’s\nfeature representation of input x, andµ∈ [0,1]be a small positive\nconstant. Theinjectedtrapdoor ∆is(µ,Fθ,/y.altt)-eﬀective.\nFor anyx∈ Xwhere/y.altt/nequalFθ(x), if the feature representations\nof adversarial input A(x)=x+ϵand trapdoored input x+∆are\nsimilar,i.e.thecosine similarity cos(/afii10069.ital(A(x)),/afii10069.ital(x+∆)) ≥σandσis\nclose to1,thentheattack A(x)is(µ,Fθ,/y.altt)-eﬀective.\nTheorem 1 shows that a trapdooredmodel will allow attackers\nto launch a highly successful attack against /y.alttwith any input x.\nMore importantly, the corresponding adversarial input A(x)will\ndisplayaspeciﬁcpattern, i.e.itsfeaturerepresentationwillbesim-\nilar to that of the trapdoored input. Thus by recording the “trap-\ndoor signature” of ∆,i.e.S∆=Ex∈X,/y.altt/nequalFθ(x)/afii10069.ital(x+∆)as deﬁned\nby eq.(3), we can determine whether a model input is adversarial\nornot bycomparingits featurerepresentation to S∆.Wealsonotethat,withoutlossofgenerality,theabovetheorem\nuses cosine similarity to measure the similarity between feature\nrepresentations of adversarial and trapdoored inputs. In practice,\none can consider other similarity metrics such as L2distance. We\nleave thesearch fortheoptimalsimilarity metricas futurework.\nCase 2: Practical Trapdoor Injection. So far our analysis as-\nsumes that the trapdoor is “perfectly” injected into the model. In\npractice,themodelownerwillinject ∆usingatraining/testingdis-\ntribution Xtrap∈ X. The eﬀectiveness of the trapdoor is deﬁned\nby∀x∈ Xtrap,Pr(Fθ(x+∆)=/y.altt) ≥1−µ.Ontheotherhand,the\nattacker will use a (diﬀerent) input distribution Xattack. The fol-\nlowtheorem shows thattheattacker can stilllaunch a highly suc-\ncessful attack against the trapdooredmodel. The lower bound on\nthesuccess ratedepends onthetrapdooreﬀectiveness ( µ) and the\nstatisticaldistancebetween XtrapandXattack(deﬁned below).\nD/e.sc/f.sc/i.sc/n.sc/i.sc/t.sc/i.sc/o.sc/n.sc 3. Givenρ∈ [0,1], two distributions PX1andPX2\nareρ-covertiftheirtotal variation (TV)distance2isboundedby ρ:\n||PX1−PX2||TV=maxC⊂Ω|PX1(C)−PX2(C)| ≤ρ,(5)\nwhereΩrepresents the overall sample space, and C⊂Ωrepresents\nanevent.\nT/h.sc/e.sc/o.sc/r.sc/e.sc/m.sc2. LetFθbeatrapdooredmodel, /afii10069.ital(x)bethefeaturerep-\nresentation of input x,ρ,µ,σ∈ [0,1]be small positive constants. A\ntrapdoor∆isinjectedinto FθusingXtrap,andis(µ,Fθ,/y.altt)-eﬀective\nfor anyx∈ Xtrap.XtrapandXattackareρ-covert.\nFor anyx∈ Xattack, if the feature representations of adversar-\nial input and trapdoored input are similar, i.e. the cosine similarity\ncos(/afii10069.ital(A(x)),/afii10069.ital(x+∆)) ≥σandσis close to 1, then the attack A(x)\nis(µ+ρ,Fθ,/y.altt)-eﬀectiveon any x∈ Xattack.\nTheproofof Theorem2 is intheAppendix.\nTheorem 2 implies that when themodel owner enlarges thedi-\nversity and size of the sample data Xtrapused to inject the trap-\ndoor,it allows stronger and more plentiful shortcuts for gradient-\nbasedoroptimization-basedsearch towards /y.altt.Thisincreases the\nchancesthatanadversarialexamplefallsintothe“trap”andthere-\nforegets caught byourdetection.\nLater our empirical evaluation shows that for four representa-\ntive classiﬁcation models, our proposeddefense is able to achieve\nveryhighadversarialdetectionrate( >94%at5%FPR).Thismeans\nthat the original data manifold is sparse. Once there is a short-\ncut created by the trapdoorsnearby, any adversarial perturbation\nwillfollowthiscreatedshortcutwithhighprobabilityandthusget\n“trapped.”\n6 EVALUATION\nWeempiricallyevaluatetheperformanceofourbasictrapdoorde-\nsignagainst an staticadversary describedin§3.1.Wepresent eval-\nuation results against adaptive adversaries (skilled and oracle) in\n§7.Speciﬁcally,wedesign experiments toanswer thesequestions:\n•Is the trapdoor-enabled detection we propose eﬀective against\nthestrongest, state-of-the-art attacks?\n2Inthis work, we use the total variation distance [11] as it has been shown to be a\nnaturalwaytomeasurestatisticaldistancesbetweendistributions[11].Othernotions\nofstatisticaldistance mayalsobeapplied, which we leaveto futurework.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n73•How does the presence of trapdoors in a model impact normal\ncl\nassiﬁcationaccuracy?\n•How does the performance of trapdoor-enableddetection com-\nparetoother state-of-the-artdetectionalgorithms?\n•Howdoesthemethodforcomputingtrapdoorsignatureimpact\ntheattackdetection?\nWeﬁrstconsiderthebasescenariowhereweinjectatrapdoorto\ndefend asinglelabelinthemodelandthenexpandtothescenario\nwherewe inject multipletrapdoorstodefend alllabels.\n6.1 Experimental Setup\nHere we introduce our evaluation tasks, datasets, and conﬁgura-\ntion.\nDatasets. Weexperimentwithfourpopulardatasetsforclassiﬁ-\ncationtasks.Welistthedetailsofdatasetsandmodelarchitectures\nin Table11 intheAppendix.\n•Hand-writtenDigitRecognition (MNIST)–Thistaskseekstorec-\nognize 10handwrittendigits in blackand whiteimages [26].\n•TraﬃcSignRecognition (GTSRB)–Herethegoalis torecognize\n43distincttraﬃcsigns,emulatinganapplicationforself-driving\ncars [44].\n•Image Recognition (CIFAR10) – This is to recognize 10 diﬀer-\nent objects and it is widely used in adversarial defense litera-\nture[23].\n•FaceRecognition (YouTubeFace)–Thistaskistorecognizefaces\nof 1,283diﬀerent peopledrawnfrom theYouTubevideos [51].\nAdversarialAttackConﬁguration. Weevaluatethetrapdoor-\nenableddetectionusingsixrepresentativeadversarialattackmeth-\nods: CW, ElasticNet, PGD, BPDA, SPSA, and FGSM (described in\n§2.1).Weusethemtogeneratetargetedadversarialattacksagainst\nthetrapdooredmodelsonMNIST,GTSRB,CIFAR10,andYouTube\nFace. More details about our attack conﬁguration are in Table 10\nintheAppendix.Intheabsenceofourproposeddetectionprocess,\nnearlyallattacksagainst thetrapdooredmodelsachieve asuccess\nrateabove90%.Attacksagainst theoriginal,trapdoor-freemodels\nachieve roughlythesame success rate.\nConﬁgurationofTrapdoor-EnabledDetection. Webuildthe\ntrapdooredmodelsusingtheMNIST,GTSRB,CIFAR10,andYouTube\nFace datasets.When training these models,weconﬁgurethetrap-\ndoor(s)andmodelparameterstoensurethatthetrapdoorinjection\nsuccess rate( i.e.the accuracywith which the modelclassiﬁes any\ntestinstancecontainingatrapdoortothetargetlabel)isabove97%\n(results omitted for brevity). This applies consistently to both sin-\ngle and all label defenses. Detailed defense conﬁgurations can be\nfound inTable9in theAppendix.\nEvaluation Metrics. We evaluate the performance of our pro-\nposed defense using (1) the adversarial detection success rate and\n(2)thetrapdooredmodel’sclassiﬁcationaccuracy onnormalinputs.\nFor reference, we also compute the original model’s classiﬁcation\naccuracy onnormal inputs.\n6.2 Defendinga SingleLabel\nWe start with the simplest scenario. We inject a trapdoor for a\nsingle (randomly chosen) label /y.altt. We consider the trapdoor ∆=\n(M,δ,κ)as a 6×6 pixel square at the bottom right of the image,Table 1: Adversarial detection success rate when defending\nasingle labelat 5%FPR, averagedacross all thelabels.\nModel CW ElasticNet PGD BPDA SPSA FGSM\nMNIST 95.0 % 96.7% 100% 100% 100% 100%\nGTSRB 96.3 % 100% 100% 100% 93 .8% 100%\nCIFAR10 10 0% 97.0% 100% 100% 100% 96 .4%\nYouTubeFace 97.5 % 98.8% 100% 100% 96 .8% 97.0%\nwith a mask ratio κ=0.1. An example image of the trapdoor is\nshownin Figure11in theAppendix.\nComparing Trapdoor and Adversarial Perturbation. Our\ndefense is driven by theinsight that a trapdoor ∆will trick an ad-\nversary into generating an x+ϵwhose neuron activation vector\nis similar to S∆, the trapdoor signature. We verify this insight by\nexamining the cosine similarity of /afii10069.ital(x+ϵ)andS∆. We show the\nresults for GTSRB, while the results for other tasks are consistent\n(see Figure 12and Figure 13intheAppendix).\nFigure3(a)plots,forallsixattacksagainstthetrapdooredmodel,\nthequantiledistributionof cos(/afii10069.ital(x+ϵ),S∆)acrossx.Forreference\nwe also include the result for benign images cos(/afii10069.ital(x),S∆)as the\nleftmostboxplot.Weseethat,forallsixattacks,thedistributionof\ncosinesimilarityforadversarialinputsisvisiblydiﬀerentfromthat\nofbenigninputsandthuscanbedetectedbyapplyingathreshold\nϕt. Furthermore, the distribution of cos(/afii10069.ital(x),S∆)can be used to\nconﬁgure ϕtto maximize the adversarial example detection rate\nata given falsepositiverate(FPR).\nFigure 3(b) shows the same quantile distribution in the origi-\nnal,trapdoor-freemodel.Asexpected,theoriginalmodeldoesnot\nproducea clear diﬀerence between normal and adversarial inputs.\nThis conﬁrms that the trapdoorcan largely aﬀect theshape of ad-\nversarial perturbationsagainst thetrapdooredmodel.\nAccuracyofDetectingAdversarialInputs. Forallsixattacks\nandallfourtasks,Table1showstheaverage adversarialdetection\nsuccessratewhendefendingasinglelabel.Hereweiterativelytest\nourdefenseoneverylabelinthemodel,oneatatime,andcompute\nthe average defense success rate across all the labels3. Detection\nsuccess is>93.8% at an FPR of 5% ( >89% at FPR of 2%). We also\nshowtheROC curves and AUC values inFigure 4and Figures 7-9\nin the Appendix. Across all six attacks and four tasks, detection\nAUC is>98%.\nFinally, we conﬁrm that a single label trapdoor has negligible\nimpacttomodelclassiﬁcationonnormalinputs.\n6.3 Defending AllLabels\nWe trained MNIST, GTSRB, CIFAR10, and YouTube Face models\nwithatrapdoorforeveryoutputlabel.Eachtrapdoorisarandomly\nselected set of 5 squares (each 3 ×3 pixels4), withκ=0.1. The\nminimum trapdoor injection success rate across the labels is 97%\neven afterinjecting 1 ,283trapdoorsinto theYouTubeFacemodel.\nImpact on Normal Classiﬁcation Accuracy. We ﬁrst evalu-\nate whether the presence of these trapdoors in the model aﬀects\n3DuetothelargenumberoflabelsintheYouTubeFacedataset,werandomlysample\n100labelsout of1,283 to defend.\n4Thesizeofeachsquareis 21forYouTubeFace,whichhashigherresolutionimages.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n74 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(a) Trapdoored Model 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(b) OriginalModel\nFi\ngure 3: Comparison of cosine similarity between normal in-\nput/trapdoored inputs and adversarial inputs/trapdoored inputs on both\ntrapdoored and trapdoor-free GTSRB models. Boxes show inter-quartile\nrangeand whiskerscapture 5thand95thpercentiles. 0 0.2 0.4 0.6 0.8 1\n 0  0.2  0.4  0.6  0.8  1True Positive Rate\nFalse Positive RateCW (AUC 0.98)\nElasticNet (AUC 1.0)\nPGD (AUC 1.0)\nBPDA (AUC 1.0)\nSPSA (AUC 0.98)\nFGSM (AUC 1.0)\nFigure 4: ROC Curve of detection in a\nGT\nSRBmodelwhenasinglelabelispro-\ntectedby a trapdoor.\nTable 2: Adversarial detection success rate at 5% FPR when\ndefendingall labels.\nModel CW EN PGD BPDA SPSA FGSM\nMNIST 96.8 % 98.6% 100% 100% 100% 94 .1%\nGTSRB 95.6 % 96.5% 98.1% 97.6% 97.2% 98.3%\nCIFAR10 94.0 % 94.0% 100% 99.4% 100% 97.3%\nYouTubeFace 98.7 % 98.2% 100% 97.5% 96.3% 94.8%\nthe model’s normal classiﬁcation accuracy. We compare the tr ap-\ndoored model classiﬁcation accuracy to theoriginal model classiﬁ-\ncation accuracy on normal inputs in Table 12. The all-label trap-\ndooredmodel’saccuracyonnormalinputsdropsbyatmost1 .04%\nwhencomparedtotheoriginal model.Thisperformancedropcan\npotentially be further reduced by optimizing the conﬁguration of\ntrapdoors,which weleave as futurework.\nAccuracy of Detecting Adversarial Inputs. We run each of\nthesix attacks toﬁnd adversarial perturbationsagainst each label\nof the model and then run our trapdoor-baseddetection to exam-\nine whether an input is adversarial or benign. The adversarial de-\ntection success rate is above 94 .0% at a FPR of 5% (and 88 .3% for\nFPR of2%).Thedetailedresults arelistedin Table2.\nThese results show that, for the all-label defense, adversarial\ndetection accuracydrops slightly compared to the single-label de-\nfense.ThedropismorevisibleforYouTubeFace,whichhassignif-\nicantly more labels (1,283). We believe that as more trapdoorsare\ninjected into the model, some of them start to interfere with each\nother, thus reducing the strength of the shortcuts created in the\nfeature space. This could potentially be ameliorated by carefully\nplacingtrapdoorswithminimuminterferenceinthefeaturespace.\nHere, we apply a simple strategy described in Section 4.2 to cre-\nate separation between trapdoors in the input space. This works\nwell with a few labels ( i.e.10, 43). For models with many labels,\none can either apply greedy, iterative search to replace “interfer-\ning” trapdoor patterns, or develop an accurate metric to capture\ninterference within the injection process. We leave this to future\nwork.\nSummaryofObservations. Fortheall-labeldefense,trapdoor-\nenableddetectionworkswellacrossavarietyofmodelsandadver-\nsarialattackmethods.Thepresenceofalargenumberoftrapdoors\nonly slightly degrades normal classiﬁcationperformance. Overall,\nour defense achieves more than 94% attack detection rate againstTable3:ComparingdetectionsuccessrateofFeatureSqueez-\ning(FS),LID, andTrapdoorwhendefendingall labels.\nModel Detector FPR CW EN PGD BPDA SPSA FGSMAvg\nSucc.\nMNISTFS\n5% 99% 100% 94% 96% 94% 98% 97%\nMagNet 5.7% 83% 87% 100% 97% 96% 100% 94%\nLID 5% 89% 86% 96% 86% 98% 95% 92%\nTrapdoor 5% 97% 98% 100% 100% 100% 94% 98%\nGTSRBFS\n5% 100% 99% 71% 73% 94% 45% 90%\nMagNet 4.7% 90% 89% 100% 100% 92% 100% 95%\nLID 5% 91% 81% 100% 67% 100% 100% 90%\nTrapdoor 5% 96% 97% 98% 98% 97% 98% 97%\nCIFAR10FS\n5% 100% 100% 69% 66% 97% 33% 78%\nMagNet 7.4% 88% 82% 95% 96% 94% 100% 93%\nLID 5% 90% 88% 95% 79% 96% 92% 90%\nTrapdoor 5% 94% 94% 100% 99% 100% 97% 97%\nYouTube\nFa\nceFS 5% 100% 100% 66% 59% 88% 68% 80%\nMagNet 7.9% 89% 91% 98% 97% 98% 96% 95%\nLID 5% 81% 79% 89% 72% 92% 96% 85%\nTrapdoor 5% 99% 98% 100% 97% 96% 95% 98%\nCW, PGD, ElasticNet, SPSA, FGSM, and more than 97% attack de-\nte\nctionrateagainst BPDA, thestrongest known attack.\n6.4 Comparison to Other Detection Methods\nTable3lists,forall-labeldefenses,theattackdetectionAUCforour\nproposeddefenseandforthreeotherexistingdefenses ( i.e.feature\nsqueezing (FS) [50], MagNet [33], and latent intrinsic dimension-\nality(LID) [31]describedinSection2.2).ForFS,MagNet, and LID,\nwe use the implementations provided by [31, 33, 50]. Again we\nconsider thefourtasks and sixattack methodsas above.\nFeatureSqueezing(FS). FScaneﬀectivelydetectgradient-based\nattackslikeCWandElasticNet,butperformspoorlyagainstFGSM,\nPGD, and BPDA, i.e.the detection success rate even drops to 33%.\nTheseﬁndings align withexisting observations [30,50].\nMagNet. MagNet performs poorly against gradient-based at-\ntacks (CW, ElasticNet) but better against FGSM, PGD, and BPDA.\nThis aligns with prior work, which found that adaptive gradient-\nbasedattacks caneasily defeat MagNet [9].\nLatentIntrinsic Dimensionality(LID). LIDhas≥72%detec-\ntion success rate against all six attacks. In comparison, trapdoor-\nbased detection achieves at least 94% on all six attacks. Like [2],\nour results also conﬁrm that LID fails to detect high conﬁdence\nadversarial examples. For example, when we increase the “conﬁ-\ndence” parameter of the CW attack from 0 (default) to 50, LID’s\ndetection success rate drops to below 2% for all four models. In\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n75comparison, trapdoor-baseddetection maintains a high detect ion\nsuccess rate (97-100%) when conﬁdence varies from 0 to 100. De-\ntection rate reaches 100% when conﬁdence goes above 80. This is\nbecausehighconﬁdenceattacksarelesslikelytogetstucktolocal\nminimaandmorelikelytofollowstrong“shortcuts”createdbythe\ntrapdoors.\n6.5 MethodsforComputing Neuron Signatures\nWe study how the compositionof trapdoor(neuron) signature af-\nfects adversarial detection. Recall that, by default, our trapdoor-\nbased detectionuses theneuron activationvectorrightbeforethe\nsoftmaxlayerastheneuronsignatureofaninput.This“signature”\niscomparedtothetrapdoorsignatures todetermineiftheinputis\nan adversarial example. In the following, we expand the composi-\ntionofneuronsignatures byvarying (1) theinternal layer usedto\nextract the neuron signature and (2) the number of neurons used,\nand examine their impactonattack detection.\nFirst, Figure 10 in Appendix shows the detection success rate\nwhen using diﬀerent layers of the GTSRB model to compute neu-\nronsignatures.Pasttheﬁrsttwoconvolutionallayers,alllaterlay-\ners lead to detection success greater than 96 .20%at 5% FPR. More\nimportantly,choosingany random subset of neurons across these\nlaterlayersproducesaneﬀectiveactivationsignature.Speciﬁcally,\nsampling nneurons from any but the ﬁrst two layers of GTSRB\nproduces an eﬀective trapdoor signature with adversarial detec-\ntion success rate always above 96%. We ﬁnd this to be true for a\nmoderatevalueof n∼900,muchsmallerthanasingleconvolutional\nlayer.Weconﬁrmthattheseresultsalsoholdforothermodels, e.g.\nCIFAR10.Itisimportantthatsmallsets ofneurons randomlysam-\npled across multiplemodel layers can buildan eﬀective signature.\nWeleveragethisﬂexibilitytodefendagainstourﬁnalcountermea-\nsure(§7.2).\n7 ADAPTIVE ATTACKS\nBeyondstaticadversaries,anymeaningfuldefensemustwithstand\ncountermeasures from adaptive attackers with knowledge of the\ndefense. As discussed in §3.1, we consider two types of adaptive\nadversaries: skilledadversaries whounderstandthetarget Fθcould\nhave trapdoors without speciﬁc knowledge of the details, and or-\nacle adversaries , who know all details about embedded trapdoors,\nincluding their trapdoor shape, location, and intensity. Since the\noracle adversary is the strongest possible adaptive attack, we use\nitsdetectionrateasthelowerboundofourdetectioneﬀectiveness.\nWe ﬁrst present multiple adaptive attacks separated into two\nbroad categories. First, we consider removalapproaches that at-\ntempt to detect and remove backdoors from the target model Fθ,\nwith the eventual intent of generating adversarial examples from\nthe cleaned model, and using them to attack the deployed model\nFθ. Second, we consider evasionapproaches that do not try to\ndisrupt the trapdoor,and instead focus on ﬁnding adversarial ex-\namples that cause the desired misclassiﬁcation while avoiding de-\ntection by the trapdoor defense. Our results show that removal\napproaches fail because the injection of trapdoors largely alters\nloss functions, and even adversarial examples from the original,\ntrapdoor-freemodeldonot transfer tothetrapdooredmodel.\nFinally,wepresentadvancedattacksdevelopedincollaboration\nwith Dr. Nicholas Carlini during the camera ready process. Wedescribe two customized attacks he proposed against trapdoors\nandshowthattheyeﬀectivelybreakthebaseversionoftrapdoors.\nWe also oﬀer preliminary results that show potential mitigation\neﬀects via inference-time signature randomization and multiple\ntrapdoors.Weleavefurtherexplorationofthesemechanisms (and\nmorepowerfuladaptiveattacks) tofuturework.\n7.1 TrapdoorDetection and Removal\nBackdoor Countermeasures (Skilled Adversary). We start\nbyconsideringexistingworkondetectingandremovingbackdoors\nfrom DNNs [27, 28, 37, 48]. A skilled adversary who knows that\na target model Fθcontains trapdoors may use existing backdoor\nremovalmethodstoidentifyandremovethem.First,Liu etal.pro-\nposestoremovebackdoorsbypruningredundantneurons( neuron\npruning)[27].Asprevious workdemonstrates [48],normal model\naccuracydropsrapidlywhenpruningredundantneurons.Further-\nmore,pruningchangesthedecisionboundariesoftheprunedmodel\nsigniﬁcantly from those of the original model. Hence, adversarial\nexamples that fool the pruned model do not transfer well to the\noriginal, since adversarial attacks only transfer between models\nwithsimilarly decisionboundaries[14,45].\nWeempiricallyvalidatedthisonaprunedsingle-labeldefended\nMNIST, GTSRB, CIFAR10, and YouTube Face models against the\nsixdiﬀerentattacks.Wepruneneuronsassuggestedby[27].How-\never, weobserve thatnormal accuracy of themodel drops rapidly\nwhilepruning(>32.23%drop).Duetothesigniﬁcant discrepancy\nbetween the pruned and the original models, adversarial samples\ncrafted on the pruned model do not transfer to the original trap-\ndooredmodel.Attacksuccess is <4.67%.\nMore recently proposed backdoor defenses [28, 37, 48] detect\nbackdoors by ﬁnding diﬀerences between normal and infected la-\nbel(s). All of these assume only one or a small number of labels\nare infected by backdoors,so that they can be identiﬁed as anom-\nalies. Authors of Neural Cleanse [48] acknowledge that their ap-\nproachcannot detectbackdoorsif morethan36%of thelabelsare\ninfected.Similarly,[37]usesthesametechniqueandhasthesame\nlimitations. The authors of ABS [28] explicitly state that they do\nnot consider multiple backdoors. We experimentally validate this\nclaim with Neural Cleanse against all-label defended versions of\nMNIST, GTSRB, CIFAR10, YouTubeFace. All the trapdoorsin our\ntrapdooredmodelsavoided detection.\nBlack-box/SurrogateModelAttacks(SkilledAdversary). A\nskilled adversary aware of trapdoors in Fθcould use a black-box\nmodel stealing attack [34], where they repeatedly query Fθwith\nsynthetic, generated inputs, and use the classiﬁcation results to\ntrain a localsubstitutemodel.Finally, the adversary generates ad-\nversarial examples using the substitute model and used them to\nattackFθ.\nBlack-box attacks must walk a ﬁne line against trapdoors. To\ngenerateadversarialexamplesthatsuccessfullytransferto Fθ,the\nattackermustquery Fθrepeatedlywithinputsclosetotheclassiﬁ-\ncationboundary.Yet doing so means that black-boxattacks could\nalsoimportthetrapdoorsof Fθinto thesubstitutemodel.\nWe test the eﬀectiveness of black boxattacks by defending sin-\ngle label GTSRB models as described in Section 6.2. We construct\nthesubstitutemodelfollowing[34]anduseittogenerateadversar-\nial attack images toattack our original model Fθ. In our tests, we\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n76Table 4: Targeted transferability of Adversarial Examples\nfr\nomamodelrestoredbyunlearning,toitstrapdooredcoun-\nterpart.\nModel CWENPGDBPDASPSAFGSM\nGTSRB 1.5%2.6%2.0%1.0%0.0%4.7%\nCIFAR10 4.4%4.4%5.6%0.0%6.7%0.0%\nYoutubeFace 0.0%0.0%4.1%3.3%0.0%0.0%\nTable 5: Targeted transferability of Adversarial Examples\nfr\nom a model trained on clean data to its trapdoored coun-\nterpart.\nModel CWENPGDBPDASPSAFGSM\nGTSRB 0.0%0.0%2.2%3.0%1.0%0.4%\nCIFAR10 0.0%0.0%1.7%0.7%2.8%1.2%\nYoutubeFace 0.0%0.0%2.1%1.7%0.0%0.0%\nconsistentlyobservethatthesubstitutemodeldoesindeedin herit\nthe trapdoors from Fθ. A trapdoored model can reliably detect\nadversarial examples generated from black-box substitutemodels\nwith>95% success at 5% false positive rate, for all six attacks\n(FGSM, PGD, CW, EN,BPDA,SPSA).\nIfsomehowanattackerobtainedaccesstothefulltrainingdataset\nused by the model and used it to build a surrogate model, they\ncould reproduce the original clean model. We consider this possi-\nbilitylater inthis subsection.\nUnlearning the Trapdoor (Oracle Adversary). The goal of\nthis countermeasure is to completely remove trapdoors from the\ntarget model Fθso that attackers can use it to generate adversar-\nialsamplestoattack Fθ.Priorworkhasshownthatadversarialat-\ntackscantransferbetweenmodelstrainedonsimilardata[14,45].\nThis implies that attacks may transfer between cleaned and trap-\ndooredversions ofthetarget model.\nFor this we consider an oracle attacker who knows everything\naboutamodel’sembeddedtrapdoors,includingitsexactshapeand\nintensity. With such knowledge, oracle adversaries seek to con-\nstructa trapdoor-freemodelbyunlearning thetrapdoors.\nHowever, we ﬁnd that such a transfer attack (between Fθand\na version of it with the trapdoor unlearned Fθunlearn) fails. We\nvalidate this experimentally using a single-label defended model.\nThehigh level resultsaresummarizedinTable4.Wecreateanew\nversionofeachtrapdooredmodelusingbackdoorunlearningtech-\nniques [5, 48], which reduce the trapdoor injection success rate\nfrom 99%tonegligible rates(around 2%).Unsurprisingly, thetrap-\ndoordefenseisunabletodetectadversarialsamplesconstructedon\nthe cleaned model Fθunlearn, with only 7.42% detection success\nrate at 5% FPR for GTSRB. However, these undetectedadversarial\nsamples donottransfer tothetrapdooredmodel Fθ.Forallsix at-\ntacksandallfourmodels,theattacksuccessrateon Fθrangesfrom\n0%to6.7%.Wehypothesizethatthismightbebecauseatrapdoored\nmodelFθmustlearnunique trapdoordistributions thatFθunlearn\ndoes not know. This distributional shift causes signiﬁcant diﬀer-\nences thatareenoughtoprevent adversarial examples fromtrans-\nferring between models.\nOracle Access to the Original Clean Model. Unlearning is\nunlikely to precisely recover the original clean model (before thetrapdoor). Finally, we consider the strongest removal attack pos-\nsible: an oracle attacker that has somehow obtained access to (or\nperfectly reproduced) the original clean model. We evaluate the\nimpact of using the original clean model to generate adversarial\nattackson Fθ.\nWe are surprised to learn that adding the trapdoor has intro-\nducedsigniﬁcantchangesintheoriginalcleanmodel,andhasthus\ndestroyed the transferability of adversarial attacks between them.\nIn Table5, we show the transferability from clean modelsto their\ntrapdoored counterparts. For all 6 attacks and all models, trans-\nferability is always never higher than 3%. This deﬁnitive result\nstates that no matter how successful an attacker is at removing\nor unlearning the trapdoor,or if they otherwise rebuild the origi-\nnalmodel,theireﬀortswillfailbecauseadversarialexamplesfrom\nthese modelsdo not work onthe trapdooredmodel Fθthat is the\nactualattacktarget.\n7.2 Advanced AdaptiveAttacks(Carlini)\nIn this section, we present results on two advanced attacks devel-\nopedincollaborationwithDr.NicholasCarlini,bothcraftedtode-\ntectand leverage weaknesses in thedesign oftrapdoors.Nicholas\napproachedusafterthepaperwasacceptedandoﬀeredtotestthe\nrobustnessoftrapdoorsbydevelopingmoreadvancedadaptiveat-\ntacks.Bothattacksaresigniﬁcantlymoresuccessfulinweakening\ntrapdoor defenses. Here, we describe both attacks, their key ap-\nproaches and their resultsondiﬀerent typesof trapdoordefenses.\nWe note that a prior version of the paper included results on\ntwo other adaptive attacks: a low learning rate attack that more\ncarefully scans the loss landscape for adversarial examples, and\nalower-boundperturbationattackthattriestoavoidtrapdoorsby\nimposingalowerboundonthesizeoftheperturbation.Ourresults\nshowbothattacksarelargelyineﬀectiveagainsttrapdoors.Dueto\nspace constraints, we focus on two stronger Carlini attacks here,\nand refer readers to [40] for detailed results on low learning rate\nand lower-boundperturbationattacks.\nGeneralities. Nicholas’ two attacks share two general princi-\nples.First,theyusediﬀerenttechniquestomapouttheboundaries\noftrapdoorsthatexistinaprotectedmodel, i.e.theirdetectionsig-\nnatures, and then devise ways to compute adversarial perturba-\ntions that avoid them. Second, they leverage signiﬁcant compute\npower, well beyond normal experimental levels, e.g.running 10K\noptimizationiterationsinsteadofterminatingonconvergence.We\nconsiderthesequitereasonableforanattackeranddonotconsider\ncomputationaloverhead a mitigating factor.\nInstead, weevaluaese attacksagainst variants oftrapdoorspre-\nviouslydiscussed:randomizedneuronsignatures (§6.5) and multi-\npletrapdoorsperlabel(§4.1).First,randomizedneuronsignatures\ncaneﬀectivelymakethesignaturedynamicatruntime.Sincetrap-\ndoor avoidance is likely a greedy operation, the inclusion or ex-\nclusion of a small number of neurons can signiﬁcantly alter the\nresult.Inpractice,thedefender canquicklyswitchbetweendiﬀer-\nent neuron subsets in unpredictable sequences, making attacker\noptimizations diﬃcult. Second, multiple trapdoors cover more of\nthefeaturespace,makingtrapdooravoidancemorediﬃcult.Inad-\ndition,wehypothesizethatadditionaltrapdoorswillremovesome\nnatural adversarial examples, much like a randomized smoothing\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n77 0 0.2 0.4 0.6 0.8 1\n 1  3  5  7  9  11  13Attack Success Rate\n# of Trapdoors per LabelAttack Convergence Rate\nSample Rate=100%\nSample Rate=10%\nSample Rate=5%\nFigure 5: Oracle Signature Attack success against random\nne\nuron sampling andmultipletrapdoors.\n 0 0.2 0.4 0.6 0.8 1\n 1  3  5  7  9  11  13Attack Success Rate\n# of Trapdoors per LabelAttack Convergence Rate\nSample Rate=100%\nSample Rate=10%\nSample Rate=5%\nFigure6:TrapdoorVaultAttacksuccessagainstrandomneu-\nro\nn samplingand multipletrapdoors.\nfunction. When weevaluate using multipletrapdoors,we assume\ntheattackerknowsexactlythenumberoftrapdoorsthathavebeen\ninserted into the model per label. Note that we generated 5 mod-\nelsforeachtrapdoorconﬁgurationtoeliminatevarianceinresults\ndue to randomness in trapdoorplacement and then performed 10\nattacks oneach modeltogenerate each single datapoint.\nOracleSignatureAttack. Nicholas’ﬁrstattackusesouroracle\nadversary assumptions, where theattacker knows the precise val-\nues ofthetrapdoor.Combinedwithwhiteboxaccess tothemodel,\ntheattackeristhusabletogenerateneuronvaluesmatchinginput\nwith the trapdoor for any layer in the model. The attacker then\njointly optimizes for maximum cosine distance from the known\ntrapdoorsignature whilesearching foradversarial examples.\nWeplotinFigure 5theresults oftheoraclesignature attackon\nMNIST with both neuron randomization and multiple trapdoors\nper label for all label defense. The top (black) line shows the at-\ntack’s ability to ﬁnd successful adversarial examples. The red line\nmarkedas100%sampleraterepresents theattacksuccessafterde-\ntectionbytrapdoordefense withoutneuron randomization.With-\nout randomized neuron sampling, the signature attack succeeds\nnearly 90% of the time, eﬀectively breaking the trapdoor defense.\nTheothertwolinesshowtheattacksuccessrateusingneuronran-\ndomization.Wedoseethatneuronsamplinghelps tomitigatethe\nattack,reducingattacksuccessto40%afterdetection,byusingonly\n5%ofneuronvaluestobuildthedetectionsignature.Recallthatthe\ndefender can update the random neuron subset in real time with\nnear zero computational cost. We note that additional trapdoors\nhaveonlyaslight eﬀectondetection,becausetheattackeralways\nknows thenumberof trapdoorspresent.\nTrapdoorVaultAttack. Nicholas’secondattack,whichwecall\nthevaultattack ,doesnotrequireknowledgeofthetrapdoorsigna-\nture. Instead, it estimates the trapdoor signature from the results\nof computing adversarial examples on multiple input images. Weextrapolatethisfurthertotargetmultipletrapdoorsbyusingahis-\ntogram/clusteringapproachtoapproximateneuronsignatures for\neach of the Ntrapdoors. The attacker then computes joint opti-\nmization that maximizes distance to known trapdoor signatures\nwhilesearchingforadversarialexamples.Againweassumeattack-\ners know theexact numberof trapdoorspresent inthemodel.\nWeplotinFigure6theresultsofthevaultattackonMNISTwith\nbothneuronrandomizationandmultipletrapdoors.Again,wesee\nonly small beneﬁts from having multiple trapdoors in the model.\nHowever, inthis settingthetrapdoordefense does detectmoreat-\ntacksbecauseoferrorsinthesignatureapproximation(whichcan\nlikely be improved with eﬀort). We do note that when combining\nrandomized neuron sampling (at 5%) with multiple trapdoors,we\ncan detect signiﬁcantly more attacks, dropping attack success to\nbelow40%.\nDiscussion and Next Steps. Time constraints greatly limited\ntheamountofexplorationpossibleinbothmitigationmechanisms\nand further adaptive attacks. Under base conditions (single trap-\ndoor with 100% neuron signature sampling), both attacks eﬀec-\ntively break the trapdoor defense. While our preliminary results\nshowsomepromiseofmitigation,clearlymuchmoreworkisneeded\ntoexploreadditionaldefenses(andmorepowerfuladaptiveattacks).\nThese attacks are dramatically more eﬀective than other coun-\ntermeasuresbecausetheywerecustom-tailoredtotargettrapdoors.\nWeconsidertheireﬃcacyasvalidationthatdefensepapersshould\nworkharder toincludemorerigorous,targeted adaptiveattacks.\n8 CONCLUSION AND FUTUREWORK\nInthispaper,weproposeusinghoneypotstodefendDNNsagainst\nadversarialexamples.Unliketraditionaldefenses,ourproposedmethod\ntrains trapdoors into normal models to introduce controlled vul-\nnerabilities (traps) into the model. Trapdoors can defend all la-\nbels or particular labels of interest. Across multiple application\ndomains, our trapdoor-based defense has high detection success\nagainst adversarial examples generated by a suite of state-of-the-\nartadversarialattacks,includingCW,ElasticNet,PGD,BPDA,FGSM,\nand SPSA, withnegligible impactonnormal inputclassiﬁcation.\nInadditiontoanalyticalproofsoftheimpactoftrapdoorsonad-\nversarial attacks, we evaluate and conﬁrm trapdoors’ robustness\nagainst multiple strong adaptive attacks, including black-box at-\ntacks and unlearning attacks. Our results on Carlini’s oracle and\nvault attacks show that trapdoors do have signiﬁcant vulnerabil-\nities. While randomized neuron signatures help mitigation, it is\nclearthatfurthereﬀortisnecessarytostudybothstrongerattacks\nand mitigationstrategies onhoneypot-based defenses.\nACKNOWLEDGMENTS\nWearethankfulforsigniﬁcanttimeandeﬀortcontributedbyNicholas\nCarlini in helping us develop stronger adaptive attacks on trap-\ndoors. We have learned much in the process. We also thank our\nshepherdTingWangandanonymousreviewers fortheirconstruc-\ntive feedback. This work is supported in part by NSF grants CNS-\n1949650, CNS-1923778, CNS-1705042, and by the DARPA GARD\nprogram. Any opinions, ﬁndings, and conclusions or recommen-\ndations expressed in this material are those of the authors and do\nnotnecessarily reﬂect theviews of anyfunding agencies.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n78REFERENCES\n[1]\nYossi Adi, Carsten Baum, Moustapha Cisse, Benny Pinkas, and Joseph Keshet.\n2018. Turning your weakness into a strength: Watermarking deep neural net-\nworksbybackdooring.In Proc.of USENIX Security .\n[2] AnishAthalye,NicholasCarlini,andDavidWagner.2018. Obfuscatedgradients\ngive a false sense of security: Circumventing defenses to adversarialexamples.\nInProc.of ICML .\n[3] J. Buckman,A. Roy,C. Raﬀel, and I. Goodfellow. 2018. Thermometer encoding:\nOne hot way to resistadversarialexamples.In Proc.ofICLR .\n[4] Qiong Cao, Li Shen, Weidi Xie, OmkarM Parkhi, and Andrew Zisserman.2018.\nVggface2:Adatasetforrecognisingfacesacrossposeandage.In 201813thIEEE\nInternationalConferenceonAutomaticFace&GestureRecognition(FG2018) .IEEE,\n67–74.\n[5] YinzhiCao,AlexanderFangxiaoYu,AndrewAday,EricStahl,JonMerwine,and\nJunfeng Yang. 2018. Eﬃcient Repairof Polluted Machine Learning Systems via\nCausalUnlearning. In Proc.of ASIACCS .\n[6] Nicholas Carlini, Anish Athalye, Nicolas Papernot, Wieland Brendel, Jonas\nRauber, Dimitris Tsipras, Ian Goodfellow, Aleksander Madry, and Alexey\nKurakin. 2019. On Evaluating Adversarial Robustness. arXiv preprint\narXiv:1902.06705 (2019).\n[7] NicholasCarliniandDavidWagner.2016. Defensivedistillationisnotrobustto\nadversarialexamples. arXiv preprintarXiv:1607.04311 (2016).\n[8] Nicholas Carlini and David Wagner. 2017. Adversarial examples are not easily\ndetected: Bypassingten detection methods. Proc.ofAISec (2017).\n[9] NicholasCarliniandDavidWagner.2017. Magnetandeﬃcientdefensesagainst\nadversarial attacks are not robust to adversarial examples. arXiv preprint\narXiv:1711.08478 (2017).\n[10] NicholasCarliniandDavidWagner.2017. Towardsevaluatingtherobustnessof\nneuralnetworks. In Proc.ofIEEES&P.\n[11] Antonin Chambolle. 2004. An algorithm for total variation minimization and\napplications. Journal of Mathematical Imagingand Vision 20,1 (2004), 89–97.\n[12] Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng Yi, and Cho-Jui Hsieh. 2018.\nEAD: elastic-net attacks to deep neural networks via adversarial examples. In\nProc.of AAAI .\n[13] Xinyun Chen, Chang Liu, Bo Li, KimberlyLu, and Dawn Song. 2017. Targeted\nBackdoor Attacks on Deep Learning Systems Using Data Poisoning. arXiv\npreprint arXiv:1712.05526 (2017).\n[14] AmbraDemontis,MarcoMelis,MauraPintor,MatthewJagielski,BattistaBiggio,\nAlina Oprea, Cristina Nita-Rotaru, and Fabio Roli. 2019. Why do adversarial\nattackstransfer?explaining transferabilityof evasionand poisoning attacks.In\nProc.of USENIX Security . 321–338.\n[15] G. S. Dhillon, K. Azizzadenesheli, J. D. Bernstein, J. Kossaiﬁ, A. Khanna, Z. C.\nLipton, and A. Anandkumar. 2018. Stochastic activation pruning for robust ad-\nversarialdefense. In Proc.ofICLR .\n[16] IanJGoodfellow, JonathonShlens,andChristianSzegedy.2014. Explainingand\nharnessingadversarialexamples. arXiv preprint arXiv:1412.6572 (2014).\n[17] Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. 2017. Badnets: Iden-\ntifying vulnerabilities in the machine learning model supply chain. In Proc. of\nMachine Learning and ComputerSecurity Workshop .\n[18] C.Guo,M.Rana,M.Cisse,andL.vanderMaaten.2018. Counteringadversarial\nimagesusing input transformations.In Proc.ofICLR .\n[19] YandongGuo,LeiZhang,YuxiaoHu,Xiaodong He,andJianfengGao.2016. Ms-\nceleb-1m:Adatasetandbenchmarkforlarge-scalefacerecognition.In European\nConference onComputer Vision .Springer,87–102.\n[20] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual\nlearning forimagerecognition. In Proc.of CVPR .\n[21] Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song. 2017.\nAdversarial example defenses: Ensembles of weak defenses are not strong. In\nProc.of WOOT .\n[22] J.ZicoKolterand EricWong. 2017. Provabledefensesagainstadversarialexam-\nples viathe convex outer adversarialpolytope. In Proc.ofNeurIPS .\n[23] AlexKrizhevskyandGeoﬀreyHinton.2009. Learningmultiplelayersoffeatures\nfromtiny images . Technical Report.\n[24] AlexeyKurakin,IanGoodfellow, andSamyBengio. 2016. Adversarialexamples\nin the physicalworld. arXiv preprintarXiv:1607.02533 (2016).\n[25] Alexey Kurakin,Ian Goodfellow, and Samy Bengio. 2017. Adversarial machine\nlearning atscale.In Proc.of ICLR .\n[26] Yann LeCun, LD Jackel, Léon Bottou, Corinna Cortes, John S Denker, Harris\nDrucker, Isabelle Guyon, UA Muller, Eduard Sackinger, Patrice Simard, et al.\n1995. Learningalgorithmsforclassiﬁcation:Acomparisononhandwrittendigit\nrecognition. Neural Networks 261(1995), 276.\n[27] Kang Liu, Brendan Dolan-Gavitt, and Siddharth Garg. 2018. Fine-pruning: De-\nfending against backdooring attacks on deep neural networks. In InternationalSymposium on Researchin Attacks,Intrusions,and Defenses .Springer,273–294.\n[28] Yingqi Liu, Wen-Chuan Lee, Guanhong Tao, Shiqing Ma, Yousra Aafer, and Xi-\nangyuZhang.2019. ABS:Scanning neuralnetworksforback-doorsbyartiﬁcial\nbrain stimulation. In Proceedings of the 2019 ACM SIGSAC Conference on Com-\nputer and CommunicationsSecurity . ACM,1265–1282.\n[29] Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang\nWang, and Xiangyu Zhang. 2018. Trojaning Attack on Neural Networks. In\nProc.of NDSS .\n[30] Shiqing Ma, Yingqi Liu, Guanhong Tao, Wen-Chuan Lee, and Xiangyu Zhang.\n2019. NIC: Detecting Adversarial Samples with Neural Network Invariant\nChecking. In Proc.ofNDSS .\n[31] XingjunMa,BoLi,YisenWang,SarahMErfani,SudanthiWijewickrema,Grant\nSchoenebeck, Dawn Song, MichaelE Houle, and JamesBailey.2018. Character-\nizingadversarialsubspacesusinglocalintrinsicdimensionality.In Proc.ofICLR .\n[32] AleksanderMadry,AleksandarMakelov,LudwigSchmidt,DimitrisTsipras,and\nAdrian Vladu. 2018. Towards deep learning models resistant to adversarial at-\ntacks.InProc.ofICLR .\n[33] Dongyu Meng and Hao Chen. 2017. Magnet: a two-pronged defense against\nadversarialexamples.In Proc.of CCS .\n[34] NicolasPapernot, PatrickMcDaniel,IanGoodfellow, SomeshJha,Z.BerkayCe-\nlik, and Ananthram Swami. 2017. Practical black-box attacks against machine\nlearning. In Proc.ofAsiaCCS .\n[35] NicolasPapernot,PatrickMcDaniel,XiWu,SomeshJha,andAnanthramSwami.\n2016. Distillation as a defense to adversarialperturbations against deep neural\nnetworks. In Proc.ofIEEES&P.\n[36] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, et al. 2015. Deep face\nrecognition.. In bmvc,Vol. 1.6.\n[37] Ximing Qiao, Yukun Yang, and Hai Li. 2019. Defending Neural Backdoors via\nGenerativeDistributionModeling. arXiv preprint arXiv:1910.04749 (2019).\n[38] P.Samangouei,M.Kabkab,andR.Chellappa.2018. Defensegan:Protectingclas-\nsiﬁersagainstadversarialattacksusinggenerativemodels. In Proc.of ICLR .\n[39] AliShafahi,WRonnyHuang,ChristophStuder,SoheilFeizi,andTomGoldstein.\n2019. Areadversarialexamplesinevitable?. In Proc.ofICLR .\n[40] ShawnShan,EmilyWenger,BolunWang,BoLi,HaitaoZheng,andBenY.Zhao.\n2020. Gotta Catch ’Em All: Using Honeypots to Catch Adversarial Attacks on\nNeuralNetworks. arXiv preprint: 1904.08554 (2020).\n[41] MahmoodSharif,SrutiBhagavatula,LujoBauer,andMichaelKReiter.2016. Ac-\ncessorize to a crime: Real and stealthy attacks on state-of-the-art face recogni-\ntion. InProc.of CCS .\n[42] Y. Song, T. Kim, S. Nowozin, S. Ermon, and N. Kushman. 2018. Pixeldefend:\nLeveraginggenerativemodels to understand and defend against adversarialex-\namples.In Proc.of ICLR .\n[43] James C Spall et al. 1992. Multivariate stochastic approximation using a simul-\ntaneous perturbation gradient approximation. IEEETrans.Automat.Control 37,\n3 (1992), 332–341.\n[44] J. Stallkamp, M. Schlipsing, J. Salmen, and C. Igel. 2012. Man vs. computer:\nBenchmarking machine learning algorithms for traﬃc sign recognition. Neu-\nral Networks (2012).\n[45] Octavian Suciu,Radu Mărginean, Yiğitcan Kaya,Hal DauméIII, and Tudor Du-\nmitraş. 2018. When Does Machine Learning FAIL? Generalized Transferability\nfor Evasionand Poisoning Attacks.In Proc.of USENIX Security .\n[46] Christian Szegedy, Wojciech Zaremba,Ilya Sutskever,Joan Bruna, Dumitru Er-\nhan, Ian Goodfellow, and Rob Fergus.2014. Intriguing properties of neural net-\nworks.In Proc.ofICLR .\n[47] Jonathan Uesato, Brendan O’Donoghue, Aaron van den Oord, and Pushmeet\nKohli.2018. Adversarialriskandthedangersofevaluatingagainstweakattacks.\narXiv preprintarXiv:1802.05666 (2018).\n[48] Bolun Wang,YuanshunYao,Shawn Shan,HuiyingLi,BimalViswanath,Haitao\nZheng,andBenY.Zhao.2019. NeuralCleanse:Identifying andMitigatingBack-\ndoor Attacksin NeuralNetworks.In Proc.of IEEES&P.\n[49] C. Xie, J. Wang, Z. Zhang, Z. Ren, and A. Yuille. 2018. Mitigating adversarial\neﬀects through randomization.In Proc.of ICLR .\n[50] Weilin Xu, David Evans, and Yanjun Qi. 2018. Feature squeezing: Detecting\nadversarialexamplesin deep neuralnetworks. In Proc.of NDSS .\n[51] YouTube[n.d.]. https://www.cs.tau.ac.il/~wolf/ytfaces/. YouTubeFacesDB.\n[52] ValentinaZantedeschi,Maria-IrinaNicolae,andAmbrishRawat.2017. Eﬃcient\ndefenses againstadversarialattacks.In Proc.of AISec .\n[53] Jialong Zhang, Zhongshu Gu,Jiyong Jang, Hui Wu, MarcPh Stoecklin, Heqing\nHuang, and Ian Molloy. 2018. Protecting intellectual property of deep neural\nnetworks with watermarking.In Proc.of AsiaCCS .\n[54] StephanZheng,YangSong,ThomasLeung,andIanGoodfellow.2016.Improving\nthe robustnessof deep neuralnetworks viastabilitytraining.In Proc.of CVPR .\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n79Table 6: Model Architecture for MNIST. FC stands for fully-\nco\nnnectedlayer.\nLayer Type #ofChannels Filter Size Stride Activation\nConv 16 5 ×5 1 ReLU\nMaxPool 16 2 ×2 2 -\nConv 32 5 ×5 1 ReLU\nMaxPool 32 2 ×2 2 -\nFC 512 - - ReLU\nFC 10 - - Softmax\nTable7: ModelArchitectureof GTSRB.\nLayer Type #ofChannels Filter Size Stride Activation\nConv 32 3 ×3 1 ReLU\nConv 32 3 ×3 1 ReLU\nMaxPool 32 2 ×2 2 -\nConv 64 3 ×3 1 ReLU\nConv 64 3 ×3 1 ReLU\nMaxPool 64 2 ×2 2 -\nConv 128 3 ×3 1 ReLU\nConv 128 3 ×3 1 ReLU\nMaxPool 128 2 ×2 2 -\nFC 512 - - ReLU\nFC 43 - - Softmax\nAPPENDIX\n8.\n1 ProofofTheorem 1& 2\nProof of Theorem1\nP/r.sc/o.sc/o.sc/f.sc.This theorem assumes that after injecting thetrapdoor\n∆into themodel,wehave\n∀x∈ X,Pr(Fθ(x+∆)=/y.altt/nequalFθ(x)) ≥1−µ.(6)\nWhen an attacker applies gradient-based optimization to ﬁnd ad-\nversarialperturbationsforaninput xtargeting /y.altt,theaboveequa-\ntion (6) implies that the partial gradient from xtowardsx+∆be-\ncomesthemajorgradienttoachievethetarget /y.altt.Notethat Fθ(x)\nis the composition of non-linear feature representation /afii10069.ital(x)and\na linear loss function (e.g. logistic regression): Fθ(x)=/afii10069.ital(x) ◦L\nwhereLrepresents the linear function. Therefore, the gradient of\nFθ(x)can becalculatedvia /afii10069.ital(x):\n∂lnFθ(x)\n∂x=∂ln[/afii10069.ital(x)\n◦L]\n∂x=c∂ln\n/afii10069.ital(x)◦L\n∂x(7)\nHerecis the constant within the linear function L. To avoid am-\nbiguity, we will focus on the derivative on /afii10069.ital(x)in the rest of the\nproof.\nGiven (7),we caninterpret (6) interms of themajorgradient:\nPx∈X[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+∆)]\n∂x≥η] ≥1−µ, (8)\nwhereηrepresents, forthegiven x,thegradient valuerequiredto\nreach/y.alttas theclassiﬁcationresult.\nNext, since ∀x∈ X,cos(/afii10069.ital(A(x)),/afii10069.ital(x+∆)) ≥σ, andσ→1,\nwithout loss of generality we have /afii10069.ital(A(x))=/afii10069.ital(x+∆)+γwhere|γ|<<|/afii10069.ital(x+∆)|. Here we rewrite the adversarial input A(x)as\nA(x)=x+ϵ. Using this condition, we can prove that the follow-\ning two conditions are true. First, because the value of γdoes not\ndepend on x, we have\n∂(/afii10069.ital(x+∆)+γ)\n∂x=∂/afii10069.ital(x+∆)\n∂x. (9)\nFurthermore,because |γ|<<|/afii10069.ital(x+∆|),wehave\n1\n/afii10069.ital(x+∆)+γ≈1\n/afii10069.ital(x+∆). (10)\nLeveraging eq.(8)-(10),we have\nPx∈X[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+ϵ)]\n∂x≥η]\n=Px∈X[1\n/afii10069.ital(x)∂/afii10069.ital(x)\n∂x−1\n/afii10069.ital(x+ϵ)∂/afii10069.ital(x+ϵ)\n∂x≥η]\n=Px∈X[1\n/afii10069.ital(x)∂/afii10069.ital(x)\n∂x−1\n/afii10069.ital(x+∆)+γ∂(/afii10069.ital(x+∆)+γ)\n∂x≥η]\n≈Px∈X[1\n/afii10069.ital(x)∂/afii10069.ital(x)\n∂x−1\n/afii10069.ital(x+∆)∂(/afii10069.ital(x+∆))\n∂x≥η]\n=Px∈X[∂[l\nn/afii10069.ital(x)−ln/afii10069.ital(x+∆)]\n∂x≥η]\n≥1−µ.\n/square\nPr\noof of Theorem2\nP/r.sc/o.sc/o.sc/f.sc.Thistheoremassumesthat,afterinjectingthetrapdoor\n∆,wehave\nPx∈Xtrap[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+∆)]\n∂x≥η] ≥1−µ(11)\nFollowingthesameproofprocedureinTheorem 1,we have\nPx∈Xtrap[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+ϵ)]\n∂x≥η] ≥1−µ(12)\nSinceXtrapandXattackareρ-covert, bydeﬁnition (seeeq.(5))\nwe have that for any event C⊂Ω, the largest possible diﬀerence\nbetweenthefollowingprobabilities Px∈Xattack[C]andPx∈Xtrap[C]\nis boundedby ρ.\nNext letCrepresent the event: (∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+ϵ)]\n∂x≥η). We\nhave, for x∈ Xattack,\nPx∈Xattack[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+ϵ)]\n∂x≥η]\n≥Px∈Xt\nrap[∂[ln/afii10069.ital(x)−ln/afii10069.ital(x+ϵ)]\n∂x≥η]−ρ\n≥1−\n(µ+ρ).\n/square\n8.2 Experiment Conﬁguration\nEvaluationDataset. We discuss in details oftraining datasets\nweusedfor theevaluation.\n•Hand-writtenDigitRecognition (MNIST)–Thistaskseekstorec-\nognize10handwrittendigits(0-9)inblackandwhiteimages[26].\nThe dataset consists of 60 ,000 training images and 10 ,000 test\nimages.TheDNNmodelisastandard4-layerconvolutionalneu-\nral network (seeTable6).\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n80 0 0.2 0.4 0.6 0.8 1\n 0  0.2  0.4  0.6  0.8  1True Positive Rate\nFalse Positive RateCW (AUC 0.99)\nElasticNet (AUC 0.99)\nPGD (AUC 1.0)\nBPDA (AUC 1.0)\nSPSA (AUC 1.0)\nFGSM (AUC 1.0)\nFigure 7: ROC Curve of detection on\nMN\nIST with single-labeldefense. 0 0.2 0.4 0.6 0.8 1\n 0  0.2  0.4  0.6  0.8  1True Positive Rate\nFalse Positive RateCW (AUC 0.99)\nElasticNet (AUC 0.99)\nPGD (AUC 1.0)\nBPDA (AUC 1.0)\nSPSA (AUC 1.0)\nFGSM (AUC 0.99)\nFigure 8: ROC Curve of detectionon CI-\nFA\nR10 with single-labeldefense. 0 0.2 0.4 0.6 0.8 1\n 0  0.2  0.4  0.6  0.8  1True Positive Rate\nFalse Positive RateCW (AUC 1.0)\nElasticNet (AUC 1.0)\nPGD (AUC 1.0)\nBPDA (AUC 1.0)\nSPSA (AUC 1.0)\nFGSM (AUC 1.0)\nFigure 9: ROC Curve of detection on\nYo\nuTubeFacewith single-labeldefense.\n 0 0.2 0.4 0.6 0.8 1\n 2  4  6  8  10  12Detection Success Rate\nDNN Layer Number\nFigure 10: Detection success rate of CW attack at 5%F PR\nwhenusingdiﬀerentlayersfordetectioninaGTSRBmodel.\nTable 8: ResNet20Model Architecturefor CIFAR10.\nLayer Name(type) #of Channels Activation Connected to\nconv_1 (Conv) 16 ReLU -\nco\nnv_2 (Conv) 16 ReLU conv_1\nconv_3 (Conv) 16 ReLU pool_2\nconv_4 (Conv) 16 ReLU conv_3\nconv_5 (Conv) 16 ReLU conv_4\nconv_6 (Conv) 16 ReLU conv_5\nconv_7 (Conv) 16 ReLU conv_6\nconv_8 (Conv) 32 ReLU conv_7\nconv_9 (Conv) 32 ReLU conv_8\nconv_10 (Conv) 32 ReLU conv_9\nconv_11 (Conv) 32 ReLU conv_10\nconv_12 (Conv) 32 ReLU conv_11\nconv_13 (Conv) 32 ReLU conv_12\nconv_14 (Conv) 32 ReLU conv_13\nconv_15 (Conv) 64 ReLU conv_14\nconv_16 (Conv) 64 ReLU conv_15\nconv_17 (Conv) 64 ReLU conv_16\nconv_18 (Conv) 64 ReLU conv_17\nconv_19 (Conv) 64 ReLU conv_18\nconv_20 (Conv) 64 ReLU conv_19\nconv_21 (Conv) 64 ReLU conv_20\npool_1(AvgPool) - - conv_21\ndropout_1(Dropout) - - pool_1\nfc_ (FC) - Softmax dropout_1\n•Traﬃc Sign Recognition ( GTSRB) – Here the goal is to recog-\nnize 43 diﬀerent traﬃc signs, emulating an application for self-\ndrivingcars.WeusetheGermanTraﬃcSignBenchmarkdataset\n(GTSRB),whichcontains35 .3Kcoloredtrainingimagesand12 .6K\ntesting images [44]. The modelconsists of 6 convolutionlayersand2denselayers(seeTable7).Thistaskis1)commonlyusedas\nan adversarial defense evaluation benchmark and 2) represents\na real-world settingrelevant toourdefense.\n•ImageRecognition (CIFAR10)–Thetaskistorecognize10diﬀer-\nent objects. The dataset contains 50K colored training images\nand 10K testing images [23]. The model is an Residual Neural\nNetwork(RNN)with20residualblocksand1denselayer[20](Ta-\nble 8). We includethis task becauseof its prevalence in general\nimage classiﬁcationand adversarial defense literature.\n•FaceRecognition (YouTubeFace)–Thistaskistorecognizefaces\nof 1,283 diﬀerent people drawn from the YouTube videos [51].\nWe build the dataset from [51] to include 1 ,283 labels, 375.6K\ntraining images, and 64 .2K testing images [13]. We use a large\nResNet-50architecturearchitecture[20]withover25millionpa-\nrameters.Weincludethistaskbecauseitsimulatesamorecom-\nplex facial recognition-based security screening scenario. De-\nfending against adversarial attack in this setting is important.\nFurthermore, the large set of labels in this task allows us to ex-\nplorethescalabilityofourtrapdoor-enableddetection.\nModelArchitecture. WenowpresentthearchitectureofDNN\nmodelsusedinourwork.\n•MNIST(Table6) is a convolutional neural network (CNN) con-\nsisting of two pairs of convolutional layers connected by max\npoolinglayers, followedbytwofullyconnectedlayers.\n•GTSRB(Table7) is a CNN consisting of threepairs ofconvolu-\ntional layers connectedbymaxpoolinglayers, followedbytwo\nfullyconnectedlayers.\n•CIFAR10 (Table8)isalsoaCNNbutincludes21sequentialcon-\nvolutional layers, followed by pooling, dropout, and fully con-\nnected layers.\n•YouTubeFace is the ResNet-50 model trained onthe YouTube\nFace dataset. It has 50 residual blocks with over 25 millions pa-\nrameters.\nDetailed information on attack conﬁguration. We evalu-\nate the trapdoor-enabled detection using six adversarial attacks:\nCW,ElasticNet,PGD,BPDA,SPSA,andFGSM(whichwehavede-\nscribed in Section 2.1). Details about the attack conﬁguration are\nlistedinTable10.\nSample Trapdoor Patterns. Figure 11 shows sample images\nthatcontainasingle-label defense trapdoor(a single 6 ×6square)\nand that contain an all-label defense trapdoor(ﬁve 3 ×3 squares).\nThe mask ratio of the trapdoors used in our experiments is ﬁxed\ntoκ=0.1.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n81Table 9: Detailedinformation on datasetsanddefenseconﬁgura tionsfor eachtrapdooredmodelwhen protectingall labels.\nModel#\nof\nLabelsTraining\nSe\ntSizeTesting\nSe\ntSizeInjection Ratio MaskRatio TrainingConﬁguration\nMNIST 10 50,000 10,000 0.5 0.1 epochs=5,batch=32,optimizer=Adam,lr=0.001\nGTSRB 43 35,288 12,630 0.5 0.1 epochs=30,batch=32,optimizer=Adam,lr=0.001\nCIFAR10 10 50,000 10,000 0.5 0.1 epochs=60,batch=32,optimizer=Adam,lr=0.001\nYouTubeFace 1,283 375,645 64,150 0.5 0.2 epochs=30,batch=32,optimizer=Adam,lr=0.001\nTable 10: Detailedinformation on attackconﬁgurations. ForM NIST experiments,we dividtheeps valueby 255.\nAttackMethod AttackConﬁguration\nCW binary step size= 9,max iterations = 1000,learning rate= 0.05 ,abortearly= True\nPGD max eps =8,# ofiteration= 100,eps of each iteration= 0.1\nElasticNet binary step size= 20,max iterations =1000,learning rate=0.5 ,abortearly= True\nBPDA max eps =8,# ofiteration= 100,eps of each iteration= 0.1\nSPSA eps = 8,#of iteration=500,learning rate= 0.1\nFGSM eps = 8\n(a) Single LabelDefenseTrapdoor\n (b) All LabelDefenseTrapdoor\nFi\ngure 11: Sample trapdoor examples used in our defense.\nWhile the actual trapdoors we used all have a mask ratio of\nκ=0.1, here we artiﬁcally increase κfrom0.1to1.0in order to\nhighlight thetrapdoorsfrom therestof the imagecontent.\nTable 11: Dataset, complexity, model architecture for each\ntask.\nTask Dataset#of\nLabelsInput\nSizeTraining\nImagesModel\nArchitecture\nDigit\nRe\ncognitionMNIST 10 28 ×28×1 60,000 2 Conv,2 Dense [6]\nTraﬃcSign\nRe\ncognitionGTSRB 43 32 ×32×3 35,288 6 Conv,2 Dense [7]\nImage\nRe\ncognitionCIFAR10 10 32 ×32×3 50,000 20 Resid,1 Dense [8]\nFacial\nRe\ncognitionYouTube\nFace1,283 224 ×224×3 375,645 ResNet-50 [20]Table 12: Trapdoored model and original model classiﬁca-\nti\nonaccuracywhen injectingtrapdoorsfor all labels.\nModelOriginalModel\nClassiﬁcationAccuracyTrapdooredModel(All Labels)\nClassiﬁcationAccuracy\nMNIST 99 .2% 98.6%\nGTSRB 97 .3% 96.3%\nCIFAR10 87 .3% 86.9%\nYouTubeFace 99 .4% 98.8%\nDatasets and Defense Conﬁguration. Ta blel 9 lists the spe-\nciﬁcdatasetsandtrainingprocessusedtoinjecttrapdoorsintothe\nfourDNN models.\nSelectingTrapdoorInjectionRatio. Asmentionedearlier,our\nanalysisshowsthatthesizeanddiversityofthetrainingdataused\ntoinjectatrapdoorcouldaﬀectitseﬀectivessoftrappingattackers.\nToexplorethisfactor,wedeﬁne trapdoorinjectionratio astheratio\nbetween the trapdooredimages and the clean images in the train-\ning dataset. Intuitively, a higher injection ratio should allow the\nmodel to learn the trapdoor better but could potentially degrade\nnormalclassiﬁcationaccuracy.\nWe defend the model with diﬀerent trapdoor injection ratios\nand examine the detection success rate. We see that only when\ntheinjectionratioisvery small( e.g.<0.03forGTSRB),themodel\nfailstolearnthetrapdoorandthereforedetectionfails.Otherwise\nthe trapdoor is highly eﬀective in terms of detecting adversarial\nexamples. Thus when building the trapdooredmodels, we use an\ninjection ratio of 0 .1 for MNIST, GTSRB, CIFAR1010, and 0 .01 for\nYouTubeFace (seeTable10).\n8.3 Additional Resultson Comparing Trapdoor\nand Adversarial Perturbation\nFigure12and Figure13show that theneuron signatures ofadver-\nsarial inputs have high cosine similarity to the neuron signatures\nof trapdoors in a trapdoored CIFAR10 and YouTube Face models\n(leftﬁgures), and thetrapdoor-freemodels(right ﬁgures).\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n82 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(a) Trapdoored Model 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(b) OriginalModel\nFi\ngure 12: Comparison of cosine similarity of normal images and adversarial images to trapdoored inputs in a trapdoored\nCIFAR10modelandinanoriginal(trapdoor-free)CIFAR10model.Theboxesshowtheinter-quartilerange,andthewhiskers\ndenotethe 5thand95thpercentiles.\n 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(a) Trapdoored Model 0 0.2 0.4 0.6 0.8 1\nBenign CW PGD Elastic\nNetBPDA SPSA FGSMCosine Similarity\n(b) OriginalModel\nFi\ngure 13: Comparison of cosine similarity of normal images and adversarial images to trapdoored inputs in a trapdoored\nYouTubeFacemodelandinanoriginal(trapdoor-free)YouTubeFacemodel.Theboxesshowtheinter-quartilerange,andthe\nwhiskers denotethe 5thand95thpercentiles.\nSession 1B: Attacking and Defending ML Systems\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n83"}
{"title": "Locating the Security Patches for Disclosed OSS Vulnerabilities with Vulnerability-Commit Correlation Ranking", "content": "Locating the Security Patches for Disclosed OSS Vulnerabilities\nwith Vulnerability-Commit Correlation Ranking\nXin Tan∗\nFudan University\n18212010028@fudan.edu.cnYuan Zhang∗\nFudan University\nyuanxzhang@fudan.edu.cnChenyuan Mi\nFudan University\n20210240143@fudan.edu.cn\nJiajun Cao\nFudan University\n20210240046@fudan.edu.cnKun Sun\nGeorge Mason University\nksun3@gmu.eduYifan Lin\nFudan University\n19210240159@fudan.edu.cn\nMin Yang\nFudan University\nm_yang@fudan.edu.cn\nABSTRACT\nSecurity patches play an important role in defending against the\nsecuritythreatsbroughtbytheincreasingOSSvulnerabilities.How-\never,thecollectionofsecuritypatchesstillremainsachallenging\nproblem. Existing works mainly adopt a matching-based design\nthatusesauxiliaryinformationinCVE/NVDtoreducethesearch\nscope of patch commits. However, our preliminary study shows\nthat these approaches can only cover a small part of disclosed OSS\nvulnerabilities (about 12%-53%) even with manual assistance.\nTo facilitate the collection of OSS security patches, this paper\nproposes a ranking-based approach, named PatchScout , which\nranks the code commits in the OSS code repository based on\ntheir correlationsto agiven vulnerability.By exploitingthe broad\ncorrelations between a vulnerability and code commits, patch\ncommits are expected to be put to front positions in the ranked\nresults. Compared with existing works, our approach could help to\nlocatemoresecuritypatchesandmeetabalancebetweenthepatchcoverageandthemanualeffortsinvolved.Weevaluate\nPatchScout\nwith685OSSCVEsandtheresultsshowthatithelpstolocate92.70%\npatches with acceptable manual workload. To further demonstrate\nthe utility of PatchScout , we perform a study on 5 popular OSS\nprojectsand225CVEstounderstandthepatchdeploymentpractice\nacross branches, and we obtain many new findings.\nCCS CONCEPTS\n•Security and privacy →Software and application security ;\n•Software and its engineering →Maintaining software.\n∗co-first authors\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.\n© 2021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3484593KEYWORDS\nSecurityPatches;Vulnerability-CommitCorrelation;PatchRanking\nACM Reference Format:\nXinTan,YuanZhang,ChenyuanMi,JiajunCao,KunSun,YifanLin,andMin\nYang. 2021. Locating the Security Patches for Disclosed OSS Vulnerabilities\nwith Vulnerability-Commit Correlation Ranking. In Proceedings of the 2021\nACMSIGSACConferenceonComputerandCommunicationsSecurity(CCS\n’21),November15–19,2021,VirtualEvent,RepublicofKorea. ACM,NewYork,\nNY, USA, 18 pages. https://doi.org/10.1145/3460120.3484593\n1 INTRODUCTION\nWith the increase of open source software (OSS), the number of\nreported OSS vulnerabilities has also experienced rapid growth.\nAs reported by WhiteSource [ 2], the number of disclosed OSS\nvulnerabilities in 2019 skyrocketed to over 6,000, which rose by\nnearly 50% compared to 2018. To mitigate these vulnerabilities,\ndevelopers usually resort to security patches.\nIn practice, security patches are central in defending against\nsecurity threats. First, the patches can be directly applied to fix the\ncorrespondingvulnerabilities.Second,hot-patchescanbederived\nfromtheoriginalsecuritypatchestoeasethedeploymentofsecurity\npatches, with the help of hot-patching frameworks [ 13,15,24,52].\nThird, security patches are useful in facilitating downstream tasks,\nsuchasvulnerablecodeclonedetection[ 38,43,47,73,74],patch\npresence testing [ 27,32,39,79]. Finally, due to their importance,\nsecuritypatcheshavebecomeanimportanttargettostudy,suchas\nunderstanding their development process and complexities [ 45,\n64,80] and their perceptions by end-users [ 62]. Therefore, the\ncollectionofsecurityvulnerabilities,aswellastheircorresponding\npatches, become an important asset for the community.\nCVE [25] and NVD [ 55] are two popular public references for\nsecurityvulnerabilities.Inparticular,CVEgiveseveryreportedvul-\nnerabilityan identificationnumber(called CVE-ID),adescription,\nand at least one public reference. Further, NVD incorporates all\nvulnerabilities in CVE with enhanced vulnerability information\nsuch as severity scores (CVSS), vulnerability type (CWE), and\naffectedsoftwareconfigurations(CPE).Basedonthesevulnerability\ndatabases,existingandemergingsecurityvulnerabilitieshavebeenefficientlysharedwithinterestedusers;however,howtoaccurately\nlocate their security patches still remains an open problem.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3282\nIn essence, security patches are code commits that are develope-\nd/deployed by OSS developers in their code repositories. However,\ndue to the large number of code commits in a code repository\n(e.g., there are about 936k commits in Linux kernel till version 5.8),\nlocatingsecuritypatchesisquitelaborious.Toreducethesearch\nscope,existingworksusuallyturntoextraauxiliaryinformationin\nthe vulnerability database. For example, Perl et al.[57] and Kim et\nal.[43]locatesecuritypatchesfromthecodecommitsthatmention\nthecorrespondingCVE-ID;otherworks[ 10,45,57,69,70]locate\nsecuritypatchesfromtheexternalreferenceURLsintheCVE/NVD\npages. As it will be demonstrated in our preliminary study (see §2),\ntheseapproachesonlycoverasmallpartofdisclosedvulnerabilities\ndue to two reasons: 1) only few vulnerability information in\nCVE/NVD is used to reduce the search scope, which is usually\nincomplete (and sometimes incorrect); 2) these approaches are\nmatching-based,whichmeanstheyeithergivefewcandidateswhen\nmatched or give no results when unmatched.\nInthe fieldofmining software repositories(MSR),thereis aline\nof research that aims to predict the components (e.g., files) to be\nfixedforabug[ 12,37,42,44,46,61,68,71,76,78,81].Bymining\nthe correlations between a bug and different software components,\ntheseworksrankthesoftwarecomponentstoreflecttheirlikelihood\nof being fixed for this bug. Inspired by these works, we propose to\ntransform the search problem of locating security patches into a\nrankingproblemon codecommits,andwedesigna systemcalled\nPatchScout to incorporate this idea. For code commit ranking,\nPatchScout features a new technique, called vulnerability-commit\ncorrelation ranking , which exploits the broad correlations between\nthe vulnerability and the code commits to put more relevant\ncode commits to the front. Different from existing approaches,\nPatchScout leverages more typesof vulnerability information to\nestimate the relevance of a code commit to a given vulnerability.In general, four groups of correlation features between a codecommit and a vulnerability are considered, namely, vulnerability\nidentifier, vulnerabilitylocation, vulnerabilitytype,and vulnerability\ndescriptivetexts.Basedonthesefeatures, PatchScout furthertrains\na RankNet [ 20] model to rank code commits. Since patch commits\nshare a lot of relevant information with the vulnerability, they are\nexpected to be put to front positions in the ranked results. With\nthe code commits ranked, the efforts to locate security patches are\ndramatically reduced than those exploring all code commits.\nCompared with existing approaches, PatchScout has several\nadvantages. First, it uses a wide range of vulnerability information,\nso it can tolerate more on the incomplete/incorrect vulnerability\ninformationinCVE/NVDpages.Second,theranking-basedsolution\nhas a higher chance to extract security patches than the existing\nmatching-basedsolutionssinceitalwaysgivesrankedresultswhile\nexisting solutions only provide results when matched. Third, by\nexploiting the underlying connections (even weak ones) between a\nvulnerabilityandcodecommits,the vulnerability-commitcorrelation\nrankingmechanismin PatchScout iscapableoflocatingpatches\nformorevulnerabilities.Similartoexistingworks, PatchScout also\nrequires manual efforts to finally locate the security patches from\ntherankedcodecommits;however,itcanbeusedasasearchenginetofacilitate thelocating ofsecurity patchesfroma largenumberofcodecommits.Without\nPatchScout ,securityexpertsmayneedto\nexplorethousandsofcommitstolocatethesecuritypatch(es)foronevulnerability.With PatchScout ,sincethecommitsareranked,\nonly afew high-ranked commits are expectedto be checked before\nthe security patches are located.\nWeevaluatetheeffectivenessof PatchScout onlocatingsecu-\nritypatchesforreal-worldOSSvulnerabilities.Specifically,wetraina ranking model for\nPatchScout with 943 CVEs and their patches,\nand test its performance with other 685 CVEs. The results show\nthatPatchScout successfullyranksthepatchcommitfor69.49%\nCVEs at the first position among all the code commits and helps to\nlocate the security patches for 92.70% CVEs at the cost of checking\n4.32 commits on average. Compared with existing approaches\nthat can locate the patches for at most 47.59% CVEs and requireto check 1.83 commits per CVE,\nPatchScout can locate 85.40%\npatches with almost the same amount of manual work involved.\nOurevaluationshowsthat PatchScout effectivelyfacilitatesthe\nlocatingofsecuritypatchesbydelicatelybalancingthecoverageof\nthe security patches and the manual efforts involved.\nTo further illustrate the security benefits of PatchScout ,w e\napply it to conduct a study on the patch deployment practice\nacross branches. Ourstudy collects 225 CVEs from5 OSS projects\nand uses PatchScout to locate the security patches for these\nvulnerabilitieson83branches.Withthehelpof PatchScout ,w e\nsuccessfullylocate1,985patcheswhileexistingapproachescanonly\nlocate 1,087 patches. Our study discovers that a large portion of\nbranchesarevulnerableandstillstayunpatched,andsomepatched\nbranchessufferfromaquitelongpatchlag.Besides,wefindthat\n38CVEsmissthereportingof152affectedversionsinCVE/NVD.\nCVE maintainers have confirmed our findings and updated theirdatabase accordingly. In addition, our study gives a landscapeabout the different types of patch backporting situations acrossbranches and analyzes different levels of technical difficulties in\npatch backporting, which raises some new research problems.\nIn summary, we make the following contributions.\n•We propose a new idea of locating security patches for disclosed\nOSS vulnerabilities, which transforms the search problem of\npatch commits into a ranking problem.\n•We present a new technique, i.e. vulnerability commit correlation\nranking,whichrankscodecommitsbasedontheirrelevancetoa\nvulnerability from multiple correlation features.\n•We evaluate the effectiveness of our proposed approach, and the\nresultsshowthatourapproachsignificantlyoutperformsexisting\nones in both patch coverage and required manual efforts.\n•We conduct the first study on the patch deployment practiceacross branches, which draws many interesting findings and\nconcludes several important research opportunities.\n2 PRELIMINARY STUDY\nSecurity patches play a central role in defending against secu-rity vulnerabilities; however, many vulnerabilities are disclosed\nwithout their patches being published at the same time. Moreover,\nlocating patches from tens of thousands of code commits is an\nextremelytime-consumingandlaboriousjob.Toavoidsearching\nthepatchesinalargescope,researchersusuallyleveragesomeextra\nreferences [ 10,45,57,69,70] or keywords [ 43,57] in CVE/NVD\ndatabases.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3283Fromexistingworks,weidentifythreemethodsthatcanbeused\nto locate the security patches of publicly reported vulnerabilities.\n•M1:searchingcommitmessageswithCVE-ID. Sometimes,develop-\nersmaydeclaretheCVE-IDinthecommitmessageofthesecurity\npatch, so the search scope of security patches can be reduced\nby using the CVE-ID as the keyword to filter those irrelevant\ncode commits. Some previous works [ 43,57] apply this method\nto collect patches for further research.\n•M2:checkingcommit-likeURLsinCVE/NVD. Externalresources\nthat are related to each CVE are provided as reference linksin CVE/NVD. Since security patches may also be collected as\nreferencelinks,previousworks[ 45,57,69,70]relyonidentifying\nthe reference URLs in a commit format1as patches.\n•M3: checking patch-tagged URLs in the NVD. In addition to\ncollectingreferencelinksforeachCVE,theNVDtagssomelinks\nto indicate what type of resources they provide. In particular,\nthe NVD assigns a “Patch ” tag for a link that refers to a security\npatch2. Therefore, the patch-tagged URLs in NVD pages have\nbeen used [10] to identify the security patches.\nThough the above approaches reduce the efforts in locating\nsecurity patches,their performances havenot been systematically\nexplored. To further understand the difficulties in locating securitypatches and the performance of existing approaches, we perform a\npreliminary study that consists of the following two experiments.\nExperiment-1: How many security patches can be located\nby existing approaches? To conduct the experiment, we first\nneedavulnerabilitydataset.AsreportedbyWhiteSource[ 1],more\nthan half of disclosed vulnerabilities are C/C++ vulnerabilities.\nTherefore, our experiment chooses C/C++ vulnerabilities as the\ntarget. In particular, we take four steps to collect a large set ofdisclosed C/C++ OSS vulnerabilities and the code repositories ofthese OSS projects: 1) we crawl all the vulnerabilities reportedbetween January 2015 and July 2020 from the NVD; 2) we select\nC/C++vulnerabilitiesfromthembyusingfilesuffix(e.g.,.c,.cpp,\n.cxx,etc.)asthekeywordstomatchthevulnerabilitydescription;3)\nwecombinekeywordsearchingandmanualinspectiontokeeponly\nC/C++ OSS vulnerabilities and confirm their affected OSS projects;\n4) we manually locate the code repository for each affected OSS\nprojectandautomaticallyclonetheserepositories.Inall,wecollect\n6,628 C/C++ vulnerabilities belonging to 798 OSS projects.\nTheabovethreeapproaches(akaM1,M2,andM3)areapplied\ntolocatethesecuritypatchesofthecollectedOSSvulnerabilities.\nSince these approaches may report wrong patch commits, their\nresults should be manually verified. To limit the manual efforts in\nverifyingtheresults,wefirstcountthenumberofCVEsthatatleast\none candidate patch could be located using each of these methods.\nNote that this result measures the upper bound of the coverage for\neach method in locating security patches. As shown in Table 1, all\nthreeapproacheshavealowcoverage.Searchingcommitmessages\nwithCVE-ID(M1)onlycovers12.01%oftheCVEs,whichimplies\nthatmostdevelopersdonotexplicitlydeclarethefixedvulnerability\nin the patch commit. With the help of the manually-collected\nexternal URLs in CVE/NVD, checking commit-like URLs (M2) and\nchecking path-tagged URLs (M3) achieve the coverage of 43.33%\n1e.g., https://gitlab.gnome.org/GNOME/libxml2/commit/0e1a49c89076\n2e.g., https://nvd.nist.gov/vuln/detail/CVE-2015-1474Table 1: The patches located for 6,628 CVEs.\nApproachCovered\nCVEsAVG Commits\nto CheckCommits\nto VerifyCommits Verified\nas Patches\nM1 796 (12.01%) 1.93 317 273\nM2 2,872 (43.33%) 1.26 721 688\nM3 3,506 (52.90%) 1.63 1,162 551\nM1+M2+M3 4,412 (66.57%) 1.78 1,531 1,029\nand 52.90%, respectively. Besides, even we combine all these three\nmethods, we can only cover the patches for 66.57% of the CVEs.\nThisexperimentillustratesthepatchinginformationprovidedby\nCVE/NVD is incomplete, and existing approaches cannot locate\nsecurity patches for a large part of the disclosed vulnerabilities.\nExperiment-2: How many manual efforts are needed in\nconfirming the security patches and what is the precisionof these approaches?\nWe randomlyselect 20%potential patches\nreported by each approach and manually verify them. Besides,\nfrom the potential patches that are covered by the combination\nmethodofM1,M2,andM3,wealsorandomlyselect20%formanual\nconfirmation. In all, it takes three security researchers 155 man-\nhours to verify these commits. To verify if an identified commit is\nacorrectpatchforthecorrespondingvulnerability,participators\ncarefully examine the commit and the vulnerability information\nand refer to public materials (e.g., bug reports) when needed.\nThedetailedverificationresultsarepresentedinTable1.Itturns\noutthatthoughtheseapproachesrequireuserstochecknomore\nthan 2 commits per CVE, incorrect patch commits are common in\ntheir results. For example, although M3 gives patch candidates for\n52.90% CVEs, only 47.42% of them are correct patches. Besides, M1\nand M2 were used by Perl et al.[57] and Liet al.[45] to collect\nsecuritypatches,becausetheyfound nofalsepositivesofthetwo\napproaches in a small test set which includes less than 100 results.\nHowever, in our evaluation with a larger test set, we find that both\napproachesreportincorrectpatchresults,renderingthatexisting\nworks may suffer from using incorrect patches in their works.\nThis finding alsodemonstrates that collecting large-scale security\npatchesisnecessaryandchallenging.Notethecommonreasonsfor\nthe false positives of these methods are: i) non-patch commits (e.g.\ntestcases)maymentionCVE-ID/Bug-IDinthecommitmessages\n(M1);ii)commit-likeURLsinNVDmayrelatetonon-patchcommits\n(M2); iii) NVD maintainers may incorrectly tag patches (M3).\nKey Findings . Our preliminary study shows that all existing\napproaches suffer from a low coverage in locating security patches\nandrequiremanualeffortstoverifytheirresults.Wefindtwomainlimitationsforexistingapproaches.First,theydonotefficientlyuse\nthe vulnerability information in CVE/NVD. When only leveraging\nlittle information (e.g., CVE-ID, reference URLs) that is usuallyincomplete and sometimes incorrect to identify patch commits,\nexistingapproachescannotcoveralargeportionofsecuritypatches.\nSecond,theyallleveragematching-basedapproaches,whichlead\nto either few matched commits or no results at all.\n3 APPROACH OVERVIEW\nAsshownin§2,existingapproachescannoteffectivelylocatethe\nsecurity patches for a large number of disclosed vulnerabilities.\nToaddressthisproblem,thissectionfirstillustratesournewidea\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3284of locating security patches, i.e. vulnerability-commit correlation\nranking,andthendescribesthecorefeaturesusedbyourranking.\n3.1 Key Idea\nGoals.Beforeintroducingournewapproachoflocatingsecurity\npatches, we first clarify the goals that our approach should meet.\n•Goal-1: Help to locate more patches. As our preliminary study\nshows, existing works cannot cover a large number of vulner-\nabilities. Therefore, our primary goal is to cover more patches\nforbetterfightingagainstvulnerabilitythreatsandpreparingfor\nmore representative patch studies [39, 45, 57, 79].\n•Goal-2:Limittheinvolvedmanualefforts. Itisdifficulttodetermine\nifasecuritypatchisthecorrectoneforaspecificvulnerability,\nexcept that patch developers explicitly state it. As a result, it\nusually requires manual efforts to verify the results. Our goal is\nto reduce the manual efforts involved in confirming the security\npatches. In other words, our approach targets locating more\npatches with the same amount of manual work.\nObservations. Wehavethefollowingobservationsthatcanhelp\nto achieve our goals.\nObservation-1: security patches are usually found as code commits\nintheOSScoderepositories. Inessence,asecuritypatchiswritten\nby the OSS developers or submitted by security experts. To fixthe vulnerability, it should be merged into the code repository.\nTherefore, security patches can be usually found as code commits.\nInotherwords,thepatchforasecurityvulnerabilitycanbelocated\nby exploring all code commits as long as the patch exists.\nObservation-2: there are broad correlations between the vulner-\nability and its security patch commit. In a security patch commit,\ndevelopers may refer to the fixed vulnerability in various ways,\nsuchasdirectlymentioningit,explaininghowthiscommitfixesthe\nvulnerability,anddescribingtheimpactofthiscommit.Meanwhile,\nthe vulnerability information in CVE/NVD usually describes the\nvulnerabilityfrommanyaspects,suchasthevulnerabilitytype,vul-\nnerabilitylocation,vulnerabilityimpact,etc.Thus,thereexistbroadcorrelationsbetweenthevulnerabilityanditspatch,facilitatingthe\nlocating of security patches for a given vulnerability.\nFigure 1 gives an example to illustrate the correlations be-\ntween the vulnerability description of CVE-2016-4417 [54] and its\npatch [72], including vulnerability location, vulnerability type, and\ndescriptivetexts.First,boththevulnerabilitydescriptionandthe\ncommitmessagementionthesamevulnerabilitylocation(wordsingreen). In addition, the code change location in the code diff is alsoconsistentwiththevulnerabilitylocation.Second,thevulnerability\ndescription introduces the type and impact (words in red) of the\nCVE, while the commit message also claims it fixes a “buffer\noverrun”bug.Besides,thecodediffalsoindicatesitfixesabuffer-\noverrunbug byupdating thebuffer sizefrom0xff to0x100. Third,\nthevulnerabilitydescriptiondescribessomeothercharacteristicsof\nthevulnerability,suchashowtotriggerthevulnerability(wordsin\nblue),whilethecommitmessagealsocontainssimilardescriptive\ntexts.Consideringallthesecorrelations,wecaneasilymarkitas\nthe security patch for CVE-2016-4417.\nObservation-3:Thecorrelationsbetweenavulnerabilityandacode\ncommit enable us to locate security patches that cannot be located by\nthe matching-based solutions. Since existing solutions introducedOff-by-one  error in epan/dissectors/packet-gsm_abis_oml.c  in the GSM A-bis \nOML dissector in Wireshark 1.12.x before 1.12.10 and 2.x before 2.0.2 allows \nremote attackers to cause a denial of service  (buffer over-read  and application \ncrash) via a crafted packet that  triggers a 0xff tag value .\n(a) NVD Description of CVE-2016-4417\ngsm_abis_oml : fix buffer overrun\nDo not read outside boundaries when tag is exactly 0xff .\n        tag = tvb_get_guint8(tvb, offset);\n        tdef = find_tlv_tag(tag);\n               ...\n               return &nm_att_tlvdef_base.def[tag];\n...\n 1  diff --git a/epan/dissectors/packet-gsm_abis_oml.c b/epan/dissectors/packet-gsm_abis_oml.c\n 2  index a6158c3..543b034 100644\n 3  --- a/ epan/dissectors/packet-gsm_abis_oml.c\n 4  +++ b/epan/dissectors/packet-gsm_abis_oml.c\n 5  @@ -618,7 +618,7 @@ struct tlv_def {\n 6   };\n 7   \n 8   struct tlv_definition {\n 9  -       struct tlv_def def[0xff];10 \n+       struct tlv_def def[0x100];\n11  };\n12   \n13  enum abis_nm_ipacc_test_no {\n(b) Patch Commit of CVE-2016-4417\nFigure1:Amotivatingexampletoillustratethecorrelations\nbetween a vulnerability and its patch commit.\nin §2 adopt a matching-based approach that only gives resultsonexactlymatching,theycannotlocatethepatchcommitinthe\nexample of Figure 1, which does not specify the CVE-ID and is not\nspecifiedinCVE/NVD.Incontrast,wecanlocateitbyexploiting\nthe correlations between the vulnerability and the code commit.New Approach.\nBased on the above observations, we propose a\nvulnerability-commitcorrelationranking approach,whichlocates\nsecurity patches by ranking all the code commits according\nto the correlation between one commit and the corresponding\nvulnerabilityinformation.Ourapproachworkslikeasearchengine,\nwhich finds and ranks all the pages (code commits) that are highly\ncorrelated to a given short description (vulnerability).\nCompared to matching-based solutions, our approach has the\nchance to locate patches for more vulnerabilities since it considers\nbroadcorrelationfeatures(evenweakones)betweenavulnerability\nandcodecommits.Besides,itusesalearning-baseddesigntoassigntheweightstothesecorrelationfeatures,soithasabettertolerance\nfor incomplete and incorrect vulnerability information. Further,\neven if our approach does not put the correct security patch at\nthe first position of the ranked results, users can verify the ranked\nresults one by one just as what they do with the search engine.\nTherefore, our approach can meet a better trade-off between the\ncoverage of the security patches and the manual efforts involved.\n3.2 Correlation Features\nOur approach takes the vulnerability information as input and\noutputs the ranked codecommits based on their correlations with\nthevulnerability.Toacquirethevulnerabilityinformation,werefer\ntotheCVE/NVDdatabases.SincetheNVDcoversmoreinformation\nthantheCVE,wemainlychoosetheNVDpageofavulnerability\nasinputtoextractcorrelatedvulnerabilityfeatures.Toformulate\nthe correlation features between the code commits and a given\nvulnerability, we first investigate what types of information an\nNVDpagecontainsandthencheckiftheseinformationmayalso\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3285Table 2: The features that are used by PatchScout to represent the correlations between a vulnerability and a code commit.\nFeature Group Features Description\nVulnerability IdentifierCVE-ID Whether the code commit mentions the CVE-ID of the target vulnerability.\nSoftware-specific Bug-ID Whether the code commit mentions the software-specific Bug-ID in the NVD Page.\nVulnerability LocationSame Function Num # of functions that appear in both code commit and NVD description.\nSame Function Ratio # of same functions/#o ffunctions that appear in the NVD description.\nUnrelated Function Num # of functions that appear in code commit but not mentioned in the NVD description.\nSame File Num # of files that appear in both code commit and NVD description.\nSame File Ratio # of same files/#o ffiles that appear in the NVD description.\nUnrelated File Num # of files that appear in code commit but not mentioned in the NVD description.\nVulnerability TypeVulnerability Type Relevance The relevance of the vulnerability type-related texts between NVD information and commit message.Patch Likelihood The probability of a commit to be a security patch.\nVulnerabilityDescriptive TextsShared-Vul-Msg-Word\n1Num # of shared words between NVD description and commit message.\nShared-Vul-Msg-Word Ratio # of Shared-Vul-Msg-Words/#o fw o r d si nNV Ddescription.\nMax of Shared-Vul-Msg-Word Frequency The max of the frequencies for all Shared-Vul-Msg-Words.Sum of Shared-Vul-Msg-Word Frequency The sum of the frequencies for all Shared-Vul-Msg-Words.\nAverage of Shared-Vul-Msg-Word Frequency The average of the frequencies for all Shared-Vul-Msg-Words.\nVariance of Shared-Vul-Msg-Word Frequency The variance of the frequencies for all Shared-Vul-Msg-Words.\nShared-Vul-Code-Word2Num # of shared words between NVD description and code diff.\nShared-Vul-Code-Word Ratio # of Shared-Vul-Code-Words/#o fw o r d si nNV Ddescription.Max of Shared-Vul-Code-Word Frequency The max of the frequencies for all Shared-Vul-Code-Words.Sum of Shared-Vul-Code-Word Frequency The sum of the frequencies for all Shared-Vul-Code-Words.\nAverage of Shared-Vul-Code-Word Frequency The average of the frequencies for all Shared-Vul-Code-Words.\nVariance of Shared-Vul-Code-Word Frequency The variance of the frequencies for all Shared-Vul-Code-Words.\n1Shared-Vul-Msg-Word: shared words between NVD description andcommit message .\n2Shared-Vul-Code-Word: shared words between NVD description andcode diff.\nbe described by developers in the patch commits. As presented\ninTable2,weconcludefourgroupsofcorrelationfeaturesthatmaybecommonlysharedbetweenthevulnerabilityinformationandthe\npatchcommits.Eachfeaturegroupdepictsthecorrelationsbetween\na commit and a vulnerability from one perspective. From the four\nfeature groups, we further formulate 22correlation features. We\nelaborate on these features below.\nVulnerabilityIdentifier. Weconsidertwotypesofvulnerability\nidentifiers — CVE-ID and software-specific Bug-ID. Mostly, dis-\nclosed vulnerabilities are publicly referred to by the CVE-ID. Inaddition, before being granted a CVE-ID, a vulnerability may be\nassignedwithasoftware-specificBug-IDwhichisusedinternally\nto track the life cycle of the vulnerability.\nVulnerability Location. The location of a vulnerability is\ndepictedusingthe fileorthefunctionthatincludesit.Werecognize\n6 features between the vulnerability and the code commit from\nthis perspective. At the file level, we divide the files modified by a\ncommitintotwocategories,namely,thosethatarementionedin\nthe vulnerability description and those that are unrelated to the\ndescription.Wecountthenumberofeachcategoryandcalculatethe\nratio of the files that are shared between the vulnerability and the\ncommit,whichcontributesto3features.Theother3function-level\nfeatures are calculated in a similar way.\nVulnerability Type. It indicates the type/impact of the vul-\nnerability, such as buffer-overflow, denial-of-service. We extract2 features between a vulnerability and a code commit. First, we\npropose vulnerability typerelevance that depicts the relevanceof\nthe vulnerability type-related texts between the NVD vulnerability\ninformationandthecommitmessage.Second,fromthecodediff\naspect,wecalculatepatchlikelihoodtorepresenttheprobabilityof\na commit to be a security patch.\nVulnerabilityDescriptiveTexts. Itconsidersthevulnerability\nfeaturesthatgenerallydescribesometypesofvulnerabilityinfor-\nmationsuchascriticalvariables,vulnerabilitytriggerconditions,\nand vulnerability causes. We use the shared words between thevulnerability information and code commits to represent their\ncorrelations.AsshowninTable2,wecalculate6statisticalfeatures\nfrom the shared words between vulnerability description and\ncommitmessage,andtheother6statisticalfeaturesfromtheshared\nwordsbetweenvulnerabilitydescriptionandcodediff.Aswewill\nelaborate later (see §4), some meaningless words (e.g., stop words)\nare removed before calculation.\n4 PATCHSCOUT DESIGN\nThissectionpresents PatchScout ,whichleveragestheproposed\nvulnerability-commitcorrelationranking tofacilitatethelocatingof\nsecuritypatchesfordisclosedOSSvulnerabilities.Wefirstintroduce\nthe workflow of PatchScout, and then elaborate its key modules.\nWorkflow. Given a target vulnerability, PatchScout takes the\nNVD database and the code repository as input and then ranks all\nthe commits in the repository according to their correlations with\nthe given vulnerability. There are mainly three phases:\n(1)Information Extraction. PatchScout extracts some basic in-\nformationelementsfrombothNVDpagesandcodecommits,\nwhich are used to generate features;\n(2)Feature Generation. PatchScout generates the correlation\nfeatures (that are introduced in §3.2) between a vulnerability\nand a code commit from the extracted information elements;\n(3)Commits Ranking. PatchScout trains a RankNet-basedmodel\nwith the generated correlation features, to rank all the code\ncommits based on their relevance to a specified vulnerability.\n4.1 Information Extraction\nAs shownin Table3, PatchScout extracts8 kindsof information\nelements from NVD pages and code commits (including commit\nmessage and commit code), which are further used in the phase of\nfeaturegeneration.Inparticular,weadoptpattern-matchingand\nnamed-entityrecognition(NER)[ 29]toextracttheseinformation\nelements from these sources. From NVD pages, we directly\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3286Table 3: The elements extracted from different sources.\nInformation\nSourceExtractedElementFeature Goup\n1\n(Used By)Extraction2\nMethod\nNVD Pagedescription VDT Extract\nvulnerability identifier VID Pattern\nfile location VL Pattern\nfunction location VL NER\nvulnerability type VT NER, Extract\nvulnerability impact VT NER\nCommit Messagemessage VDT Extract\nvulnerability identifier VID Pattern\nvulnerability type VT NER\nvulnerability impact VT NER\nCommit Codecode diff VDT, VT Extract\nfile location VL Pattern\nfunction location VL Pattern\n1VDT represents vulnerability descriptive texts ; VID represents vulnerability\nidentifier; VL represents vulnerability location ; VT represents vulnerability type.\n2Extract: this information can be directly extracted; Pattern: extract information\nvia pattern-matching; NER: extract information via named-entity recognition.\nextractthevulnerabilitydescription,CVE-ID,andvulnerabilitytype\n(CWE). Further, from the extracted vulnerability description, we\nfurtherextractfilelocationviapattern-matchingandleverageNER\ntoidentifyfunctionlocation,vulnerabilitytype,andvulnerability\nimpact. Besides, we also use pattern-matching to extract the\nsoftware-specific bug-ID from the reference URLs of an NVD page\nas the complementary vulnerability identifier. From the commit\nmessage,weextractvulnerabilityidentifierviapattern-matching\nandidentifyvulnerabilitytypeandvulnerabilityimpactviaNER.\nFrom the commit code, we can directly extract the code diff\nand the file location and function location can be extracted via\npattern-matching.\nDuringtheinformationextractionphase,wemainlyusepattern-\nmatching and NER, which are detailed below:\n•Pattern-matching. We summarize common patterns of some\ninformationelements(filelocation,functionlocation,software-\nspecific bug-ID) and use regular expressions to extract such\nelements.Forexample,wematchfilesuffix(e.g.,.c,.h,.cpp,etc.)to\nidentifyfilelocationinvulnerabilitydescriptionwiththeregular\nexpression: ([a-zA-Z0-9]|-|_|/)+\\.(cpp|cc|cxx|cp|CC|hpp|hh|C|c|h) .\n•Named-entityRecognition. Inordertoconstructatrainingset,we\ncollect 600 NVD descriptions and 164 patch commit messages\nandmanuallylabelthevulnerabilitytype,vulnerabilityimpact,\nand function location in these texts. Thereafter, we train an NER\nmodelonthisdatasetandapplythetrainedmodelin PatchScout\nto extract these elements.\n4.2 Feature Generation\nFrom the 8 kinds of information elements extracted between a\nvulnerabilityandacodecommit, PatchScout furthergenerates22\ncorrelation features (as listed in Table 2).\n4.2.1 Vulnerability Identifier & Vulnerability Location. Asdescribed\nin Table 2, the features in the vulnerability identifier group and\nvulnerability location group are easy to generate. For vulnerability\nidentifier group, we can directly determine whether a code commit\nandanNVD pagerefertothesameCVE-ID orthesamesoftware-\nspecific bug-ID based on the extracted elements of vulnerabilityidentifier. For vulnerability location group, based on the extracted\nelements of file/function location, we count the shared elements\nbetween a code commit and an NVD page and compute the 6\nvulnerability location features as their definitions in Table 2.\n4.2.2 Vulnerability Type Relevance. Foravulnerability,itstypeis\nusually mentioned in the vulnerability description and the CWE\ninformationofitsNVDpage,aswellasinthecommitmessageof\nits patch. Meanwhile, the impact of a vulnerability which is closely\nrelated to its vulnerability type, may also be mentioned in its NVD\npageandpatchcommit.Therefore,weusethetwokinds(i.e.,the\nvulnerability type and the vulnerability impact) of vulnerability\ntype-related texts in an NVD page and a code commit to predict\ntheirvulnerabilitytyperelevance.Thesefeatureshelp PatchScout\nto narrow down the search scope of patch commits.\nTaxonomyofTypeRelevance. Asintroducedin§4.1, PatchScout\nhas extracted vulnerability type-related entities (i.e., vulnerability\ntypeandimpact)fromNVDpagesandcommitmessages.However,\nlittle is known about what kind of relevance may exist between\nthese entities. To this end, we conduct a study to find it out.\nFirst, we randomly select 500 vulnerabilities that cover 47\nCWEs in our training set (see §6.1) and collect a set of 1,219\nvulnerability type-related entities from their NVD pages and\nsecurity patch commits. Second, we normalize each entity toa word bag. Specifically, the normalization process consists of\nsplittingtheextractedentitiesintowordsequences,removingthe\nstop words, stemming, lemmatizing, and substituting synonym on\nthe remaining words with the help of Natural Language Toolkit\n(NLTK) [48]. Third, we group the entities with the same word bag,\nwhich generates 31 entity groups. Note that there are 41 entities\nthat do not belong to any group. Finally, from the 31 entity groups\nand41entities,wemanuallysummarizethreekindsofrelevance\nthat may exist between every two entity:\n•Inclusionrelationship describestherelationshipbetweentwovul-\nnerabilitytypeentitiesortwovulnerabilityimpactentities.There\nare two situations: 1) the vulnerability type/impact described by\nthe two entities is the same or quite similar (e.g., buffer overflow\nandbufferoverrun);2)thevulnerabilitytype/impactdescribed\nby one entity is covered by the other entity (e.g., stack buffer\noverflow and buffer overflow).\n•Causality relationship depicts the relationship between a vulner-\nability type entity and a vulnerability impact entity, when the\nformer one may lead to the latter one. For example, there is a\ncausality relation between stack-overflow and denial-of-service.\n•Irrelevance relationship represents that there is no relation\nbetween the two entities.\nGenerating the Type Relevance Feature. Given thetaxonomy\nof type relevance, PatchScout generates the vulnerability type\nrelevance feature between a vulnerability and a code commit from\ntwo sets of vulnerability type-related entities (i.e., one is extracted\nfrom the NVD page and the other is extracted from the commitmessage) and represents this feature with a three-tuple which\nindicatestheproportionofeverykindofrelevancebetweenthetwosets.Therearethreestepsingeneratingthisfeature:1)ittransforms\nthetwosetsofentitiesintotwosetsofnormalizedwordbags(as\nwhatwedointheabovestudy);2)itenumerateseverywordbag\nin the two sets to identify the relevance between a word bag in\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3287one set and another word bag in the other set (the identification\nmethod is explained later); 3) based on the frequencies of every\nkind of relevance, it computes the proportion for each of them and\nencodes these proportions into a three-tuple. To be specific, we\nidentify the relevance between two entities (word bags) as follows:\n(1)We use set operation to test if there exists an inclusion relation\nbetween two word bags.\n(2)Sincemost(96.64%=1,178/1,219)ofthecollectedvulnerability\ntype-related entities in the previous study can be grouped into\n31 unique normalized word bags, it is affordable to manuallylabel the causality relationships between the 240 (16\n×15)\nword bag pairs. As shown in Table 13 (in §A.3), there are 16\nvulnerabilitytypegroups(e.g.,bufferoverflow,integeroverflow,\nuseafterfree)and15vulnerabilityimpactgroups(e.g.,denialofservice,segmentationfault),andwelabel150causalityrelations\nbetween them. Based on these labels, it is straightforward to\ntest if there exists a causality relation between two word bags.\nFor those unlabelled word bags (3.36%), we simply consider\nthere is no causality relation between them.\n(3)If there is no causality or inclusion relation between two word\nbags, they are considered to be irrelevant.\n4.2.3 Patch Likelihood. Code commits in an OSS project have\nvariouspurposes,suchasfixingperformancebugs,fixingvulner-\nabilities, functionality updates, code clean-up [ 35]. As presented\nin Table 2, we use the patch likelihood feature to represent the\nprobability of a code commit to be a security patch, which helps to\nput the patch commits in front of other commits.\nWithasimilarpurpose,Wang etal.[69]haveproposedalearning-\nbasedclassificationalgorithmtoidentifysecuritypatchesfromOSS\ncode commits. Their classification is based on the changed code\nlinesandprogramelements(e.g.,conditionalstatement,function\ncall, etc) in a commit. Inspired by this work, PatchScout also\nleveragesalearning-basedapproachtopredictthepatchlikelihood\nof a code commit. Our work differs from this one in two aspects.\nFirst,fromtheperspectiveoftheusedfeatures,weintroducetwo\nnew features (detailed in §A.1) and collect a set of 62 features\n(see Table 12 in §A.1) from a code commit for patch likelihood\nprediction.Second,differentfromexistingworks[ 69]whichaimto\nidentify only security patch commits, we want to predict the patch\nlikelihood for every commit.\nIn short, PatchScout predicts the patch likelihood of a code\ncommitinthreesteps.First,itgeneratesthetextfeatures(No.1-8\nin Table 12) from the texts in the code diff. Second, it performs\nan AST-based code diff analysis to identify the added/removed/up-\ndated/moved program elements and syntactic hunks, and thengenerates the syntactic features (No.9-62 in Table 12) from them.Finally, it trains 5 binary classification models [\n17,18,33,36,58]\nwith these features and gives a patch likelihood for every code\ncommit. To construct a training set, we use 943 security patch\ncommitsand943non-securitypatchcommitsthatareverifiedin\nour preliminary study (see §2).\n4.2.4 Vulnerability Descriptive Texts. The features in the group\nof vulnerability descriptive texts are used to capture the textualrelevance between vulnerability descriptions and code commits\nvia theirshared words. Specifically, we collect shared words fromtwo separated groups: one is between vulnerability descriptionandcommitmessage,andtheotheroneisbetweenvulnerability\ndescriptionandcommitcode.Thesharedwordsareidentifiedintwosteps.First,wesplitthedescriptivetextswithnon-lettercharacters\nand then remove the stop words (e.g., prepositions and articles).Second,wetaketheintersectionoftwowordsetstoidentifythe\nsharedwordsbetweenthem.Sinceawordmayappearseveraltimes\nin a text, we not only count the shared words but also count the\nfrequencyofeachsharedword.Basedonthesewords,wecalculate\n12 statistical features according to the definition in Table 2.\n4.3 Commits Ranking\nWith the generated 22 correlation features, PatchScout trains a\nmachinelearningmodeltorankthecodecommits.Tobespecific,we\nchoose to use RankNet [ 19], a pairwise learning-to-rank algorithm\nfor code commits ranking based on two observations. First, weobserve that code commit ranking is a classification problem onan extremely imbalanced dataset, where only few commits are\nsecuritypatches(akapositivecases)foragivenvulnerabilityand\ntherestofthecommitsareallnegativecases.Thoughclassifying\nimbalancedataisquitechallenging[ 34,49],RankNetisshownto\nbe a promising solution to tackle the class imbalance problem [ 26].\nSecond,RankNethasbeendemonstrateditseffectivenessinreal-\nworld ranking problems, such as Web page ranking [ 22], search\nengine personalization [63] and product recommendation [41].\nTechnically, RankNet trains a neural-network-based scoring\nmodel to give a score for every object (e.g., code commit), andthen ranks all the objects based on their scores. In particular, to\ntrainaRankNetmodel,weneedtoprepareasetofobjectpairs< 𝑥𝑖,\n𝑥𝑗> with labels (i.e., whether 𝑥𝑖or𝑥𝑗is a correct patch commit).\nThereafter, RankNet initializes a neural network with random\nparameters and trainsthe model based on thelabeled object pairs.\nIn all, the training process consists of the following steps:\n(1)Foreachfedobjectpair< 𝑥𝑖,𝑥𝑗>,wecalculatethe trueprobability\nthat𝑥𝑖ranks higher than 𝑥𝑗as:\n𝑃𝑖𝑗=⎧⎪⎪⎪ ⎨\n⎪⎪⎪⎩1 𝑖𝑓 𝑥\n𝑖𝑖𝑠 𝑝𝑎𝑡𝑐ℎ𝑎𝑛𝑑 𝑥 𝑗𝑖𝑠 𝑛𝑜𝑡\n0.5𝑏𝑜𝑡ℎ𝑥𝑖𝑎𝑛𝑑 𝑥𝑗𝑎𝑟𝑒(𝑛𝑜𝑛−)𝑝𝑎𝑡𝑐ℎ𝑒𝑠\n0 𝑖𝑓 𝑥𝑗𝑖𝑠 𝑝𝑎𝑡𝑐ℎ𝑎𝑛𝑑 𝑥 𝑖𝑖𝑠 𝑛𝑜𝑡\n(2)Byrepresentinganobjectasafeaturevector,theneuralnetwork\ngives a score for every object. With the given scores for an\nobjectpair< 𝑠𝑖,𝑠𝑗>(𝑠𝑖for𝑥𝑖,𝑠𝑗for𝑥𝑗),wecalculatethe learned\nprobability that𝑥𝑖should be ranked higher than 𝑥𝑗as:\n𝑃𝑖𝑗=1\n1+𝑒−(𝑠𝑖−𝑠𝑗)\n(3)With the true probability (𝑃𝑖𝑗) and the learned probability (𝑃𝑖𝑗),\na cross entropy cost function 𝐶is calculated as:\n𝐶=−𝑃𝑖𝑗𝑙𝑜𝑔𝑃𝑖𝑗−(1−𝑃𝑖𝑗)𝑙𝑜𝑔(1−𝑃𝑖𝑗)\n(4)Usingthiscostfunction,theneuralnetworkscoringmodelis\ntrained to minimize the cost in the training set.\n5 IMPLEMENTATION\nWeimplementaprototypeof PatchScout ,whichcontains2,243\nlines of Python code and 451 lines of Java code. Specifically, we\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3288leverage GitPython [ 4] to traverse code commits in OSS code\nrepositories, and build an NER model based on NeuroNER [ 29]\ntoextractvulnerabilitytype-relatedentitiesandfunctionentities\nfromNVDdescriptionandcommitmessages.Fortyperelevance\nanalysis, we use NLTK (a Python NLP toolkit) [ 48] to normalize\nentities. We use its nltk.tokenize module to split the entities into\nwordsequences,filterthestopwordsaccordingtothestopword\nlistin the nltk.corpus module,use its nltk.stem moduleto perform\nstemmingandlemmatizing,andleveragetheWordNetdatabase[ 67]\nin thenltk.corpus module to find the synonyms and perform\nsynonym substitution. For patch likelihood prediction, we use\nGumtree [ 31] to perform AST-based code diff analysis. For commit\nranking,weimplementtheRankNetalgorithm[ 19]onPyTorch[ 56].\nOur prototype is extensible to support vulnerabilities in various\nprogramminglanguages,sincemostofthefeaturesweselectare\nlanguage-independent. The major extension effort is to train a new\nNER-based parser and enhance the AST-based code diff analysis\nfor the new language.\n6 EVALUATION\nThissectionevaluates PatchScout inlocatingpatchesfordisclosed\nOSS vulnerabilities. It first introduces the experimental setup\nand then presents the evaluation results on the effectiveness of\nPatchScout ,thecontributionsoftheproposedfeatures,andthe\npossibilityofenhancing PatchScout bypredictingthebugfixfiles.\n6.1 Experimental Setup\nOur evaluation requires a number of OSS vulnerabilities including\ntheir security patches for the purpose of training and testing. In\nourpreliminarystudy(see§2),wehavecollectedalargenumber\nofOSSCVEsasavulnerabilitydataset.Therefore,ourevaluation\nalso uses this dataset.Model Training. PatchScout\nneeds labelled samples to train\nthe commit ranking model. Since we have manually verified\n2,200 potential patch commits (see experiment-2 of §2) in our\npreliminary study, we use the verified patch commits as positive\nsamples.Specifically,afterremovingtheduplicatepatchcommits,\nthepositivesamplesconsistof943uniquepatchcommitsaswell\nas943disclosedvulnerabilities.Foreachpositivesample( 𝑥𝑝𝑎𝑡𝑐ℎ),\nwe randomly select 5,000 other commits from the Git repository as\nnegativesamples,andthenconstruct5,000samplepairs< 𝑥𝑝𝑎𝑡𝑐ℎ,\n𝑥𝑜𝑡ℎ𝑒𝑟 𝑖>, where 𝑥𝑜𝑡ℎ𝑒𝑟 𝑖is a negative sample for 𝑥𝑝𝑎𝑡𝑐ℎ. Note that\nwhenarepositorycontainslessthan5,000commits,wetakeallthe\nothercommitsoftherepositoryasnegativesamplesinthatcase.In\nall,our trainingsethas 3,329,286samplepairs. Weuse anUbuntu\n16.04 64-bit machine (with 314 GB memory, 4 Intel Xeon Gold 5215\nprocessors,and1GeForceRTX2080TiGPU)formodeltraining.By\nfeeding the training set into a RankNet algorithm, it takes about 3\nhours to train the ranking model for PatchScout.\nTestingSet. We construct a testing set consisting of 685 disclosed\nvulnerabilities and their patch commits within two steps. First, we\nrandomly pick out 800 CVEs which do not overlap the training set.\nSecond, we try our best to locate their patches, by not only taking\nthethreeintuitiveapproachesmentionedin§2butalsochecking\nother resources, such as bug tracking reports and vulnerability-\nrelatedcodecommits.Atlast,wesuccessfullylocatethesecuritypatches for 685 CVEs (belonging to 187 OSS), and use them as the\ntestingset.Theremaining115CVEsareconsideredasunpatched\nandthusignoredinthetestingset.Inall,threesecurityresearchers\nparticipate in constructing the testing set and double-checking all\nthe security patches, which costs 240 man-hours.Baselines.\nTo the best of our knowledge, our work is the first one\nthat provides a systematic way to locate the security patches ofdisclosed OSS vulnerabilities. As described in §2, existing worksmainly adopt three intuitive methods for such a task. Therefore,\nwe include these intuitive methods as the baselines. To further\ndemonstratethebenefitsoftheranking-baseddesign,wealsodevise\nan enhanced keyword matching-based method as the baseline,namedM4. It works as follows. First, it uses the same method as\nPatchScout toextractvulnerabilityidentifiers,locations,andtypes\nfrom NVD pages. Second, to make a fair comparison, it uses the\ntechniquesin§4.2.2toextendsynonymsforextractedvulnerability\ntypes. Third, it uses the extended vulnerability types, identifiers,and locations as keywords to search the commits and ranks the\nmatchedcommitsbythenumberofkeywordstheyhit.Notethat\nfor commits with the same number of matched keywords, they\narerankedrandomlyandtheexperimentisrepeatedsixtimesto\nreduce the effect of randomness.Metrics.\nWe use the following two metrics to evaluate the effec-\ntiveness of PatchScout and baselines.\n•Recall.ForM1,M2andM3,ifapatchiscoveredbytheirreturn\nresults, we consider they successfully locate the patch. For\nPatchScout and M4, if a patch is in its top N (a parameter set\nby users) results, we consider the patch is successfully located\nand we name it as top-N recall.\n•Manual Efforts. For M1, M2 and M3, since they are matching-\nbased rather than ranking-based, all the matched commits have\nthe same priority to the users. Since all the matched commits\nneed to be manually verified, we use the number of matchedcommits to measure the involved manual efforts. When using\nPatchScout and M4, users check the ranked code commits one\nbyonetolookforapatchcommit.Therefore,weusethenumber\nof commits that need to be manually checked before finding\nthe patch commit to calculate the required manual efforts. In\nparticular, if the correct security patch for a CVE is ranked 𝑅-\nth byPatchScout and the users are asked to check the top N\ncommitsgivenby PatchScout tolocatethepatch,themanual\neffortsforlocatingthesecuritypatchofthisCVEis 𝑚𝑖𝑛(𝑅,𝑁).\nAccordingly,theaverageinvolvedmanualeffortsfor 𝑛CVEscan\nbe calculated as/summationtext.1𝑛\n𝑖=1𝑚𝑖𝑛(𝑅𝑖,𝑁)\n𝑛.\n6.2 Effectiveness\nTable 4 presents the overall results. We find that PatchScout\nranks the security patches of 69.49% CVEs at the first position.\nMoreover, by checking 4.32 commits on average over the top30 commits ranked by\nPatchScout , we can locate the security\npatches for 92.70% CVEs. Since locating the security patches by\nsearchingnumerouscodecommitsisextremelytime-consuming\nandlaborious,theinvolvedmanualefforthereisacceptablylow.Incontrast,evenwhencombiningallthethreebaselines(M1+M2+M3),\nonly47.59% patchescanbe locatedwith1.83 commitsonaverage\nto be checked. Interestingly, if users are asked to only check the\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3289Table 4: Performance of PatchScout and baselines on\nlocating security patches.\nApproaches Recall Manual Efforts\nM1: searching with CVE-ID 11.53% 2.30\nM2: checking commit-like URLs 40.00% 1.14\nM3: checking patch-tagged URLs 31.53% 1.61\nM1+M2+M3 47.59% 1.83\nM4: enhanced keyword matching (N=1) 40.88% 1.00M4: enhanced keyword matching (N=5) 61.80% 2.92M4: enhanced keyword matching (N=30) 80.10% 9.37PatchScout (N=1) 69.49% 1.00\nPatchScout (N=5) 85.40% 1.86\nPatchScout (N=30) 92.70% 4.32\ntop 5 commits given by PatchScout , they only need to check 1.86\ncommits per CVE (close to that of M1+M2+M3), while they can\nlocate 85.40% patches (37.81% more than M1+M2+M3). Though M4\nis enhanced with the keywords extracted by PatchScout , it can\nonlyrank40.88%patchesatthefirstposition.Evenwhenwecheck\nthe top 30 commits give by M4, we can only locate 80.10% patches\nbutpaymorethantwicemanualeffortsthan PatchScout .These\nresultsclearlydemonstratethestrengthof PatchScout onlocating\nsecurity patches for more vulnerabilities with less manual efforts.\nFalse Negatives Breakdown. ThoughPatchScout has covered\nthe patches for most of the disclosed vulnerabilities, it still fails on\n7.30%(50)CVEsinthetestingset,evenwhentheparameterNis\nset to 30. We manually check all the 50 false negatives (FN) and\ndiscoverthefollowing two causes.In §8,wefurtherdiscuss howto\nmitigate these FNs.\n•Low-quality vulnerability information in the NVD. Although\nPatchScout utilizes broad correlations between the vulnera-\nbility information and the code commits, it requires to extract\nmeaningfulinformation.However,insomeCVEs,wefoundtheir\nNVD pages only contain low-quality information that describes\nnospecificfeaturesofavulnerability.Inthesecases, PatchScout\ncannot extract useful features (those depicted in Table 2) from\nthe NVD, thus failing to rank their security patch commits in\nfront of other commits.\n•Giantcommits. Wefindthatdeveloperssometimesmergemul-\ntiple code updates for different purposes into a single (gi-ant) commit. If a giant commit contains a security patch, its\nvulnerability-irrelevant information and code behaviors weaken\nitsrelevancetothecorrespondingsecurityvulnerability.Itmakes\nPatchScout lower its ranking and eventually causes FNs.\nPatch Distribution at Each Rank. To measure the distribution\nofpatchesateachrank,wealsovarytheparameterNtotestthe\nperformanceof PatchScout .The resultsare presentedinTable 5.\nWe find that the more efforts users put in checking the ranked\ncommits,themoresecuritypatchestheycanlocate.Overall,77.66%patchcommitscanbelocatedbycheckingatmostthetop2commits\nranked by PatchScout , and more than 90% patch commits can be\nlocated by checking about 3 commits on average (3.04 commits per\nCVE when N = 15). These results clearly show that PatchScout\neffectively balances the coverage of the security patches and the\ninvolved manual efforts, by ranking the code commits that are the\nmost likely security patches to the front.Table 5: Performance of PatchScout with different N.\nTop NRecallManual Efforts Top NRecallManual Efforts\n1 69.49% 1.00 8 87.88% 2.27\n2 77.66% 1.31 9 88.47% 2.39\n3 82.48% 1.53 10 88.76% 2.51\n4 84.09% 1.70 15 90.36% 3.04\n5 85.40% 1.86 20 91.24% 3.50\n6 86.42% 2.01 25 91.82% 3.93\n7 87.30% 2.14 30 92.70% 4.32\nTable 6: Contribution of each feature group.\nTop N Drop Identifier Drop Location Drop Type Drop Texts\n1 45.40% (24.09% ↓) 58.54% (10.95% ↓) 62.48% (7.01% ↓) 61.90% (7.59% ↓)\n2 57.96% (19.70% ↓) 66.13% (11.53% ↓) 74.31% (3.35% ↓) 73.14% (4.52% ↓)\n3 63.94% (18.54% ↓) 69.49% (12.99% ↓) 78.54% (3.94% ↓) 77.23% (5.25% ↓)\n4 67.45% (16.64% ↓) 71.82% (12.27% ↓) 80.00% (4.09% ↓) 80.29% (3.80% ↓)\n5 70.07% (15.33% ↓) 72.99% (12.41% ↓) 81.90% (3.50% ↓) 82.34% (3.06% ↓)\n6 71.97% (14.45% ↓) 74.45% (11.97% ↓) 82.48% (3.94% ↓) 84.23% (2.19% ↓)\n7 73.28% (14.02% ↓) 75.77% (11.53% ↓) 83.07% (4.23% ↓) 84.96% (2.34% ↓)\n8 73.87% (14.01% ↓) 76.64% (11.24% ↓) 84.23% (3.65% ↓) 85.55% (2.33% ↓)\n9 75.18% (13.29% ↓) 77.37% (11.10% ↓) 85.26% (3.21% ↓) 85.99% (2.48% ↓)\n10 75.91% (12.85% ↓) 77.96% (10.80% ↓) 85.26% (3.50% ↓) 86.42% (2.34% ↓)\nThe percentage in parentheses represents the reduction in recall for this model\ncompared to the original model that takes all the feature groups.\n6.3 Feature Group Contributions\nAs presented in Table 2, PatchScout uses four correlative feature\ngroups to rank code commits. To measure the contribution of each\nfeaturegrouptotheoverallperformance,wetrainfournewrankingmodelsthatdroponefeaturegroupeach.Thefourweakenedmodels\nare trained and tested with the same dataset of PatchScout.\nAsTable6shows,the vulnerabilityidentifier contributesthemost.\nForexample,itincreasestherecallby24.09%whenN=1.Thisis\nbecause the vulnerability identifier is specific to a vulnerabilityand may reveal the most direct relation between a vulnerability\nand itspatch commit.Similarly, the featuregroup of vulnerability\nlocationalsocontributessignificantlytotheoverallperformance,\nsinceithelpstoexcludealargenumberofirrelevantcodecommits.\nBesides, we find that even weak correlations (e.g., vulnerability\ntype,vulnerabilitydescriptivetexts)betweenavulnerabilityand\na code commit play very important roles in locating the patch\ncommits.Theynotonlyhelptolocatethesecuritypatchesformore\nvulnerabilities, but also help to rank them to more front positions.\nInsummary,wefindeachfeaturegroupeffectivelyimprovesthe\nperformanceof PatchScout inhelpingtolocatethepatchcommits.\n6.4 PossibilityofLeveragingBugFixPrediction\nSecuritypatchisalsoatypeofbugfix.Existingworksonpredicting\nthe fix of a bug [ 37,42,44,46,81] might help to further reduce the\nsearch scope of security patches. We conduct several experiments\ntoexplorethispossibility.Ourexperimentsfocusontwoquestions:\nHow can an ideal bug fix predictor help PatchScout ?How\ndo the existing bug fix prediction techniques help?Leveraging an ideal bug fix predictor.\nWe first investigate\nwhetheranidealbugfixpredictorcanhelp PatchScout reducethe\nsearchscope.Inparticular,weusethepatchedfile(s)inasecurity\npatchasanidealbugfixpredictor.Forthe209CVEswhosepatches\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3290are not ranked as top-1 by PatchScout (§6.2), we analyze the non-\npatch commits that are ranked at a more front position than the\npatch commits. Under a conservative strategy, PatchScout can\nfilter out 49.80% non-patch commits that do not modify any file\npredictedbytheidealbugfixpredictor.Besides,if PatchScout only\nkeepsthecommitsthatmodifythesamefilespredictedbytheideal\nbugfixpredictor,79.57%non-patchcommitscanberemoved.By\nleveragingthepredictedpatchedfilesasthe vulnerabilitylocation\ninformation during the training and testing of PatchScout , its\ntop-1 and top-5 recall increases by 8.03% and 5.84% respectively. In\nsummary, we find an ideal bug fix predictor can largely reduce the\nsearch scope of security patches.Leveraging existing works in bug fix prediction.\nWe then\nleverage two existing bug fix prediction techniques, IR-based\nbug localization [ 37,42,46,81] and usual suspect [ 42,53], to\nimprovePatchScout .First,theIR-basedbuglocalizationstudies\nhow to predict the files to be fixed from a bug report. In particular,\nwe use BugLocator3[81] (an information retrieval-based bug\nlocalization tool) to analyze the bug report of a vulnerability,\nand we use the predicted to-be-fixed files as a supplement to thevulnerability location information extracted from the NVD page.\nIn our testing set,\nBugLocator successfully predicts a patch file\nin its top-5 ranked results for 347 CVEs (50.66%), and for 409CVEs (59.71%) in its top-10 ranked results. However, we find thetop-1 recall of\nPatchScout drops 2.92% when using the top-5\nprediction results of BugLocator and drops more (4.23%) when\nusingthetop-10predictionresultsof BugLocator .Themainreason\nis that BugLocator cannot accurately predict the patch files for\na vulnerability. The wrongly predicted patch files decrease the\ncorrelationsimilaritywiththetruepatchcommits,buttheymay\nincrease the correlation similarity with the non-patch commits.\nNote the recent efforts [ 37,46] apply deep learning to improve the\nperformanceofbuglocalization,successfullypredictingapatchfileinitstop-10rankedresultsformorethan80%bugs.Sincethesetools\nare not available, we cannot directly evaluate them. Meanwhile,\nwe believe PatchScout can hardly benefit from them either, since\ntheir accuracy is still not high.\nSecond, according to the observation of [ 42,53], most bug fixes\nare applied on a small fraction of components, which means thefiles that have been fixed before may have a higher chance to be\nfixedfurther.Toverifywhethersuchusualsuspectcanhelpfilter\nnon-patchcommits,weperformanexperiment.First,weselect3\nOSSprojects(LinuxKernel, Wireshark,and tcpdump)thathavemore\nthan 100 CVEs in the OSS vulnerability dataset collected in §2 and\nmanually locate the patch files for these CVEs. Second, we collect\nthe top-10 most frequently fixed files for each project and use\nthesefilesasasupplementtothe vulnerabilitylocation information\nextracted from the NVD page. Then, we use PatchScout to locate\nthesecurity patchesforthe112 CVEsofthe 3OSSprojectsin our\ntestingset.Theresultsshowthatthetop-1recallof PatchScout\ndrops 10.71%. Again, we find the reason is that the usual suspect of\nvulnerablecomponentsisnotaccurateenoughtohelplocatethe\npatch for a specific vulnerability.\n3ThesourcecodeofBugLocatorisavailableathttps://github.com/exatoa/Bench4BL.\nBesides, we enhance it to support C/C++ projects by introducing a new code parser.Takeaway. Based on the above experiments, we find that an ideal\nbug fix predictor greatly helps PatchScout and the accuracy of\nbugfixpredictiontechniquessignificantlyaffecttheireffectiveness\nin improving PatchScout . These findings motivate more accurate\nbug fix prediction techniques.\n7 PATCH DEPLOYMENT ACROSS BRANCHES\nWenowillustratethesecuritybenefitsof PatchScout viaconduct-\ning a study on the patch deployment practice across branches.\n7.1 Study Design\nThedevelopmentofOSSisusuallymanagedwithinbranchesand\neachbranchcorrespondstoaspecificversion.Whenavulnerabilityisreported,asecuritypatchisdevelopedonitsmasterbranch.Since\nsome old versions may be also affected and still-in-use, developers\nshould deploy the security patch to these branches/versions too,\nthough introducing some maintenance overhead at the same time.\nHowever, to the best of our knowledge, little is known about such\npatch deployment practice across branches in the real world.\nByrankingasetofcodecommitsaccordingtotheirrelevanceto\na vulnerability, PatchScout also helps to locate the security patch\nofagivenvulnerabilityunderaspecificbranch.Therefore,weapply\nPatchScout to perform the first study on patch deployment prac-\nticeacrossdifferentbranches.Specifically,ourstudyisorganized\nfrom three aspects: patch deployment status ,patch backporting , and\npatchdeploymentlag.Aswewillshowlater,thisstudyishardto\nbe conducted without the help of PatchScout.CVEsandBranches.\nTostudypatchdeploymentpracticeonmulti-\nbranches,wemainlyconsiderpopularOSSprojects. Inparticular,\nweselectfourpopularC/C++OSS(LinuxKernel[ 6],Wireshark[ 11],\nQEMU [7], and FFmpeg [ 3]) and one Java OSS (Jenkins [ 5]) as our\nstudy targets. To construct a set of CVE-branch pairs, for eachOSS, we randomly select 45 CVEs that were reported after 2016\nandcollectbranchesintheirGitrepositoriesthathavenewcode\ncommitsafter 2016.Inall,our studyconsistsof 3,735CVE-branch\npairs (225 CVEs and 83 branches). Note that we only consider\nstable/releasebranchesinthestudy.Thedetailedinformationabout\nthese branches and CVEs is listed in Table 14 (in §A.3).Patch Collection.\nFor each CVE-branch pair, PatchScout is\napplied to help locate the patch commit for the specific CVEand branch. We also extend\nPatchScout to support Java OSS\nvulnerabilities according to the instructions in §5. Based on the\nranked code commits by PatchScout , we manually check the top\n30 candidates to locate the security patch. In all, we successfully\nlocate the security patches for 1,985 CVE-branch pairs with 33\nman-hours. The results are shown in Table 7.\nWefurtherinvestigateeachCVE-branchpairthathasnosecurity\npatch located by PatchScout . There are mainly four situations: 1)\nthe branch is not affected by the vulnerability4(184not-affected\ncases); 2) the branch has already been out-of-maintenance5before\nthe vulnerability is disclosed (1,206 not-maintained cases); 3) the\nbranch is affected and maintained but has not applied the patch\n(150not-patched cases);4)thebranchispatchedbut PatchScout\nfails to locate their patch commits (210 cases). For these 210 cases,\n4We manually confirm the branch is not affected by the vulnerability.\n5We find the branch has no code commits after the vulnerability disclosed date.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3291Table 7: Patch deployment status on different branches.\nSoftware#o f\nCVEs#o f\nBranches#o f\nCVE-Branches# of patched\nCVE-Branches# (%) of patches identified\nby PatchScout# (%) of patches identified\nwith M1+M2+M3\nLinux Kernel 45 30 1,350 709 671 (94.64%) 439 (61.92%)\nWireshark 45 8 360 232 214 (92.24%) 59 (25.43%)\nQEMU 45 14 630 353 342 (96.88%) 264 (74.79%)\nFFmpeg 45 12 540 388 362 (93.30%) 206 (53.09%)\nJenkins 45 19 855 513 396 (77.19%) 119 (23.20%)\nTotal 225 83 3,735 2,195 1,985 (90.43%) 1,087 (49.52%)\nTable 8: Not-patched CVEs and branches for each OSS.\nSoftware# of not-patched\nCVE-branches# (%) of CVEs with\nnot-patched branches# (%) of branches with\nnot-patched CVEs\nLinux Kernel 38 (2.81%) 20 (44.44%) 18 (60.00%)\nWireshark 16 (4.44%) 10 (22.22%) 8 (100%)\nQEMU 33 (5.24%) 28 (62.22%) 7 (50.00%)\nFFmpeg 50 (9.26%) 19 (42.22%) 7 (58.33%)\nJenkins 13 (1.52%) 13 (28.89%) 3 (15.79%)\nTotal 150 (4.02%) 90 (40.00%) 43 (51.81%)\nwemanuallylocatethepatchcommitsfromtheGitrepositorywith\n21man-hours.Atlast,wecollectthesecuritypatchesfor2,195CVE-\nbranchpairs.Note PatchScout helpslocate90.43%patchcommits,\nandonly49.52%(1,087)patchcommitscanbelocatedbycombining\nthe three baseline methods introduced in §6. Also, 1,985 patches\nare located with the help of PatchScout in 33 hours (1 minute per\npatch),andthelocatingoftheother210patchescosts21hours(6\nminutesperpatch)when PatchScout cannothelp.Itdemonstrates\nthe importance of PatchScout in facilitating such studies.\n7.2 Patch Deployment Status\nNot-patchedCVEsandBranches. Asmentionedabove,thereare\n150CVE-branchpairsthataremaintainedbutnot-patched.Such\nsituationsareverydangerousbecausethesebranchesarestillunder\nmaintenance (which means they may still have users in-use) but\nforgettoapplysomesecuritypatches.Wefurtherbreakdownthese\nnot-patchedpairsinTable8.Surprisingly,wefindsuchnot-patched\nsituations are quite popular from the perspective of both CVE\nentriesandbranches.Forexample,thereare90(40.00%)CVEentries\nhavingatleastonenot-patchedbranchand43(51.81%)branches\nhaving at least one not-patched CVE. This finding shows that a\ngreat many branches are ignored during the patch deployment\nprocess, which brings great risks to the end-users.\nIt is well-believed that vulnerabilities with higher risks will\nbe more seriously treated by OSS developers/maintainers. To\nverify this assumption, we explore the correlation between the\nnot-patched ratio of each CVE with its CVSS score (as presented\ninFigure4in§A.3).Wearesurprisedtofindthat30(33.33%)not-\npatchedCVEsbelongtohigh-riskvulnerabilities(CVSSscore>=\n7.0), and the distribution of not-patched ratio is independent of\nthe CVSS score of each CVE. The not-patched ratio of the severest\nCVEisnotsignificantlylowerthanthoseofothervulnerabilities.Itimpliesthatthemaintainersmaynottakethevulnerabilityseverity\ninto consideration when propagating patches across branches.\nAffected Versions in CVE/NVD. Muetal.[51],Dongetal.[30]\nand Daiet al.[28] find that the information about the affected\nversionsinCVE/NVDmaybeincomplete.Sincethepatchpresence\ninformation of a branch (version) indicates if it is affected, we canTable 9: Miss-reported affected versions in CVE/NVD.\nSoftware# of CVE-branches with\naffected versions# of CVEs with\naffected versions\nLinux Kernel 73/1,350 (5.41%) 15/45 (33.33%)Wireshark 0/360 (0.00%) 0/45 (0.00%)QEMU 3/630 (0.48%) 3/45 (6.67%)FFmpeg 76/540 (14.07%) 20/45 (44.44%)Jenkins 0/855 (0.00%) 0/45 (0.00%)\nTotal 152/3,735 (4.07%) 38/225 (16.89%)\nusethisinformationtocheckthecorrectnessoftheaffectedversions\nof a vulnerability in CVE/NVD. To be more specific, if the security\npatchisfoundatabranch(version)andthebranchexistsbeforethe\nvulnerability report date, this branch is thought to be affected. We\nusethe2,195CVE-branchpairswithidentifiedpatchestomanually\ncheck the affected versions in CVE/NVD.\nIn all, we find 152 affected versions for 38 CVEs are missed\n(detailedinTable9).Wereportallthesemissedaffectedversions\ntotheCVEcommunity,whichhasconfirmedallourfindingsand\nhasupdatedthedescriptionsabouttheaffectedversionsforthese\n38 CVEs. Though PatchScout is not designed for such a task (i.e.,\nfindingmiss-reportedaffectedversions),thisexperimentrenders\nits benefits to the community from another angle.\n7.3 Patch Backporting\nSecurity patches are usually developed on a certain branch and\nthen deployed to other affected branches. During the cross-branch\npatch deployment, developers may need to adjust the originalpatch according to the code of the target branch. We investigateall the patches that are located in §7.1 to measure the effortsin cross-branch patch deployment. Specifically, from the 2,195CVE-branches with identified patches, we find 734 unique patch\ncommit IDs.On average, 3.26 uniquepatches aredeveloped tofix a\nvulnerability on different branches.\nEfforts in Patch Backporting. For each CVE, we recognize its\nfirst-developed patch as the original patch and treat others as\nbackportedones.Basedonthedifferencebetweentheoriginalpatch\nandabackportedpatch,weclassifythreetypesofeffortsthatare\nrequired in backporting patches. The first type is to directly apply\ntheoriginalpatchwithoutanychange.Thesecondtypeneedsto\nadjust the line number of the original patch according to the target\nbranch, but the code diff is not changed. The third type needs code\nadaptionandcustomization,sincethecodediffofthebackported\npatch is different from the original one.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3292Table 10: Percentage of different backported patches.\nSoftware Type-11Type-22Type-33\nLinux Kernel 61 (27.85%) 144 (65.75%) 14 (6.39%)\nWireshark 26 (28.89%) 53 (58.89%) 11 (12.22%)\nQEMU 12 (41.38%) 16 (55.17%) 1 (3.45%)FFmpeg 63 (36.84%) 101 (59.06%) 7 (4.09%)\nJenkins\n4N/A N/A N/A\nTotal 162 (31.83%) 314 (61.69%) 33 (6.48%)\n1. Direct deployment. 2. Line NO. adjustment. 3. Code adaption.\n4. Jenkins has no backported patches among different branches.\nAsshowninTable10,developerscandirectlyapplythepatch\nfor 31.83% branches and need to adjust the code line number for\n61.69% cases. For the remaining 6.48% cases, developers have to\ncustomize the patch code to fit the target branch.\nDifficulties in Code Adaption. Tounderstandthedifficultiesin\nadapting the patch code, we analyze all the 33 patches that need\ncode adaption in Table 10.\n•Updatingcodeirrelevantelements(11cases). Thecodedifference\nbetweenanoriginalpatchandthebackportedoneiscausedby\ncode irrelevant elements, such as comments and indentation.\n•Merging multiple commits (3 cases). When developers merge the\noriginal security patch and other code updates into a single\ncommit and deploy it on a branch, the resulting backportedcommit is different from the original security patch in code\nbehaviors.Thoughthemergedcommithasdifferentcodefrom\nthe original patch commit, the major technical difficulties of this\ntype of code adaption lie in merging several code commits.\n•Fitting different code context (19 cases). We also find that the\ncontext of the pre-patched code may differ on different branches.\nAsaresult,developershavetounderstandthevulnerabilitylogic\nand put more efforts into adapting the original patch to a new\ncode context on the target branch.\nIn conclusion, our study makes the first attempt to shed some\nlightontheeffortsanddifficultiesinpatchbackportingwithreal-\nworldOSSprojectsandCVEs.Ourstudyclassifies differenttypes\nofpatchbackportingsituationsandrecognizesdifferentlevelsof\ncodeadaption,whichcouldfacilitatesomefollow-upresearch,such\nas assisting patch backporting and identifying backported patches.\n7.4 Patch Deployment Lag\nIn addition to the difference among patch commits on different\nbranches, their patch deployment time also varies significantly.\nVulnerability Disclosure Time vs. First Patch Time. First, we\ncollect the time when the first patch was applied and compare it\nwith the vulnerability disclosure time (as presented in Figure 2)\n. Specifically, the average time lag is -24.21 days, which means\ndevelopersusuallyrespondtothereportedvulnerabilitiesintime.\nFurthermore, there are 65 CVEs whose first patch is deployed after\nthevulnerabilitydisclosureand24CVEsarefixedevenafterone\nmonth. These delays in vulnerability fixing lengthen the attack\nwindow of those vulnerabilities.\nFirst Patch Time vs. Last Patch Time. We also collect the\npropagation time of a patch from the earliest branch to the lastbranch and present the results in Table 11 (in §A.3). On average,\nit takes 71.76 days to propagate the first patch to other branches.\nNum ber of CVEs\n0255075100\n(earlier, -366] [-365, -183] [-182, -31][-30, -1] [0, 30][31, later)244199\n53\n62\nLagging time distribution(day)\nFigure 2: Lag between the time when the CVE is disclosed\nand the time of the first patch.\nBesides, the median of the propagation time is 26 days and thelongest propagation time is 702 days. The patch delay across\nbranches prolongs the risks of these vulnerabilities over end-users.\n7.5 Takeaway\nOurstudydemonstratesthatalargefractionofaffectedbranches\nare stillunpatched and otherbranches, whilepatched, suffer from\na quite long patch lag. We propose some suggestions to improve\nthe patch deployment process across branches.\nVerifying affected versions of a vulnerability. Our study finds\nthat CVE/NVD misses many affected versions, which may ulti-mately mislead the developers to forget deploying patches onthose branches. Correct information about the affected versions\nwouldhelpdeveloperstolocatethecandidatebranchesforpatch\ndeployment. Therefore, how to verify the affected versions for a\nvulnerability becomes an important problem. To this end, code\nclone detection [ 38,43,47] and directed fuzzing [ 16,23] may be\nused here to locate the potential affected branches.\nManaging patch deployment progress. We suppose that software\ndevelopers/maintainers might intentionally prioritize the patchdeployment process due to constrained resources. However, we\nfind no obvious clue for such assumption in our study. This means\nthe current patch deployment practice among multiple branches is\nlackofmanagement.Therefore,itcallsforautomatictoolstocheckthepatchdeploymentstatusacrossbranches,sothedeveloperspay\nmore attention to deploy patches to all affected branches in time.\nEasing patch backporting. As discussed in §7.3, the original\npatch sometimes requires some extra efforts (either line number\nadjustmentorcodeadaption)todeployonotherbranches,which\nincreases the cost of patch propagating. It indicates that someautomatic techniques are needed to ease the process of patchbackporting, e.g., adjusting the line number when deploying\npatches, testing the applicability of a security patch to a branch.\n8 DISCUSSION\nIdentifyinggenericpatchesandthenlinkingbacktospecific\nvulnerabilities. SPIDER [ 50] and [69] aim to identify generic\npatches. However, we may face coverage issues when directlyadopting them, since the recall of [\n69] is 79.6% and SPIDER only\nidentifies55.37%CVEpatchesassafe-patches.Instead, PatchScout\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3293enhances [ 69] to measure the patch likelihood of each commit and\nuses it as a feature to improve patch locating and ranking.\nCollectingvulnerabilityinformationfrommoresources. As\nshowninourevaluation,sometimesthequalityofthevulnerability\ninformation in NVD is low, which limits the effectiveness of\nPatchScout in locating security patches. We report our initial\nresults in extracting more information from bug reports in §A.2. In\nthe future, we plan to collect information from more vulnerability\ndatabases, such as SecurityTracker [9], SecurityFocus [8].Deeplyanalyzingthecommitcode.\nThecodeinapatchcommit\ncontains much useful information to understand the vulnerability.\nHowever, we only use the AST of the code diff to predict itspatch likelihood. In fact, more vulnerability-related informationcan be extracted from the code commit by deeply analyzing its\ncode. For example, we can leverage static analysis [ 65] or symbolic\nexecution [ 21,59] techniques to analyze whether the commit\nintroduces a boundary check on an array, which is highly relevant\nto fixing a buffer overflow vulnerability.Locatingpatchcommitsforotherkindsofbugs.\nInadditionto\nlocatingsecuritypatches,ourgeneralideaofrankingcodecommits\ncan be also applied to locating the patch commits for other bugtypes (e.g., performance bugs, functional bugs). For example, by\nanalyzingsomeperformancebugsreportedbyJin etal.[40],wealso\nfindbroadcorrelations(e.g.,bugidentifier,buglocation,descriptive\ntexts) between the performance bugs and their patches. In the\nfuture, we will explore the possibility of bug-commit correlation\nrankingto locate patch commits for other kinds of bugs.\nLocating vulnerability-introducing commits. There may be\ntwo kinds of commits related to a vulnerability in the code\nrepository: a vulnerability-introducing commit which introduces\na vulnerability and a patch commit which fixes a vulnerability.\nIntuitively, both kinds of commits may be located by PatchScout .\nInfact,wedonotfindavulnerability-introducingcommitduring\nourevaluationandstudy.Thisisbecausedifferentfromthepatch\ncommits, the correlations between the vulnerability-introducing\ncommits and the vulnerabilities are indirect and implicit.\n9 RELATED WORK\nBug Fix Prediction. Predicating the fix of a bug is a popular\nresearch topic in the field of mining software repositories (MSR).\nAnviket al.[14] propose a learning-based approach to predict the\ndevelopersthatshouldfixabug.Information-retrieval-basedbug\nlocalization techniques [ 12,37,42,44,46,61,68,71,76,78,81]\nsuggestthecodecomponents(e.g.,files,functions)thatarelikely\nto be fixed for a bug by mining bug reports and source code. While\nthese works intend to ease the patch development by predictingsome properties of a patch,\nPatchScout focuses on easing the\nlocating of patch commits in the code repository. Furthermore, as\ndemonstrated in our evaluation, locating security patches requires\nmore accurate correlating than predicting bug fix. To provide\neffectivepatchlocating, PatchScout considersbroadcorrelation\nfeatures and incorporates a learning-based rank system.Security Patch Identification.\nExisting works also make some\nattemptstocollectsecuritypatches.Xu etal.[75]proposeapattern\nmatching-basedapproachtoidentifysecuritypatchesinbinaries.\nTianetal.[66]andWang etal.[69]leveragemachinelearningtoidentify security patches at the source code level. Specifically, Tian\netal.[66]extractfeaturesfrombothcommitmessagesandcodediffs,\nwhile Wang et al.[69] focus on mining more code diff features for\npatchidentification.Further,SPIDER[ 50]introducestheconcept\nofsafe patch for security patch identification. All these works\nidentify the security patches but cannot associate them with the\nvulnerabilities they fix. Different from these works, PatchScout\nsupports locating the security patches of a specified vulnerability.\nSecurity Patch Study. Since security patches are widely used,\nthey have become an important target to study. Rescorla et al.[60]\nanalyze OpenSSLsecurity patches tounderstand users’responses\nto vulnerabilities. Yin et al.[77] perform a study on incorrect\npatches to categorize incorrect patch patterns and understand the\ncausesbehindthem.Zhong etal.[80]andSoto etal.[64]studya\nlarge-scale of patches to guide automatic bug repair. Further, Li et\nal.[45] conduct a comprehensive study on the development life\ncycleofsecuritypatches.Dai etal.[27]performastudyonpatch\ndeployment practice on downstream binaries with the support of a\npatchpresencetestingtool.However,asfarasweknow,thereis\nnostudyaboutthepracticeofpatchdeploymentacrossdifferent\nbranches. With the help of PatchScout , this paper could perform\nthe first study on patch deployment practice across branches.\n10 CONCLUSION\nThis paper presents PatchScout , a software tool to help locate\nthe security patches for disclosed OSS vulnerabilities in their\ncode repositories. The key idea of PatchScout is to transform\nthe search problem of locating security patches into a ranking\nproblem on code commits. To rank patch commits in front of other\ncommits, PatchScout proposes a vulnerability-commit correlation\nrankingmechanism,whichexploitsthebroadcorrelationsbetween\na vulnerability and a code commit. The ranking-based designenables\nPatchScout to locate more security patches and meet a\nbalancebetweenthepatchcoverageandthemanualeffortsinvolved.Our evaluation on 685 OSS vulnerabilities shows that\nPatchScout\nsignificantly outperforms all existing methods in both patchcoverage and manual workload. With the help of\nPatchScout ,\nthispaperperformsthefirststudyonpatchdeploymentpractice\nacrossbrancheswith5popularOSSprojectsand225CVEs,drawing\nmany interesting findings and new research directions.\nACKNOWLEDGEMENT\nWewouldliketothanktheanonymousreviewersfortheirinsightful\ncomments.ThisworkwassupportedinpartbytheNationalNatural\nScience Foundation of China (U1836213, U1836210, U1736208,61972099, 62172105), Natural Science Foundation of Shanghai\n(19ZR1404800).YuanZhangwassupportedinpartbytheShanghai\nRising-Star Program under Grant 21QA1400700. Kun Sun wassupported by U.S. ARMY under Grant W56KGU-20-C-0008. Min\nYang is the corresponding author, and a faculty of Shanghai\nInstituteofIntelligentElectronics&Systems,ShanghaiInstitutefor\nAdvancedCommunicationandDataScience,andEngineeringRe-\nsearch Center of CyberSecurity Auditing and Monitoring, Ministry\nof Education, China.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3294REFERENCES\n[1]2019. Whatarethemostsecureprogramminglanguages? https://www.whites\nourcesoftware.com/most-secure-programming-languages/.\n[2]2020. Opensourcevulnerabilitymanagementreport. https://www.whitesources\noftware.com/open-source-vulnerability-management-report/.\n[3] 2021. FFmpeg. https://git.ffmpeg.org/ffmpeg.\n[4] 2021. GitPython. https://github.com/gitpython-developers/GitPython.[5] 2021. Jenkins. https://github.com/jenkinsci/jenkins.[6]\n2021. Linux Kernel. https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux\n.git.\n[7] 2021. QEMU. https://git.qemu.org/git/qemu.git.[8] 2021. Security Focus. https://www.securityfocus.com/.[9] 2021. Security Tracker. https://securitytracker.com/.\n[10]\n2021. Vulnerable code database Project. https://github.com/google/vulncode-db.\n[11] 2021. Wireshark. https://gitlab.com/wireshark/wireshark.[12]\nShayanA.Akbarand AvinashC.Kak.2019. SCOR:SourceCodeRetrievalwith\nSemanticsandOrder.In Proceedingsofthe16thInternationalConferenceonMining\nSoftware Repositories (MSR).\n[13]GautamAltekar,IlyaBagrak,PaulBurstein,andAndrewSchultz.[n.d.]. OPUS:\nOnline Patches and Updates for Security. In Proceedings of the 14th USENIX\nSecurity Symposium (USENIX Security).\n[14]JohnAnvik,LyndonHiew,andGailC.Murphy.2006. WhoShouldFixThisBug?.\nInProceedingsofthe28thInternationalConferenceonSoftwareEngineering(ICSE) .\n[15]Jeff Arnold and M. Frans Kaashoek. 2009. Ksplice: Automatic Rebootless Kernel\nUpdates.In Proceedingsofthe4thACMEuropeanConferenceonComputerSystems\n(EuroSys).\n[16]MarcelBöhme,Van-ThuanPham,Manh-DungNguyen,andAbhikRoychoudhury.\n[n.d.]. Directed Greybox Fuzzing. In Proceedings of the 24th ACM SIGSAC\nConference on Computer and Communications Security (CCS).\n[17]Léon Bottou. [n.d.]. Large-scale Machine Learning with Stochastic Gradient\nDescent. In Proceedings of the 19th International Conference on Computational\nStatistics (COMPSTAT).\n[18] Leo Breiman. [n.d.]. Bagging predictors. Machine learning ([n.d.]).\n[19]ChrisBurges,TalShaked,ErinRenshaw,AriLazier,MattDeeds,NicoleHamilton,\nand Greg Hullender. 2005. Learning to Rank Using Gradient Descent. In\nProceedings of the 22nd International Conference on Machine Learning (ICML).\n[20]ChristopherJCBurges.2010. FromRankNettoLambdaRanktoLambdaMart:An\nOverview. Learning (2010).\n[21]Cristian Cadar, Daniel Dunbar, and Dawson Engler. 2008. KLEE: Unassisted and\nAutomatic Generation of High-Coverage Tests for Complex Systems Programs.\nInProceedings of the 8th USENIX Conference on Operating Systems Design and\nImplementation (OSDI).\n[22]Olivier Chapelle and Yi Chang. [n.d.]. Yahoo! Learning to Rank Challenge\nOverview. In Proceedings of the Learning to Rank Challenge.\n[23]HongxuChen,YinxingXue,YuekangLi,BihuanChen,XiaofeiXie,XiuhengWu,\nand Yang Liu. 2018. Hawkeye: Towards a Desired Directed Grey-Box Fuzzer. In\nProceedingsofthe25thACMSIGSACConferenceonComputerandCommunications\nSecurity (CCS).\n[24]YueChen,YulongZhang,ZhiWang,LiangzhaoXia,ChenfuBao,andTaoWei.\n2017. Adaptive Android Kernel Live Patching. In Proceedings of the 26th USENIX\nSecurity Symposium (USENIX Security).\n[25]MITRE Corporation. 2021. Common Vulnerabilities and Exposures. https:\n//cve.mitre.org/.\n[26]RicardoCruz,KelwinFernandes,JaimeSCardoso,andJoaquimFPintoCosta.\n[n.d.]. Tackling Class Imbalance with Ranking. In Proceedings of the 2016\nInternational Joint Conference on Neural Networks (IJCNN).\n[27]JiarunDai,YuanZhang,ZheyueJiang,YingtianZhou,JunyanChen,XinyuXing,\nXiaohan Zhang, Xin Tan, Min Yang, and Zhemin Yang. [n.d.]. BScout: Direct\nWholePatchPresenceTestforJavaExecutables.In Proceedingsofthe29thUSENIX\nSecurity Symposium (USENIX Security).\n[28]JiarunDai,YuanZhang,HailongXu,HaimingLyu,ZichengWu,XinyuXing,and\nMinYang.2021. FacilitatingVulnerabilityAssessmentthroughPoCMigration.In\nProceedingsofthe28thACMSIGSACConferenceonComputerandCommunications\nSecurity (CCS).\n[29]Franck Dernoncourt, Ji Young Lee, and Peter Szolovits. [n.d.]. NeuroNER: an\nEasy-to-use Program for Named-entity Recognition based on Neural Networks.\nInProceedings of the 2017 Conference on Empirical Methods in Natural Language\nProcessing: System Demonstrations (EMNLP).\n[30]YingDong,WenboGuo,YueqiChen,XinyuXing,YuqingZhang,andGangWang.\n2019. Towards the Detection of Inconsistencies in Public Security Vulnerability\nReports.In Proceedingsofthe28thUSENIXSecuritySymposium(USENIXSecurity).\n[31]Jean-Rémy Falleri, Floréal Morandat, Xavier Blanc, Matias Martinez, and Martin\nMonperrus. [n.d.]. Fine-grained and Accurate Source Code Differencing. In\nProceedings of the 29th ACM/IEEE international conference on Automated software\nengineering (ASE).\n[32]Qian Feng, Rundong Zhou, Yanhui Zhao, Jia Ma, Yifei Wang, Na Yu, Xudong Jin,\nJian Wang, Ahmed Azab, and Peng Ning. [n.d.]. Learning Binary Representation\nfor Automatic Patch Detection. In Proceedings of the 16th IEEE Annual ConsumerCommunications & Networking Conference (CCNC).\n[33]Nir Friedman, Dan Geiger, and Moises Goldszmidt. [n.d.]. Bayesian Network\nClassifiers. Machine learning ([n.d.]).\n[34]Guo Haixiang, Li Yijing, Jennifer Shang, Gu Mingyun, Huang Yuanyue, and\nGong Bing. [n.d.]. Learning from Class-imbalanced Data: Review of Methods\nand Applications. Expert Systems with Applications ([n.d.]).\n[35]Abram Hindle, Daniel M. German, Michael W. Godfrey, and Richard C. Holt.\n2009. AutomaticClassificationofLargeChangesintoMaintenancecategories.\nInProceedings of the 17th International Conference on Program Comprehension\n(ICPC).\n[36]Tin Kam Ho. [n.d.]. Random Decision Forests. In Proceedings of the 3rd\nInternational Conference on Document Analysis and Recognition (ICDAR).\n[37]Xuan Huo, Ming Li, and Zhi-Hua Zhou. 2016. Learning Unified Features\nfrom Natural and Programming Languages for Locating Buggy Source Code.InProceedings of the Twenty-Fifth International Joint Conference on Artificial\nIntelligence (IJCAI).\n[38]Jiyong Jang, Abeer Agrawal, and David Brumley. [n.d.]. ReDeBug: Finding\nUnpatched Code Clones in Entire OS Distributions. In Proceedings of the 33rd\nIEEE Symposium on Security and Privacy (S&P).\n[39]Zheyue Jiang, Yuan Zhang, Jun Xu, Qi Wen, Zhenghe Wang, Xiaohan Zhang,\nXinyu Xing, Min Yang, and Zhemin Yang. 2020. PDiff: Semantic-based Patch\nPresenceTestingforDownstreamKernels.In Proceedingsofthe27thACMSIGSAC\nConference on Computer and Communications Security (CCS).\n[40]Guoliang Jin, Linhai Song, Xiaoming Shi, Joel Scherpelz, and Shan Lu. 2012.\nUnderstanding and Detecting Real-World Performance Bugs. In Proceedings\nof the 33rd ACM SIGPLAN Conference on Programming Language Design and\nImplementation (PLDI).\n[41]ShubhraKantiKarmakerSantu,ParikshitSondhi,andChengXiangZhai.2017.\nOnApplicationofLearningtoRankforE-CommerceSearch.In Proceedingsof\nthe 40th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval (SIGIR).\n[42]DongsunKim,YidaTao,SunghunKim,andAndreasZeller.[n.d.]. Whereshould\nwe fix this bug? a two-phase recommendation model. IEEE transactions on\nsoftware Engineering 39, 11 ([n.d.]).\n[43]Seulbae Kim, Seunghoon Woo, Heejo Lee, and Hakjoo Oh. [n.d.]. VUDDY: A\nScalableApproachforVulnerableCodeCloneDiscovery.In Proceedingsofthe\n38th IEEE Symposium on Security and Privacy (S&P).\n[44]AnNgocLam,AnhTuanNguyen,HoanAnhNguyen,andTienN.Nguyen.2017.\nBug Localization with Combination of Deep Learning and Information Retrieval.\nInProceedings of the 25th International Conference on Program Comprehension\n(ICPC).\n[45]Frank Li and Vern Paxson. [n.d.]. A Large-scale Empirical Study of Security\nPatches. In Proceedings of the 24th ACM SIGSAC Conference on Computer and\nCommunications Security (CCS).\n[46]Hongliang Liang, Lu Sun, Meilin Wang, and Yuxing Yang. [n.d.]. Deep learning\nwith customized abstract syntax tree for bug localization. IEEE Access 7 ([n.d.]).\n[47]ZhenLiu,QiangWei,andYanCao.[n.d.]. Vfdetect:AVulnerableCodeClone\nDetectionSystemBasedonVulnerabilityFingerprint.In Proceedingsofthe3rd\nInformation Technology and Mechatronics Engineering Conference (ITOEC).\n[48]Edward Loper and Steven Bird. [n.d.]. NLTK: the Natural Language Toolkit.\nInProceedings of the ACL-02 Workshop on Effective tools and methodologies for\nteaching natural language processing and computational linguistics-Volume 1.\n[49]Victoria López, Alberto Fernández, Salvador García, Vasile Palade, and Francisco\nHerrera.[n.d.]. AnInsightintoClassificationwithImbalancedData:Empirical\nResults and Current Trends on Using Data Intrinsic Characteristics. Information\nsciences([n.d.]).\n[50]AravindMachiry,NiloRedini,EricCamellini,ChristopherKruegel,andGiovanni\nVigna. 2020. SPIDER: Enabling Fast Patch Propagation In Related Software\nRepositories. In Proceedings of the 41th IEEE Symposium on Security and Privacy\n(S&P).\n[51]Dongliang Mu, Alejandro Cuevas, Limin Yang, Hang Hu, Xinyu Xing, Bing Mao,\nand Gang Wang. 2018. Understanding the Reproducibility of Crowd-reported\nSecurityVulnerabilities.In Proceedingsofthe27thUSENIXSecuritySymposium\n(USENIX Security).\n[52]Collin Mulliner, Jon Oberheide, William Robertson, and Engin Kirda. [n.d.].\nPatchdroid: Scalable Third-party Security Patches for Android Devices. InProceedings of the 29th Annual Computer Security Applications Conference\n(ACSAC).\n[53]Stephan Neuhaus, Thomas Zimmermann, Christian Holler, and Andreas Zeller.\n2007. Predicting Vulnerable Software Components. In Proceedings of the 14th\nACM Conference on Computer and Communications Security (CCS).\n[54]U.S.NationalInstituteofStandardsandTechnology.2016. NVD-CVE-2016-4417.\nhttps://nvd.nist.gov/vuln/detail/CVE-2016-4417.\n[55]U.S.NationalInstituteofStandardsandTechnology.2021. NationalVulnerability\nDatabase. https://nvd.nist.gov/home.cfm.\n[56]Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury,\nGregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga,\nAlban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison,\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3295AlykhanTejani,SasankChilamkurthy,BenoitSteiner,LuFang,JunjieBai,and\nSoumithChintala.[n.d.].In Proceedingsofthe32ndAdvancesinNeuralInformation\nProcessing Systems (NIPS).\n[57]HenningPerl,SergejDechand,MatthewSmith,DanielArp,FabianYamaguchi,\nKonradRieck,SaschaFahl,andYaseminAcar.2015. VCCFinder:FindingPotential\nVulnerabilities in Open-Source Projects to Assist Code Audits. In Proceedings\nof the 22nd ACM SIGSAC Conference on Computerand Communications Security\n(CCS).\n[58]John C Platt. [n.d.]. Advances in Kernel Methods. Chapter Fast Training of\nSupport Vector Machines using Sequential Minimal Optimization. MIT Press,\nCambridge, MA, USA ([n.d.]).\n[59]Sebastian Poeplau and Aurélien Francillon. [n.d.]. Symbolic Execution withSymCC: Don’t Interpret, Compile!. In Proceedings of the 29th USENIX Security\nSymposium (USENIX Security).\n[60]Eric Rescorla. [n.d.]. Security holes... Who cares?. In Proceedings of the 12th\nUSENIX Security Symposium (USENIX Security).\n[61]Ripon K. Saha, Matthew Lease, Sarfraz Khurshid, and Dewayne E. Perry.\n2013. Improving Bug Localization Using Structured Information Retrieval. In\nProceedingsofthe28thIEEE/ACMInternationalConferenceonAutomatedSoftware\nEngineering (ASE).\n[62]Armin Sarabi, Ziyun Zhu, Chaowei Xiao, Mingyan Liu, and Tudor Dumitraş.\n[n.d.]. Patch Me If You Can: A Study on the Effects of Individual User Behavior\non the End-Host Vulnerability State. In Proceedings of the 2017 International\nConference on Passive and Active Network Measurement (PAM).\n[63]YangSong,HongningWang,andXiaodongHe.2014. AdaptingDeepRankNet\nforPersonalizedSearch.In Proceedingsofthe7thACMInternationalConference\non Web Search and Data Mining (WSDM).\n[64]MauricioSoto,FerdianThung,Chu-PanWong,ClaireLeGoues,andDavidLo.\n2016. A Deeper Look into Bug Fixes: Patterns, Replacements, Deletions, and\nAdditions. In Proceedings of the 13th Working Conference on Mining Software\nRepositories (MSR).\n[65]Yulei Sui and Jingling Xue. [n.d.]. SVF: Interprocedural Static Value-Flow\nAnalysisinLLVM.In Proceedingsofthe25thInternationalConferenceonCompiler\nConstruction (CC).\n[66]YuanTian,JuliaLawall,andDavidLo.2012. IdentifyingLinuxBugFixingPatches.InProceedingsofthe34thInternationalConferenceonSoftwareEngineering(ICSE) .\n[67] Princeton University. 2010. WordNet. https://wordnet.princeton.edu/.[68]\nShaoweiWangandDavidLo.2014.VersionHistory,SimilarReport,andStructure:PuttingThemTogetherforImprovedBugLocalization.In Proceedingsofthe22nd\nInternational Conference on Program Comprehension (ICPC).\n[69]XindaWang,KunSun,ArcherBatcheller,andSushilJajodia.[n.d.]. Detecting\n\"0-Day\" Vulnerability: An Empirical Study of Secret Security Patch in OSS. In\nProceedings of the 49th Annual IEEE/IFIP International Conference on Dependable\nSystems and Networks (DSN).\n[70]Xinda Wang, Shu Wang, Pengbin Feng, Kun Sun, and Sushil Jajodia. 2021.PatchDB: A Large-Scale Security Patch Dataset. In 2021 51st Annual IEEE/IFIP\nInternational Conference on Dependable Systems and Networks (DSN).\n[71]MingWen,RongxinWu,andShing-ChiCheung.2016. Locus:LocatingBugsfrom\nSoftware Changes.In Proceedings ofthe31stIEEE/ACMInternational Conference\non Automated Software Engineering (ASE).\n[72]Wireshark. 2016. Patchof CVE-2016-4417. https://gitlab.com/wireshark/wires\nhark/-/commit/c31425f9ae15067e26ccc6183c206c34713cb256.\n[73]Yang Xiao, Bihuan Chen, Chendong Yu, Zhengzi Xu, Zimu Yuan, Feng Li,Binghong Liu, Yang Liu, Wei Huo, Wei Zou, and Wenchang Shi. 2020. MVP:Detecting Vulnerabilities using Patch-Enhanced Vulnerability Signatures. In\nProceedings of the 29th USENIX Security Symposium (USENIX Security).\n[74]YifeiXu,ZhengziXu,BihuanChen,FuSong,YangLiu,andTingLiu.2020. Patch\nBased Vulnerability Matching for Binary Programs. In Proceedings of the 29th\nACMSIGSOFTInternationalSymposiumonSoftwareTestingandAnalysis(ISSTA) .\n[75]ZhengziXu,BihuanChen,MahinthanChandramohan,YangLiu,andFuSong.\n[n.d.]. SPAIN: security patch analysis for binaries towards understanding the\npain and pills. In Proceedings of the 39th International Conference on Software\nEngineering (ICSE).\n[76]XinYe,RazvanBunescu,andChangLiu.2014. LearningtoRankRelevantFilesforBug Reports Using Domain Knowledge. In Proceedings of the 22nd ACM SIGSOFT\nInternational Symposium on Foundations of Software Engineering (FSE).\n[77]Zuoning Yin, Ding Yuan, Yuanyuan Zhou, Shankar Pasupathy, and Lakshmi\nBairavasundaram. 2011. How Do Fixes Become Bugs?. In Proceedings of the 19th\nACMSIGSOFTSymposiumandthe13thEuropeanConferenceonFoundationsof\nSoftware Engineering (ESEC/FSE).\n[78]KlausChangsunYoum,JuneAhn,JeonghoKim,andEunseokLee.[n.d.]. Bug\nlocalization based on code change histories and bug reports. In Asia-Pacific\nSoftware Engineering Conference (APSEC).\n[79]Hang Zhangand Zhiyun Qian.2018. Preciseand Accurate PatchPresence Test\nfor Binaries. In Proceedings of the 27th USENIX Security Symposium (USENIX\nSecurity). USA.\n[80]HaoZhongandZhendongSu.2015. AnEmpiricalStudyonRealBugFixes.In\nProceedings of the 37th IEEE International Conference on Software Engineering(ICSE).\n[81]Jian Zhou, Hongyu Zhang, and David Lo. 2012. Where Should the Bugs BeFixed? - More Accurate Information Retrieval-Based Bug Localization Based\nonBugReports.In Proceedingsofthe34thInternationalConferenceonSoftware\nEngineering (ICSE).\nA APPENDIX\nA.1 Features in Predicting Patch Likelihood\nTo predict the patch likelihood of a code commit, PatchScout\nleverages a learning-based approach. It collects a set of 62 features\n(seeTable12)fromacodecommit.Comparedto[ 69],weintroduce\nthe following two new features.\n•Updateandmovementofprogramelements. Wangetal.recognize\nthecodediffasasequenceofadditionsanddeletionsofprogram\nelements.However,weobservethatsomeadditionsanddeletions\nshould be recognized as updates and movements to illustrate\nthe real purposes of these code changes. Figure 3 gives two\nexamples: Figure 3 (a) fixes an infinite recursion vulnerability by\nupdating the branch condition (line 16 to line 18); while Figure 3\n(b)fixesaheapbufferoverflowbymovingtheconditioncheck\n(line 9, 10) to the inside of the loop (line 16, 17). In these\ntwo cases, simply recognizing the code changes as addition\nand deletion would overlook the real semantic (update andmovement) behind it. Therefore, we introduce the featuresof updates and movements on program elements (No.45-58in Table 12) into the classification model. These features are\ncollected by matching the patterns of additions and deletions.\n•Syntactic hunks. The discreteness of the code diff may help\nto differ patch commits from other commits. To represent the\ndiscreteness of the code diff, Wang et al.use textual-level hunks\n(i.e., a chunk of code consisting of continuous modified code\nlines and several unmodified code lines around them). However,\ntextual-level changes in code lines do not directly reflect the\nsyntactic-levelchangesinprogramelements,sowealsoconsider\nhowdiscretethecodediffisatthesyntacticlevel.Inparticular,\nwe introduce 4 syntactic hunk features (No.59-62 in Table 12)\nwhich use continuous added/removed/updated/moved program\nelements to represent the discreteness at the syntactic level. We\nextract these features by simply counting the syntactic hunks.\nA.2 Enhance PatchScout with Bug Reports\nWe conductan experimentto measurethe possibilityof usingthe\nvulnerabilityinformationinbugreportstoenhance PatchScout .\nSpecifically,fromthe1,628(=943+685)CVEsinourtrainingsetand\ntesting set, we find 1,391 bug reports in their NVD pages. From\nthese reports,we successfullyextract more vulnerability identifier ,\nvulnerability location, vulnerability type information for 641 CVEs,\nusingthesamemethodin§4.1.Wethenenhance PatchScout to\nusethesenewfeaturesduringtrainingandtesting.However,wefind that the effectiveness of\nPatchScout decreases a little after\nadopting the features extracted from bug reports. To be specific,the top-1 recall of\nPatchScout drops 0.88% and its top-10 recall\ndrops1.02%.Wefurtherinvestigatethesenewfeaturesandfindthat\nthough more information is extracted from the bug reports, much\nofitisincorrect,e.g.,bugreportsusuallycontainstacktraceswhich\nhave many patch-irrelevant functions and files. In particular, we\nfindthatfor400CVEs,therelevancebetweenthetruepatchcommit\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3296andthevulnerabilityinformationdegradesinthecorresponding\nfeature dimensions. It turns out that the form of information in\nthe bug reports is more complex, and a more accurate information\nextractor is required to enhance PatchScout.\nA.3 Supplementary Tables and Figures\n 1  diff --git a/src/frompnm.c b/src/frompnm.c\n 2  index 86d0c03..de73766 100644\n 3  --- a/src/frompnm.c\n 4  +++ b/src/frompnm.c\n 5  @@ -36,13 +36,15 @@ pnm_get_line(unsigned char *p, unsigned char *end, ...\n 6       int n;\n 7   \n 8       do { 9  \n+        /* read the line */\n10          for (n = 0 ; p < end && *p >= ' '; p ++) {\n11              if (n < 255) {12                  line[n\n++] = *p;\n13              }\n14          }\n15   \n16 -        if (p < end && *p == '\\n') {\n17 +        /* skip invald characters */\n18 +        if (p < end && *p < ' ') {\n19              p ++;\n20          }\n21\n(a) Patch Commit of CVE-2019-11024\n 1  diff --git a/coders/sgi.c b/coders/sgi.c\n 2  index 236bf4cb9..415598122 100644\n 3  --- a/coders/sgi.c\n 4  +++ b/coders/sgi.c\n 5  @@ -953,8 +953,6 @@ static MagickBooleanType WriteSGIImage(const ImageInfo ...\n 6     assert(image->signature == MagickCoreSignature);\n 7     if (image->debug != MagickFalse)\n 8         (void) LogMagickEvent(TraceEvent,GetMagickModule(),\"%s\",image->filename);\n 9  -  if ((image->columns > 65535UL) || (image->rows > 65535UL))\n10 -      ThrowWriterException(ImageError,\"WidthOrHeightExceedsLimit\");\n11     assert(exception != (ExceptionInfo *) NULL);\n12     ...\n13     do\n14     {\n15         ...\n16 +       if ((image->columns > 65535UL) || (image->rows > 65535UL))\n17 +           ThrowWriterException(ImageError,\"WidthOrHeightExceedsLimit\");\n18         ...\n(b) Patch Commit of CVE-2019-19948\nFigure3:Examplesofsecuritypatchfixingvulnerabilitybyupdate or movement.\nTable11:Propagationtime(day)betweenthefirstpatchand\nthe last patch on all affected branches.\nSoftware Minimum Median Average Maximum\nLinux Kernel 1 57.5 79.98 517Wireshark 0 0 23.70 702QEMU 0 106.5 116.38 228\nFFmpeg 0 38 84.44 420\nJenkins\n1N/A N/A N/A N/A\nTotal 0 26 71.76 702\n1In Jenkins, there’s only one unique patch on all patched branches\nfor each vulnerability, which means there’s no patch propagation.Table 12: Features to predict the patch likelihood of a\ncommit.\nNo. Feature\n1 # of changed files\n2 # of changed functions\n3 # of hunks4 # of same hunk\n5 - 8 # of added/removed/total/net lines\n9 - 12 # of added/removed/total/net conditional statements\n13 - 16 # of added/removed/total/net loops\n17 - 20 # of added/removed/total/net logical expressions21 - 24 # of added/removed/total/net functions\n25 - 28 # of added/removed/total/net function calls\n29 - 32 # of added/removed/total/net assignments33 - 36 # of added/removed/total/net memory related operations\n37 - 40 # of added/removed/total/net exits\n41 - 44 # of added/removed/total/net returns45 # of updated conditional statements\n46 # of updated loops\n47 # of updated logical expressions48 # of updated function calls\n49 # of updated memory related operations\n50 # of updated returns\n51 # of updated operands in conditional statement\n52 # of updated operands in loop53 # of updated operands in logical expression\n54 # of updated operands in function call\n55 # of updated operands in memory related operation56 # of updated operands in return\n57 # of moved conditional statements\n58 # of moved loops59 - 62 # of added/removed/updated/moved syntactic hunks\n  4 5 6 7 8 9 10\n  CVSS Score80\n60\n40\n20\n0  Not-patched Ratio(%)\nFigure 4: The not-patched ratios among different CVEs.\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3297Table 13: Vulnerability type groups, vulnerability impact groups and the causality relations between them.\nVulnerability Type Groups (16) Vulnerability Impact Groups (15)\noverflowdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, code execution, unspecified impact, assertion failure\nbuffer overflowdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, code execution, unspecified impact, assertion failure\ninteger overflow denial of service, crash, unspecified impact, assertion failure\nheap overflowdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, code execution, unspecified impact, assertion failure\nstack overflowdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, code execution, unspecified impact, assertion failure\noff by onedenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, code execution, unspecified impact, assertion failure\nuse after freedenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,obtain sensitive information,unspecified\nimpact, assertion failure\ndouble freedenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,obtain sensitive information,unspecified\nimpact, assertion failure\ninfinite loopdenial of service, memory issues, memory leak, memory corruption, memory consumption,\nunspecified impact, stack consumption\nout of bound accessdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,obtain sensitive information,unspecified\nimpact, assertion failure, bus error\nout of bound writedenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,unspecified impact,assertion failure, bus\nerror\nnull pointer dereferencedenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalid memory access, unspecified impact, assertion failure\nout of bound readmemory issues, memory corruption, invalid memory access, obtain sensitive information,\nunspecified impact, assertion failure, bus error\nmiss bound checkdenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,obtain sensitive information,unspecified\nimpact, assertion failure\ndivide by zerodenial of service, crash, segmentation fault, segmentation violation, unspecified impact,\nassertion failure\nrace conditiondenial ofservice, crash,segmentation fault, segmentationviolation, memoryissues, memory\ncorruption, invalidmemory access,code execution,obtain sensitive information,unspecified\nimpact, assertion failure\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3298Table 14: Detailed Dataset Information of CVEs and Branches for Patch Deployment Study across Branches (see §7).\nSoftware CVEs Branches\nLinux KernelCVE-2017-5577 CVE-2017-6214 CVE-2017-7273 CVE-2017-7889 CVE-2017-8063\nCVE-2017-10911 CVE-2017-11473 CVE-2017-12193 CVE-2017-16530 CVE-2017-16995\nCVE-2018-5332 CVE-2018-5803 CVE-2018-7492 CVE-2017-18204 CVE-2017-18216\nCVE-2018-10940 CVE-2018-13099 CVE-2018-13096 CVE-2018-13405 CVE-2018-16276\nCVE-2018-19854 CVE-2019-11833 CVE-2019-12817 CVE-2018-20961 CVE-2019-15222\nCVE-2019-15919 CVE-2019-15923 CVE-2019-15927 CVE-2019-17052 CVE-2019-19079CVE-2019-19078 CVE-2019-19065 CVE-2019-19061 CVE-2019-19052 CVE-2019-19534\nCVE-2019-19535 CVE-2019-19807 CVE-2020-9383 CVE-2020-11494 CVE-2020-11884\nCVE-2020-12768 CVE-2020-13143 CVE-2020-13974 CVE-2020-14416 CVE-2020-15393linux-3.2.y linux-3.10.y\nlinux-3.12.y linux-3.16.y\nlinux-3.18.y linux-4.1.y\nlinux-4.4.y linux-4.8.ylinux-4.9.y linux-4.10.ylinux-4.11.y linux-4.12.ylinux-4.13.y linux-4.14.ylinux-4.15.y linux-4.16.ylinux-4.17.y linux-4.18.ylinux-4.19.y linux-4.20.y\nlinux-5.0.y linux-5.1.y\nlinux-5.2.y linux-5.3.ylinux-5.4.y linux-5.5.ylinux-5.6.y linux-5.7.ylinux-5.8.y master\nWiresharkCVE-2016-5359 CVE-2016-6507 CVE-2016-6509 CVE-2016-6512 CVE-2017-5597\nCVE-2017-6474 CVE-2017-7701 CVE-2017-7703 CVE-2017-7748 CVE-2017-7747\nCVE-2018-7420 CVE-2018-7336 CVE-2018-7321 CVE-2018-9268 CVE-2018-9265\nCVE-2018-9273 CVE-2018-9257 CVE-2018-9258 CVE-2018-9271 CVE-2018-11356CVE-2018-11354 CVE-2018-14370 CVE-2018-14341 CVE-2018-14343 CVE-2018-16058\nCVE-2018-18225 CVE-2018-19626 CVE-2019-5721 CVE-2019-5717 CVE-2019-5716\nCVE-2019-9209 CVE-2019-9214 CVE-2019-10902 CVE-2019-10894 CVE-2019-10896CVE-2019-10900 CVE-2019-10903 CVE-2019-12295 CVE-2019-13619 CVE-2019-19553\nCVE-2020-7044 CVE-2020-7045 CVE-2020-9428 CVE-2020-9431 CVE-2020-13164master-1.12 master-2.0\nmaster-2.2 master-2.4master-2.6 master-3.0\nmaster-3.2 master\nQEMUCVE-2016-4037 CVE-2016-6490 CVE-2016-6835 CVE-2016-6836 CVE-2016-7116\nCVE-2016-7466 CVE-2016-7421 CVE-2016-9102 CVE-2016-9105 CVE-2016-9106\nCVE-2017-5525 CVE-2017-5552 CVE-2017-5578 CVE-2017-5579 CVE-2017-5667\nCVE-2017-5857 CVE-2017-5898 CVE-2017-5931 CVE-2017-5973 CVE-2017-5987CVE-2017-6058 CVE-2017-7377 CVE-2017-8086 CVE-2017-8284 CVE-2017-18030\nCVE-2018-15746 CVE-2018-17958 CVE-2018-18849 CVE-2018-19489 CVE-2018-20126\nCVE-2018-20125 CVE-2018-20123 CVE-2018-20216 CVE-2019-5008 CVE-2019-3812CVE-2019-6501 CVE-2019-6778 CVE-2018-20815 CVE-2019-12155 CVE-2019-13164\nCVE-2019-15034 CVE-2019-20382 CVE-2020-11102 CVE-2020-11869 CVE-2020-13765stable-2.5 stable-2.6\nstable-2.7 stable-2.8stable-2.9 stable-2.10stable-2.11 stable-2.12\nstable-3.0 stable-3.1\nstable-4.0 stable-4.1stable-4.2 master\nFFmpegCVE-2016-6164 CVE-2016-6920 CVE-2016-10190 CVE-2016-10192 CVE-2017-7865\nCVE-2017-7862 CVE-2017-9990 CVE-2017-9992 CVE-2017-9994 CVE-2017-9991\nCVE-2017-11399 CVE-2017-11719 CVE-2017-14058 CVE-2017-14170 CVE-2017-14169\nCVE-2017-14171 CVE-2017-14767 CVE-2017-15672 CVE-2017-16840 CVE-2017-17081CVE-2018-6621 CVE-2018-6912 CVE-2018-7557 CVE-2018-7751 CVE-2018-12459\nCVE-2018-12458 CVE-2018-12460 CVE-2018-13301 CVE-2018-13300 CVE-2018-13303\nCVE-2018-13302 CVE-2018-13305 CVE-2018-13304 CVE-2018-14394 CVE-2018-14395CVE-2018-15822 CVE-2019-1000016 CVE-2019-9721 CVE-2019-9718 CVE-2019-11338\nCVE-2019-12730 CVE-2019-17539 CVE-2019-17542 CVE-2020-12284 CVE-2020-13904release/2.4 release/2.8\nrelease/3.0 release/3.1release/3.2 release/3.3release/3.4 release/4.0\nrelease/4.1 release/4.2\nrelease/4.3 master\nJenkinsCVE-2016-0788 CVE-2016-0789 CVE-2016-3725 CVE-2016-9299 CVE-2017-2600\nCVE-2017-2606 CVE-2017-2608 CVE-2017-2610 CVE-2017-2601 CVE-2017-2611\nCVE-2017-2602 CVE-2017-1000362 CVE-2017-1000399 CVE-2017-1000393 CVE-2017-1000391\nCVE-2017-1000355 CVE-2018-1000169 CVE-2018-1000193 CVE-2018-1000194 CVE-2018-1999003CVE-2018-1999001 CVE-2018-1999044 CVE-2018-1000861 CVE-2018-1000862 CVE-2018-1000864\nCVE-2018-1000408 CVE-2018-1000406 CVE-2018-1000409 CVE-2018-1000410 CVE-2018-1000407\nCVE-2019-10406 CVE-2019-10405 CVE-2019-10404 CVE-2019-10401 CVE-2019-10384CVE-2019-10383 CVE-2019-10353 CVE-2019-1003050 CVE-2019-1003049 CVE-2020-2161\nCVE-2020-2105 CVE-2020-2104 CVE-2020-2103 CVE-2020-2102 CVE-2020-2162stable-2.107 stable-2.121\nstable-2.138 stable-2.150stable-2.164 stable-2.176stable-2.190 stable-2.19stable-2.204 stable-2.222stable-2.235 stable-2.249\nstable-2.32 stable-2.46\nstable-2.60 stable-2.7stable-2.73 stable-2.89master\nSession 12B: Analyzing Crashes and Incidents\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n3299"}
{"title": "QuantumHammer: A Practical Hybrid Attack on the LUOV Signature Scheme", "content": "QuantumHammer: A Practical Hybrid Attack on the LUOV\nSignature Scheme\nKoksal Mus∗\nkmus@wpi.edu\nWorcester Polytechnic Institute\nIstanbul Aydin University\nWorcester, MA, USASaad Islam∗\nsislam@wpi.edu\nWorcester Polytechnic Institute\nWorcester, MA, USABerk Sunar\nsunar@wpi.edu\nWorcester Polytechnic Institute\nWorcester, MA, USA\nABSTRACT\nPost-quantum schemes are expected to replace existing public-key\nschemes within a decade in billions of devices. To facilitate the\ntransition, the US National Institute for Standards and Technology\n(NIST)isrunningastandardizationprocess.Multivariatesignatures\nis one of the main categories in NIST’s post-quantum cryptogra-\nphycompetition.Amongthefourcandidatesinthiscategory,the\nLUOV and Rainbow schemes are based on the Oil and Vinegar\nscheme, first introduced in 1997 which has withstood over twodecades ofcryptanalysis. Beyond mathematicalsecurity andeffi-ciency, security against side-channel attacks is a major concernin the competition. The current sentiment is that post-quantumschemes may be more resistant to fault-injection attacks due to\ntheirlargekeysizesandthelackofalgebraicstructure.Weshow\nthat this is not true.\nWe introduce a novel hybrid attack, QuantumHammer, and\ndemonstrate it on the constant-time implementation of LUOV cur-\nrently in Round 2 of the NIST post-quantum competition. TheQuantumHammer attack is a combination of two attacks, a bit-\ntracing attack enabled via Rowhammer fault injection and a divide\nand conquer attack that uses bit-tracing as an oracle. Using bit-\ntracing, anattacker withaccess tofaulty signaturescollected using\nRowhammerattack,canrecoversecretkeybitsalbeitslowly.We\nemploy a divide and conquer attack which exploits the structure inthekeygenerationpartofLUOVandsolvesthesystemofequations\nforthe secretkey moreefficientlywith fewkeybits recoveredviabit-tracing.\nWe have demonstrated the first successful in-the-wild attack\non LUOV recovering all 11K key bits with less than 4 hours ofanactiveRowhammerattack.Thepost-processingpartishighly\nparallelandthuscanbetriviallyspedupusingmodestresources.\nQuantumHammerdoesnotmakeanyunrealisticassumptions,only\nrequires software co-location (no physical access), and thereforecanbeusedtotargetsharedcloudserversorinothersandboxed\nenvironments.\n∗Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’20, November 9–13, 2020, Virtual Event, USA\n© 2020 Association for Computing Machinery.\nACM ISBN 978-1-4503-7089-9/20/11...$15.00\nhttps://doi.org/10.1145/3372297.3417272CCS CONCEPTS\n•Securityandprivacy →Hardwareattacksandcountermea-\nsures;Cryptanalysis and other attacks.\nKEYWORDS\nRowhammerattack,faultattacks,post-quantumcryptography,mul-\ntivariate cryptography, algebraic attack.\nACM Reference Format:\nKoksal Mus, Saad Islam, and Berk Sunar. 2020. QuantumHammer: A Prac-\nticalHybridAttackontheLUOVSignatureScheme.In Proceedingsofthe\n2020ACMSIGSACConferenceonComputerandCommunicationsSecurity\n(CCS ’20), November 9–13, 2020, Virtual Event, USA. ACM, New York, NY,\nUSA, 14 pages. https://doi.org/10.1145/3372297.3417272\n1 INTRODUCTION\nTheemergenceofquantumcomputerswillrendertraditionalpublic-\nkey schemes such as RSA and ECC insecure. Shor’s algorithm [ 41]\nwill be able to break the underlying hard factorization and discrete\nlogproblems.Quantumcomputerswillalsoaffectsymmetric-key\ncryptosystems,buttheirimpactcanbeovercomebymildlyincreas-\ning key sizes. For instance, using Grover’s search algorithm [ 20]\none may brute force a 128-bit secure system in 264iterations. In\ngeneral, Grover’s algorithm reduces the complexity of symmetric-\nkey schemes from 𝑂(𝑁)to𝑂(√\n𝑁), wherelog2(𝑁)is the security\nlevel in bits. Hence, doubling the key size may be a solution to\nretain the security level.\nThe US NIST has recently started a competition for quantum\nsecure public-key cryptosystems for digital signatures, Public-Key\nEncryption(PKE)andKey-EstablishmentMechanisms(KEMs)[ 33].\nIntheNISTPost-QuantumCryptography(PQC)Standardization\nprocess[1],26schemespassedthefirstroundandarecurrentlycom-\npetinginthesecondround,ofwhich9aredigitalsignatureschemes.\nTheevaluationcriteriaconsistsofthreemajorcomponentssecurity,\ncostandperformanceandalgorithmandimplementationcharac-\nteristics.\nBased on the underlying hard problems, the submissions are di-\nvidedinto5broadcategories:lattice-based,code-based,hash-based,\nisogeny-based and multivariate schemes. These categories have\ndifferentcharacteristics withvaryingkeysizes andperformances.\nMultivariate is one of the main categories which is known to be\nveryefficientforresourceconstraintdevicesbutontheotherhand,\nthe key sizes are quite large. Under this category, there are four\nsignature schemes namely GeMSS, LUOV, MQDSS and Rainbow.MQDSS is based on the Fiat-Shamir construction and GeMSS isa faster variant of QUARTZ. Lifted Unbalanced Oil and Vinegar\n(LUOV) is an improvement of the Unbalanced Oil and Vinegar\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1071(UOV)schemewithsmallerpublickeys.Rainbowisanextension\nof UOV with an additional oil layer.\nA number of side-channel attacks have been performed on PQC\nschemes. Bruinderink et al. [ 8] performed the first side-channel\nattack on lattice-based signature schemes in 2016, specifically a\nflushandreloadattackonBLISS.TheattackwasextendedtoBLISS-\nBbyPessletal.[ 36].BothoftheseattackstargetedtheBernoulliand\nCDT sampling. An extension to this work was presented by Bootle\netal.[6]whichmanagestorecover100%ofthesecretkeycompared\nto only 7% in the previous work [ 17]. Another side-channel attack\nby Ravi et al. [ 37] achieving existential forgery targeted Dilithium,\na lattice-based signature scheme.\nA more recent timing attack focused on the error-correcting\ncodes used in lattice-based schemes by D’Anvers et al. [ 12]i n2 0 1 9 .\nCorrelationPowerAnalysis(CPA)attackhasalsobeenshownto\nbe effective by Park et al. [ 34] on Rainbow and UOV. The early\ntiming attacks motivated a number of efforts to design constant-time discrete gaussian samplers, i.e. [\n25,26,49]. In fact, many of\nthe NIST submissions, including LUOV, provided constant-time\nimplementationstoeliminateanypassiveside-channelattacks. The\nNISTRound2versionofLUOV,specificallyaddedarandomsaltfor\neverymessageandrequiredrandomlygeneratedvinegarstodefend\nagainst the side-channel and fault injection attacks.\nA more recent noteworthy work by Ding et al. [ 13,15]p r e -\nsented a (purely) algebraic attack, i.e. the subfield differential at-\ntack.Withoutanyside-channelinformation,theattackmanaged\nto significantly reduce the security level of LUOV. Specifically, for\nLUOV-8-58-237, the complexity is reduced from 2146to 2105which\nis lower than the minimum security level criteria established byNIST for the post-quantum competition. The updated version ofLUOV now uses finite fields\n𝐺𝐹(2𝑟), where r is a prime, which\nrenders the subfield differential attack inapplicable1\nThere is some research aimed at evaluating the resilience of\npost-quantum schemes against fault attacks. Genet et al. [ 19] have\ndemonstratedafaultattackonahash-baseddigitalsignatureschemeSPHINCS.AnotherdifferentialfaultattackwasintroducedbyBruin-\nderink et al. [ 9] on deterministic lattice signatures. Espitau et al.\n[16]havepresentedfaultattacksonlatticebasedsignatureschemes\nBLISS, GLP, PASSSign and Ring-TESLA. Blindel et al. [ 4] have also\napplied fault attacks on lattice based signature schemes namely\nBLISS,ring-TESLAandGLP.Ravietal.[ 38]havepresentedfaultat-\ntacksonlatticebasedschemesNewHope,Kyber,FrodoandDilithium.\nThisresearchisbasedonhardwarefaultslikeelectromagneticfault\ninjections andclock glitches.Post-quantumschemes aremorediffi-\ncult to attack via side-channel or fault attacks due to their massive\nkeysthatrunintomanyKBytes inmanycasesandthelackofalge-braicstructure.CollectingKBytesthroughslowbit-flipsorleakages\nobserved by the attacker over extended durations is impracticalsince its highly unlikely for a victim to be present and continu-\nously running the target cryptographic primitive. Therefore, small\nside-channel leakages and fewer faults may not entirely break the\nscheme. On the other hand, these schemes are based on strong\npost-quantum (conjectured) hard problems which have withstood\nyearsof cryptanalysis.Here weopt foradifferentattackstrategy,\ni.e.,weanalyzeLUOVusingacombinationoffaultinjectionswhile\n1The updated version is available at the author’s website [44].simultaneously targeting the algebraic structure. Hence we follow\na hybrid attack strategy.\n1.1 Our Contribution\nWe have discovered a practical technique which recovers all se-\ncret key bits in LUOV. QuantumHammer proceeds by injecting\nfaults, collecting faulty signatures, followed by the divide and con-\nquer attack. The faults are achieved using a realistic software only\napproach via a Rowhammer attack. In summary, in this work:\n(1)We introduce a simple technique that uses faulty signatures\nto mathematically trace and recover key bits. Each faulty\nsignature yields a key bit. While not efficient, the technique\ngivesusatoolwethenamplifytheefficiencyofourattack\nusing a analytical approach.\n(2)The analytical attack exploits structures in the generation\nofthepublickeyusingasmallnumberofrecoveredkeybits\n(using a modest number of faults injections), the complexity\nof attacking the overall multivariate system reduced to a\nnumber of much smaller MV problems, which are tractable\nwith modest resources using brute force.\n(3)Our attack is software only, i.e. we do not assume any phys-\nical access to the device. This also permits remote attackson shared cloud servers or in browsers. We assume that\nthe memory module is susceptible to Rowhammer and that\nfaulty signatures can be recovered.\n(4)Earlier fault attacks on post-quantum schemes assumed hy-\npotheticalfaults.Wepresentasuccessfulend-to-endRowham-merattackon constant-time AVX2optimizedimplementation\nof the multivariate post-quantum signature scheme LUOV.\n(5)We have demonstrated full key recovery of 11,229 bits for\nLUOV-7-57-197inlessthan4hoursofonlineRowhammer\nattack and 49 hours of offline post-processing.\n(6)This attack is applicable to all the variants of LUOV Scheme\ncurrently competing in Round 2 of NIST’s competition in-\ncluding the updates [44] after Ding et al. attack [15].\n1.2 Outline\nInSection1.3,weexplaintherelatedworkindetail.InSection2,\nwegiveabriefexplanationofRowhammerattackandOilandVine-\ngar Schemes, specifically LUOV Scheme. In Section 3, our novel\nbit-tracingattackonLUOVisexplainedwithexperimentsandre-\nsults. Section 4 details our QuantumHammer on LUOV. Section 5\ncontains experimental results of QuantumHammer. Section 6 pro-\nposesthecountermeasures.WeprovideadiscussioninSection7\nand Section 8 concludes the work.\n1.3 Related Work\nOn Rainbow-like schemes, Ding et al. [ 14] introduced an algebraic\nReconciliationattackasanearlyworkin2008.Afterwards,asfor\nfaultattacksonmultivariateschemes,onlyafewresultsexist:In\n2011byHashimotoetal.[ 23]onBigFieldtypeandStepwiseTrian-\ngularSystem(STS)includingUOVandRainbow.In2019,Kramer\net al.[30] have alsoworked on UOV andRainbow extending the\nearlier work. We will only talk about UOV and Rainbow in thissection and not the Big Field type schemes. Reconciliation is analgebraic attack whereas other two works assume physical fault\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1072attacks, first introduced by Boneh et al. [ 5] but there are no details\nonfaultinjectiontechnique.Krameretal.claimedthatrandomness\nofvinegarvariablesandalsothelayersinRainbowprovidegood\nprotectionagainstfaultattacks.Thesestudiesconsiderthereattack\nscenarios:\nScenario1(AlgebraicAttack) Inthisscenario[ 14],weassume\na purely algebraic attack that improves on brute force but does\nnot assume any physical fault or any side channel information.Specifically, the aim is to invert the public map\nPby finding a\nsequenceofchangeofbasismatrices. Pisdecomposedintoaseries\noflineartransformationswhicharerecoveredstepbystepwhich\nsignificantly reduces the security level.\nScenario 2 (Central Map) It assumes that a coefficient of the\nsecret quadratic central map Fhas been faulted. By signing ran-\ndomlychosenmessageswiththefaulty F/primeandverifyingthesig-\nnatures with the correct public key P, partial information about\nthesecretlineartransformationmatrix Scanberecoveredusing\n𝛿=S◦(F/prime−F)◦T ,whereTisanothersecret lineartransfor-\nmationmatrix.As (F/prime−F)issparse, Scanbepartiallyrecovered.\nAt least𝑚−1 faults are required to recover some part of the secret\nkeymatrix S,where𝑚isthenumberofequationsinthesystem.\nBoth[23]and[30]haveanassumptionthattheattackcaninduce\nfaults in either S,ForTand providedthe success probabilities of\nhitting thecentral map F. Krameret al. haveadditionally assumed\nastrongerattackerwhocandirectlyattack Forevenspecificcoef-\nficientsof Ftoavoidunwantedscenarios.Krameretal.[ 30]refute\naclaimmadeearlierbyHashimotoetal.[ 23]andclaimthatUOV\nisimmunetothefaultattackonthecentralmap.Itisbecausethe\nattack is recovering part of Sand notT, which is not present in\nthe UOV scheme.\nScenario 3(Fixed Vinegar) This scenario assumes that the at-\ntackerisabletofixpartofrandomlychosenvinegarvariablesfrom\n(𝑥𝑣−𝑢+1,...,𝑥𝑣),where𝑢isthenumberofvinegarvariablesfixed\noutoftotal 𝑣vinegarvariablesduringmultiplesignaturecompu-\ntationsessions.Afterthat,message/signaturepairsaregenerated\nand utilized to recover the secrets. 𝑛−𝑢+1 pairs are needed to\nrecover part of T. As the attack recovers partial information about\nT, itisapplicable to both theUOV and Rainbow schemesbut still\nnot sufficient to recover the secret key.\nShim et al. [ 40] have recently presented an algebraic fault analy-\nsisattackontheUOVandRainbowschemes.Theyhaveassumeda\nsimilarscenario offixed(reused)vinegar buttheyhave twomore\nscenarios as well: revealed and set to zero vinegar. They are also\nassuming physical faults and there are no details on how the faults\nare injected. Based upon the number of faulty vinegar values, they\ngivethecomplexitiesfortheattacks.ForUOV,59Bytesoffaulty\nvinegar are needed for full key recovery. They also provide the\nresultsforLUOVwhicharetheonlyfaultattackresultssofaron\nLUOV scheme. Due to the large parameter sizes, the results arenot very promising to obtain a practical attack to target real life\ndeployments. Assuming 171 Bytes and 169 Bytes of faulty vinegar\nvalues for LUOV-8-63-256 and LUOV-8-49-242, the complexities\ndrop from 2181and 2192to 2127and 2109, respectively.\nThe authors have not demonstrated the fault attack. In practice,\nfixing a large contiguous portion of vinegar values by physical faultinjection or Rowhammer is very hard to achieve if at all possible.Our attack scenario\nis different from those presented in exist-\ning works [ 5,14,23,30]. We are inducing faults in the last stage\nofthesigningalgorithminthelineartransformation TofLUOV\nscheme.Wehaveactuallyverifiedtheassumption,i.e.,weimple-\nmentedanattackthatinducesbitflipsin T.Notethattheattack\ndoesnothaveanycontrolinthepositionofthebitflipsaswithin T\nas assumed by our attack scenario. Also, we have the ability to de-\ntectifthebitflipwasin Tornot.Wehavepracticallydemonstrated\nthismodelbyinducingthebitflipsusingtheRowhammerattack\nand not just assuming the faults as in previous research. To the\nbestofourknowledge,thisisthefirstworkwhichactuallyinduces\nbitflips(faults)throughsoftwareinpost-quantumcryptographic\nschemes.Thegoalhereistomakeuseofthefaultysignaturesto\ntrackbacktotheflippedbitsandleakthesecretbitsof T.W edo\nnot need any correct and faulty signature pairs. Rather we are able\ntocorrectthefaultysignaturebymodifyingthepublicsignature\nvaluesandverifyingthemodifiedsignaturesusingsignaturever-\nification mechanism as an oracle. Some recovered bits from this\nbit-tracingattackareusedtodecreasethecomplexityofthesolu-\ntionofMultivariateQuadratic(MQ)systemtoapracticallysolvablesmallerMQandMultivariateLinear(ML)systemsbyusingadivide\nandconquerattacktorecovertherestoftheprivatekeybits.We\ncall this hybrid attack as QuantumHammer.\n2 BACKGROUND\n2.1 Rowhammer Attack\nTheRowhammerattackisasoftware-inducedhardware-faultattack\ndiscovered in 2014 by Kim et al. [ 27]. Data is stored in the form\nof bits in the DRAMs in memory cells, composed of capacitors\nandtransistors.Achargedcapacitorrepresentsabinaryoneand\na discharged capacitor a binary zero or vice versa according to\ntheconvention.Thereisathresholdtodecidethevalueofthebit\naccording tothe voltage level.These cells areplaced very closeto\neachother, generally64Kcellsin arow.As capacitorsleakcharge\nover time, they need to be refreshed after a certain time period,\ntypically after every 64 ms. But if a DRAM row is activated rapidly,\nitcanaffecttheneighboringrowsduetoinductionandrefreshrateof64msmightnotbeenoughtomaintainthestateofthecapacitor.\nThis phenomena causes the voltage levels to cross the threshold\nwhich results in bit flips.\nAs,theDRAMissharedbetweendifferentprocessesorvirtual\nmachines, this bit flipping can lead to serious consequences. To\nperform a successful Rowhammer attack from an attacker process\nto a victim process sharing the same DRAM, the victim has tobelocatedatoneofthevulnerableDRAMrowsidentifiedbythe\nattacker. Therefore, the attacker first identifies the rows vulnerable\ntoRowhammerandthenfreethemfromtheprocess.Nextstepis\nto either wait for the victim to get that memory space assigned by\nthe OS or force the victim to be placed at these rows. There are\nvarious techniques in the literature to achieve this, i.e. spraying\n[22,39,46],grooming[ 43]andmemory-waylaying[ 21,31,47].The\nattackworksbecausethebitflipsarehighlyreproducible,which\nmeans once the attacker has identified a list of bad cells in theDRAM,shecanflipthevaluesofthesamecellscausingabitflip\ninthevictimprocess.PreviousresearchshowsthatRowhammer\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1073attackisapplicableincloudscenarios[ 10]andheterogeneousFPGA-\nCPUplatforms[45]. Itcanbe launchedremotelyover thenetwork\n[32,42]. Rowhammer is even applicable on ECC chips [ 11] and\nDDR4 memories with Target Row Refresh (TRR) mitigations [ 18].\n2.2 Oil and Vinegar Schemes\nConsider a system of 𝑚Multivariate Quadratic (MQ) polynomials\nwith𝑛variables𝑥1,...,𝑥𝑛\n𝑝𝑘(𝑥1,...,𝑥𝑛)=𝑛/summationdisplay.1\n𝑖=1𝑛/summationdisplay.1\n𝑗=𝑖𝑝𝑘\n𝑖𝑗·𝑥𝑖𝑥𝑗+𝑛/summationdisplay.1\n𝑖=1𝑝𝑘\n𝑖·𝑥𝑖+𝑝𝑘\n0(1)\nNotethat,sinceweareusingbooleanequations,wereservedthe\nexponent for use as an index.\nSolving the MQ system is conjectured hard for sufficiently large\n𝑚and𝑛. The MQ challenge by Yasuda et al. [ 48] gives a way to\ngaugethedifficultyofsolvingreal-lifeMQinstanceswithmoderate\nsizeinstances.Amultivariatesignatureschememaybebuildaround\nthe MQ system: the coefficients represent the public key P, the\nsystem is solved for the hash of the message, the variable values\nthatsatisfytheequation(thesolutiontotheMQsystem)represents\nthe signature. It is hard to solve this system and find a signaturefor a desired message unless we have a trapdoor\nP=S◦F◦T ,\nwhereSandTarethesecretinvertiblelineartransformationsand\nFis the secret quadratic map having a special structure given as\n𝑓𝑘(𝑥1,...,𝑥𝑛)=𝑣/summationdisplay.1\n𝑖=1𝑛/summationdisplay.1\n𝑗=𝑖𝛼𝑘\n𝑖𝑗·𝑥𝑖𝑥𝑗+𝑛/summationdisplay.1\n𝑖=1𝛽𝑘\n𝑖·𝑥𝑖+𝛾𝑘(2)\nHere,𝑛variables𝑥1,...,𝑥𝑛aredividedintotwoparts, 𝑥1,...,𝑥𝑣as\nthe vinegar variables and 𝑥𝑣+1,...,𝑥𝑛as the𝑚oil variables where\n𝑛=𝑣+𝑚. The parameters 𝛼𝑘\n𝑖𝑗,𝛽𝑘\n𝑖and𝛾𝑘are chosen randomly\nfromafinitefield Fwhere𝑘rangesfrom1to 𝑚.Thespecialtyof\nthis structure is that there is no quadratic term with multiplication\noftwooilvariables.So,ifvinegarvariablesarechosenrandomly\nandinsertedintothesystem,itcollapsestoalinearsystemwhich\ncan be easily solved for the remaining oil variables using Gaussian\nelimination.Notethat,oilvariablesarepublicwhereasvinegarsare\nkept secret. The structure of Fis then hidden using a secret linear\ntransformation T. The detailed explanation of the LUOV signature\nschemes which utilize this structure is given in Section 2.3.\nThe first Oiland Vinegar scheme wasproposed by Patarin [ 35]\nin 1997which was brokenby Kipnis andShamir [ 29] in1998. The\nmodified version of the scheme named UOV was then proposed by\nKipnisetal.[ 28]in1999.Themaindifferencewastounbalancethe\nnumberofoilandvinegarvariablesbyincreasingthenumberof\nvinegar variables to render the attack ineffective.\n2.3 LUOV\nThe public keys of UOV are prohibitively large to prevent wide-\nscaledeployment.ThismotivatedanotherproposalnamedLUOV\nby Beullens et al. [ 2]. LUOV was submitted to NIST for the PQC\nstandardizationprocessandiscurrentlycompetinginRound2.One\nof the main innovation of LUOV is to reduce the large key sizes\ninUOVinthewaythatkeysaregeneratedandstored.Insteadof\nstoringandtransferringlargepublickeyseverytime,LUOVmakes\nuseof theideathatgenerating thekeyswhenever needed usinga\nsponge type hash function and using a private seed for the privatekeyandpublicseedandadditional 𝑄2∈F𝑚×𝑚(𝑚+1)/2\n2matrixfor\nthepublickey.HerewegiveabriefdescriptionoftheLUOVscheme.\nAdetaileddescriptionandsupportingdocumentationcanbefound\nin [3].\n2.3.1Key Generation. process is depicted in Figure 1. Briefly,\n𝑝𝑟𝑖𝑣𝑎𝑡𝑒_𝑠𝑒𝑒𝑑is hashed by a sponge type hash function Hgenerat-\ning𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑and𝑣×𝑚private binary secret linear transforma-\ntion matrix T. Another hash function Ggenerates public parame-\nters𝐶∈F𝑚\n2,𝐿∈F𝑚×𝑛\n2and𝑄1∈F𝑚×𝑣(𝑣+1)/2+𝑣𝑚\n2by hashing the\n𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑.A𝑣×𝑣uppertriangularmatrix 𝑃𝑘\n1and𝑣×𝑚matrix𝑃𝑘\n2\naregeneratedby 𝑓𝑖𝑛𝑑𝑃𝑘\n1and𝑓𝑖𝑛𝑑𝑃𝑘\n2algorithmsrespectivelyusing\n𝑄1andanintegercounter 𝑘.Thedetailsofthealgorithmscanbe\nfound in [ 3]. In this work, we do not need the details of generation\nof𝑃𝑘\n1and𝑃𝑘\n2, hence, we will consider 𝑃𝑘\n1and𝑃𝑘\n2as given fixed\nrandom binary matrices. 𝑃𝑘\n1and𝑃𝑘\n2are given as:\n𝑃𝑘\n1=/parenlefttpA/parenleftexA/parenleftexA/parenleftexA/parenleftexA/parenleftexA\n/parenleftbtA𝑎\n𝑘\n1,1𝑎𝑘\n1,2···𝑎𝑘\n1,𝑣\n0𝑎𝑘\n2,2···𝑎𝑘\n2,𝑣\n............\n00 ···𝑎\n𝑘𝑣,𝑣/parenrighttpA/parenrightexA/parenrightexA/parenrightexA/parenrightexA/parenrightexA\n/parenrightbtA\n𝑣,𝑣,𝑃𝑘\n2=/parenlefttpA/parenleftexA/parenleftexA/parenleftexA/parenleftexA/parenleftexA\n/parenleftbtA𝑏\n𝑘\n1,1𝑏𝑘\n1,2···𝑏𝑘\n1,𝑚\n𝑏𝑘\n2,1𝑏𝑘\n2,2···𝑏𝑘\n2,𝑚\n............\n𝑏\n𝑘\n𝑣,1𝑏𝑘\n𝑣,2···𝑏𝑘𝑣,𝑚/parenrighttpA/parenrightexA/parenrightexA/parenrightexA/parenrightexA/parenrightexA\n/parenrightbtA\n𝑣,𝑚\nIntermediate 𝑚×𝑚matrix𝑃𝑘\n3is generated by the formula 𝑃𝑘\n3=\n−𝑇𝑇𝑃𝑘\n1𝑇+𝑇𝑇𝑃𝑘\n2where𝑘=1,...,𝑚. Therefore, (𝑖,𝑗)𝑡ℎelement of\n𝑃𝑘\n3is\n𝑝𝑘\n3(𝑖,𝑗)=𝑣/summationdisplay.1\n𝛼=1𝑡𝛼,𝑗𝛼/summationdisplay.1\n𝑙=1𝑡𝑙,𝑖𝑎𝑙,𝛼+𝑣/summationdisplay.1\n𝛾=1𝑡𝛾,𝑖𝑏𝛾,𝑗for𝑖,𝑗∈{1,···,𝑚}.(3)\n𝑚×𝑚/dotacc(𝑚+1)\n2binarypublickeymatrix 𝑄2isgeneratedbyEquation4.\nIt is important to emphasize that 𝑃𝑘\n3constitutes the 𝑘𝑡ℎrow of𝑄2.\n𝑄2(𝑘,𝛽𝑖,𝑗)=/braceleftBigg\n𝑝𝑘\n3(𝑖,𝑗) ,𝑖=𝑗\n𝑝𝑘\n3(𝑖,𝑗)⊕𝑝𝑘\n3(𝑗,𝑖),𝑖<𝑗(4)\nwhere𝛽𝑖,𝑗=(𝑖−1)𝑚+𝑗−/summationtext.1𝑖−1\n𝛼=0𝛼,𝑖,𝑗,𝑘∈{1,···,𝑚}and𝛽𝑖,𝑗=\n1,...,𝑚(𝑚+1)/2.\nFor instance the k𝑡ℎrow of𝑄2is of the following form:\n(𝑝𝑘\n3(1,1),𝑝𝑘\n3(1,2)⊕𝑝𝑘\n3(2,1),𝑝𝑘\n3(1,3)⊕𝑝𝑘\n3(3,1),···,𝑝𝑘\n3(2,2),\n𝑝𝑘\n3(2,3)⊕𝑝𝑘\n3(3,2),···,𝑝𝑘\n3(3,3),···,𝑝𝑘\n3(𝑚,𝑚)).\nKey generation algorithm outputs 𝑝𝑟𝑖𝑣𝑎𝑡𝑒_𝑠𝑒𝑒𝑑as the private key\nand𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑and𝑄2asthepublickey.Publicmap Pneededfor\nsignature verification is the concatenation of 𝐶,𝐿,𝑄1and𝑄2.\n2.3.2SignatureGeneration. primitiveofLUOVisshowninFig-\nure2andexplainedinAlgorithm1whichisdividedintofourparts,\nParameter Generation,AugmentedMatrix Generation, Gaussian\nElimination and Generation of the Signature for the sake of sim-plicity. It is important to note that\n𝑜is publicly available in the\nsignature. Therefore, it is known to the adversary.\n2.3.3SignatureVerification. Theverifiergenerates 𝐶,𝐿and𝑄1\nfrom the𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑using the hash function G. These parts are\nthen combined with the publicly available 𝑄2to form the public\nmapP. Similar to the signing algorithm, the message 𝑀and the\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1074ܳଵ^ƉŽŶŐĞ\u0003dǇƉĞ\u0003\n,ĂƐŚ\u0003\n&ƵŶĐƚŝŽŶ\n݁ݐܽݒ݅ݎ݌࣢\nܥ݀݁݁ݏ ǡܮ\n࣮\u0003݂ܲ݀݊݅ଵ௞\n݂ܲ݀݊݅ଶ௞ܲଷ௞ ܲଷ௞ൌ்ܶܲଵ௞ܶ൅்ܶܲଶ௞ܳଶ݈ܾܿ݅ݑ݌̴݀݁݁ݏ݈ܾܿ݅ݑ݌ \n݀݁݁ݏ࣡\nWƌŝǀĂƚĞ\u0003<ĞǇ\n݁ݐܽݒ݅ݎ݌̴݀݁݁ݏWƵďůŝĐ\u0003<ĞǇ\n\u0003ܳଶ\n݈ܾܿ݅ݑ݌̴݀݁݁ݏ\nFigure 1: LUOV public and private key generation processes.\nFigure 2: Signature generation algorithm explained in four steps.\nAlgorithm 1 LUOV Signature Generation\nInput:𝑝𝑟𝑖𝑣𝑎𝑡𝑒_𝑠𝑒𝑒𝑑, Message 𝑀\nOutput:Signature (𝑆||𝑠𝑎𝑙𝑡)\n1:Parameter Generation: Binary linear transformation Tand\n𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑aregeneratedbythehashofrandom 𝑝𝑟𝑖𝑣𝑎𝑡𝑒_𝑠𝑒𝑒𝑑.\nThen,thehashof 𝑝𝑢𝑏𝑙𝑖𝑐_𝑠𝑒𝑒𝑑outputs𝐶,𝐿and𝑄1.Concatena-\ntionofmessage 𝑀andarandom 𝑠𝑎𝑙𝑡hashedby Hproduces\nmessageℎto be signed.\n2:Augmented Matrix Generation: Insert randomly chosen\nvinegar variables 𝑣into theMQ system F(𝑠/prime)=ℎwhich col-\nlapses to a linear system. The augmented matrix generation\nalgorithm is explained in 9.\n3:Gaussian Elimination: Linear system can be easily solved\nby Gaussian elimination which gives oil variables 𝑜. Note that,\noil variables depend on ℎand𝑣since the other parameters are\ngenerated by the same 𝑝𝑟𝑖𝑣𝑎𝑡𝑒_𝑠𝑒𝑒𝑑.\n4:Generation of the Signature: Signature 𝑆is the concatena-\ntion of𝑠=T·𝑜+𝑣,𝑜and𝑠𝑎𝑙𝑡.\nreturn(𝑠||𝑜||𝑠𝑎𝑙𝑡)\n𝑠𝑎𝑙𝑡are concatenated, then hashed using Hto form the digest ℎ.I f\nP(𝑠)=ℎ, then the signature is verified, otherwise rejected.\n3 A NOVEL BIT-TRACING ATTACK ON LUOV\nInthissectionweoutlineanovelfaultinjectionattackonLUOV.\nTheattacksucceedsinefficientlyrecoveringsecretkeybitsfrom\nfaulty signatures whereas faults may be injected through software\nonly Rowhammer attack. The attack consists of three main phases,\npre-processing, online and post-processing phase.\nThepre-processingphasewhichincludestemplating,needstobe\ncarried out on the same machine on which victim will be running.\nThe purpose of this phase is to collect the physical addresses of\nthe memory locations susceptible to Rowhammer. The victim does\nnot need to be present or running in the pre-processing phase. The\nvictim can then be placed at those addresses in the online phase\nwhen the victim process starts running. In the online phase thevictimisfirstforcedtobeplacedatthetargetaddressesandthen\ntheRowhammer attackinduces bitflipsin aparticular areaofthe\nvictim while the victim is carrying out the signing operations. This\ncauses the victim to generate faulty signatures which are public\nandcollectedbytheattacker.Aftercollectinganumberoffaulty\nsignatures,ournovelbittracingalgorithmiscarriedoutinthepost-\nprocessing phase which can be done offline on any other machine\nor cluster.\nThe DRAM modules installed in the system are susceptible to\nRowhammer attack. The attacker and victim processes are co-\nlocatedonthesameDRAMchip.Theattackercaninducebitflipsin\nthe linear transformation Tof LUOV scheme and is able to collect\nthe faulty signatures. The attacker has no control or knowledge\noverthepositionofthebitflipswithin TandtheTmatrixishuge\ne.g. 11,229 bits for LUOV-7-57-197 [ 44]. Also, the attacker does not\nknow the value of the flipped bit. The target of the attacker is to\ntracebacktothepositionoftheflippedbitaswellastorecoverthe\nvalueofthebitbyjustusingthefaultysignatures.Theattackerhas\nnoknowledgeofthecorrectsignaturesandcanonlyusethepublic\nparameters to perform the attack. Moreover, the attacker is not\nusing huge pages for contiguous memory. Also, she does not have\nany knowledge of the DRAM mappings which convert physical ad-\ndresses to DRAM ranks, banks, rows and columns. The bit-tracing\nis summarized in Figure 3 and then each step is explained in detail\nalong-with results.\n3.1 Pre-processing Phase (Templating)\nThepre-processing(templating)phaseoftheattackiscarriedout\nonthemachinewheretheattackerandthevictimareco-located,\nsharingthesameDRAMmodule.Thevictimdoesnotneedtobe\npresent or running in this phase. As double-sided Rowhammer\nrequirescontiguous chunkofphysicalmemory,weallocate a256\nMBytes buffer and look for an 8 MBytes of contiguous memory\nusingSpoiler[ 24].Afterthat,rowconflictsarefoundtoidentifythe\nvirtualaddressesmappedtothesameDRAMbank.Thisisachieved\nusing a side channel since the data coming from the same bank\nwill take longer as compared to the data coming from the other\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n10753UH\u0010SURFHVVLQJ\u00033KDVH\n\u000b7HPSODWLQJ\f2QOLQH\u00033KDVH\n\u000b5RZKDPPHU\u0003$WWDFN\f3RVW\u0010SURFHVVLQJ\u00033KDVH )DXOW\\\u0003VLJQDWXUHV 7DUJHW\u0003DGGUHVVHV\n\u0014\u0011\u0003&RQWLJXRXV\u0003PHPRU\\\u0003GHWHFWLRQ\n\u0015\u0011\u0003)LQGLQJ\u0003'5$0\u0003URZ\u0003FRQIOLFWV\u0016\u0011\u0003'RXEOH\u0010VLGHG\u00035RZKDPPHU\u0017\u0011\u0003)UHHLQJ\u0003WDUJHW\u0003DGGUHVVHV\u0014\u0011\u00033ODFLQJ\u0003YLFWLP\u0003DW\u0003IOLSS\\\u0003DGGUHVVHV\u0015\u0011\u0003'RXEOH\u0010VLGHG\u00035RZKDPPHU\n.H\\\u0003ELWV\nFigure 3: Phases of novel bit-tracing attack on LUOV\n0 20 40 60 80 100 120 140 160 180 200\nPage Number250300350400450Cycles\nFigure 4: Row conflicts for the pages from the detected con-\ntiguousmemory.Thehighertimingsindicatethatthepagesare mapped to the same DRAM bank which are the targetfor the Rowhammer attack.\nbanks. As the data from the row buffer needs to be copied backto the original row before the data from another row within the\nsame bank is loaded into the row buffer, it creates additional delay.\nThe measurements are shown in Figure 4 and a threshold value of\n380 cyclesis set inour experiments. Thisthreshold value mayvary\nfrom one machine to another.\n0123456789 1 0\nNumber of Hammers 107050100150200250 Number of Bit Flips10 flips\n01 flips\nTotal flips\nFigure 5: Number of bit flips increases with the increase in\nnumber of hammers. The experiment is repeated 30 timesfor each number of hammers on an 8 MBytes contiguouschunk of memory and the results are then averaged out.\nOncewefindthevirtualaddressesmappedtothesameDRAM\nbank, we start the process of double-sided Rowhammer to findtheDRAMrowssuitableforRowhammer.Wefound125rowsin8 MBytes of contiguous memory which are mapped to the same\nbank. Our results indicate that the rows in the DRAM are ordered\nsequentially if the targeted memory is contiguous. These rows are\nthen taken 3 at a time with aggressor rows on the sides and the\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0011\u0011\u0011\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\n\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0013\u0014\u0003\u0014\u0003\u0013\u0014\u0003\u0014\u0003\u0014\u0003\u0011\u0011\u0011\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003 \u0013\u0014\u0003\u0014\u0003\u0014\n\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0011\u0011\u0011\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\n\u0011\u0011\u0011\u0011\u0011\u0011\n\u000b\u0014ĺ\u0013\u0003ELW\u0003IOLSV\f$JJUHVVRU\u00035RZ\n$JJUHVVRU\u00035RZ9LFWLP\u00035RZ\n\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0011\u0011\u0011\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\n\u0013\u0003\u0013\u0003\u0013\u0003\u0014\u0013 \u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003 \u0014\u0013\u0003\u0011\u0011\u0011\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003 \u0014\u0013\u0003\u0013\u0003\u0013\u0003\u0013\u0003\u0013\n\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0011\u0011\u0011\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\u0003\u0014\n\u0011\u0011\u0011\u0011\u0011\u0011\n\u000b\u0013ĺ\u0014\u0003ELW\u0003IOLSV\f$JJUHVVRU\u00035RZ$JJUHVVRU\u00035RZ9LFWLP\u00035RZ\nFigure6:Double-sidedRowhammerwithdifferentdatapat-\nterns. If the attacker rows are filled with all zeros, the bitflips occur in\n1− →0direction and if the attacker rows are\nfilled with all ones, the bits are flipped from 0− →1. This\nstrategyhelpstorecoverthevaluesofthebitpositionsof T\ntraced by the bit-tracing attack.\nvictim row in the middle and aggressor rows are accessed (ham-\nmered) repeatedly to get flips in the victim row. The number of bit\nflips found within this contiguous chunk can be seen in Figure 5against the number of hammers. It is observed that the number\nofbitflipsincreasewiththenumberofhammers.Tofindthesus-\nceptible memory locations in the pre-processing phase we set a\nvalue for number of hammers as 106. The other observation is that\nthere is not much difference between the number of 1 − →0 flips\nand 0− →1 flips. To achieve bidirectional flips, we fill the aggressor\nrows with all zeros and the victim row with all ones for 1 − →0 flips\nandaggressorrowswithallonesandthevictimwithallzerosfor\n0− →1 flips as explained in Figure 6.\nThefinalstepofthepre-processingphaseistofreethevulnerable\nmemory pages from the attacker process so that the victim can be\nplaced at that location for the online attack. We do this by using\n𝑚𝑢𝑛𝑚𝑎𝑝 instruction for every 8 KBytes row. As the bit flips are\nhighlyreproducible,Rowhammerwillflipthesamebitsagainbut\nin the victim process in the online phase.\nTheexperimentsarecarriedoutonaHaswellsystemwithDDR3\nmemory, running Ubuntu OS. 17,129 vulnerable physical addresses\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1076are found in 5.7 hours. These experiments are done repeatedly\nusing a script as 8 MBytes of contiguous memory is not enoughfor gathering these many addresses. So, 256 MBytes of memory\nisallocatedagainandagainoutofwhich8MBytesofcontiguous\nchunkisdetected.Eachchunkisthencheckedforallpossiblebit\nflips. A big single chunk of contiguous memory is hard to find in a\nlive system running various processes.\n3.2 Online Phase (Rowhammer attack)\nThe pre-processing phase gives a list of vulnerable physical ad-\ndresses andthe goalofthe onlinephase isto firstplace thetarget\nlinear transformation Tof LUOV scheme at one of those physical\naddressesandthendothedouble-sidedrowhammeragaintoget\nbit flips in T. For experimental purposes, we achieve this by keep\nallocatingmemorypagesforthe Twithinthevictimprocessuntil\nit either gets in one of the target addresses or one page next to a\ntarget address. This is because one DRAM row comprises 8 KBytes\nhaving two 4 KBytes pages and the size of the Tmatrix is less\nthan a 4 KBytes page. For LUOV-7-57-197, the size of the linear\ntransformationmatrix Tis(57×197)/8=1,404Bytes.Hence,if\nTgets in either of the two pages of the target row, we can start\ndoing the Rowhammer attack. This process is time consuming as a\nlarge number of memory pages are allocated until Tis mapped to\nthe desired target address.\nThe placement of victim can also be achieved by using other\ntechniquespresentintheliteraturelikespraying[ 22,39,46],groom-\ning [43] and memory-waylaying [ 21,31,47]. Figure 7 shows the\nnumberof Tbitsflippedagainsttime.Thenumberofbitflipsdo\nnot increase linearly with time as we start getting the same bitflips over and over again. Out of 25,335 bit flips, only 8,902 were\nunique in 16 hours of the online phase. We can see that in the first\nhour we get 1,334 bit flips, little less than a double in two hours\nand after that the bit flips are getting repeated more often. Still, we\nare able to recover approximately 80% of the Tbits in 16 hours.\nFigure8indicatesthenumberofbitflipspercolumnof Twhich\nwillbeusedbyQuantumHammerinSection4.Theworkingofthe\nattack is verified when the victim and attacker process are running\nindependently in different terminals but due to the system crashes,\nmemory constraints, disk errors and synchronization problems,\nthe attacker and the victim process are combined as we needed to\nrunthe experimentsforl6 hourscontinuously.For example,in a\n2GB memory in which only 25% memory is available in a running\nsystem,twoseparateprocessesstarttakingtheswappartition.This\nmakes the system slow and unresponsive.\n3.3 Post-processing Phase\nThe post-processing phase takes the faulty signatures collected\nin the online phase and is able to recover the key bits of T.W e\nconsider it a weakness of the LUOV scheme because the faulty\npublicsignaturesshouldnotleadbacktothesecretkeybitsof T.\nIntheLUOVscheme,if Tisrecovered,thesecretcentralmap F\ncan be easily computed using the public map P,a sP=F◦T.\nThus,recovering Tisenoughtobreaktheschemeandforgingany\nsignature. The bit-tracing algorithm can be executed offline on any\nother system or cluster independently.In the last stage of LUOV, there is a linear transformation T\nwhichgivesthesignatureastheoutput.Theintuitionbehindthe\nbit-tracing attack is to flip bits in Tand observe the effect on\nthe signature values. Once we get a faulty signature, the signature\nverificationalgorithmisutilizedasanoracletocorrectthesignature\nby iteratively modifying the faulty signature. When the correctsignature is found and the verification test is passed, bit-tracing\nalgorithm mathematically tracks back to the flipped bit and is able\ntogetinformationaboutthepositionoftheflippedbit.Byfilling\ntheattackerrowswithallonesandthevictimrowwithallzeros,\nwe can tell that the flipped bit was a zero or vice versa.\nWe target the last part of the signature generation algorithm of\nLUOVwhichisalineartransformation 𝑠𝑣×1=T𝑣×𝑚×𝑜𝑚×1⊕𝑣𝑣×1\nor in the matrix form as Equation 5.\n⎡⎢⎢⎢⎢⎢⎣𝑠\n1\n...\n𝑠𝑣⎤⎥⎥⎥⎥⎥⎦=⎡⎢⎢⎢⎢⎢⎣𝑡\n11... 𝑡1𝑚\n.........\n𝑡\n𝑣1... 𝑡𝑣𝑚⎤⎥⎥⎥⎥⎥⎦×⎡⎢⎢⎢⎢⎢⎣𝑜\n1\n...\n𝑜𝑚⎤⎥⎥⎥⎥⎥⎦⊕⎡⎢⎢⎢⎢⎢⎣𝑣\n1\n...\n𝑣𝑣⎤⎥⎥⎥⎥⎥⎦(5)\nOurbit-tracingalgorithmforLUOVisgivenin2whichtakes 𝑣×\n𝑚signatureverificationstotrace1bitof Tfor1bitflip.Theinputs\ntothealgorithmareallpublicparameters:1)thefaultysignature\n𝑆whichwegetafterflippingthebitusingRowhammerattack,2)\nthemessage 𝑀,3)publicmap P.Thealgorithmfindsthecorrect\nsignaturebyreplacingeachelementof 𝑠withtheXORofitselfand\neach element of the oil variables. On successful verification, the\nindexesofthebitflip (𝑟,𝑐)inTarereturnedwhichindicatesthe\nbit flip position in T.\nAlgorithm 2 Bit-tracing algorithm for LUOV - Offline\n1:procedure Tracebit( 𝑆,𝑠𝑎𝑙𝑡)\nInput:(𝑆,𝑠𝑎𝑙𝑡) ⊲Faulty signature\n𝑀- Message , P- Public map\nOutput:Returns(𝑟,𝑐)⊲Recovered bit flip position in T\n2:ℎ←−H(𝑀||0𝑥00||𝑠𝑎𝑙𝑡)\n3:for𝑟from1tovdo\n4: for𝑐from1tomdo\n5: 𝑆[𝑟]←−𝑆[𝑟]⊕𝑆[𝑐+𝑣]\n6: if𝑃(𝑆)≠ℎthen\n7: 𝑆[𝑟]←−𝑆[𝑟]⊕𝑆[𝑐+𝑣]\n8: else\n9: return𝑟,𝑐\n10: break\n11: end if\n12: end for\n13:end for\n14:end procedure\nIf there is a bit flip somewhere in T, say at index (𝑟,𝑐), multipli-\ncation of𝑟𝑡ℎrow ofTand𝑜results in a difference in 𝑠which is𝑜𝑐\nat the term 𝑠𝑐.A st h e𝑜and𝑠are public, we can try all potential\ndifferenceswhicharetheelementsof 𝑜XORedwithallelements\nof the𝑠to check which one of the oil variable caused the error\ndue to a bit flip in T. We achieve this by replacing each element\nof𝑠with its XOR of all elements of 𝑜one by one and pass it to the\nsignature verification oracle. Once, the signature gets verified, we\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n10771 Hour\n1334 bits\n10 20 30 40 5020\n406080\n100120140160180Rows of T197 572 Hours\n2511 bits\n10 20 30 40 504 Hours\n4323 bits\n10 20 30 40 50\nColumns of T197 578 Hours\n6737 bits\n10 20 30 40 5016 Hours\n8902 bits\n10 20 30 40 50\nFigure7:OnlinephaseofRowhammerattack.Theplotdepictsthebitflipsinthe Tmatrixintheformofpixels,wherewhite\npixels indicate the flipped bits. Approximately 80% of the key bits are flipped in 16 hours.\n10 20 30 40 50\nColumn number of T197 5750100150Bits recovered per col of T197 5716h\n8h\n4h\n2h\n1h\nFigure 8: Number of bits recovered per column of Tin 16\nhours of online phase.\ngettheindexesoftheflippedbitin T,whichare (𝑟,𝑐).Thevalue\nof the bit can be recovered by knowing the direction of the bit flip.\nA0− →1 flip means that the key bit was originally 0 and a 1 − →0\nbitflipmeansthatthekeybitwas1.Theamountoftimeneeded\nfor this offline post processing bit-tracing algorithm is shown in\nTable 1 for all variants of LUOV AVX2 optimized implementations.\nFor 2-bit scenario, Algorithm 2 can be modified to recover 2 bits\nofTif𝑣×𝑚verifications fails to correct the signature. In this\nscenario,therearetwocases.Firstoneisthat2bitflipsareinthe\ndifferentrowsof Twhichrequiresustotakeallcombinationsof\nelements of 𝑠, 2 at a time which is/parenleftbig𝑣\n2/parenrightbig. For each combination, we\nneed𝑚2verificationsbyXORingbothelementsofthecombination\nwith all elements of 𝑜. The first scenario hence needs 𝑚2×/parenleftbig𝑣\n2/parenrightbig\nverifications. For 2 bit flips in the same row, the error is just in one\nelementof 𝑠.Foreachelementof 𝑠,weneedtoXORallcombinations\nof𝑜, 2 at a time with the element of 𝑠, until we find the correct\nsignature. This scenario requires 𝑣×/parenleftbig𝑚\n2/parenrightbigverifications. In total, we\nneed𝑣𝑚+𝑚2/parenleftbig𝑣\n2/parenrightbig+𝑣/parenleftbig𝑚\n2/parenrightbigsignature verifications for 1 bit and 2 bitscenarioscombined.Iftherearemultiplebitflipsin Tintheonline\nphase, they can be controlled by changing the data patterns in the\naggressor rows and turning on and off certain bit flips. We have\nsuccessfullytestedthismethodviaanindependentexperiment.Butfoundthatitincreasesthedurationoftheonlinephase.Itwasmore\nefficient to just ignore the rare cases of more than 2 bit flips.\nTable 1: Post computation times for bit-tracing attack, 2 on\nLUOV. This computation is done offline and can easily beparallelized and distributed. The measurements are takenon a single machine with a Skylake Intel Core i5-6440HQCPU@2.6GHzprocessor.Notethatthesetimingsarefor 𝑣×\n𝑚verifications which is the worst case scenario. In practice,\nthe bits are traced in fewer iterations depending upon theposition of the bit flip in T.\nImplementation LUOV Variant 1-bit Tracing\nOffline(Sec)\nAVX2 luov-7-57-197-chacha 1.58\nluov-7-57-197-keccak 11.44\nluov-7-83-283-chacha 10.46\nluov-7-83-283-keccak 58.22\nluov-7-110-374-chacha 35.19\nluov-7-110-374-keccak 239.34\nAVX2 luov-7-57-197-chacha 0.36\n(precompute) luov-7-57-197-keccak 0.36\nluov-7-83-283-chacha 1.64\nluov-7-83-283-keccak 1.63\nluov-7-110-374-chacha 4.98\nluov-7-110-374-keccak 4.99\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n10783.4 Performance\nTable1summarizesthetimeittakestoperformthepost-processing\ntime, i.e. the bit-tracing step. The computation is performed offline\nandcaneasilybeparallelizedsinceallthisstepdoesistosearchfor\nthe faultlocation usingthe faulty signature.Enabled byRowham-\nmer, the bit-tracing attack manages to effectively recover bits of\nT, the secret key matrix. Assuming single faults, each recovered\nsecret key bit requires a successful Rowhammer fault injection,\nwhichtakessignificantamountoftime,i.e.wegetabout23flipsper\nminuteonourtargetplatforminthefirsthour,whiletheflipping\nperformancedegradeswithtime,seeFigure5.Rememberthatfor\nLUOV-7-57-197 we have 11,229 key bits to recover. Recovering the\nentiresignaturekeybit-by-bitwouldtakemorethan16hoursof\nlive observation which is unrealistic.\nAlternatively, if we try to reduce the complexity of the LUOV\nMQequationsystemtoenableSATsolvingthenthebeststrategy\nwould be to target specific rows of Tusing Rowhammer. Using\neach fully recovered row, we can recover a vinegar variable. As\ntheoriginaloilandvinegarschemewithequalnumberofoiland\nvinegar variables already was shown to be breakable by Patarin,\nweneedtoeliminate 𝑣−𝑚variableswhichmeans 𝑣−𝑚rowsof\nTneedtoberecoveredusingRowhammerattack.Thisapproach\ntoo is costly.\nRather than trying to recover the entire key or to eliminate\nvinegar variables until the security collapses, we introduce a novel\nattack,i.e.,QuantumHammerasdescribedinthefollowingsection,\nthat uses the bit-tracing attack as an oracle.\n4 QUANTUMHAMMER\nWepresentQuantumHammerattackthatsignificantlyreducesthe\ncomplexity to the LUOV MQ system by splitting it into smaller\nMQ problems. This is achieved by using the bit-tracing attack as\nan oracle to recover a small number of specifically chosen key bits.\nOverall attack complexity is drastically reduced compared to an\nattackthatonlyusesbit-tracing.Nextwedelveintothedetailsof\ntheLUOVconstruction.Specificallyweanalyzethekeygeneration\nprocess to obtain a simpler formulation.\n4.1 Divide-and-Conquer Attack\nLet𝑀𝑄(𝑣,𝑚)and𝑀𝐿(𝑣,𝑚)representsystemsof 𝑚quadraticand\n𝑚linearequationsof 𝑣unknowns,respectively.Ouraimistoattack\nkeygenerationpartofLUOVexplainedinSection2.3.1andrecoverbooleanprivatelineartransformationmatrix\nT.Thepublicparame-\nter𝑄2isgeneratedfromtheintermediate 𝑚×𝑚thebooleanmatrix\n𝑃𝑘\n3byEquation4. 𝑃𝑘\n3isformulatedintermsof 𝑃𝑘\n1,𝑃𝑘\n2andTwhere\n𝑃𝑘\n1and𝑃𝑘\n2are publicly re-generatable from public parameter 𝑄1.\nTherefore,foradirectattack,weneedtosolvea 𝑀𝑄(𝑣·𝑚,𝑚3+𝑚2\n2)\nin which equations are from Equation 4 and unknowns are the\nelementsof T.FortheNISTRound2submissionLUOV-7-57-197,\nwithparameters 𝑚=57and𝑣=197solvingtheoverallquadratic\nsystem appears infeasible unless there is a major breakthrough.\nInstead of trying to attack the 𝑚𝑣-bit secret key matrix Tas\na whole, or recovering some part of Tby bit-tracing attack and\napplying exhaustive search to the rest, we gain a more powerful\nattack, QuantumHammer, by exploiting the relation between thepublic matrices 𝑃𝑘\n1,𝑃𝑘\n2,𝑄2, where𝑘from 1 to𝑚and private linear\ntransformation matrix T(remember the LUOV key generation\nprocess in Figure 1).\nWe start by making some observations on the structure of 𝑄2.\n4.2 Observations on the structure of 𝑄2\nEventhough 𝑄2yieldsalarge 𝑀𝑄(𝑣·𝑚,𝑚3+𝑚2\n2)system,onecan\ndivide𝑄2columnbycolumnandconsideritasasetofcombination\nof discrete,smaller MQ systemsin terms of columnsof T, i.e.,set\nof𝑀𝑄(𝑣,𝑚)and𝑀𝑄(2𝑣,𝑚)systemsbyEquation4andEquation3.\nAssuming bit-tracing attack recovers 𝑥bits from a column of T,\nitispossibletoreducetherelatedsystemsintooneof 𝑀𝑄(𝑣−𝑥,𝑚),\n𝑀𝐿(𝑣−𝑥,𝑚)and𝑀𝐿(𝑣,𝑚)systems. These equations have certain\nstructurethatwewishtoexploittorecovertheentire T,column\nby column. The following definitions and observations will lead us\nto divide and conquer attack:\n(1)DefineA𝑖asthesetof 𝑚equationsof 𝑣variables,𝑀𝑄(𝑣,𝑚)\nwhere equations are 𝑄2𝑘,𝛽𝑖,𝑖=𝑝𝑘\n3(𝑖,𝑖)for𝑘from 1 to𝑚and\nvariables are the 𝑖𝑡ℎcolumn of T, i.e.,𝑡1𝑖,···,𝑡𝑣𝑖.\n(2)Suppose𝑥elementsof 𝑖𝑡ℎcolumnof Tareknown/recovered.\nDefineA𝑖(𝑥)asareducedsystemof A𝑖byinsertingthe 𝑥\nrecovered bits into A𝑖. Note that, inserting 𝑥variables into\nA𝑖reduces the system to 𝑀𝑄(𝑣−𝑥,𝑚)from𝑀𝑄(𝑣,𝑚).\n(3)DefineB𝑖,𝑗asthesetof 𝑚equationsof2 𝑣variables,𝑀𝑄(2𝑣,𝑚)\nwhere the equations are 𝑄2(𝑘,𝛽𝑖,𝑗)=𝑝𝑘\n3(𝑖,𝑗)⊕𝑝𝑘\n3(𝑗,𝑖)for𝑘\nfrom 1 to𝑚and variables are the 𝑖𝑡ℎand𝑗𝑡ℎcolumns of T,\ni.e.,𝑡1𝑖,···,𝑡𝑣𝑖,𝑡1𝑗,···,𝑡𝑣𝑗.\n(4)Suppose𝑖𝑡ℎcolumnof T,i.e.𝑡1𝑖,···,𝑡𝑣𝑖,isknown.Inserting\nthese variables into B𝑖,𝑗reduces the system from quadratic\n𝑀𝑄(2𝑣,𝑚)system to a linear 𝑀𝐿(𝑣,𝑚)system, where the\nunknownsare 𝑡1𝑗,···,𝑡𝑣𝑗.Wedenotetheinsertionofthe 𝑖𝑡ℎ\ncolumnof TintoB𝑖,𝑗byB𝑖,𝑗(𝑡𝑖,0).Notethat,thisreduces\nthe hard problem 𝑀𝑄(2𝑣,𝑚)into underdetermined linear\n𝑀𝐿(𝑣,𝑚)system.\n(5)Suppose𝑥elementsofthe 𝑗𝑡ℎcolumnof Tandtheentire 𝑖𝑡ℎ\ncolumnof Tareknown.Insertingtheseknownvariablesinto\nB𝑖,𝑗reduces the system from 𝑀𝑄(2𝑣,𝑚)to𝑀𝐿(𝑣−𝑥,𝑚).\nThenewsystemisdenotedby B𝑖,𝑗(𝑡𝑖,𝑥).If𝑥≥𝑣−𝑚then\nthesystemreducestoanoverdeterminedlinearsystemfrom\nanunderdeterminedone.Therefore,thenewsystemhasa\nunique solution and is efficiently solvable.\n4.3 A Practical Divide and Conquer Attack\nWe are going to use bit-tracing attack as an oracle to recover some\nbitsofsomecolumninmatrix T.Informally,QuantumHammer\nproceeds as follows:\n4.3.1Bit-tracing(Section 3): Suppose𝑥bits in some column of\nTisenoughtoreduce 𝑀𝑄(𝑣,𝑚)systemintoasolvable 𝑀𝑄(𝑣−𝑥,𝑚)\nsystem. When 𝑥bits are recovered via bit-tracing in some column,\nwestopbit-tracingandrecoverthebitsasexplainedinSection3.\nApply bit-tracing attack, and recover bits of Tuntil the highest\nnumber of recovered bits from a column is 𝑣−𝑚. Pick the high-\nest/ceilingleftbig𝑣\n𝑚/ceilingrightbigcolumns. Assume the highest number of recovered bits\nare𝑥1,𝑥2,𝑥3and𝑥4bits in𝛼1,𝛼2,𝛼3and𝛼4𝑡ℎcolumns of T,\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1079respectively. Note that, bit-tracing recovers additional bits from\ndifferentcolumnsof T.But,having/ceilingleftbig𝑣\n𝑚/ceilingrightbig\ncolumnsof Tisenoughto\nreducetheMQsystemsintoMLsystemsandcanefficientlysolve\nit.Therefore,wedonotneedtousetheremainingbitsrecovered\nby bit-tracing in different columns of T.\nAlgorithm 3 Quadratic Steps\n1:procedure QuadSteps( (𝛼1,𝑥1),···,(𝛼𝜅,𝑥𝜅))\nInput:High recovered columns from Bit-tracing\nOutput: (𝑡𝛼𝑖,···,𝑡𝛼𝜅)⊲entire columns of input vectors\n2:A𝛼1(𝑥1)←𝑀𝑄_𝐺𝑒𝑛(𝛼1,𝑥1) ⊲5 in Appx\n3:𝑡𝛼1←𝐸𝑞𝑛_𝑆𝑜𝑙𝑣𝑒𝑟(A𝛼1(𝑥1),∅) ⊲7 in Appx\n4:for𝑖from2to𝜅=/ceilingleftbig𝑣\n𝑚/ceilingrightbig\ndo\n5: A𝛼𝑖(𝑥𝑖)←𝑀𝑄_𝐺𝑒𝑛(𝛼𝑖,𝑥𝑖). ⊲Quadratic Step\n6: for𝑗from1toi-1do\n7: B𝛼𝑖,𝛼𝑗(𝑥𝑖,𝑡𝑗)←𝑀𝐿_𝐺𝑒𝑛((𝛼𝑖,𝑥𝑖),(𝛼𝑗,𝑡𝑗))\n⊲6 in Appx\n8: end for\n9:𝑡𝑖←𝐸𝑞𝑛_𝑆𝑜𝑙𝑣𝑒𝑟(A𝛼𝑖(𝑥𝑖),/uniontext.1𝑖−1\n𝑗=1B𝛼𝑖,𝛼𝑗(𝑥𝑖,𝑡𝑗))\n10:end for\n11:end procedure\n4.3.2Quadratic Steps (Algorithm 3):\n(1)Consider A𝛼1, more specifically, consider the elements of\n𝛽𝛼1,𝛼1=(𝛼1−1)𝑚+𝛼1(𝛼1+1)\n2𝑡ℎcolumn of 𝑄2which are\n𝑝𝑘\n3(𝛼1,𝛼1)termsof𝑃𝑘\n3for𝑘from1to𝑚and𝛼1isthehighest\ncolumn of T. Inserting 𝑥1recovered bits into the system\nA𝛼1reducesthe 𝑀𝑄(𝑣,𝑚)systeminto 𝑀𝑄(𝑣−𝑥1,𝑚).W e\nrecover the remaining 𝑣−𝑥1elements of 𝛼1𝑡ℎcolumnT\nwhich are 𝑡1𝛼1,···,𝑡𝑣𝛼1.\n(2)Insertrecovered 𝛼1𝑡ℎcolumnof TintoB𝛼1,𝛼2and𝑥2recov-\nered bits of 𝛼2𝑡ℎcolumn of Tinto the systems B𝛼1,𝛼2and\nA𝛼2reducingthesystemsinto B𝛼1,𝛼2(𝑡𝛼1,𝑥2)andA𝛼2(𝑥2),\nrespectively. Thus, the system reduces to practically solv-\nable𝑀𝑄(𝑣−𝑥2,𝑚)/uniontext.1𝑀𝐿(𝑣−𝑥2,𝑚).Thesolutionofthere-\nduced system gives the full 𝛼2𝑛𝑑column of Twhich are\n𝑡1𝛼2,···,𝑡𝑣𝛼2.Notethat,eventhoughsolving 𝑀𝑄(𝑣−𝑥2,𝑚)\nisharderthansolving 𝑀𝑄(𝑣−𝑥1,𝑚),thereare 𝑚additional\nlinear equations from 𝑀𝐿(𝑣−𝑥2,𝑚)which decrease the\nnumberofunknownsfrom 𝑣−𝑥2to𝑣−𝑥2−𝑚.Therefore,\n𝑀𝑄(𝑣−𝑥2,𝑚)/uniontext.1𝑀𝐿(𝑣−𝑥2,𝑚)isamucheasiersystemto\nsolve than 𝑀𝑄(𝑣−𝑥1,𝑚).\n(3)Apply the same strategy to 𝛼3𝑡ℎcolumn of T, i.e., insert 𝛼1\nand𝛼2𝑡ℎcolumns of Twhich are recovered in the first two\nsteps, into the systems B𝛼1,𝛼3,B𝛼2,𝛼3andA𝛼3. The com-\nplexityreducesto B𝛼1,𝛼3(𝑡1,𝑥3)/uniontext.1B𝛼2,𝛼3(𝑡2,𝑥3)/uniontext.1A𝛼3(𝑥3).\nThus,thesystemreducesto 𝑀𝐿(𝑣−𝑥3,2𝑚)/uniontext.1𝑀𝑄(𝑣−𝑥3,𝑚)\nwhichhasthesolutionof 𝑥𝑡ℎ\n3unknownsfromthe 𝛼3column\nwhichare𝑡1𝛼3,···,𝑡𝑣𝛼3.Notethat,thesolutionofthesystem\nis equivalent to the solution of 𝑀𝑄(𝑣−𝑥3−2𝑚,𝑚)which\nis much easier than the previous steps.\n(4)The same strategy can be applied to recover 𝛼4𝑡ℎcolumn of\nTbyusingpreviouslyrecoveredcolumnsof Tinaddition\nto recovered 𝑥4bits of the 𝛼4𝑡ℎcolumn in bit-tracing attack.Inserting the known elements will reduce the complexity to\n𝑀𝐿(𝑣−𝑥4,3𝑚)/uniontext.1𝑀𝑄(𝑣−𝑥4,𝑚).Thisisasolvablesystem\nsince it is equivalent to 𝑀𝑄(𝑣−𝑥4−3𝑚,𝑚). The solution\ngives us𝛼4𝑡ℎcolumn elements 𝑡1𝛼3,···,𝑡𝑣𝛼3.\nAfter/ceilingleftbig𝑣\n𝑚/ceilingrightbigsteps,/ceilingleftbig𝑣\n𝑚/ceilingrightbigrecovered columns of Tare enough to\nreduce the smaller MQ systems of remaining columns into overde-\nterminedMLsystems.Inthefollowingsteps,wearegoingtoexplain\nhow one can reduce any small MQ system to a ML if/ceilingleftbig𝑣\n𝑚/ceilingrightbig\ncolumns\nare recovered.\nAlgorithm 4 Linear Steps\n1:procedure LinearSteps( (𝛼1,𝑡𝛼1),···,(𝛼𝜅,𝑡𝛼𝜅))\nInput:Recovered Columns\nOutput: (𝑡1,···,𝑡𝑚) ⊲columns of T\n2:for𝑖from1to𝑚do ⊲except{𝛼1,···,𝛼𝜅}\n3: for𝑗from1to𝜅do\n4: B𝑖,𝛼𝑗(∅,𝑡𝛼𝑗)←𝑀𝐿_𝐺𝑒𝑛((𝑖,∅),(𝛼𝑗,𝑡𝛼𝑗))\n⊲𝑀𝐿(𝑣,𝑚)\n5: end for\n6:𝑡𝑖←𝐸𝑞𝑛_𝑆𝑜𝑙𝑣𝑒𝑟(∅,/uniontext.1𝜅\n𝑗=1B𝑖,𝛼𝑗(0,𝑡𝛼𝑗))⊲𝑀𝐿(𝑣,𝜅·𝑚)\n7:end for\n8:return𝑡𝑖\n9:end procedure\n4.3.3LinearSteps(Algorithm4): Supposethereare/ceilingleftbig𝑣\n𝑚/ceilingrightbig\nrecov-\nered columns of Tfrom the quadratic steps. Inserting the bits of\nrecovered columns into the related systems will give us the follow-\ning reduced ML system:\n⌈𝑣\n𝑚⌉/uniondisplay.1\n𝑖=1B𝛼𝑖,𝛽(𝑡𝑖,0)\nwhere𝛼𝑖’s are the column numbers of recovered columns of T\nand𝛽isthecolumnnumberofattackedcolumnof T.Thisgives\nus an overdetermined 𝑀𝐿(𝑣,/ceilingleftbig𝑣\n𝑚/ceilingrightbig\n·𝑚)system which can be solved\nefficiently.\nNotethat,bythelinearsteps,wecanrecovertherestof Tcolumns\none by one in 𝑚−/ceilingleftbig𝑣\n𝑚/ceilingrightbig\nsteps.\n5 EXPERIMENTAL RESULTS\nTable 2: Exhaustive search timing for is different sizes for\n𝑀𝑄(𝑛,𝑛)taken on Nvidia GTX 1080Ti GPU.\n𝑛=𝑚Time𝑛=𝑚Time𝑛=𝑚Time\n40 2.7s 52 1h 32m 55 6h 15m\n43 12s 53 3h 3m 56 24h 45m\n49 11m 33s 54 3h 6m 57 49h 30m\nBit-tracing:\nWe have attacked the constant-time AVX2 optimized implementa-\ntion of LUOV-7-57-197 [ 44] on a Haswell system equipped with\nIntel Core i7-4770 CPU @ 3.40GHz, 2 GBytes DDR3 DRAM, model\nSamsung (M378B5773DH0-CH9). Pre-processing (templating) step\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1080is performed in 5.7 hours to find 17,129 physical addresses vulnera-\nbleto Rowhammer.After that,16hours ofonlinephase iscarried\noutinwhichthevictimisrunningandperformingsigningopera-\ntions.Usingbit-tracingattack,werecover4,116bitswith3hours\nand 49 minutes of online observation. The faulty signatures are\nprocessed offline on a separate machine to recover the key bits2.\nNote that the attack recovers up to 140 bits in any column of T\nwhich is enough for a successful QuantumHammer attack. The\ndistribution of the bits in the 57 columns of Tis given in Figure 9.\nSome columns of Thave been located in DRAM buffers that are\nmore flippy than others.\n140135 133 131\n5 1 01 52 02 53 03 54 04 55 05 5\nColumn number of T197 5750100150Bits recovered per col of T197 57 Attack Instance - 3h 49m\nHighest - Col 5\n2nd Highest - Col 23\n3rd Highest - Col 7\n4th Highest - Col 21\nFigure 9: Bit-tracing attack recovers up to 140 key bits per\ncolumn of Tin less than 4 hours of Rowhammer on a 2\nGBytes DDR3 Samsung DRAM (M378B5773DH0-CH9).\nQuadratic Steps:\nInpreparationforQuantumHammer, 𝑝𝑘\n3(𝑖,𝑗)weregeneratedby\nthe Equation 3 using the coefficients from 𝑃𝑘\n1and𝑃𝑘\n2. MQ systems\nare generatedby Equation4 using 𝑝𝑘\n3(𝑖,𝑗)equations. Tosolve the\ngenerated system of equations, we focused on/ceilingleftbig𝑣\n𝑚/ceilingrightbig\n=/ceilingleftbig197\n57/ceilingrightbig\n=4\ncolumns with the highest number of recovered bits: columns 5, 23,\n7 and 21 with 140, 135, 133 and 131 recovered bits, respectively. In\nevery step of quadratic and linear steps, we recover a column of T.\nExperimental results of quadratic steps are given in Table 3.\nItisimportanttonotethat,inthefirststep,werecoverthe5𝑡ℎ\ncolumnof T,bysolvinga 𝑀𝑄(57,57)systemreducedfromtheun-\nderdetermined 𝑀𝑄(197,57)thanksto140recoveredbitsobtained\nby the bit-tracing attack. Without it, it would not be possible to\nrecover the rest of the 5𝑡ℎcolumn. The system is solved by ex-\nhaustive search in roughly 49 hours on i7 Intel CPU with Nvidia\nGTX1080TiGPU.InTable2exhaustivesearchtimingfordifferent\nsizes of𝑀𝑄(𝑛,𝑛)is given. We used the GPU implementation of\n[7]compiledusingtheNvidiaCUDA10.0framework.Theoffline\nexhaustivesearchcanbetriviallyspedupbyemployingmultiple\nGPUs since the search is fully parallelizable.\nIn the second step, we targeted 23𝑟𝑑column with the 135 bits\nrecovered bits from bit-tracing. With these 135 bits, the system\nstarts out as 𝑀𝑄(62,57). Next, we insert the values obtained from\nthe 5𝑡ℎcolumn to reduce the complexity to 𝑀𝑄(5,57).W ec a n\ninstantly solve this system via exhaustive search. At this point, by\ninsertingtherecoveredbitsinthefirsttwosteps,wereducedthe\nremaining equations into (over-defined) linear systems only.\n2The source code for QuantumHammer is made available at http://github.com/\nVernamLab/QuantumHammer.Linear Steps:\nInthequadraticsteps,werecovered4columnsof T.Insertingthese\nvalues into remaining equations will give us an under determined\n𝑀𝐿(197,57)system. We end up with 228 linear equations with 197\nunknowns which can be solved via Gaussian elimination. Even\nthough we can generate more linear equations by using more bits\nofTpreviouslyrecoveredbybit-tracing,wedonotneedanyextra\nequationstosolvethesystem.In53steps,alltheremainingcolumns\nofTare recovered as summarized in Table 4.\n6 COUNTERMEASURES\nThe effectiveness of QuantumHammer requires us to consider\npractical countermeasures at various levels:\nPreventingRowhammer: Themosteffectivesolutiontoprevent\nany Rowhammer fault-injection attack is to implement stronger\nisolation,suchasusingdedicatedinstancesforanysensitivepro-\ncesses. If isolation is not possible, an effective alternative approach\nto reduce the impact of Rowhammer is increasing the DRAM row\nrefreshrate.DDR3andDDR4refresheachrowatleastevery64ms.\nThat said many systems permit the refresh rates at 32 or 16 ms for\nbetter memory stability.OnlineDetectionofRowhammer:\nOnemayalsoseektoemploy\nactive countermeasures for online detection of Rowhammer. For\nthis, Hardware Performance Counters (HPCs) can be used to moni-\ntorcounterslikecachehitsandcachemissestodetectRowhammer.\nSuppressing Faulty Signatures: Another way to counter faults\ninthesignatureschemesistoverifythesignaturesatsenderside\nbefore sending it but that will involve additional processing. A\nfaster approach can be to repeat the final linear transformation\nstage of the signing operation with an independently generated T\nandcheckifthesignaturesareidentical.Clearly,inthiscaseone\nmust ensure that the checking mechanism itself does not become a\ntarget itself.\n7 DISCUSSION\nThe first algebraic attack targeting UOV type schemes which does\nnot require any physical access is Reconciliation attack introduced\nby Ding et al. [ 14]. The attack aims to invert the public map. De-\ncomposing the public map Pinto the multiplication of a series\nof specific linear transformations allows the attacker to recover\nevery transformation one-by-one by exhaustive search algorithms\nsuch as F4/F5 or FXL. The result is a purely algebraic attack that\nsignificantly reduces the assumed security margin of LUOV.\nIntheDivide-and-ConquerAttack,wefollowasimilarapproach\ninthesensethatweexploitoneoftheinnovationsofLUOV,i.e.the\nstructureofthepublickey 𝑄2.BeingempoweredbyRowhammer\nandthebit-tracingattack,wetaketheattackfurtherintofullrecov-\neryofallkeybits.ThisisachievedbyconvertingtheMQsystem\ninto smaller under-determined MQ systems which are in the same\nformastheoriginalMQsystem.Insteadofdecomposingthematrix,\nweregroup theequationsintoa discretesetofvariables. Without\nthe amplification of the fault attack, it would not be possible to\nsolve the smallerMQ systems since theyare underdetermined. In\nthissense,ouroverallQuantumHammerattackrepresentanovel\napproach.\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1081Table 3: Quadratic steps in our experimental QuantumHammer on LUOV-7-57-197. In every step, table lists the targeted\ncolumn of T, number of recovered bits during bit-tracing, size of ML system obtained after inserting previously recovered\ncolumns, complexity of the solution for the linear part, number of linear equations and unknowns, parameters for the qua-\ndratic part, and the complexity of the overall system after using ML to reduce the unknowns in quadratic part.\nStepTarget\nColNum.\nof\nRec.\nbitsLinear Part Quadratic Part\nOverallComplexity Insrtd\nColEquationSystemComplexityML SystemEquationSystemComplexityMQ System\nLinear\nEqnsUnk QuadEqnsUnk\n15140 -- - --A5(140)𝑀𝑄(57,57)5757𝑀𝑄(57,57)\n223135 5B5,23(197,135)𝑀𝐿(62,57)5762A23(135)𝑀𝑄(62,57)562𝑀𝑄(5,57)\n371335B5,7(197,133)𝑀𝐿(64,57)11464A7(133)𝑀𝑄(64,57)5764𝑀𝐿(64,114)23B23,7(197,133)𝑀𝐿(64,57)\n4211315B5,21(197,131)𝑀𝐿(66,57)\n17166A21(131)𝑀𝑄(66,57)5766𝑀𝐿(66,171) 23B23,21(197,131)𝑀𝐿(66,57)\n7B7,21(197,131)𝑀𝐿(66,57)\nTable4:LinearstepsinourexperimentalQuantumHammeronLUOV-7-57-197.Ineverystep,tableliststhetargetedcolumn\nofT,insertedcolumnsusedtogenerateMLsystem,andresultantequationsystems,thesizeofthegeneratedMLsystems,and\nthe number of equations and unknowns in the overall linear system and overall complexity are given.\nStepNmbrTarget\nColLinear PartOverall\nComplexityInserted\nColEquation\nSystemEquivalent\nSystemML System\nLinear Equations Unknowns\n5 15B5,1(197,0)𝑀𝐿(197,57)\n228 197𝑀𝐿(197,228)23B23,1(197,0)𝑀𝐿(197,57)\n7B7,1(197,0)𝑀𝐿(197,57)\n21B21,1(197,0)𝑀𝐿(197,57)\n...... ... ......\n57 575B5,57(197,0)𝑀𝐿(197,57)\n228 197𝑀𝐿(197,228)23B23,57(197,0)𝑀𝐿(197,57)\n7B7,57(197,0)𝑀𝐿(197,57)\n21B21,57(197,0)𝑀𝐿(197,57)\nPreventing Algebraic Collapse: What enables QuantumHam-\nmeristhattheMQequationsuseasmallsubsetofthekeybitsin\nthewaythekeygenerationprimitiveisdefinedforLUOV.Hence,\nrecovering a small fraction of the key bits via Rowhammer and\nthebit-tracingattackwassufficienttocollapsetheMQsystemto\nsmaller size tractable MQ systems. In many scenarios, a small frac-\ntion of the key bits may be recovered using side-channel attacks.\nHence this attack poses a serious threat to real-life deployments.\nTopreventsuchcollapseitwouldbeprudenttochecktheresulting\nMQ system underlying the security of the scheme at design time\nunder the assumption that any fixed size subset of the key bits are\ncompromised.\n8 CONCLUSION\nRowhammerattackcanleadtoseriousconsequencesbyflipping\nbits in other processes and leaking key information. Post-quantum\nschemesareexpectedtoreplacetheexistingpublic-keyschemesinnearfuture.Thisresearchshowsthatbothhardwareandcrypto-\ngraphicsecurityareofutmostimportanceforcryptosystems.LUOV\nsignature scheme, currently in round two of NIST’s PQC standard-\nization process is based on the well known oil and vinegar scheme\nwhichwithstoodovertwodecadesofcryptanalysis.Wehaveana-\nlyzed the scheme both mathematically and implementation wise\nand found weaknesses in both areas. The QuantumHammerattack\ncombinesbothweaknessestolaunchasuccessfulattackrecovering\nthe full secret key of the scheme. There is a need to evaluate the\nhardwareandsoftwareimplementationsofthecryptosystemsin\ncombination with the mathematical evaluation.\nACKNOWLEDGMENTS\nWe thank our anonymous reviewers for their insightful comments\nfor improving the quality of this paper. This work is supportedby U.S. Department of State, Bureau of Educational and Cultural\nAffair’s Fulbright Program and by the National Science Foundation\nunder grant CNS-1814406.\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1082REFERENCES\n[1]Gorjan Alagic, Gorjan Alagic, Jacob Alperin-Sheriff, Daniel Apon, David Cooper,\nQuynhDang,Yi-KaiLiu,CarlMiller,DustinMoody,RenePeralta,etal .2019.Sta-\ntusreportonthefirstroundoftheNISTpost-quantumcryptographystandardization\nprocess. US Department of Commerce, NIST.\n[2]Ward Beullens and Bart Preneel. 2017. Field lifting for smaller UOV public keys.\nInInternational Conference on Cryptology in India. Springer, 227–246.\n[3]WardBeullens,AlanSzepieniec,FrederikVercauteren,andBartPreneel.2017.\nLUOV: Signature scheme proposal for NIST PQC project. (2017).\n[4]Nina Bindel, Johannes Buchmann, and Juliane Krämer. 2016. Lattice-based\nsignatureschemesandtheirsensitivitytofaultattacks.In 2016WorkshoponFault\nDiagnosis and Tolerance in Cryptography (FDTC). IEEE, 63–77.\n[5]Dan Boneh, Richard A. DeMillo, and Richard J. Lipton. 1997. On the Importance\nof Checking Cryptographic Protocols for Faults. In Advances in Cryptology —\nEUROCRYPT ’97, Walter Fumy (Ed.). Springer, 37–51.\n[6]Jonathan Bootle, Claire Delaplace, Thomas Espitau, Pierre-Alain Fouque, and\nMehdi Tibouchi. 2018. LWE without modular reduction and improved side-channel attacks against BLISS. In International Conference on the Theory and\nApplication of Cryptology and Information Security. Springer, 494–524.\n[7]Charles Bouillaguet, Hsieh-Chung Chen, Chen-Mou Cheng, Tung Chou, Ruben\nNiederhagen, Adi Shamir, and Bo-Yin Yang. 2010. Fast Exhaustive Search forPolynomial Systems in\nF2.I nCryptographic Hardware and Embedded Systems,\nCHES 2010, Stefan Mangard and François-Xavier Standaert (Eds.). Springer, 203–\n218.\n[8]Leon Groot Bruinderink, Andreas Hülsing, Tanja Lange, and Yuval Yarom. 2016.\nFlush, Gauss, and Reload–a cache attack on the BLISS lattice-based signature\nscheme. In Cryptographic Hardware and Embedded Systems. Springer, 323–345.\n[9]Leon Groot Bruinderink and Peter Pessl. 2018. Differential fault attacks on\ndeterministiclatticesignatures. IACRTransactionsonCryptographicHardware\nand Embedded Systems (2018), 21–43.\n[10]Lucian Cojocar, Jeremie Kim, Minesh Patel, Lillian Tsai, Stefan Saroiu, Alec\nWolman,andOnurMutlu.2020. AreWeSusceptibletoRowhammer?AnEnd-to-\nEnd Methodology for Cloud Providers. arXiv:2003.04498 [cs.CR]\n[11]LucianCojocar,KavehRazavi,CristianoGiuffrida,andHerbertBos.2019. Exploit-\ningcorrectingcodes:Ontheeffectivenessofeccmemoryagainstrowhammer\nattacks. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 55–71.\n[12]Jan-Pieter D’Anvers, Marcel Tiepelt, Frederik Vercauteren, and Ingrid Ver-bauwhede. 2019. Timing attacks on Error Correcting Codes in Post-Quantum\nSecure Schemes. IACR Cryptology ePrint Archive 2019 (2019), 292.\n[13]Jintai Ding, Joshua Deaton, Kurt Schmidt, Vishakha, and Zheng Zhang. 2019.\nCryptanalysis of The Lifted Unbalanced Oil Vinegar Signature Scheme. Cryptol-\nogy ePrint Archive, Report 2019/1490. https://eprint.iacr.org/2019/1490.\n[14]JintaiDing,Bo-YinYang,Chia-HsinOwenChen,Ming-ShingChen,andChen-\nMou Cheng. 2008. New Differential-Algebraic Attacks and Reparametrization of\nRainbow. In Applied Cryptography and Network Security. Springer, 242–257.\n[15]JintaiDing,ZhengZhang,JoshuaDeaton,KurtSchmidt,andFVishakha.2019.\nNewattacksonliftedunbalancedoilvinegar.In The2ndNISTPQCStandardization\nConference.\n[16]T. Espitau, P. Fouque, B. Gérard, and M. Tibouchi. 2018. Loop-Abort FaultsonLattice-BasedSignatureSchemesandKeyExchangeProtocols. IEEETrans.\nComput.67, 11 (2018), 1535–1549.\n[17]Thomas Espitau, Pierre-Alain Fouque, Benoît Gérard, and Mehdi Tibouchi. 2017.\nSide-channelattacksonBLISSlattice-basedsignatures:Exploitingbranchtracing\nagainst strongswan and electromagnetic emanations in microcontrollers. In\nProceedingsofthe2017ACMSIGSACConferenceonComputerandCommunications\nSecurity. 1857–1874.\n[18]P. Frigo, E. Vannacc, H. Hassan, V. der Veen, O. Mutlu, C. Giuffrida, H. Bos, and\nK.Razavi.2020. TRRespass:ExploitingtheManySidesofTargetRowRefresh.In\n2020 IEEE Symposium on Security and Privacy (SP). 747–762.\n[19]Aymeric Genêt, Matthias J Kannwischer, Hervé Pelletier, and Andrew McLauch-\nlan. 2018. Practical Fault Injection Attacks on SPHINCS. IACR Cryptology ePrint\nArchive2018 (2018), 674.\n[20]LovKGrover.1996. Afastquantummechanicalalgorithmfordatabasesearch.\narXiv preprint quant-ph/9605043 (1996).\n[21]DanielGruss,MoritzLipp,MichaelSchwarz,DanielGenkin,JonasJuffinger,Sioli\nO’Connell, Wolfgang Schoechl, and Yuval Yarom. 2018. Another flip in the wall\nof Rowhammer defenses. In 2018 IEEE Symposium on Security and Privacy (S&P).\n245–261.\n[22]DanielGruss,ClémentineMaurice,andStefanMangard.2016. Rowhammer.js:\nA remote software-induced fault attack in javascript. In International Conference\nonDetectionofIntrusionsandMalware,andVulnerabilityAssessment.Springer,\n300–321.\n[23]Yasufumi Hashimoto, Tsuyoshi Takagi, and Kouichi Sakurai. 2011. General Fault\nAttacks on Multivariate Public Key Cryptosystems. In Post-Quantum Cryptogra-\nphy, Bo-Yin Yang (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 1–18.\n[24]Saad Islam, Ahmad Moghimi, Ida Bruhns, Moritz Krebbel, Berk Gulmezoglu,\nThomasEisenbarth,andBerkSunar.2019. SPOILER:SpeculativeLoadHazardsBoost Rowhammer and Cache Attacks. In 28th USENIX Security Symposium\n(USENIX Security 19). 621–637.\n[25]AngshumanKarmakar,SujoySinhaRoy,OscarReparaz,FrederikVercauteren,\nand Ingrid Verbauwhede. 2018. Constant-time discrete gaussian sampling. IEEE\nTrans. Comput. 67, 11 (2018), 1561–1571.\n[26]AngshumanKarmakar,SujoySinhaRoy,FrederikVercauteren,andIngridVer-\nbauwhede. 2019. Pushing the speed limit of constant-time discrete Gaussiansampling. A case study on the Falcon signature scheme. In Annual Design Au-\ntomation Conference. ACM, 88.\n[27]Yoongu Kim, Ross Daly, Jeremie Kim, Chris Fallin, Ji Hye Lee, Donghyuk Lee,ChrisWilkerson,KonradLai,andOnurMutlu.2014. FlippingBitsinMemory\nWithout Accessing Them: An Experimental Study of DRAM Disturbance Errors\n(ISCA ’14). 361–372.\n[28]AviadKipnis,JacquesPatarin,andLouisGoubin.1999.Unbalancedoilandvinegar\nsignature schemes. In International Conference on the Theory and Applications of\nCryptographic Techniques. Springer, 206–222.\n[29]AviadKipnisandAdiShamir.1998. Cryptanalysisoftheoilandvinegarsignature\nscheme. In Annual International Cryptology Conference. Springer, 257–266.\n[30]Juliane Krämer and Mirjam Loiero. 2019. Fault Attacks on UOV and Rainbow.InConstructive Side-Channel Analysis and Secure Design, Ilia Polian and Marc\nStöttinger (Eds.). Springer International Publishing, Cham, 193–214.\n[31]AndrewKwong,DanielGenkin,DanielGruss,andYuvalYarom.2020. RAMBleed:ReadingBitsinMemoryWithoutAccessingThem.In IEEESymposiumonSecurity\nand Privacy (S&P).\n[32]MoritzLipp,MisikerTadesseAga,MichaelSchwarz,DanielGruss,Clémentine\nMaurice, Lukas Raab, and Lukas Lamster. 2018. Nethammer: Inducing rowham-\nmer faults through network requests. arXiv preprint arXiv:1805.04956 (2018).\n[33]NIST. 2017. Post-Quantum Cryptography Standardization. https:\n//csrc.nist.gov/projects/post-quantum-cryptography/post-quantum-\ncryptography-standardization.\n[34]Aesun Park, Kyung-Ah Shim, Namhun Koo, and Dong-Guk Han. 2018. Side-Channel Attacks on Post-Quantum Signature Schemes based on Multivariate\nQuadraticEquations-RainbowandUOV-. IACRTrans.Cryptogr.Hardw.Embed.\nSyst.2018 (2018), 500–523.\n[35]Jacques Patarin. 1997. The oil and vinegar signaturescheme. In Dagstuhl Work-\nshop on Cryptography September, 1997.\n[36]Peter Pessl, Leon Groot Bruinderink, and Yuval Yarom. 2017. To BLISS-B or not\ntobe:AttackingstrongSwan’sImplementationofPost-QuantumSignatures.In\nComputer and Communications Security. ACM, 1843–1855.\n[37]Prasanna Ravi, MahabirPrasad Jhanwar, James Howe, Anupam Chattopadhyay,\nandShivamBhasin.2018. Side-channelAssistedExistentialForgeryAttackon\nDilithium-A NIST PQC candidate. IACR Cryptology ePrint Archive (2018), 821.\n[38]PrasannaRavi,DebapriyaBasuRoy,ShivamBhasin,AnupamChattopadhyay,\nand Debdeep Mukhopadhyay. 2019. Number “Not Used” Once-Practical Fault\nAttack on pqm4 Implementations of NIST Candidates. In International Workshop\non Constructive Side-Channel Analysis and Secure Design. Springer, 232–250.\n[39]MarkSeabornandThomasDullien.2015. ExploitingtheDRAMrowhammerbug\nto gain kernel privileges. Black Hat 15 (2015).\n[40]K.ShimandN.Koo.2020. AlgebraicFaultAnalysisofUOVandRainbowwiththe\nLeakage of Random Vinegar Values. IEEE Transactions on Information Forensics\nand Security (2020), 1–1.\n[41]Peter W Shor. 1999. Polynomial-time algorithms for prime factorization and\ndiscrete logarithms on a quantum computer. SIAM review 41, 2 (1999), 303–332.\n[42]Andrei Tatar, Radhesh Krishnan Konoth, Elias Athanasopoulos, Cristiano Giuf-\nfrida,HerbertBos,andKavehRazavi.2018. Throwhammer:Rowhammerattacks\nover the network and defenses. In 2018 USENIX Annual Technical Conference 18.\n213–226.\n[43]Victor Van Der Veen, Yanick Fratantonio, Martina Lindorfer, Daniel Gruss,Clementine Maurice, Giovanni Vigna, Herbert Bos, Kaveh Razavi, and Cris-tiano Giuffrida. 2016. Drammer: Deterministic rowhammer attacks onmobileplatforms. In Proceedings of the 2016 ACM SIGSAC conference on computer and\ncommunications security. ACM, 1675–1689.\n[44]BeullensWard,PreneelBart,SzepieniecAlan,andVercauterenFréderik.2020.LUOV - MQ signature scheme. https://www.esat.kuleuven.be/cosic/pqcrypto/\nluov/.\n[45]ZaneWeissman,ThoreTiemann,DanielMoghimi,EvanCustodio,ThomasEisen-\nbarth,andBerkSunar.2019. JackHammer:EfficientRowhammeronHeteroge-\nneous FPGA-CPU Platforms. arXiv:1912.11523 [cs.CR]\n[46]YuanXiao,XiaokuanZhang,YinqianZhang,andRaduTeodorescu.2016. One\nbit flips, one cloud flops: Cross-vm row hammer attacks and privilege escalation.\nIn25th USENIX Security Symposium 16. 19–35.\n[47]Lai Xu, Rongwei Yu, Lina Wang, and Weijie Liu. 2019. Memway: in-\nmemorywaylayingaccelerationforpracticalrowhammerattacksagainstbinaries.\nTsinghua Science and Technology 24, 5 (2019), 535–545.\n[48]TakanoriYasuda,XavierDahan,Yun-JuHuang,TsuyoshiTakagi,andKouichi\nSakurai. 2015. MQ Challenge: Hardness Evaluation of Solving Multivariate\nQuadratic Problems. IACR Cryptology ePrint Archive 2015 (2015), 275.\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1083[49]RaymondKZhao,RonSteinfeld,andAminSakzad.2018. FACCT:FAst,Compact,\nandConstant-TimeDiscreteGaussianSampleroverIntegers. IACRCryptology\nePrint Archive 2018 (2018), 1234.\nA DIVIDE-AND-CONQUER ATTACK\nAlgorithm 5 MQ Generator\n1:procedure MQ_Gen(𝑖,𝑥)\n𝑖: column# in T\n𝑥: known elements in 𝑖𝑡ℎcolumn of T\nOutput:A𝑖(𝑥)\n2:𝐴𝑖←𝐺𝑒𝑛𝑀𝑄(𝑖) ⊲use Equation 3 for 𝑖=𝑗\n3:𝐴𝑖(𝑥)←𝐼𝑛𝑠𝑒𝑟𝑡𝑉𝑒𝑐 (𝐴𝑖,𝑥) ⊲Section 4.2,item 2\n4:return𝐴𝑖(𝑥)\n5:end procedure\nAlgorithm 6 ML Generator\n1:procedure ML_Gen( (𝑖,𝑥),(𝑗,𝑦))\n𝑖,𝑗: column# in T,\n𝑥: known elements in the 𝑥𝑡ℎcolumn of T\n𝑦: known elements in the 𝑦𝑡ℎcolumn of T\nOutput:B𝑖,𝑗(𝑥,𝑦)\n2:𝐵𝑖,𝑗←𝐸𝑞𝑛𝐺𝑒𝑛(𝑖,𝑗) ⊲Section 4.2,item 3\n3:𝐵𝑖,𝑗(𝑥,𝑦)←𝐼𝑛𝑠𝑒𝑟𝑡𝑉𝑒𝑐 (𝐵𝑖,𝑗,𝑥,𝑦)⊲Section 4.2,item 5\n4:returnB𝑖,𝑗(𝑥,𝑦)\n5:end procedure\nAlgorithm 7 Equation Solver\n1:procedure Eqn_Solver( A𝑖(𝑥),/uniontext.1𝑖−1\n𝑗=1B𝑖,𝑗(𝑥,𝑦𝑗))\nOutput:𝑡𝑗orfail\n2:if𝑣−𝑥≤𝑚then\nSolveA𝑖(𝑥) ⊲∼𝑀𝑄(𝑣−𝑥,𝑚)\n3:else if𝑣−𝑥−(𝑖−1)𝑚≤0then\nSolve/uniontext.1𝑖−1\n𝑗=1B𝑖,𝑗(𝑥,𝑦𝑗) ⊲∼𝑀𝑄((𝑖−1)𝑚,𝑣−𝑥)\n4:else if0≤𝑣−𝑥−(𝑖−1)𝑚≤𝑚then\nSolveA𝑖(𝑥)∪/uniontext.1𝑖−1\n𝑗=1B𝑖,𝑗(𝑥,𝑦𝑗) ⊲∼𝑀𝑄(𝑣−𝑥−𝑚,𝑚)\n5:else\n6: return fail ⊲Not a solvable system\n7:end if\n8:return𝑡𝑗\n9:end procedure\nAlgorithm 8 Coefficient Matrix Generator\n1:procedure Matrix_Gen( 𝑄1)\nOutput:𝑃3\n𝑘,𝑄2\n2:𝑃𝑘1←𝑓𝑖𝑛𝑑𝑃𝑘1(𝑄1,𝑘) ⊲[3]\n3:𝑃𝑘2←𝑓𝑖𝑛𝑑𝑃𝑘2(𝑄1,𝑘) ⊲[3]\n4:𝑃𝑘3←𝐺𝑒𝑛𝑃𝑘3(𝑃𝑘1,𝑃𝑘2,𝑘) ⊲∼𝑀𝑄(𝑣−𝑥,𝑣−𝑥)\n5:𝑄2←𝐺𝑒𝑛𝑄2(𝑃𝑘3) ⊲Equation 4\n6:return𝑃3\n𝑘,𝑄2\n7:end procedureB LUOV - BUILD AUGMENTED MATRIX\nAlgorithm 9 LUOV - Build Augmented Matrix\n1:procedure BuildAugmented( 𝐶,𝐿,𝑄1,T,ℎ,𝑣)\nOutput:𝐿𝐻𝑆||𝑅𝐻𝑆=(𝐴||𝑏)\n2:𝑅𝐻𝑆← −ℎ−𝐶−𝐿𝑠(𝑣||0)𝑇\n3:𝐿𝐻𝑆← −𝐿/parenleftbigg−𝑇\n1𝑚/parenrightbigg\n4:for𝑘from 1 to𝑚do\n5:𝑃𝑘1← −𝑓𝑖𝑛𝑑𝑃𝐾1(𝑘,𝑄1)\n6:𝑃𝑘2← −𝑓𝑖𝑛𝑑𝑃𝐾2(𝑘,𝑄1)\n7:𝑅𝐻𝑆[𝑘]←−𝑅𝐻𝑆[𝑘]−𝑣𝑡𝑃𝑘,1𝑣\n8:𝐹𝑘,2←−(𝑃𝑘,1+𝑃𝑇\n𝑘,1)T +𝑃𝑘,2\n9:𝐿𝐻𝑆[𝑘]←−𝐿𝐻𝑆[𝑘]+𝑣𝐹𝑘,2\n10:end for\n11:return𝐿𝐻𝑆||𝑅𝐻𝑆\n12:end procedure\nSession 4A: Post-Quantum Cryptography\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1084"}
{"title": "SmashEx: Smashing SGX Enclaves Using Exceptions Jinhua Cui∗", "content": "SmashEx: Smashing SGX Enclaves Using Exceptions\nJinhua Cui∗\n2\nNational University of Defense Technology\nChangsha, China\njhcui.gid@gmail .comJason Zhijingcheng Yu∗\nNational University of Singapore\nSingapore\nyu.zhi@comp .nus.edu.sgShweta Shinde\nETH Zürich\nZürich, Switzerland\nshweta.shivajishinde@inf .ethz.ch\nPrateek Saxena\nNational University of Singapore\nSingapore\nprateeks@comp .nus.edu.sgZhiping Cai\nNational University of Defense Technology\nChangsha, China\nzpcai@nudt .edu.cn\nABSTRACT\nExceptionsareacommodityhardwarefunctionalitywhichiscentral\nto multi-tasking OSes as well as event-driven user applications.\nNormally,theOSassiststheuserapplicationbyliftingthesemantics\nof exceptions received from hardware to program-friendly user\nsignals and exception handling interfaces. However, can exception\nhandlers work securely in user enclaves, such as those enabled by\nIntel SGX, where the OS is nottrusted by the enclave code?\nIn this paper, we introduce a new attack called SmashEx which\nexploitstheOS-enclaveinterfaceforasynchronousexceptionsin\nSGX. It demonstrates the importance of a fundamental property\nof safe atomic execution that is required on this interface. In the\nabsenceofatomicity,weshowthatasynchronousexceptionhan-\ndling in SGX enclaves is complicated and prone to re-entrancy\nvulnerabilities.Ourattacksdo notassumeanymemoryerrorsin\nthe enclavecode, side channels,or application-specific logicflaws.\nWe concretely demonstrate exploits that cause arbitrary disclo-\nsure of enclave private memory and code-reuse (ROP) attacks in\nthe enclave. We show reliable exploits on two widely-used SGX\nruntimes, Intel SGX SDK and Microsoft Open Enclave, running\nOpenSSL and cURL libraries respectively. We tested a total of 14\nframeworks,includingIntelSGXSDKandMicrosoftOpenEnclave,\n10of which are vulnerable. We discuss how the vulnerability mani-\nfestsonbothSGX1-basedandSGX2-basedplatforms.Wepresent\npotential mitigation and long-term defenses for SmashEx.\nCCS CONCEPTS\n•Securityandprivacy →Trustedcomputing ;Softwaresecu-\nrity engineering.\n∗Both authorscontributed equally to this research.\n2The author carried out this research while visiting National University of Singapore.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,\ntopostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’21, November 15ś19, 2021, Virtual Event, Republic of Korea\n©2021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi .org/10.1145/3460120 .3484821KEYWORDS\nTEE;IntelSGX;Exceptionhandling;Atomicity;Re-entrancyvul-\nnerability; Code-reuse attack\nACM Reference Format:\nJinhuaCui,JasonZhijingchengYu,ShwetaShinde,PrateekSaxena,andZhip-\ning Cai. 2021. SmashEx: Smashing SGX Enclaves Using Exceptions. In Pro-\nceedings of the 2021 ACM SIGSAC Conference on Computer and Commu-\nnications Security (CCS ’21), November 15ś19, 2021, Virtual Event, Repub-\nlicofKorea. ACM,NewYork,NY,USA,15pages.https://doi .org/10.1145/\n3460120.3484821\n1 INTRODUCTION\nExceptionsareabasicfunctionalityavailableonmodernprocessors\nandareubiquitouslyusedbytheOSandreal-worldapplications.\nThe OS makes use of exceptions for multiplexing processes and re-\nsources, e.g., via timer interrupts and page faults. Applications use\nprogrammaticconstructs,suchasexceptionandsignalhandling,\nto deal with dynamic events or runtime errors. The underlying\nOS is in charge of monitoring and delivering hardware generated-\nexceptions to a user process. This design allows application devel-\nopers to focus on what to do when an event occurs.\nRecently, a new form of hardware isolation has been enabled\nby enclaves such as those provided by Intel SGX. SGX allows user\napplicationstobepartitionedintohardware-isolatedcompartments\ncalledenclaves,whichareprotectedfromprivilegedsystemsoft-\nware(e.g.,thehypervisorandtheOS).Themainguaranteeprovided\nbyenclavesisprotectingtheconfidentialityandintegrityofcode\nrunninginthem.Enclavesareanimportantstep,forexample,to-\nwards reducing the dependence on privileged OSes and towards\nconfidential computation [ 3,4]. This presents a unique security\nmodelÐa trusted enclave running alongside an untrusted OS. This\npaperstudieshowexceptionsarehandledonSGX,aplatformwhere\nthe OS and user enclave do nottrust each other.\nExceptions are events that hardware generates and software\nhandles. There are two design choices for enabling exceptions for\nenclaves. The trusted hardware can directly deliver the exceptions\ntotheenclavecode.Alternatively,thehardwarecandeliverittothe\nOS,asinnon-SGXsystems.ThecurrentSGXimplementationtakes\nthesecondapproach.Insuchadesign,theOScanrouteanexception\nto the enclave along with the description of the exception event.\nOncetheexceptionisdeliveredtotheenclavebyeithermechanism,\nthe enclave can execute the exception handler. Since the enclave\ndoesnottrusttheOS,thisinterfacerequirescarefuldesigntoensure\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n779\nsecurity. There are three entities interacting: the user enclave, the\ntrusted\nSGX hardware, and the untrusted OS.\nMany exceptions are synchronous in the sense that the enclave\ncode can control when these exceptions are raised. But, certain\nexceptions are asynchronous, i.e., they can be triggered outside the\ncontrol of the enclave. The OS has the power to trigger such excep-\ntions at any time. The design of any hardware enclave abstraction\nthat supports asynchronous exceptions needs to provide at least\nthree security properties on enclave-OS context switches:\n•Register statesave/restore. When anexception interruptsan\nenclave, the integrity and confidentiality of the requisite\nenclave register state should be preserved in the presence of\na malicious OS.\n•Safe control resumption. After an exception, the execution\nresumes either at the point of interruption or at the start of\nan enclave-defined handler.\n•Atomicity. The hardware must support sufficient mecha-\nnismsfor theenclave topreventexceptionhandling whenit\nis executing inside certain critical sections.\nThe SGX hardware provides the first two properties, but not\nthe third. An enclave can turn off delivery of certain programmer-\ndefined exception throughout its execution by statically setting\nits hardware configuration. However, if the enclave does not stati-\ncally disable exceptionsÐwhich is useful for signal handlingÐSGX\ndoesnotallowtheenclavetoselectivelymaskexceptionsatcertain\ntimes during execution. This effectively means that the SGX hard-\nware does not provide any explicit runtime primitives for ensuring\natomicityofcriticalsectionsintheenclave,whenexceptionsare\nstaticallyenabled.Thelackofsuchaprimitiveopensupenclavesto\nre-entrancyvulnerabilities whichcaninturnleadtoseriousexploits.\nTodemonstratethisclearly,weintroduceapowerfulattackcalled\nSmashEx,whichdoesnotassumeanysidechannelsorpre-existing\nmemorysafetybugsintheenclaveapplicationcode.Wesuccess-\nfully execute the attack to compromise both confidentiality and\nintegrityguaranteesforenclaveapplicationsonSGX.Ourattackon\nSSL implementations for instance can cause a malicious OS to spill\nout secret keys residing in private memory. To demonstrate the\nfull power of SmashEx, we leveragethe re-entrancy vulnerability\ntoeffectcode-reuse(e.g.,ROP[ 50])andarbitrarymemorydisclo-\nsure attacks on enclaves. We construct end-to-end PoC exploits for\ntwo widely-used SGX runtimes: Intel SGX SDK [ 16] and Microsoft\nOpenEnclave[ 45].WetargetanOpenSSLimplementationbased\nonIntelSGXSDKandthecURLapplicationbasedonOpenEnclave\nrespectively.TheattacksaredemonstratedonthelatestSGX2hard-\nware,butalsoextendstoSGX1runtimesthathaveasynchronous\nexception handling enabled.\nIn this paper, we explain why the root re-entrancy vulnerabil-\nityexploitedby SmashEx isfundamentalÐifwewanttosupport\nasynchronous exception handling on SGX, careful re-entrant de-\nsignintheenclaveiscritical.Intotal,wesurvey 14SGXruntime\nframeworks and deem that the vulnerability affects 10of them on\nSGX2. While the exploits do not immediately carry over to 4of\nthe runtimes, we point out that this comes at the cost of a limit to\ntheir exception handling functionality or extra complexity in their\ndesign and implementation. We discuss the effectiveness of vari-\noussoftwaremitigationsfor SmashEx.Werecommendpotential\nTrusted\nUntrustedPublic\nmemoryEnclave\nprivate\nmemory\nR/W\nRing 0-2\nHardwareOS kernelHostEnclave\nInterrupt\nhandlerAPIC timer\ninterface\nEEXITEENTER\nERESUMEAEXR/W/X\nRing 3Figure 1: SGX enclave interfaces and memory protection.\nhardware abstractions for exposing atomic execution primitives to\nenclavestosimplifydefenses.Thesemaybeofindependentinterest\nto future enclave designs.\nContribution. Muchpriorattentionhasbeendevotedtosafedata\nand control exchange at the enclave-OS interface (e.g., for Iago\nattacks [34]). Our main contribution is to highlight a third missing\ndefenseprimitiveattheenclave-OSinterface:ensuring atomicity in\nre-entrant enclave code. When enclaves support the standard pro-\ngrammingmodelofasynchronousexceptions,re-entrancyconcerns\narise. Our SmashEx attack makes this issue concrete for study.\n2 BACKGROUND\nIntel SGX introduces the notion of enclavesÐhardware isolated\nmemory regions for sensitive execution. We refer to the code that\nexecutes inside an enclave as enclave software. The code and the\ndata of enclave software, including its stack (enclave private stack ),\narestoredinside enclavememoryandprotected bytheSGXhard-\nware.IntheSGXtrustmodel,onlythehardwareandtheenclave\nsoftwarearetrusted.Alltheothersoftwareonthesystem,including\nprivileged software such as the OS, is considered untrusted. This\nincludestheuserprocessinchargeofcreatingandinteractingwith\ntheenclave,whichwerefertoasits hostprocess.TheSGXhardware\ndoesnotallowtheuntrustedsoftwaretoaccessenclavememory.\nHowever, enclave software can read or write memory regions out-\nside the enclave boundary, which are also accessible to the host\nprocess. We refer to such a shared virtual address space accessible\nto both an enclave and its host process as the public memory.\nEnclave software requires mechanisms to request services from\nthe non-enclave/OS code as well as to receive notifications (e.g.,\nsignals) from it. The SGX hardware has two kinds of interfaces,\nsynchronous and asynchronous, for switching between the OS and\nanenclave.Figure1depictssuchinterfacesalongsidetheprotected\nmemory region for an SGX enclave.\nSynchronous Entry/Exits. Synchronousentry/exitsareneeded\nin enclaves to interface with the host application and the OS for\nsynchronous or blocking communication. To help safeguard the\ninterface,theSGXhardwarestrictlyrestrictsthetransferofcontrol\nbetween enclave and non-enclave code. Two specific instructions,\nEENTERandEEXIT, are used to synchronously enter and exit an\nenclaverespectively.The EENTERinstructionjumpstoafixeden-\nclave entry point that is pre-configured during enclave creation.\n2\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n780CPU registerenclavestackCPUregister\nEENTEREEXIT\nFixed entry:2\n3\n41Untrusted software Trusted enclave\nSave RestoreTrusted code\nOcall\nOcall return\nTrusted codexor%xdx,%xdx\n...Host\nprocessFigure 2: Synchronous entry/exit in an ocallon SGX.\nAn enclave can specify a public memory location and exit to it via\ntheEEXITinstruction. EENTERandEEXITdonotscrub or replace\nthe register state during context switches. Instead, the hardware\nkeepsmostoftheregistersunchanged.Itistheresponsibilityofthe\nenclavesoftwaretopreparetheregisterstateforenclaveexecution\nafterEENTERand to prevent leaking secrets through the register\nstate after EEXIT. This is necessary for normal functionality, for\nexample,topropagateanydataargumentsbetweentheenclaveand\ntheOS.Anenclavecanprovidefunctionsforuntrustedsoftware\ntoinvokeinaso-called ecall,whichconsistsofapaired EENTER\nanda subsequent EEXIT.In addition,synchronous entry/exitscan\nalsobeusedtosupport ocalls,whereenclavesrequesttoinvoke\nfunctions provided by untrusted software (shown in Figure 2).\nSinceEEXITandEENTERdo not take care of the register state,\ntheenclavecodehastosavetheenclaveCPUcontextonitsprivate\nstackandrestoreitwhenreturningfromthe ocalllater.The ocall\ninterface has been the subject of much scrutiny in prior work,\nlargely due to the risk of Iago attacks [34, 42, 56, 59].\nAsynchronousEntry/Exits. Inadditiontosynchronousexits,an\nenclave can exit asynchronously as a result of exceptions (e.g.,\ntimer interrupts, page faults, division-by-zero). During such an\nAEX(AsynchronousEnclaveeXit),theenclavestoresthecurrent\nenclave execution context in a special data structure called the\nState Save Area (SSA) located inside the enclave private memory.\nAsynchronousentry/exitsaredifferentfromsynchronousevents\nbecause they can arise at any time during the enclave execution,\ninterrupting it involuntarily. To ensure safe enclave-OS transitions,\nthe SGX hardware implements the following mechanisms:\n•Safe control resumption. At an AEX, the hardware automati-\ncally stores the current instruction pointer ( rip) in the SSA.\nTheuntrustedhostprocessmayexecutean ERESUME instruc-\ntionlatertotransfercontrolbacktotheenclave.Atthispoint,\nSGX hardware enforces that the enclave resumes execution\nfrom the ripvalue stored inside the SSA.\n•Register save/restore. In addition to rip, the hardware saves\ntheremainingenclaveexecutioncontext(e.g.,general-purpose\nregisters) in the SSA. Before exit, the hardware scrubs the\nregister values to prevent data leakage through them. On\nERESUME,thehardwarerestorestheregistervaluesfromSSA.\nAsynchronousExceptionHandlinginSGXEnclaves. Thesim-\nple mechanisms above are sufficient to protect an enclave while\nenclavestackSSAregionCPU register\nHost\nprocessOS kernel\nEENTER3\nEEXIT5Signal\nTrusted enclave4Exception1AEX2\nUntrusted software Hardware\nERESUME6\nException \nhandler\nSave Copy...\nint i=6/0;Trusted code:\nFigure 3: Exception handling mechanism in Intel SGX SDK.\nThe SGX\nhardware performs an AEX and transfers the con-\ntroltotheOSwhenanexceptionoccurs( 1○2○).TheOSdeliv-\nersacorrespondingsignaltothehostprocess,whichthenre-\nenters the enclave via EENTER(3○). The enclave performs in-\nenclaveexceptionhandling( 4○)andexitstothehostprocess\nviaEEXIT(5○),whichthenresumestheenclaveexecutionvia\nERESUME (6○). During this process, the CPU state of the in-\nterrupted enclave is first saved into the SSA upon the AEX,\nfromwhichitisthencopiedtotheenclaveprivatestackdur-\ning in-enclave exception handling.\nallowingexceptionstointerruptitsexecution.However,inorder\nto also allow the enclave to handle exceptions (including decid-\ningtheresumptionpointbymodifyingtheSSAcontent),amore\ncomplexmechanismisdesigned(showninFigure3)inSGXrun-\ntimes. Instead of resuming the enclave immediately via ERESUME,\nthe untrusted host process re-enters the enclave using EENTERand\npasses relevant information about the exception. Note that this\nnew flowstarts with a normal EENTERwhich leavesthe rspvalue\nuninitialized,sotheenclavehastosetupitsprivatestackbefore\nexecutinganyrealexceptionhandler.InbothIntelSGXSDKand\nMicrosoft Open Enclave (among others; see Section 8), the enclave\nloadsthestackpointerfromthesaved rspintheSSA,effectively\nreusing the same stack of the interrupted thread. After the enclave\nfinishes handling the exception in the SDK, it uses EEXITto return\ncontrol to the untrusted software, which then resumes the enclave\nexecution via ERESUME.\nKey Observation. To perform exception handling, the enclave\nneeds to be re-entered and operate on a context that overlaps with\nthatoftheinterruptedthread.Therefore,theabovedesignforin-\nenclave handlers requires the enclave to be re-entrant.\nSGXRuntimes. SincetheSGXenclaveprogrammingmodelissig-\nnificantlydifferentfromatraditionalone,itcanbecumbersomefor\ndevelopers to use the low-level SGX interfaces. Therefore, enclave\ndevelopers usually use frameworks that provide high-level abstrac-\ntions to hide away the details of exception handling, ocall,ecall,\nandsoon.Suchsoftwareframeworks,referredtoasSGXenclave\nruntimes in this paper, execute inside enclaves. Since runtimes are\napartoftheenclavetrustedcomputingbase,theirdesignandim-\nplementation are crucial to the security of enclave applications.\nWesurvey 14runtimes(Table1)andfindthattheyhavevarying\ndegrees of exception handling support.\n3\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n781Software VersionVulnerable\ntoSmashEx?Exception\nhandling\nIntel SGX SDK [16] 2.13/enc-97/enc-97\nMicr\nosoft Open Enclave [46]0.15.0/enc-97/enc-97\nRedHat Enarx [12] 02dab73/enc-97/enc-97\nGraphene-SGX [33] 1.1/enc-100/enc-97\nApache Teaclave [1] 0.2.0/enc-97/enc-97\nGoogle Asylo [29] 0.6.2/enc-97/enc-97\nFortanix Rust EDP [39] 3341ce1/enc-100 /enc-100\nAlibaba Inclavare [14] 0.6.0/enc-100 /enc-100\nRatel[24] 1.1/enc-100/enc-97\nSGX-LKL [49] b6e838e/enc-97/enc-97\nEdgelessRT [11] 8a6f11f/enc-97/enc-97\nRust SGX SDK [62] 1.1.3/enc-97/enc-97\nCoSMIX [48] 4e67f55/enc-97/enc-97\nVeracruz [26] cbf01a9/enc-97/enc-97\nTable 1: Summary of different enclave runtime designs.\n/enc-97denotesthat\ntheenclaveruntimeisdeemedexploitableby\nSmashEx and/enc-100denotesthattheenclaveruntimeisdeemed\nunexploitable by SmashEx under any enclave settings. For\nthe exception handling, /enc-97denotes handling asynchronous\nexceptions is supported in enclaves and /enc-100denotes no sup-\nport for handling exceptions in enclaves.\n3 ATTACK OVERVIEW\nAn enclave must be re-entrant to safely handle exceptions by itself.\nHowever, an important primitive, namely atomicity, is missing. We\nillustrate the need for atomicity by outlining SmashEx, a novel\nattack that exploits a re-entrancy vulnerability present in many\nSGX frameworks.\n3.1 Threat Model\nAssumptions. Thesecurity-sensitivepartoftheapplicationexe-\ncutes, together with any runtime libraries, in the victim enclave.\nThe enclave interacts with the external environment, including the\nOS and the host process, which are assumed to be arbitrarily mali-\ncious.TheSGXhardwareistrusted.Theenclavecodeisassumed\ntobebenignandwedo notassumethatithasanyauxiliarybugs\norside channelsthat aidtheattacker. Weassumethat theenclave\ncode, however, is running without ASLR (Address Space Layout\nRandomization),i.e.,certaincriticaladdressesaredeterministicand\nknowntothe attacker.Thisisthedefault setuponnearlyallSGX\nplatformruntimeswehavesurveyed.Wediscusshowtoextendour\nattacks when ASLR or other auxiliary defenses are enabled in Sec-\ntion9.Theenclaveisassumedtohaveenabledtheasynchronous\nexception handling interface.\nAttack Goal & Scope. Ourattack goalis tobreakthe basicmem-\nory protection guarantees offered by SGX enclaves. Specifically,\nweaimtobreakconfidentialitybyenablinganarbitrarymemory\ndisclosure attack by which the attacker can reveal the victim en-\nclavememorycontentsinfull.Tobreakintegrity,ourattackaims\ntoenableROPattacksintheenclave.Mostruntimesthatsupport\nin-enclave exception handling are susceptible to our attack. In our\nsurveysummarizedinTable1, 12/14runtimessupportthisfunc-\ntionality.Amongthe 12runtimes,wefindthat 10aresusceptibleto\nEnclave moves\nregs to stackEnclave \ncleans regsEnclave ret \nuses stack\nInvalid page \npermissionsInterrupt handlerHW moves\nregs to SSAFixed entry: HW \npreserves regs\nOcall impl moves \nvalues to regsEEXIT EENTER #PF\nAEXException handler\nmoves SSA to stack\nEENTER EEXIT ERESUMEHW moves\nSSA to regsA B CFigure4:Statediagramdepictingthere-entrancyvulnerabil-\nity.\nTheclearboxesdenoteenclavestates,andthegrayboxes\ndenote OS states. The solid black arrows show the ocallex-\necutionflowwherethedottedblackboxdenotesthecritical\nsection. The dashed red arrows show the in-enclave excep-\ntionhandlingflow,injectedbytheOSwhentheenclaveisin\ncriticalsection,thuscorruptingtheenclavestate(i.e.,stack).\ntheSmashEx attack.Wepresentproof-of-concept(PoC)exploits\nfortwoofthemostpopularruntimes,IntelSGXSDKandOpenEn-\nclave, as case studies in Section 7. Intel SGX SDK is widely used in\nmultiple other runtimes and Open Enclave is part of the Microsoft\nConfidentialComputingFramework(CCF).Since SmashEx arises\ndirectly on the enclave-OS interface, any application that uses a\nvulnerable runtime is exploitable. We have also constructed PoC\nexploitsforallbutRedHatEnarx,forwhichwehaveconfirmedthe\nexploitability through code inspection (see Section 8).\n3.2 The Re-entrancy Vulnerability\nTodemonstratethere-entrancyissueclearly,weoutlinetheflowof\nexceptionhandlingonIntelSGXSDKforSGX2,bothundernormal\nexecution and under a SmashEx attack. It executes similarly on\nSGX1 and extends to other runtimes (see Section 8).\nConsider the flow that handles returning from an ocall. Fig-\nure 4 shows this flow with black solid arrows inside the dotted\nbox, which executes logic labeled 𝐴→𝐵→𝐶in that sequence.\nThis flow, however, can be interrupted when asynchronous excep-\ntions arrive. The dashed red arrows in Figure 4 show the execution\nflow when handling in-enclave exceptions corresponding to the\nEENTER→EEXIT→ERESUMEpreviouslyhighlightedinSection2.\nBoth flows are benign, but operate on overlapping enclave con-\ntexts.Thisclearlyhighlightsthatsuch ocallreturnflowandthe\nexception handling flow should be written with care to ensure that\ntheyinterleavesafely.Specifically,whenthe ocallreturnflowis\ninterrupted,theenclaveshouldbeinaconsistentstatefortheex-\nceptionhandlingflowtoprogresscorrectly,andwhentheexception\nhandling flow completes, the enclave state should also be ready for\nthe enclave to resume. This adds considerable complexity when\nin-enclaveexceptionsaretobesupported,regardlessofwhether\nthe OS is acting maliciously.\nInthisexample,themainvulnerabilitypointthatenables SmashEx\nis in theocallreturn flow, which requires atomicity for executing\ncertain critical sections that update the enclave context (shown\nin the dotted black box in Figure 4). The state transitions for the\nocallreturnflowmustcheckandcleanuptheregistervaluesre-\nturnedbytheOSandthenusethemtosetuptheenclaveprivate\n4\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n782Trusted enclave\nxor %xdx,%xdx\n...Untrusted software\nEENTER\nAEXCPU\nregisters\nSSA \nregionSet page permissions\nto non-executable\nReturn from\nan OCALL\nKernel interrupt\nhandlerSaveEntry point code page\n(a)\nTrusted enclave Untrusted software\nAEXRegistersRegisters SSA region\nStack M Exception\nhandlingEENTER (b)\nTrusted enclave\ncall ocall\nmov %rax,%rdi\ngadget 1\n...Original return addr:\nTarget addr:Stack M\n...\narg 2\narg 1\nret_addr\n... (c)\nFigure\n5: Sub-components of SmashEx . (a) Injecting an AEX at the fixed entry point; (b) Corrupting the in-enclave memory\n(corrupteddataisdepictedinred);(c)Returningtothetargetthattheattackerhasspecifiedinthecontrolledanchor(inblue).\nstack. Before this is finished, the enclave is in an inconsistent state,\nwith register values (in particular, the stack pointer rsp) provided\nby the untrusted OS.\nItisimportant,therefore,thattheenclaveshouldnotbeinter-\nrupted to perform exception handling when it is still executing\nin such an inconsistent state. However, the SGX enclave abstrac-\ntiondoesnotprovideprimitivesforensuringatomicexecutionof\ncritical sections in the enclave. For example, it is not possible to\nselectivelymaskinterruptsforcertaincriticalsections.Theenclave\nmust either statically disable all user-defined asynchronous excep-\ntion handling1or risk being interrupted arbitrarily if exception\nhandling is statically allowed. The lack of atomicity results in a\npowerful attack vector which SmashEx leverages.\n3.3 High-level Attack Steps\nAs illustrated in Figure 5, SmashEx starts with the attacker trig-\ngeringanexceptionimmediatelyaftertheenclaveisentered(via\nEENTER) to return from an ocall(Figure 5a). The hardware copies\nthe attacker-controlled registers into the SSA region, which the en-\nclaveexceptionhandlerinturnusestodeterminethestackaddress\nandthedatatolateruse.Thisgivestheattackerthecapabilityof\ncorruptingthestackcontentoftheenclave(Figure5b).Bycarefully\ncrafting the register values, the attacker can exploit this capability\nto corruptan enclavestack locationthat theenclave willlater use\ntoloadareturnaddress(wecallthislocationan anchor),thereby\nhijacking the control flow of the enclave (Figure 5c). Figure 6 de-\nscribes the detailed steps SmashEx follows, which we will discuss\nin Sections 4, 5, and 6.\n3.4 Difference to Prior Attacks\nSmashEx is the first attack that demonstrates the exception han-\ndlingattackvectorinIntelSGX. that SmashEx isconceptuallyclose\nto known prior attacks on enclave memory safety, synchroniza-\ntion,andscheduling.However, SmashEx issignificantlydifferent.\nBriefly, previous attacks assume much more than SmashEx:\n•AsyncShock[ 2]assumesthatthesynchronizationlogic(e.g.,\nusing mutexes) between two or more enclave threads is\nbuggy.Incontrast,thevulnerability SmashEx exploitsarises\nduetoatomicityviolationintheenclave-OSinteraction,to\nwhich thread synchronization is irrelevant.\n1In SGX, the runtime can disable all in-enclave exception handling by setting the\nTCS.NSSA enclave configuration to one.\nTrusted enclave Untrusted software\nEENTER\nAEXSSA \nregionReturn from\nan OCALL\nKernel interrupt\nhandlerRSP\nR8\n…Craft regs\nSet permsRSP\nR8\n…\nUser space\nhandlerEENTER\nenclave\nstack1\n2\n3 Signal\n4\nEEXIT\nmov $arg 2,%rsi\nmov $arg 1,%rdi\nret (ret addr )\n...ERESUME\n6Restore in OCALL \nreturn logic5Save\nCopy\nEnclave entry point:\nException handler:\nxor%xdx,%xdx\n...sp=ssa.rsp;\ninfo=(info*)sp;\ninfo.r8=ssa.r8;...xor%xdx,%xdx\n...\nFigure 6: SmashEx Overview. The attacker directly controls\nthe untrusted software, including the OS and the host pro-\ncess. Data that the attacker can control is in red.\n•Game of Threads [ 61] shows that by manipulating thread\nscheduling, a malicious OS is able to stably exploit faulty\nthread synchronization logic in enclave applications. For\nexample,formachinelearningtrainingworkloadswithout\nfrequent threadsynchronization, malicious schedulingcan\ndegrade accuracy and bias the model.\n•TheGuard’sDilemma[ 31]assumestheexistenceofmemory\nvulnerabilitiesintheenclaveapplicationandusesthemto\ndemonstratecode-reuseattackssuchasROP.In SmashEx,\nwe do not assume any such pre-existing memory errors.\n4 ARBITRARY WRITE CAPABILITY\nTheSmashEx attackstartswithenablingtheattackertoperforman\narbitrary write to an attacker-specified anchor location (Figure 5a).\nStep1:PreparingMaliciousRegisterValues. Theattackerloads\nmaliciousvaluesintoregistersrightbefore EENTERtoensurethat\nthe attacker-specified register state is preserved.\nStep 2: Injecting an Exception at the Precise Time/Location.\nSmashEx requires that the AEX event occurs shortly after enclave\nentry,beforetheenclavecleansuptheregisterstate.Thereareat\nleast two ways to achieve this:\n5\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n783(a)Pagefaults. Weidentifythepagethatcontainsthefirstenclave\ninstruction and pre-set its access permissions to be non-executable.\nThe malicious OS is still in charge of the enclave page permissions\nandcantriviallydothis.Inparticular,theOSknowstheexactpage\naddress because it has to set up the enclave memory layout before\nlaunchinganenclave.Notethatthisaddresscannotbehiddenfrom\ntheattacker(e.g.,viarandomization[ 31,52])becausethehardware\nhas to know the exact entry point for the enclave. As described\ninSection3,weusethismechanismtotriggerapagefaultwhen\nthe enclave attempts to execute the first enclave instruction. When\nthe page fault is triggered, the hardware delivers it to the attacker-\ncontrolled OS, which then forwards it to the enclave for handling.\n(b)Timerinterrupts. Wecanalsointerrupttheenclaveexecution\nvia the APIC timer. Prior work [ 60] has shown that the OS can\ninvoke the APIC timer interface to precisely interrupt the enclave\nexecutionatanydesiredpoint.Theremainingchallengeistoinject\nthe timer interrupt at the exact moment. Before returning from an\nocall, we set the APIC timer to the one-shot mode. We set the\ntimer count such that the interrupt will occur immediately after\nEENTER. In order to stably achieve this, we execute the enclave\nindebugmodeandtunethetimercountto interruptattheright\ntime. In our experiments, whenwe reuse this same timer count in\nproduction mode, we can reliably inject the interrupt.\nStep 3: Re-entering the Enclave for Exception Handling. Af-\nter the untrusted OS gains control because of the AEX, it re-enters\nthe enclave (via EENTER) for handling the exception. This time, the\nattackerallowstheenclavetoprogressaftertheenclaveentryby\nreverting the access protection to the original permissions, if page\nfaults are used in Step 2.\nStep4:TrickingtheEnclaveintoUsingMaliciousValues. To\nhandletheAEX,theenclavefirstneedstopreparetheenclavestack\nforthein-enclavehandlerbyloadingthe rspregisterfromtheSSA\n(see Section 2). It then copies the SSA content onto this stack for\nthe handler to use as function arguments. Since the attacker can\ncontrol the values of rspand the other saved registers in the SSA,\nit has gained thecapability of tricking the enclave intowriting an\nattacker-specified value to an attacker-specified stack location. To\nhijack the enclave control flow, the attacker uses this capability\nto control an anchor, i.e., a location later used by the enclave to\nretrieveareturnaddress.Morespecifically,theattackercanchoose\nthe stack location that stores the return address for the current\nocallas the anchor.\nAchievedCapability. Using the above steps, the attacker has the\ncapability to write an arbitrary value to a particular location. This\nwrite capability is the first part for scaffolding a control-flow hi-\njacking attack. In Sections 5 and 6, we explain how to leverage this\ncapability to effect powerful end-to-end attacks.\n5 SETTING UP THE STACK\nSo far, the attack has only corrupted one anchor location on the\nstack. Our final goal is to demonstrate a powerful ROP attack [ 50].\nTo this end, our next step is to escalate the attacker’s capability to:\n•Point the stack pointer to an attacker-controlled region;\n•Tricktheenclaveintousingthevaluestoredattheanchor\nfor a control-flow transfer.\nCopied during \nexception handling…\n…\nocall arg 2\nocall arg 1\nocall ret_addr\nRBP\n…\n…\n…Attacker-controlled \nstack MSSA region\n…\nRDX\nRBX\nRSP\nRBP\nRSI\nRDI\nR8~R15\n…Anchor\n… …Figure7:Enclavememorycorruptionby SmashEx duringex-\nception handling in Intel SGX SDK. The attacker is able to\ncontrol the stack pointer in the SSA (in red) and the anchor\non the enclave private stack (in blue). The other data that\nthe attacker can control in SmashEx is shown in gray.\nStep 5: Pointing the Stack Pointer to Attacker Memory. A\nROP attack requires the attacker to control data on the victim’s\nstacksogadgetscanbestrungtogetherthroughaseriesofreturn\naddresses. As illustrated in Figure 7, in the exception handling\nprocess (Section 2), the in-enclave exception handler copies the\nregister state stored in the SSA region into a region of the enclave\nprivatestack(say 𝑀).ThisSSAstateconsistsofagroupofregisters\nwhich the SGX hardware has saved during the AEX event, and\nwhich, as explained earlier, are attacker-controlled. The attacker\nmay therefore use 𝑀to store the gadget addresses. To make the\nenclave use this region as its stack, the attacker needs to point the\nenclaverspvalue to it aftertheocallreturn is completed. This\ncan be easily done by setting the anchor value to the address of\na gadget that moves the value of a register (which the attacker\nalready controls through returning from ocall) into rsp.\nSmashEx does not require the memory region for preparing the\ngadget addresses to be the same as the region 𝑀. Since the SGX\nhardwareallowsanenclavetouseastackinsidethepublicmemory,\ntheattackercansimplysetupthegadgetaddressesinabufferin\nthe host process (located in the public memory), and use the same\nmethodtopoint rsptoit.Weusethisstrategyforourexploiton\nOpen Enclave and the earlier one for Intel SGX SDK.\nStep 6: Effecting a Control Transfer Using the Anchor. After\nStep 5, the region 𝑀itself is the stack with attacker-controlled\nvalues and the stack pointer ( rsp) points to it. This is part of what\nwe need to start a ROP attack. It remains to cause a control-flow\ntransferwiththecorruptedanchorvalue(Figure5c).Theexception\nhandlerdoes notimmediatelyusetheanchorvalueafterthecopy\nlogic.Severalcontroltransfersandcontextswitches2happenbefore\nthe anchor is used, but the content of 𝑀remains unchanged.\nNotethatalthoughitispossibletosettheanchortoanyvalue,\npointing it to the public memory will merely crash the enclave\n(hence falling short of a code-reuse attack) since SGX enclaves\n2The exception handler performs several other operations and exits the enclave using\nanEEXITinstruction to the untrusted code, which then performs an ERESUME instruc-\ntiontotransfercontrolbacktotheenclavetocompletetheexceptionhandlingandthe\nocallreturnflowinterrupted.Thispartofthelogicusestheanchorinacontrol-transfer\ninstructionÐthisiswhywechosetheanchortobethereturnaddressusedinresuming\nafter the last ocall.\n6\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n784Effective code \ndue to ROPGadgets Attacker-controlled \nstack M\nmov dst, % rdi\nmov src, % rsi\nmov len, % rdx\njmpmemcpypop %rdi\nret\npop %rsi\nret\npop %rdx\nretdst\nsrc\nlen\nmemcpyFigure 8: A chain of ROP gadgets in the malicious stack to\ninvokememcpywith\nattacker-controlled arguments.\ncannotexecutecodefrompublicmemory.Forthisreason,wemust\nconfine the anchor value to private memory addresses.\nAchieved Capability. At the end of Steps 5 and 6, the enclave\nstartsexecutingwiththestackcontentcontrolledbytheattacker.\nBycarefullycraftingthestackcontent,theattackerisabletoconvert\nthis capability to a full-blown ROP exploit.\n6 ROP EXPLOITS\nAt this point, the attacker can already control both the enclave\ninstructionpointer( rip)andtheenclavestackcontent.Next,we\nescalatetheattacker’scapabilitytobeingabletoexecuteasequence\nof ROP gadgets that exist in the enclave code [ 50]. We discuss the\nwaystoachievethisfortwodifferentgoals:tostealenclavesecrets\nand to execute desirable ROP gadgets.\nGoal 1. Compromising Enclave Confidentiality. Enclave run-\ntimes (e.g., Intel SGX SDK, Open Enclave SDK) usually implement\ntheirown memcpyfunctionforin-enclaveoperations.Suchafunc-\ntion performs memory copy on any accessible memory location\nregardlessoftheenclaveboundary,andacceptsthreearguments\nthat specify the source and the destination as well as the size of\nthedatatocopy.Thethreeargumentsarepassedin registers rdi,\nrsi, andrdx. We can use this function in our chain of gadgets.\nFirst, we set up arbitrary values into registers using memory-to-\nregistermovegadgets.Thenwechainagadgettoinvokethe memcpy\nfunction. This allows us to move arbitrary regions of memory to\narbitrary locations. For example, we can point the sourceaddress\nargumenttothestartoftheenclaveand destination addressto\na public memory region. Such a gadget will dump the entire en-\nclave memory. Alternatively, we can point the sourceto sensitive\ndata (e.g., SSL keys, enclave ephemeral keys) to selectively leak se-\ncrets. To compromise enclave confidentiality, we use ROP gadgets\ntomanipulate theenclaveto executea memcpyfunction.Through\nmanual inspection, we find and locate memcpyimplementations\ninthetrustedruntimecodeofbothIntelSGXSDKandMicrosoft\nOpen Enclave. We also find three pop reg; ret gadgets in the\nruntimesthatallowtheattackertopopulatethethreeregisterswith\nvalues from the attacker-controlled external stack. As illustrated\nin Figure 8, the attacker can perform the desired memcpyand steal\nenclave secrets by chaining the ROP gadgets on the external stack.\nGoal 2. Arbitrary Code Injection in Enclave. Similarly,theat-\ntacker can copy arbitrary code to the enclave memory and execute\nit. It points the sourceto a malicious code payload outside the\nenclaveandthe destination toanenclavepage.Specifically,iftheattacker sets the source to a prepared shellcode in the public mem-\nory and the destination to an executable and writable region in the\nenclaveprivatememory,itwillbeabletoinjecttheshellcodetothe\nenclave.Theattackercanthenpointthesubsequentreturnaddress\non the external stack to the injected shellcode in the enclave to\nexecuteit.SincecertainapplicationssuchasJITcompilersneedex-\necutableandwritableenclavememoryregions, SmashEx caninject\nandexecutearbitrarycode.OnanSGX2platformwheredynamic\nadjustmentofenclavepagepermissionsissupported, SmashEx can\nuse ROP gadgets to make certain pages executable and writable\nbefore injecting and executing the shellcode.\nOther Desirable ROP Gadgets. In addition to the ROP gadget\nchains discussed above, the attacker may also use others that serve\na wide range of goals. Prior work [ 31] has concluded that a ROP\nattack in an SGX enclave can be very expressive. More specifically,\nspecialgadgetsavailableinanSGXruntime(e.g.,IntelSGXSDK)\nenable the attacker to control the entire register file if it already\ncontrolsrsp,rdiandrsi.SmashEx meets thiscriterion required\nbypreviousattacks.Wecanthereforereproduceanyattacksshown\nby this prior work3but without their assumptions of common\nmemoryvulnerabilitiessuchasbufferoverflowintheenclavecode.\n7 ATTACKING REAL SYSTEMS\nWe present the low-level implementation challenges in executing\nend-to-endattacksontwoapplicationsascasestudies:anOpenSSL\nport with Intel SGX SDK and a cURL port with Open Enclave.\nWe run all the victim enclaves and the SmashEx exploits on an\nIntelNUCKitNUC7PJYHwithSGX2support, 8GBDRAM, 128MB\nEPC, and a Ubuntu 18.04 installation (Linux kernel 5.4.0-72). For\nSGXenclaveruntimes,weuseIntelSGXSDK2.13,SGXdriver2.11,\nand Open Enclave 0.15.0 [ 46], since these are the latest versions\navailable at the time of our experiments.\n7.1 Intel SGX SDK\nCase Study: OpenSSL v1.1.1i. Intel SGX SSL [ 17] is a crypto-\ngraphic library that uses OpenSSL [ 21] to provide general-purpose\ncryptographicservices(e.g.,keygeneration,encryption/decryption\noperations, decision-making statements) for SGX enclave applica-\ntions. For our end-to-end attack, we target a test program bundled\nwithIntelSGXSSL,wheretheenclavegeneratesapublic/private\nRSAkeypair.Byleakingthisprivatekey,weshowthat SmashEx\ncan breach the Intel SGX protections.\nWe have to locate the target in-enclave secret before we can\nlaunchSmashEx.Forthis purpose,wedisableASLRsystem-wide\nand pre-run the enclave once to record the addresses. In our attack\nrun,wewaitfortheenclavetoinvokeaspecific ocallthatreports\ntheresulttotheuserafterfinishingthecomputation.Wechooseto\nstart our attack after this ocall, because by this point, the enclave\nhas created the private key in its private memory. To copy the\nsecretkeytothepublicmemory,weusethe memcpygadgetchain\ndescribedinSection6.Theattackcausestheenclavetocopythe\n1024-bit key to the public memory.\n3Forexample,theattackercanchainthe asm_oret andcontinue_execution gadgets\nin Intel SGX SDK or oe_longjmp andoe_continue_execution in Open Enclave to\ncontrol a wider range of registers [31].\n7\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n785ImplementationChallenges. Weencounteredthefollowingtwo\nmain challenges when launching SmashEx against Intel SGX SDK.\nBypassingoverrun andalignmentchecks. Duringexception han-\ndling, the SGX runtime performs security checks to sanitize and\nensure consistency of certain enclave states. For instance, the in-\nenclave exception handler(see Listing 1) derivesthe stack pointer\nfromtheSSA.Thenitchecksthatthestackpointerisavalidenclave\nstackaddressandsatisfiesapre-definedalignmentrequirement.4\nWe set the malicious stack pointer to a legitimate enclave stack\naddress that obeys the required alignment to pass those checks.\n1... // check validity of thread_data, tcs, stack canary, enclave state,\nexception flag, ssa region\n2ssa_gpr = reinterpret_cast<ssa_gpr_t *>(thread_data->first_ssa_gpr);\n3sp = ssa_gpr->REG(sp);\n4... // check stack overrun\n5info = (sgx_exception_info_t *)sp;\n6if(ssa_gpr->exit_info.valid != 1) { // exception handlers are not allowed to\ncall in a non-exception state\n7gotodefault_handler;\n8}\n9...\n10info->cpu_context.r8 = ssa_gpr->r8;\n11...\n12info->cpu_context.r15 = ssa_gpr->r15;\n13... // alignment will be checked after exception is handled\nListing 1: Operations and security checks during exception\nhandling in\nIntel SGX SDK.\nTheocallreturn logic (see Listing 2) also includes important\nchecksthatourattackhastocircumvent.Forinstance,beforerestor-\ning theocallcontext,5the enclave sanitizes the ocallcontext\npointertoensurethatitisontheenclavestack(Lines3and5).In\naddition,theenclavechecksthevalidityofpartofthe ocallcon-\ntextcontent(Lines7and9).However,thosechecksdonotcoverthe\ndata that SmashEx needs to overwrite. We craft a legitimate stack\npointervaluetocontroltheanchorwithoutcorruptingthechecked\nmemory region. In this way, our attack bypasses the checks.\n1uintptr_t last_sp = thread_data->last_sp;\n2ocall_context_t *context = reinterpret_cast<ocall_context_t*>(thread_data->\nlast_sp);\n3if(0 == last_sp || last_sp <= (uintptr_t)&context)\n4returnSGX_ERROR_UNEXPECTED;\n5if(last_sp > thread_data->stack_base_addr - 30 * sizeof(size_t))\n6returnSGX_ERROR_UNEXPECTED;\n7if(context->ocall_flag != ocall_flag)\n8returnSGX_ERROR_UNEXPECTED;\n9if(context->pre_last_sp > thread_data->stack_base_addr ||\n10 context->pre_last_sp <= (uintptr_t)context)\n11returnSGX_ERROR_UNEXPECTED;\n12thread_data->last_sp = context->pre_last_sp;\n13asm_oret(last_sp, ms);\nListing2:Securitychecksbeforerestoringthe ocallcontext\nin\nIntel SGX SDK.\nRestoring host process stack after AEX. Recall that in Step 1 of\nSmashEx, we prepare the rspwith a malicious address that points\nto the enclave private memory. When we trigger an AEX in Step 2,\nthe hardware retains the rspeven after exiting the enclave. Ad-\nditionally,thehardwaretransferscontroltotheOSforkernelex-\nception handling. The kernel generates a corresponding signal for\n4In IntelSGX SDK 2.13, the is_valid_sp function performs such checks.\n5ocallcontextisadatastructureontheenclavestackthatstoresthecontextofthe\nenclave before an ocall.theexceptionandwantstodeliverthesignaltothehostprocess.\nThe kernel attempts to do this by using the rspto place the signal-\nrelated information on the host process stack. Since the rspstill\npoints to an in-enclave address, the kernel cannot perform this\noperation. However,for Step3 ofour SmashEx, itisnecessarythat\nthe attacker handle this signal in the host process. We ensure that\nwhen the OS accesses the rspit is pointing to a host stack location\nwith thesigaltstack() system call, which allows a user process\nto specify a separate signal handling stack. Alternatively, when the\nattackermovesmaliciousvaluesto rspinStep1,wecansavethe\ncurrentrspinthehostprocess.AftertheAEX,whenthecontrol\ncomes to the kernel, we restore the saved rspvalue to the rsp\nregister. Note that the malicious rspvalue has already been stored\nin the SSA at this point. Therefore, we can safely change the rsp.\nOur PoC integrates those two mechanisms to overcome the\nimplementation quirks of Intel SGX SDK.\n7.2 Open Enclave SDK\nCase Study: cURL v7.67.1. The cURL library implements a wide\nrange of application-layer network protocols, including HTTP,\nHTTPS,SMTP,andsoon.OpenEnclaveprovidesanofficialport\nof cURL [ 47] to allow applications that require secure network pro-\ntocols (e.g., HTTPS) to benefit from the protection of SGX. The\nenclave private memory contains several pieces of sensitive in-\nformationsuchassecurechannelkeys,enclaveprivatekeys,and\nHTTPS plaintext responses.\nWerunSmashEx onanOpenEnclavecURLtestprogramand\ndump the whole enclave private memory to the public memory.\nThiswillallowustoextractallthesecretsinsidetheenclaveprivate\nmemory.Weobtainthevirtualaddressrangesoftheenclavepri-\nvate memory regions by consulting the untrusted library of Open\nEnclave. The libraryis responsible for creating the enclave,and is\nthereforeawareoftheenclaveaddressspacelayout.Toensurethat\nthe enclave private memory contains secret data at the time of our\nattack, we wait for the enclave to finish sufficient ocalls before\nlaunchingtheattack.Inourexperiment,wewaituntilrightafter\nthe150𝑡ℎocallto startSmashEx, where we use the gadgets from\nSection 6 to dump the enclave content. The dumped data in our\nexperiment includes secrets such as plaintext HTTPS responses.\nConfiguring theAPIC Timer. We use the APIC timer to trigger\nthe AEX at the precise moment [ 60]. Typically, only the OS kernel\ncan configure the APIC timer. However, in order to trigger the\nexception at precisely the first instruction of the enclave, we want\ntoshortenthetimegapbetweenconfiguringtheAPICtimerand\nentering the enclave. Therefore, instead of configuring the APIC\ntimer inside the kernel space, we map the interface of the APIC\ntimer (memory-mapped I/O) directly to the address space of the\nhostprocess,andconfiguretheAPICtimerintheuserspaceshortly\nbefore entering the enclave via EENTER.\n8 ATTACK EXTENSIBILITY\nThe ramifications of unsafe re-entrancy in enclave handlers go\nbeyondthetargetplatformconfigurationsÐhardwareversionand\nruntimeÐwe used for our end-to-end attacks.\n8\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n7868.1 Extensibility to SGX1\nSGX1 and SGX2 have the same exception handling mechanism.\nThe main difference is that in SGX2, the enclave can request the\nhardware to notify the enclave about certain exceptions, such as\npage faults. This allows enclaves to dynamically manage memory.\nThe attack steps described so far assume SGX2, but they largely\nalsoapplytoSGX1.UnlikeSGX2,SGX1doesnotsupportreporting\npagefaultstotheenclave.Whensuchaneventoccurs,theSGX1\nhardware performs an AEX, but with one difference to SGX2: it\ndoes so without setting SSA.EXITINFO.valid , a field in the SSA\nregion, to 1. Both Intel SGX SDK and Open Enclave perform a\nvalidity check on this field in their exception handlers and only\nexecute the handler if SSA.EXITINFO.valid is1. In Open Enclave,\nby the time this check is done, SmashEx can already corrupt the\nanchor. Therefore, SmashEx works on Open Enclave with SGX1.\nIn Intel SGX SDK, SmashEx needs to bypass the above check to\nsucceed.Weexaminedthe 8exceptions(unconditionallysupported\nexceptions [ 15]) supported in SGX1. None can be used to trigger\ntheAEXattheenclaveentry.Asaresult,wearenotabletoexploit\nIntel SGX SDK on SGX1 with SmashEx.\nHowever, this safety comes with a trade-off in functionality for\nIntel SGX SDK: with this check in force, Intel SGX SDK disables\nasynchronous events on SGX1 and does not support programming\nprimitives for user-defined signal handlers. The root vulnerability\n(i.e., the lack of atomicity) is fundamental. We hypothesized that it\nwouldaffectSGX1ifIntelSGXSDKallowedexecutionofin-enclave\nexceptionhandlers,andconfirmedourhypothesisbyremovingthe\nvalidity check in the Intel SGX SDK and repeating our attack. Our\nPoCworkssuccessfullyonIntelSDKforSGX1withtheone-line\nvalidity check removed.\n8.2 Extensibility to Other Enclave Runtimes\nApart from Intel SGX SDK and Open Enclave, we survey 12other\nenclaveruntimestounderstandhowthevulnerabilityimpactsthem.\nWe report that 8of them are vulnerable to SmashEx, and have\nverified this by constructing SmashEx PoC exploits against them.\nDerivatives of Intel SGX SDK & Open Enclave. In our survey,\n8enclave runtimes are based on either Intel SGX SDK or Open\nEnclaveSDK.Amongthem, 6runtimesuseIntelSGXSDKorOpen\nEnclaveasitis,withoutanymodificationtotheexceptionhandling\nlogic. Those include Apache Teaclave [ 1], Rust SGX SDK [ 62], CoS-\nMIX [48], and Veracruz [ 26] which are based on Intel SGX SDK,\nandSGX-LKL[ 49]andEdgelessRT[ 11]whicharebasedonOpen\nEnclave.Sincealltherelevantinterfacesarestillexposedandun-\nchanged, such runtimes inherit the vulnerability from the runtime\nthey are based on. The other 2runtimes, Google Asylo [ 29] and\nRatel[24],usemodifiedIntelSGXSDK.Theyhavealteredthebe-\nhaviorsof exception handlingorotherenclave interfacesrelevant\ntoSmashEx andhenceneedtobeexaminedindividually.Google\nAsylo[29]keepstheoriginalexceptionhandlinginterfaceandas\na result is vulnerable to SmashEx. However, it also provides an\nalternative exception handling interface which uses a dedicated\nstackandcannotbeexploitedby SmashEx.Ratel[ 24]isimmune\ntoSmashEx because it uses a separate pre-allocated enclave stack\nforexceptionhandling.Wediscussthededicated-stackdesignin\ndetails in Section 9.1.IndependentRuntimes. RedHatEnarx[ 12]hasitsownSGXrun-\ntime independent of Intel SGX SDK and Open Enclave. Listing 3\nshows how it sets up the exception handler stack shortly after\nthe enclave is re-entered for exception handling. Similarly to its\ncounterpart in Open Enclave, the code loads the saved rspregister\nfrom the SSA region, shifts it by a fixed offset, and starts storing\nuntrustedregistervaluesatthatlocation.Wethereforeconclude,\nthroughourbest-effortcodeinspection,that SmashEx wouldwork\nsuccessfully on RedHat Enarx. Though open-source, RedHat Enarx\ndoes not have fully functioning code base yet [ 13]. Thus, we were\nnot able to experimentally demonstrate and confirm that SmashEx\nworks on it.\n1shl$12, % rax # %rax= CSSA * 4096\n2mov%rcx, % r11 # %r11= &Layout\n3add%rax, % r11 # %r11= &aex[CSSA - 1]\n4\n5mov RSP (%r11), %r10 # %r10= aex[CSSA - 1].gpr.rsp\n6sub$128, % r10 # Skip the red zone\n7and$~0xf, % r10 # Align\n8\n9movSRSP(%r11), % rax # %rax= syscall return stack pointer\n10\n11xchg%r10, % rsp # Swap to trusted stack\n12pushq$0 # Align stack\n13push%r10 # Save untrusted %rsp\n14savep # Save untrusted preserved registers\nListing 3: Exception handler stack setup in RedHat Enarx.\nThe other three runtimes developed independently of Intel SGX\nSDK and Open Enclave SDKÐAlibaba Inclavare [ 14], Fortanix Rust\nEDP [39], and Graphene-SGX [ 33,58]Ðare deemed immune to\nSmashEx throughmanualinspection.AlibabaInclavare[ 14]and\nFortanixRustEDP[ 39]bothsimplydisableallin-enclaveexception\nhandling,whichlimitstheenclavefunctionality.Graphene-SGX[ 33,\n58]introducessoftware-basedatomicitytosafelyhandleexceptions,\nwhich we elaborate on in Section 9.3.\n9 DEFENDING AGAINST SMASHEX\nThe proof-of-concept exploits for SmashEx are viable because the\nenclave runtimes (a) use the common program stack for exception\nhandling;and(b)lack software-orhardware-enforced atomicity.\nAn ideal solution would be to defeat both (a) and (b). However, we\ndiscuss the mitigations for these two issues separately. We summa-\nrizehowcertaindesignchoicesrenderenclaveruntimesimmune\ntoSmashEx, by disabling either requirement (a) or (b):\n•Useadedicatedstackforexceptionhandling(e.g.,Ratel[ 24]\nand the alternative mechanism in Google Asylo [29]);\n•Disableexceptionhandling(e.g.,FortanixRustEDP[ 39]and\nAlibaba Inclavare [14]);\n•Program the exception handler in a re-entrant way (e.g.,\nGraphene-SGX [33]).\nHowever, those designs come with significant downsides either\nby limiting the enclave functionality or by introducing complexity.\n9.1 Dedicated Exception Handler Stack\nUnlike the original exception handler in Intel SGX SDK, the excep-\ntion handling interfaces in Google Asylo and Ratel use a dedicated\nstackseparatefromtheoneusedbytheinterruptedthread.They\nthereforeavoidrelyingonthe rspvalueintheSSAregionwhich\nSmashEx exploits to control the anchor. However, since both of\n9\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n787them reserve only one separate stack, exception handling through\nsuch interfaces cannot be nested. In other words, if during the han-\ndlingofanexception,anotherexceptionoccurs,thisnewexception\ncannot be handled inside the enclave. This limits the compatibil-\nity between Google Asylo or Ratel and traditional programming\nmodels where signals can be nested. One can adapt these runtimes\ntosupportnestedexceptionsbyreservinganindividualstackfor\neach level of nested exceptions. However, the fixed memory size\nrequired by each reserved stack may limit its scalability.\n9.2 Disabling Exception Handling\nBothFortanixRustEDP[ 39]andAlibabaInclavare[ 14]areimmune\ntoSmashEx because they do not support any in-enclave exception\nhandling.TheyconfigureenclavessothattheSGXhardwareforbids\nthe untrusted software from re-entering the enclave via EENTER\nafter an AEX. Specifically, the configuration parameter, TCS.NSSA ,\nwhensetto1,impliesthatthehardwarecanstoreatmost1AEX\ncontextinsidetheSSAatanytime.Whenevertheuntrustedsoft-\nwareattemptstore-entertheenclavevia EENTERfollowinganAEX,\nthehardwaredisallowsitbecauseoftheinsufficientAEXcontext\nslots to hold another potential AEX after the re-entry. Without the\npossibilityofare-entry,in-enclaveexceptionhandlingiseffectively\ndisabled. Making an enclave thread execution fully synchronous\nthis way simplifies the reasoning about re-entrancy. However, this\ndesignchoicelimits thefunctionalityoftheenclavesoftware.For\nexample, the try-catchexception handling primitive widely used\ninmodernhigh-levelprogramminglanguagescannotleveragehard-\nware exception support inside an enclave, making them inefficient\nand cumbersome to enable. It hinders the implementation of signal\nhandlingmechanismscommonlyprovidedbymodernOSessuchas\nLinux, which are important to the functioning of user applications.\nSuchlimitationsdegradethecompatibilityofAlibabaInclavareand\nFortanix Rust EDP with traditional programming models.\n9.3 Re-entrant Exception Handling\nAnSGXruntimesoftwaremayattempttoprovideatomicprimitives\nfor re-entrant exception handling. One example is Graphene-SGX.\n1movqSGX_GPR_RIP(%rbx), % rax\n2leaq.Locall_about_to_eexit_begin(%rip), % r11\n3cmpq%r11, % rax\n4jb.Lhandle_interrupted_ocall_case_c\n5leaq.Locall_about_to_eexit_end(%rip), % r11\n6cmpq%r11, % rax\n7jae.Lhandle_interrupted_ocall_case_c\n8\n9// ...\n10\n11.Lhandle_interrupted_ocall_case_c:\n12movq%rdi, SGX_GPR_RSI(% rbx) # external eventfor .Lreturn_from_ocall\n13leaq.Lreturn_from_ocall_after_stack_restore(%rip), % rax\n14movq%rax, SGX_GPR_RIP(% rbx)\n15movq%rsi, SGX_GPR_RSP(% rbx)\n16movq$0, % gs:SGX_PRE_OCALL_STACK\n17andq $(~(RFLAGS_DF | RFLAGS_AC)), SGX_GPR_RFLAGS(%rbx)\n18jmp.Leexit_exception\nListing 4: Emulation of part of the sanitization logic at\nenclave\nentry in the exception handler of Graphene-SGX.\nGraphene-SGX. Itusesthesamestackfromtheinterruptedthread\nfor exception handling. However, in our investigation, we find that\nGraphene-SGX does not blindly load the stack pointer from the\nSSAregion.Instead,itexaminesthelocationoftheAEX(the ripregistervalueinsidetheSSAregion),andhandlesitdifferentlyin\ndifferent cases. For example, when Graphene-SGX finds that the\nAEX occurred within the sanitization logic at the enclave entry, it\nwill emulate the unfinished sanitization logic. Instead of operating\non real registers as in normal execution, it operates on the register\nvaluesstoredintheSSAregion(seeListing4).Thisseparatesthe\nexecution of the sanitization logic and the exception handler. Thus,\nwhen the enclave starts the post-sanitization processing of the\nAEX,thestackhasalreadybeencorrectlysetupandisnolonger\ncontrolled by the untrusted software.\n1leaq.Ltmp_rip_saved0(%rip), % rax\n2cmpq%rax, SGX_GPR_RIP(% rbx)\n3je.Lemulate_tmp_rip_saved0\n4\n5leaq.Ltmp_rip_saved1(%rip), % rax\n6cmpq%rax, SGX_GPR_RIP(% rbx)\n7je.Lemulate_tmp_rip_saved1\n8\n9leaq.Ltmp_rip_saved2(%rip), % rax\n10cmpq%rax, SGX_GPR_RIP(% rbx)\n11je.Lemulate_tmp_rip_saved2\n12\n13jmp.Lemulate_tmp_rip_end\n14\n15.Lemulate_tmp_rip_saved0:\n16# emulate movqSGX_CPU_CONTEXT_R15 - SGX_CPU_CONTEXT_RIP(%rsp), %r15\n17movqSGX_GPR_RSP(%rbx), % rax\n18movqSGX_CPU_CONTEXT_R15 - SGX_CPU_CONTEXT_RIP(%rax), %rax\n19movq%rax, SGX_GPR_R15(% rbx)\n20.Lemulate_tmp_rip_saved1:\n21# emulate movqSGX_CPU_CONTEXT_RSP - SGX_CPU_CONTEXT_RIP(%rsp), %rsp\n22movqSGX_GPR_RSP(%rbx), % rax\n23movqSGX_CPU_CONTEXT_RSP - SGX_CPU_CONTEXT_RIP(%rax), %rax\n24movq%rax, SGX_GPR_RSP(% rbx)\n25.Lemulate_tmp_rip_saved2:\n26# emulate jmp*% gs:SGX_TMP_RIP\n27movq%gs:SGX_TMP_RIP, % rax\n28movq%rax, SGX_GPR_RIP(% rbx)\n29.Lemulate_tmp_rip_end:\n30movqSGX_GPR_RSP(%rbx), % rsi\n31// ...\nListing 5: Emulation of part of the enclave context\nrestoration\ncodeintheexceptionhandlerofGraphene-SGX.\n1.Ltmp_rip_saved0:\n2movqSGX_CPU_CONTEXT_R15 - SGX_CPU_CONTEXT_RIP(%rsp), %r15\n3.Ltmp_rip_saved1:\n4movqSGX_CPU_CONTEXT_RSP - SGX_CPU_CONTEXT_RIP(%rsp), %rsp\n5.Ltmp_rip_saved2:\n6jmp*%gs:SGX_TMP_RIP\nListing 6: Part of the enclave context restoration\ncode\n. Graphene-SGX emulates its execution instruction by\ninstruction in the exception handler (see Listing 5).\nBesides emulating the sanitization logic and register setup at\nthe enclave entry point, Graphene-SGX emulates the execution of\ntheinterruptedthreadwhenevertheAEXoccursinothercritical\nregionswheretheenclavestateisunsafeforexceptionhandling.\nListings5and6showmoreexamples.Aftertheemulation,theAEX\nappearstohaveoccurredoutsidethecriticalregions.Bydoingthis,\nGraphene-SGX effectively makes the enclave exception handler\nsafely re-entrant.\nThisdesignissignificantlymorenuancedandcomplex.Wenote\nthat it has been the result of years of patching and revising. The\nsignal and exception handling design for Graphene-SGX has un-\ndergone several iterations in the past three years [18, 22, 23].\nAlternativeImplementationStrategies. Thedesignadoptedby\nGraphene-SGX is not the only possible implementation strategy\nand can be generalized by addressing two key questions.\n10\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n788Q1.Howcantheenclaveidentifywhetheranexceptionoccurred\ninside a critical section?\nQ2.WhatshouldtheenclavedowhentheuntrustedOSattempts\nto deliver an exception during a critical section to the enclave?\nTrackingCriticalSections. Theenclavecantrackitsowncritical\nsectionsexplicitly.Specifically,theenclaveruntimesoftwarecan\nmaintain the location information (e.g., code address ranges) about\nall its critical sections. When required, it can check if the code\naddress where the exception occurred falls within the range of\nknown critical sections. This is the option chosen by Graphene-\nSGX.Alternatively,theenclavesoftwarecanmaintainaper-thread\n1-bitflaginits privatememory.Itsetstheflagwhenevertheenclave\nisabouttoenteracriticalsection,andclearsitimmediatelyafter\nexiting a critical section. To check if an exception happened in a\ncritical section, the enclave exception handler can check this flag.\nHandling Exceptions in Critical Sections. If the enclave is in-\nterrupted midway in a critical section, one approach is to emulate\ntherestofthecriticalsection.Moreprecisely,theenclaveexception\nhandlercanidentifythepointofinterruption,lookupthecritical\nsection, and emulate the remaining part of the interrupted critical\nsection.Afterthat,thehandlercanperformthereal(non-emulated)\nexception handling. With this mechanism, the enclave gets an il-\nlusion that the exception occurred immediately after the critical\nsection.Thisdesignworksonlyincaseswheretheenclaveruntime\nhassufficientinformationaboutthecriticalsectionstoemulateit.\nThis is the option chosen by Graphene-SGX.\nA second way is to postpone the exception handling. Instead of\nimmediatelyinvokingtheexceptionhandler,theenclaveruntime\nsoftwarecanchoosetoexecutethecurrentcriticalsection.Once\nthesectionends,theruntimeexecutesthehandler.Thismechanism\nrequirestheenclaveruntimetomaintainthereceivedexceptions\n(e.g., via setting a per-thread pending flag) and add logic at the end\nof each critical section to handle pending exceptions.\nFinally,astraightforwardwayistoignoreanyexceptionsthat\narrive whena critical sectionis being executed.However,it isim-\nportanttoensurefunctionalcorrectnesswhentheOSiscooperative.\nForinstance,anexceptionshouldnotbelostwhenacooperative\nOSdeliversitwhiletheenclaveisinacriticalsection,unlessthe\nenclaveexposessufficientinformation(e.g.,bysettingOS-visible\ncriticalsectionflags)toallowtheOStoavoiddeliveringexceptions\nduring critical sections.\nCaveats. Although the above design options are conceptually sim-\nple,thereareseveralimplementationdetailsthatneedcarefulatten-\ntion. The first issue arises when an enclave has to maintain a data\nstructuretotrackpendingexceptions(e.g.,abitmapthatrecordsthe\npostponed exception types). After the critical section, the enclave\nneeds to read such data structures to process the postponed excep-\ntions.Shouldthecodethatdoesthisbeincludedaspartofthesame\ncriticalsection?Ifitispartofthecriticalsection,thedatastructure\noperationsmustbemadere-entrant.Thisisbecause,inacritical\nsection,adeliveredexceptionwilltriggerwriteoperationstothe\ndata structures. If it is outside the critical section, one must either\nensure the same re-entrancy property or ensure that no exception\nhandling code contains critical sections, and hence may involve\nwrite operations to the data structures.The second issue concerns the use of a critical flag. One must\nensurethattheflagcoversalllocationswhereexceptionsshould\nnot be handled. One location particularly prone to negligence is\nimmediatelyafteranenclaveentry( EENTER).Asdemonstratedby\nSmashEx, exceptions immediately after the enclave entry, when\nuntrustedOSstillcontrolstheregistervalues,cannotbehandled\ndirectly.Iftheenclavereliesonaninstructiontosettheflagafter\nthe enclave entry, this leave a window of time between enclave\nentryand when theflag isset. To avoid thisproblem, an enclave\nmust ensure that the flag is set before an EEXIT.\nA third issue stems from the requirement of exception-free han-\ndler implementations. Although one can carefully implementhan-\ndler logic to be free of certain programming-oriented exceptions\n(e.g.,dividebyzero),OS-inducedpagefaultsaredifficulttoavoid.\nForinstance,ifanenclaveusescustompagefaulthandlersonSGX2,\ndelivery of page faults to the enclave cannot be delayed or ignored,\nespeciallyforfaultsonpagesaccessedwithinacriticalsectionof\nthe exception handler itself.\nInsummary,whiletherearesoftware-basedstrategiesforachiev-\ning re-entrant exception handling, they introduce considerable\ncomplexity to ensure desired functionality and security.\n9.4 Impact of Other Memory Defenses\nAsecondlineofdefensesaimatthwartingthecode-reuseattack\nsteps (Steps 5 and 6) of SmashEx.\nBypassing ASLR. TheSmashEx attack requires the attacker to\nknow the exact address of the anchor. Since the OS allocates the\nvirtualmemoryrangefortheenclaveandsetsthepagepermissions,\ntheattackerknowsthattheenclavestackwillbewithinacertain\nrange. However, the enclave may randomize the base address of its\nstack (e.g., Asylo [ 29]) to prevent the attacker from predicting the\nanchor location accurately. The attacker can adapt SmashEx in the\nfollowing ways to overcome this hurdle.\nThefirststrategyfollowstheobservationthatSteps1ś4areto\noverwrite more than one memory location. For example, in our\nGoogle Asylo [ 29] PoC exploit (elided here), we can overwrite 152\nbytes, out of which 64bytes are freely controllable by the attacker.\nThe attacker can therefore set all those locations to the desired\nvaluefortheanchorinthehopeofhittingtheactualanchor.Given\nthatGoogleAsyloinitializesthestackbaseaddressbyadvancing\nthe stack by a random amount between 1and2048, this strategy\nhas an attack success rate of 3.125%per trial.\nOne of the issues with using ASLR defenses in our context is\nthat a failed trial results in an invalid memory access which in\nturncreatesanotherexception.Thisgivestheattackeradditional\nopportunities to reenter the enclave. To concretely illustrate the\nissue, we implemented a multi-round proof-of-concept attack vari-\nantofSmashEx specializedforGoogleAsylo.Amulti-roundattack\ntrial has multiple rounds, where each round executes Steps 1ś4\noftheSmashEx proceduretocorruptonelocation.Notethatthe\nattacker-corruptedlocationisusedinStep5.Ifwemispredictthe\nanchoraddressasthecorruptionvalue,theenclavewillpotentially\ncrashinthesubsequentsteps.Whatremains,therefore,istokeep\niterating Steps 1ś4 while making sure that the enclave does not\nprogresstoStep5,i.e.,toresumethereturnfrom ocall.Toachieve\n11\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n789this, the attacker uses an invalid ecallnumber6to enter the en-\nclave in Step 1, instead of the one that requests a return from an\nocall.WhentheenclaveresumesexecutionafterAEXattheentry\npoint, it checks the ecallcommand. Since the ecallcommand is\ninvalid, the enclave forces an EEXIT. As a result, Steps 5ś6 will not\ntakeplaceandinsteadSteps1ś4repeat.Theattackercanthenkeep\nrepeating this procedure of using bad ecallnumbers and corrupt\none new location each time reliably. Finally, after controlling suffi-\ncientlocations,theattackerperformsan EENTERwiththecorrect\necallnumber.Inthislastiteration,theenclaveperformsSteps5ś6\nandusesabadstackvalue,thuscorruptingtheanchorreliablyeven\nin the presence of ASLR.\nBypassing Stack Canary. The stack canary is a widely-deployed\ndefenseagainstbufferoverflowexploits[ 37].Theattackerhasto\ncorruptunintendedstacklocationsasasideeffectofthememory\ncorruption.While SmashEx doesnotinvolveabufferoverflow,it\ndoes corrupt unintended locations beyond the anchor itself. There-\nfore, it is conceptually possible to mitigate SmashEx with stack\ncanaries. However, the stack canary supported in common modern\nCcompilers(e.g.,with -fstack-protector-all inGCC)doesnot\nhelp protect against SmashEx. Unlike the return address of a func-\ntion call, the stack canary automatically generated by the compiler\ndoes not protect the saved ocallcontext, and hence the anchor,\nthatSmashEx aims to control. Moreover, even if all code pointers\non the stack have been carefully protected by stack canaries, the\nattackercanadapt SmashEx tolaunchadata-orientedattack[ 41]\nwithout controlling code pointers. In addition, due to a lack of\nchecks on the stack pointer, on some SGX runtimes (e.g., Open\nEnclave) SmashEx has the option to control non-stack locations,\nincludingwherethesecretstackcanaryvalueisstored.Thismakes\nexisting stack canary defenses ineffective against SmashEx.\n9.5 Better Hardware Support for Atomicity\nWhileitispossibletoimplementtheenclavesoftwareinasafely\nre-entrantway,doingthisentailsafairlycomplicateddesignwhich\nis difficult to reason about. This motivates us to propose strategies\nofenablingatomicitysupportinhardware,whichSGXcurrently\nlacks. We start by examining the atomicity support available to the\nOS and traditional user applications.\nAtomicity in the OS. Since the OS can configure hardware inter-\nruptandexceptionsources(e.g.,interruptcontrollers),itcansimply\ndisableinterruptsandexceptionswheneveritdesiresatomicity.For\nSGX enclave software, however, an untrusted party (i.e., the OS)\ncan trigger an exception at any time. The enclave has no way of\ncontrolling or predicting when it will be interrupted.\nAtomicity in Traditional User Applications. Traditional user\napplicationsrelyontheOStocontrolwhentheycanbeinterrupted\nand re-entered in the midst of their execution(e.g., for signal han-\ndling). For example, POSIX-compliant OSes define the set of sce-\nnarioswheretheycandeliversignalstoauserprocess[ 20].User\nprocesses can use the sigprocmask system call to dynamically en-\nable or disable the delivery of a certain signal during runtime. For\n6Theecallnumber is an integer that the untrusted software passes to the enclave\nupon anecallto indicate which enclave function to execute.SGX enclaves, the OS or the host process is still in charge of invok-\ningin-enclaveexceptionhandlers,butitisnottrustedandshould\nnot be relied on to decide when to perform a re-entry.\nEnablingAtomicityPrimitivesinHardware. Wepointoutthat\nin both the above cases, the atomicity guarantee is provided by\na different but trusted entity (the hardware or the OS) through\ndisabling either interrupts or re-entry upon an interrupt. For an\nSGXenclave,onlythehardwarecanbesuchatrustedentity.We\ndiscussthepotentialchangesintheSGXhardwareabstractionto\nenable atomicity primitive for enclaves. Following the inspiration\nfrom the atomicity primitives available to the OS and traditional\nuserapplications,wediscusstwodirections:disablingexceptions\nand disabling re-entry.\nDirection1:TemporarilyDisablingInterruptsandExceptions. Intel\nSGX can be adapted to allow enclaves to dynamically enable or\ndisableinterruptsandexceptionsfromhardware,similarlytothe\nprimitivesOSesusetoachieveatomicity.TheSGXhardwarecan\nprotecttheenclaveexecutionfrombeinginterruptedattherequest\noftheenclave.Anaïvedesignthatallowstheenclavetousethis\nprimitivewithoutrestrictionswillenableanenclavetofullyoccupy\na hardware thread for an arbitrarily long period, thus launching\ndenial-of-service(DoS)attacksagainsttheOS.ToavoidDoSattacks,\nthe SGX hardware can let the OS decide whether to accept or deny\nsuchrequestsfromenclaves.Thehardwarerelaysthedecisionofthe\nOStotheenclave,whointurncanmakeaninformeddecisionabout\nexecutingcriticalcode.Forexample,theOSmaybasesuchdecisions\nonapre-exchangedquotaforinterruptdisabling:itmaypermitthe\nenclavetorunwithinterruptsdisabledfor(say) 100cyclesinevery\n10Kcyclesexecutedintheenclave.Insuchacase,corresponding\nsupport for counting and limiting the enclave execution cycles\nwill need to be available inside the hardware. Such an enclave-\nOScontractfacilitatedandenforcedbythehardware,ifdesigned\ncarefully, can guarantee atomicity while preventing DoS.\nDirection 2: Temporarily Disabling Enclave Re-entry. Instead of\nblocking interrupts or exceptions, another option is to allow the\nenclavetodisableenclavere-entryduringruntime.Inthisdesign,\nthe enclave can still be interrupted when it has disabled enclave\nre-entry, leaving untrusted software the chance to perform excep-\ntion handling and manage resources accordingly. However, the\nSGXhardwareonlyallowsittoresumetheenclaveexecutionvia\nERESUME, but disallows re-entry into the enclave via EENTER. Im-\nmediately after enclave entry, since the enclave software needs\nto perform crucial operations to complete a context switch into\nthe enclave, the enclave hardware should preferably automatically\nmask enclave re-entry by default to ensure its atomicity.\nBoth directions pose the risk of opening a new side channel.\nThe attacker may learn whether an enclave is inside a critical code\nregion simply by attempting to deliver an exception into it. Never-\ntheless,webelieveaddressingatomicityontheOS-enclaveinterface\nthrough a carefully designed hardware abstraction is promising\nfuture work. We hope these directions offer a starting point.\n10 RELATED WORK\nTheSmashEx attackistargetedatIntelSGXenclaves.Itstemsfrom\nunsafe re-entrancy at the OS-enclave interface. We have demon-\nstratedthat,ifexploited,itcanleadtocode-reuseattacks.Inthis\n12\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n790sectionweexamineprominentworkonsecuringhost-enclavein-\nterfacesonIntelSGX,code-reuseattackstargetingSGXenclaves,\nand re-entrancy vulnerabilities in non-enclave settings.\nSecurity of Synchronous SGX Interfaces. Since the introduc-\ntion of Intel SGX, there has been abundant work on the security of\nthesynchronousinterfacesbetweenuntrustedsoftwareandSGX\nenclaves.Previousworkhasdiscoveredthatanattackercancom-\npromisetheconfidentialityandintegrityofanenclavebyproviding\nmalicious system call return values, referred to as Iago attacks [ 34].\nEliminatingsuchthreatsrequiresenclavesoftwaretocarefullyscru-\ntinize system call return values passed into an enclave [ 28,55,58],\nwith the aid of formal verification [ 56] or software testing tech-\nniques [38]. Inaddition, enclave runtimes may forget toclean cer-\ntain registersafter a contextswitch intoan enclave, thusopening\nuptheenclavetoattacks[ 27,59].Thesynchronousinterfacehas\nbeenasubjectofcomprehensivesurveyandcategorizationofat-\ntacks [42]. Unlike these lines of work, our paper examines the\nsecurity of asynchronous OS-enclave interfaces.\nSecurityofAsynchronousSGXInterfaces. Existingattackshave\nshown that timer interrupts or page faults can be leveraged to leak\nenclave secrets through side channels [ 32,60,63,64]. Defending\nagainstsuchside-channelattacksisnon-trivial[ 35,53,54].Previous\nworkhasexaminedtheattackavenueofenclavethreadscheduling.\nIntheSGXthreatmodel,theattackercancontrolthescheduling\nandinfluencetheenclavelogic.Suchmanipulationscancompro-\nmise enclave confidentiality and integrity if the enclave logic is\ninfluenced by scheduling. For example, the attacker can affect the\nenclavebehaviorbyexploitingexistingsynchronizationbugs[ 2]or\nbreakingassumptionsmadebytheenclaveapplicationregarding\nthe thread scheduling algorithm [ 61]. However, the security impli-\ncationsoftheasynchronousinterfacesofSGXenclaveshavenot\nbeen comprehensively studied. Specifically, to our knowledge, our\nworkisthefirsttostudythesecurityimplicationsattheOS-enclave\ninterface for asynchronous exceptions on SGX.\nCode-reuse Attacks on SGX. The prevalence of code-reuse at-\ntacks in non-enclave applications is well studied [ 57]. Although\nenclaves reduce the size of the trusted computing base, they are\nsusceptible to corruption if the enclave code has unsafe memory\nusage.Thus,enclavesarenotimmunetocode-reuseattacks[ 36].\nDark-ROP [ 43] demonstrates a ROP attack even when the enclave\nbinary is end-to-end encrypted [ 30,51] such that the attacker can-\nnot inspect it. They assume a fixed enclave address space layout,\nwhich allows the attacker to probe the locations of useful gad-\ngetsthrough trials-and-errors.Thisassumption isjustifiedbythe\ndifficulty in applying defense techniques such as ASLR to SGX\nenclaves due to the constraints imposed by the Intel SGX design.\nSGX-Shield [ 52] proposes a strategy to enable ASLR in SGX en-\nclavesandpreventcode-reuseattacks.However,asshowninthe\nsubsequentwork,SGX-Shielddoesnotrandomize thecodeinside\nthe trusted runtime of the enclave. This allows the attacker to\nexploit memory-unsafe enclave code and launch powerful ROP at-\ntacks [31].SmashEx demonstrates a code-reuse attack on enclaves.\nHowever,unliketheexistingwork,wedonotassumeapre-existing\nmemory vulnerability in the enclave software.\nRe-entrancyVulnerabilities&Defenses. Traditionalasynchro-\nnousinterfaces,suchasthesignalhandler,arepronetore-entrancychallenges[ 65].Suchvulnerabilitiesarecommoninseveralother\nsystems[5ś7,9,10,40,44].SmashEx isthefirstattackthatexploits\nre-entrancy vulnerabilities in the context of Intel SGX. Preventing\nre-entrancy bugs in general involves introducing a notion of atom-\nicity. For instance, when the code is operating in a critical section,\ntheuserapplicationcanrequesttheOStomaskcertainsignals(i.e.,\ntopausetheirdelivery)[ 25].Ourworkmakesthefirstattemptto\ncompareandcontrastexceptionhandlinginIntelSGXversustradi-\ntionalsystems.Ourfindingshighlighttheneedforbetterhardware\nabstractions to enable safely re-entrant enclave code.\nSmashEx bringsattentiontoanewavenueofpowerfulattacks\non Intel SGX. It can serve as a motivation to further scrutinize and\nfortify the enclave asynchronous interface.\n11 RESPONSIBLE DISCLOSURE\nWe informed the affected partiesÐIntel for Intel SGX SDK and Mi-\ncrosoft for Open Enclave SDKÐon 3 May 2021. Intel and Microsoft\nacknowledged the attack and assigned CVE-2021-33767 [ 8]. Af-\nter due process, Intel and Microsoft released patches for SmashEx\non 13 July 2021. In addition, they released public advisories on\n13 July 2021 [ 19] and 15 September 2021. We have assisted Intel\nand Microsoft to coordinate responsible disclosures to the affected\nruntimes listed in Table 1, where it was requested.\n12 CONCLUSION\nAsynchronous exception handling is a commodity functionality\nfor real-world applications today, which are increasingly utilizing\nenclaves. In this work, we show the importance of providing atom-\nicityguaranteesattheOS-enclaveinterfaceforsuchexceptions.We\nhave introduced a new attack called SmashEx in this work, which\nexploitstheinherentre-entrancyinterfacerequiredinexception\nhandlingonSGX.Ourexploitsdemonstratetheissueconcretelyon\npopularSGXruntimeframeworks.Wehopeourworkinitiatescare-\nfulconsideration forasynchronous exceptionhandlingin existing\nSGX frameworks as well as in future enclave designs.\nAVAILABILITY\nWe maintain further information regarding SmashEx, including\nhowtoacquiretheproof-of-conceptexploitsforeducationalpur-\nposes, at https://jasonyu1996 .github.io/SmashEx/.\nACKNOWLEDGMENTS\nWe thank the anonymous CCS reviewers for their valuable sugges-\ntions. This work was supported by Crystal Center at National Uni-\nversityofSingapore.ZhipingCai’sworkwasfundedbyNational\nNatural Science Foundation of China (62072465). Any opinions,\nfindings, and conclusions or recommendations expressed in this\nmaterial are those of the authors only.\nREFERENCES\n[1][n.d.]. Apache Teaclave: A Universal Secure Computing Platform. https://\nteaclave.apache.org/.\n[2] [n.d.]. AsyncShock: Exploiting Synchronisation Bugs in Intel SGX Enclaves.\n[3][n.d.]. ConfidentialComputingConsortium-OpenSourceCommunity. https:\n//confidentialcomputing .io/.\n[4][n.d.]. Confidential Consortium Framework - Microsoft Research.\nhttps://www .microsoft .com/en-us/research/project/confidential-consortium-\nframework/.\n13\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n791[5][n.d.]. CVE - CVE-2011-1285: The regular-expression functionality in Google\nChromebefore10.0.648.127doesnotproperlyimplement reentrancy,whichal-\nlowsremoteattackerstocauseadenialofservice(memorycorruption)orpossibly\nhaveunspecifiedotherimpactviaunknownvectors. https://cve .mitre.org/cgi-\nbin/cvename .cgi?name=CVE-2011-1285.\n[6][n.d.]. CVE-CVE-2016-5185:Blinkin Google Chromepriorto54.0.2840.59for\nWindows, Mac, and Linux; 54.0.2840.85 for Android incorrectly allowed reen-\ntrance of FrameView::updateLifecyclePhasesInternal(), which allowed a remote\nattacker to perform an out of bounds memory read via crafted HTML pages.\nhttps://cve .mitre.org/cgi-bin/cvename .cgi?name=CVE-2016-5185.\n[7][n.d.]. CVE - CVE-2018-16065: A Javascript reentrancy issues that caused a\nuse-after-free in V8 in Google Chrome prior to 69.0.3497.81 allowed a remote\nattacker to execute arbitrary code inside a sandbox via a crafted HTML page.\nhttps://cve .mitre.org/cgi-bin/cvename .cgi?name=CVE-2018-16065.\n[8][n.d.]. CVE-2021-33767 - Security Update Guide - Microsoft - Open Enclave\nSDK Elevation of Privilege Vulnerability. https://msrc .microsoft .com/update-\nguide/vulnerability/CVE-2021-33767.\n[9][n.d.]. CWE - CWE-1265: Unintended Reentrant Invocation of Non-reentrant\nCode Via Nested Calls (4.4). https://cwe .mitre.org/data/definitions/1265 .html.\n[10][n.d.]. CWE-CWE-479:SignalHandlerUseofaNon-reentrantFunction(4.4).\nhttps://cwe .mitre.org/data/definitions/479 .html.\n[11][n.d.]. Edgeless RT: an SDK and a runtime for Intel SGX. https://github .com/\nedgelesssys/edgelessrt.\n[12][n.d.]. Enarx: an application deployment system enabling applications to run\nwithin TEE. https://github .com/enarx/enarx/wiki/Enarx-Introduction.\n[13][n.d.]. Enarx FAQ ·enarx/enarx Wiki. https://github .com/enarx/enarx/wiki/\nEnarx-FAQ.\n[14] [n.d.]. Inclavare Containers. https://inclavare-containers .io/.\n[15] [n.d.]. Intel 64 and IA-32 Architectures Software Developer Manuals.\n[16][n.d.]. IntelSoftwareGuardExtensionsSDK-Documentation|IntelSoftware.\nhttps://software .intel.com/en-us/sgx-sdk/documentation.\n[17][n.d.]. Intel Software Guard Extensions SSL cryptographic library. https://\ngithub.com/intel/intel-sgx-ssl.\n[18][n.d.]. [LibOS] Rework signal handling by boryspoplawski ·Pull Request #2090 ·\noscarlab/graphene. https://github .com/oscarlab/graphene/pull/2090.\n[19][n.d.]. OpenEnclaveSDKElevationofPrivilegeVulnerability ·Advisory ·ope-\nnenclave/openenclave. https://github .com/openenclave/openenclave/security/\nadvisories/GHSA-mj87-466f-jq42.\n[20][n.d.]. The Open Group Base Specifications Issue 7, 2018 edition. https:\n//pubs.opengroup .org/onlinepubs/9699919799/.\n[21][n.d.]. OpenSSL:CryptographyandSSL/TLSToolkit. https://www .openssl.org/.\n[22][n.d.]. [Pal/Linux-SGX] enclave_entry.S fix stack on exception and ocall by\nyamahata ·Pull Request #696 ·oscarlab/graphene. https://github .com/oscarlab/\ngraphene/pull/696.\n[23][n.d.]. [Pal/Linux-SGX] Fix super-subtle bugs in SGX enter/ex-\nit/AEX flows by dimakuv ·Pull Request #1663 ·oscarlab/graphene.\nhttps://github.com/oscarlab/graphene/pull/1663.\n[24][n.d.]. Ratel: a general framework for instruction-level interposition on enclaved\napplications. https://ratel-enclave .github.io/.\n[25][n.d.]. sigprocmask(2) - Linux manual page. https://man7 .org/linux/man-pages/\nman2/sigprocmask .2.html.\n[26][n.d.]. Veracruz: privacy-preservingcollaborative compute. https://github .com/\nveracruz-project/veracruz.\n[27]Fritz Alder, Jo Van Bulck, David F. Oswald, and Frank Piessens. 2020. Faulty\nPointUnit:ABIPoisoningAttacksonIntelSGX.In ACSAC’20:AnnualComputer\nSecurityApplicationsConference,Virtual Event/Austin,TX,USA,7-11December,\n2020. ACM, 415ś427. https://doi .org/10.1145/3427228 .3427270\n[28]SergeiArnautov,BohdanTrach,FranzGregor,ThomasKnauth,AndreMartin,\nChristianPriebe,JoshuaLind,DivyaMuthukumaran,DanielO’Keeffe,MarkL\nStillwell, David Goltzsche, Dave Eyers, Rüdiger Kapitza, Peter Pietzuch, and\nChristofFetzer.2016. SCONE:SecureLinuxContainerswithIntelSGX.In OSDI.\n[29]asylo2019. GoogleAsylo:Anopenandflexibleframeworkforenclaveapplica-\ntions. https://asylo .dev/.\n[30]AndrewBaumann,MarcusPeinado,andGalenHunt.2014.ShieldingApplications\nfrom an Untrusted Cloud with Haven. In OSDI.\n[31]Andrea Biondo, Mauro Conti, Lucas Davi, Tommaso Frassetto, and Ahmad-Reza\nSadeghi. 2018. The Guard’s Dilemma: Efficient Code-Reuse Attacks against\nIntel SGX. In Proceedings of the 27th USENIX Conference on Security Symposium\n(Baltimore, MD, USA) (SEC’18). USENIX Association, USA, 1213ś1227.\n[32]Jo Van Bulck, Nico Weichbrodt, Rüdiger Kapitza, Frank Piessens, and Raoul\nStrackx. 2017. Telling Your Secrets without Page Faults: Stealthy Page\nTable-Based Attacks on Enclaved Execution. In 26th USENIX Security Sym-\nposium (USENIX Security 17). USENIX Association, Vancouver, BC, 1041ś\n1056. https://www .usenix.org/conference/usenixsecurity17/technical-sessions/\npresentation/van-bulck\n[33]Chia che Tsai, Donald E. Porter, and Mona Vij. 2017. Graphene-SGX: A Practical\nLibraryOSforUnmodifiedApplicationsonSGX.In 2017USENIXAnnualTechnical\nConference (USENIX ATC 17). USENIX Association, Santa Clara, CA, 645ś658.https://www .usenix.org/conference/atc17/technical-sessions/presentation/tsai\n[34] Stephen Checkoway and Hovav Shacham. 2013. Iago Attacks: Why the System\nCall API is a Bad Untrusted RPC Interface. In Proceedings of the Eighteenth\nInternationalConferenceonArchitecturalSupportforProgrammingLanguagesand\nOperating Systems (ASPLOS ’13).\n[35]GuoxingChen,WenhaoWang,TianyuChen,SanchuanChen,YinqianZhang,\nXiaoFeng Wang, Ten-Hwang Lai, and Dongdai Lin. 2018. Racing in Hyperspace:\nClosing Hyper-Threading SideChannels on SGX with Contrived Data Races.In\n2018 IEEE Symposium on Security and Privacy, SP 2018, Proceedings, 21-23 May\n2018, San Francisco, California, USA. IEEE Computer Society, 178ś194. https:\n//doi.org/10.1109/SP.2018.00024\n[36]Tobias Cloosters, Michael Rodler, and Lucas Davi. 2020. TeeRex: Discovery and\nExploitation of Memory Corruption Vulnerabilities in SGX Enclaves. In 29th\nUSENIX Security Symposium. http://tubiblio .ulb.tu-darmstadt .de/119694/\n[37]Crispan Cowan. 1998. StackGuard: Automatic Adaptive Detection and Pre-\nvention of Buffer-Overflow Attacks. In Proceedings of the 7th USENIX Security\nSymposium, San Antonio, TX, USA, January 26-29, 1998, Aviel D. Rubin (Ed.).\nUSENIX Association. https://www .usenix.org/conference/7th-usenix-security-\nsymposium/stackguard-automatic-adaptive-detection-and-prevention\n[38]Rongzhen Cui, Lianying Zhao, and David Lie. 2021. Emilia: Catching Iago in\nLegacy Code. https://doi .org/10.14722/ndss .2021.24328\n[39]fortanix-rust-sgx[n.d.]. fortanix/rust-sgx:TheFortanixRustEnclaveDevelop-\nment Platform. https://github .com/fortanix/rust-sgx.\n[40]Shelly Grossman, Ittai Abraham, Guy Golan-Gueta, Yan Michalevsky, Noam\nRinetzky, Mooly Sagiv, and Yoni Zohar. 2017. Online Detection of Effectively\nCallback Free Objects with Applications to Smart Contracts. POPL (2017).\n[41]Hong Hu, Shweta Shinde, Sendroiu Adrian, Zheng Leong Chua, Prateek Saxena,\nandZhenkaiLiang.2016. Data-OrientedProgramming:OntheExpressiveness\nofNon-controlDataAttacks.In IEEESymposiumonSecurityandPrivacy,SP2016,\nSan Jose, CA, USA, May 22-26, 2016. 969ś986. https://doi .org/10.1109/SP.2016.62\n[42]Mustakimur Rahman Khandaker, Yueqiang Cheng, Zhi Wang, and Tao Wei.\n2020. COINAttacks:OnInsecurityofEnclaveUntrustedInterfacesinSGX.In\nProceedings of the Twenty-Fifth International Conference on Architectural Support\nfor Programming Languages and Operating Systems (ASPLOS ’20).\n[43]JaehyukLee,JinsooJang,YeongjinJang,NohyunKwak,YeseulChoi,Changho\nChoi,TaesooKim,MarcusPeinado,andBrentByungHoonKang.2017.Hackingin\nDarkness:Return-orientedProgrammingagainstSecureEnclaves.In 26thUSENIX\nSecurity Symposium (USENIX Security 17). USENIX Association, Vancouver,\nBC,523ś539. https://www .usenix.org/conference/usenixsecurity17/technical-\nsessions/presentation/lee-jaehyuk\n[44]ShanLu,SoyeonPark,EunsooSeo,andYuanyuanZhou.2008. LearningfromMis-\ntakes: A Comprehensive Study on Real World Concurrency Bug Characteristics.\n(2008).\n[45] open-enclave [n.d.]. Open Enclave SDK. https://openenclave .io/sdk/.\n[46]openenclave [n.d.]. OpenEnclave. https://github .com/openenclave/openenclave/\ntree/v0.15.0.\n[47]openenclave-curl [n.d.]. OpenEnclave Curl. https://github .com/openenclave/\nopenenclave-curl.\n[48]Meni Orenbach, Yan Michalevsky, Christof Fetzer, and Mark Silberstein. 2019.\nCoSMIX: a compiler-based system for secure memory instrumentation and exe-\ncutioninenclaves.In 2019USENIXAnnualTechnicalConference(USENIXATC\n19). 555ś570.\n[49]ChristianPriebe,DivyaMuthukumaran,JoshuaLind,HuanzhouZhu,ShujieCui,\nVasily A Sartakov, and Peter Pietzuch. 2019. SGX-LKL: Securing the Host OS\nInterface for Trusted Execution. arXiv preprint arXiv:1908.11143 (2019).\n[50]Ryan Roemer, Erik Buchanan, Hovav Shacham, and Stefan Savage. 2012. Return-\nOriented Programming: Systems, Languages, and Applications. ACM Trans.\nInf.Syst.Secur. 15,1,Article2(March2012),34pages. https://doi .org/10.1145/\n2133375.2133377\n[51]Felix Schuster, Manuel Costa, Cedric Fournet, Christos Gkantsidis, Marcus\nPeinado, Gloria Mainar-Ruiz, and Mark Russinovich. 2015. VC3: Trustworthy\nData Analytics in the Cloud. In IEEE S&P.\n[52]Jaebaek Seo, Byoungyoung Lee, Seong Min Kim, Ming-Wei Shih, Insik Shin,\nDongsuHan,andTaesooKim.2017. SGX-Shield:EnablingAddressSpaceLayout\nRandomization for SGX Programs.. In NDSS.\n[53]Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. 2017. T-SGX:\nEradicating Controlled-Channel Attacks Against Enclave Programs. In NDSS.\nInternet Society.\n[54]Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena.\n2016. PreventingPageFaultsfromTellingYourSecrets.In Proceedingsofthe11th\nACMonAsiaConferenceonComputerandCommunicationsSecurity (ASIACCS\n’16).\n[55]ShwetaShinde,DatLeTien, ShrutiTople,and PrateekSaxena.2017. Panoply:\nLow-TCBLinuxApplicationsWithSGXEnclaves.In 24thAnnualNetworkand\nDistributed System Security Symposium, NDSS.\n[56]Shweta Shinde, Shengyi Wang, Pinghai Yuan, Aquinas Hobor, Abhik Roychoud-\nhury, and Prateek Saxena. 2020. BesFS: A POSIX Filesystem for Enclaves with a\nMechanized Safety Proof. In 29th USENIX Security Symposium (USENIX Security\n14\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n79220).\n[57]László Szekeres, Mathias Payer, Tao Wei, and Dawn Song. 2013. SoK: Eternal\nWarin Memory.In 2013IEEE Symposiumon Securityand Privacy.48ś62. https:\n//doi.org/10.1109/SP.2013.13\n[58]Chia-CheTsai,KumarSaurabhArora,NehalBandi,BhushanJain,WilliamJannen,\nJitin John, Harry A. Kalodner, Vrushali Kulkarni, Daniela Oliveira, and Donald E.\nPorter.2014.CooperationandSecurityIsolationofLibraryOSesforMulti-Process\nApplications. In EuroSys.\n[59]JoVanBulck,DavidOswald,EduardMarin,AbdullaAldoseri,FlavioD.Garcia,\nand Frank Piessens. 2019. A Tale of Two Worlds: Assessing the Vulnerability of\nEnclave Shielding Runtimes. In Proceedings of the 2019 ACM SIGSAC Conference\non Computer and Communications Security (CCS ’19).\n[60]Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2017. SGX-Step: A Practical\nAttackFrameworkforPreciseEnclaveExecutionControl.In 2ndWorkshopon\nSystem Software for Trusted Execution (SysTEX). ACM, 4:1ś4:6.\n[61]Jose Rodrigo Sanchez Vicarte, Benjamin Schreiber, Riccardo Paccagnella, and\nChristopherW.Fletcher.2020. GameofThreads:EnablingAsynchronousPoison-\ningAttacks.In ASPLOS’20:ArchitecturalSupportforProgrammingLanguagesandOperating Systems, Lausanne, Switzerland, March 16-20, 2020, James R. Larus,\nLuis Ceze, and Karin Strauss (Eds.). ACM, 35ś52. https://doi .org/10.1145/\n3373376.3378462\n[62]HuiboWang,PeiWang,YuDing,MingshenSun,YimingJing,RanDuan,LongLi,\nYulong Zhang, Tao Wei, and Zhiqiang Lin. 2019. Towards Memory Safe Enclave\nProgramming with Rust-SGX. In CCS.\n[63]Wenhao Wang, Guoxing Chen, Xiaorui Pan, Yinqian Zhang, XiaoFeng Wang,\nVincentBindschaedler,HaixuTang,andCarlA.Gunter.2017. LeakyCauldron\non the Dark Land: Understanding Memory Side-Channel Hazards in SGX. CoRR\nabs/1705.07289 (2017). arXiv:1705.07289 http://arxiv .org/abs/1705 .07289\n[64]YuanzhongXu,WeidongCui,andMarcusPeinado.2015. Controlled-Channel\nAttacks: Deterministic Side Channels for Untrusted Operating Systems.In 2015\nIEEE Symposium on Security and Privacy. 640ś656. https://doi .org/10.1109/\nSP.2015.45\n[65]Michal Zalewski. 2001. Delivering Signals for Fun and Profit: Understanding,\nexploiting and preventing signal-handling related vulnerabilities. (2001). https:\n//lcamtuf.coredump .cx/signals .txt\n15\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n793"}
{"title": "Statically Discovering High-Order Taint Style Vulnerabilities in OS Kernels", "content": "Statically Discovering High-Order Taint Style Vulnerabilities in\nOS Kernels\nHang Zhang\nhzhan033@ucr.edu\nUC RiversideWeiteng Chen\nwchen130@ucr.edu\nUC RiversideYu Hao\nyhao016@ucr.edu\nUC RiversideGuoren Li\ngli076@ucr.edu\nUC Riverside\nYizhuo Zhai\nyzhai003@ucr.edu\nUC RiversideXiaochen Zou\nxzou017@ucr.edu\nUC RiversideZhiyun Qian\nzhiyunq@cs.ucr.edu\nUC Riverside\nABSTRACT\nStatic analysis is known to yield numerous false alarms when used\nin bug finding, especially for complex vulnerabilities in large code\nbasesliketheLinuxkernel.Oneimportantclassofsuchcomplex\nvulnerabilitiesiswhatwecall“high-ordertaintstylevulnerability”,\nwhere the taint flow from the user input to the vulnerable site\ncrosses the boundary of a single entry function invocation (i.e.,\nsyscall). Due to the large scope and high precision requirement,\nfew have attempted to solve the problem.\nIn this paper, we present SUTURE, a highly precise and scalable\nstaticanalysistoolcapableofdiscoveringhigh-ordervulnerabili-\nties in OS kernels. SUTURE employs a novel summary-based high-\norder taint flow construction approach to efficiently enumerate thecross-entrytaintflows,whileincorporatingmultipleinnovativeen-\nhancements on analysis precision that are unseen in existing tools,\nresulting in a highly precise inter-procedural flow-, context-, field-,\nindex-, and opportunistically path-sensitive static taint analysis.\nWeapplySUTUREtodiscoverhigh-ordertaintvulnerabilities\ninmultipleAndroidkernelsfrommainstreamvendors(e.g., Google,\nSamsung,Huawei),theresultsshowthatSUTUREcanbothconfirm\nknown high-order vulnerabilities and uncover new ones. So far,\nSUTUREgenerates79truepositivewarninggroups,ofwhich19\nhave been confirmed by the vendors, including a high severity\nvulnerability rated by Google. SUTURE also achieves a reasonable\nfalse positive rate (51.23%) perceived by users of our tool.\nCCS CONCEPTS\n•Securityandprivacy →Systemssecurity ;•Theoryofcom-\nputation →Program reasoning.\nKEYWORDS\nOS kernels; Vulnerability discovery; Static program analysis\nACM Reference Format:\nHang Zhang, Weiteng Chen, Yu Hao, Guoren Li, Yizhuo Zhai, Xiaochen\nZou, and Zhiyun Qian. 2021. Statically Discovering High-Order Taint Style\nHang Zhang is a postdoc researcher at Georgia Tech at the time of publication.\nThe second to sixth authors contribute equally in helping with the evaluation.\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthefirstpage.Copyrightsforthird-partycomponentsofthisworkmustbehonored.\nFor all other uses, contact the owner/author(s).\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea.\n© 2021 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-8454-4/21/11.\nhttps://doi.org/10.1145/3460120.3484798Vulnerabilities in OS Kernels. In Proceedings of the 2021 ACM SIGSAC\nConference on Computer and Communications Security (CCS ’21), November\n15–19, 2021, Virtual Event, Republic of Korea. ACM, New York, NY, USA,\n14 pages. https://doi.org/10.1145/3460120.3484798\n1 INTRODUCTION\nAmajorweaknessofstaticanalysisforbugfindingisthehighfalse\npositiverate,whichisonereasonwhydynamicapproachessuchas\nfuzzingisgainingmuchmorepopularitywhereanybugsfoundare\ntechnicallytruepositives.Thisweaknessisespeciallysignificant\nwithlargeandcomplexsoftwaresuchastheLinuxkernel,where\nmany bugs are triggered after a sequence of syscall invocations.\nSpecifically,thelargestatespacecreatedbymultipleprogramentrypoints (permutation of syscalls) makes it extremely challenging forstatic analysis to be both precise and scalable. On the other hand, a\nfuzzerlikeSyzkaller[ 3]cangeneraterandombutmeaningfultest\ncases involving different sequences of syscalls guided by coverage,\nandprovestobeeffectiveatfindingsuchbugs.However,thereisno\nguaranteethatitwillbeabletouncoverallbugsduetoitsnature\nof random exploration.\nOne important class of the aforementioned complex bugs is the\nhigh-ordertaintstylevulnerabilities,whereanattacker-controlled\ninput(i.e., taintsource)ispropagatedtosensitiveoperations(i.e.,\ntaint sink) without proper sanitization, following a complexcontrol/data flow involving multiple entry function invocations.For example, an entry function\nA()copies its user-provided\nargument to a global variable G, which is later used as an array\nindex unchecked in another entry function B(), causing an\nout-of-bound access. The orderhere refers to the number of entry\nfunction invocations that are needed to trigger the vulnerability.\nCompared to the simple “one-shot” taint vulnerabilities where the\ntaint propagation is confined within a single entry function\ninvocation ( i.e.,first-order), high-order bugs frequently seen in the\nstateful software (e.g., Linux kernel) are much more difficult to\nuncover, due to the need to reason about the complicated\ncross-entry taint propagation.\nIdeally, we want a static analysis tool that can systematically\nanalyze the program to identify the high-order vulnerabilities with\na good coverage, while minimizing false alarms. However, this is a\ndifficult task because of the following specific challenges:Challenge 1.\nThetoolneedstoefficientlyenumeratecross-entry\ntaint flows. Intuitively, since multiple entry functions can beinvoked in any order, an analysis needs to walk through manypossible permutations and repeatedly analyze a same entry in\ndifferent permutations, which is a significant scalability challenge.\n \nThis work is licensed under a Creative Commons Attribution International 4.0 License . \nCCS '21, November 15 –19, 2021, Virtual Event, Republic of Korea.  \n© 2021 Copyright is held by the owner/author(s).  \nACM ISBN 978 -1-4503-8454-4/21/11.  \nhttps://doi.org/10.1145/3460120.3484798   \nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n811\nChallenge2. Theanalysisneedstobeaccurateandpreciseenough\ntohandlethecross-entrytaintflowswhichcanbelengthy.Since\nthese flows are usually “concatenated” from multiple local flows\nwithin individual entry functions, any inaccuracy will accumulate\nand eventually cause an unacceptable number of false alarms.\nGiven these challenges, although there are many existing works\non statically discovering taint style vulnerabilities [ 8,10,26,40],\nfew can discover high-order ones. The closest work is by Dahse et\nal.[14], focusing on only the second-order vulnerability in web\napplications, which are very different and relatively simple\ncompared to Linux kernel (e.g., higher-level programming\nlanguages compared to C, fewer entry points and fixed taint\npropagation paths around the limited central data storage).\nIn this paper, we develop a novel static analysis tool that can\naddress the above challenges and discover high-order (arbitraryorders) taint vulnerabilities in the Linux kernel (and potentiallyany other stateful C programs) effectively and efficiently. Toovercome the first challenge (i.e., scalability), our core idea is to\nfirstanalyzeeachentryfunctionindependently(onlyforonce)and\ncreateanabstractsummaryregardingitstaintbehaviorsforboth\nlocal and global variables, then in the vulnerability discovery\nphase, we construct high-order taint flows on demand by querying\nthe individual summaries. This enables an efficient high-order\ntaint flow enumeration. As for the second challenge (i.e., accuracy\nand precision), we integrate many innovative and/or practical\nfeatures into the static analysis to boost its precision. They include\nan opportunistic path-sensitive analysis piggybacked through a\nflow-sensitive one, handling ambiguous all-to-all memory updates,\nand many others that result in a highly precise inter-procedureflow-, context-, field-, index-, and opportunistic path-sensitivestatic taint analysis. Besides, we also make considerable efforts\nhandling kernel code patterns (e.g., indirect calls).\nWe evaluate our tool on driver modules of different Android\nkernels used in various mobile devices (e.g., Google, Samsung,\nHuawei). The results show that our tool can discover previouslyunknown high-order taint vulnerabilities. So far, our tool has\nreported79truepositivewarninggroups,ofwhich19havebeen\nconfirmed by developers, including one high severity vulnerability\nas rated by Google. Our tool also achieves a reasonable false\npositiverateasperceivedbythewarningreviewers(51.23%)and\nan acceptable performance (e.g., concurrently analyze all 37\nmodules of a target kernel within 30 hrs).\nWe summarize our major contributions as below:\n(1) To our best knowledge, we are the first to attempt to system-\naticallyandstaticallydiscoverhigh-ordertaintstylevulnerabilities\nintheLinuxkernel.Ourmethodcanalsobeeasilygeneralizedto\nother stateful software.\n(2) We implement a prototype tool SUTURE, which is able to\nconstruct high-order taint flows with high-precision points-to and\ntaintanalyses,makingitgeneralenoughforourproblemaswellasothersrequiringstatictaintanalysis.WewillopensourceSUTURE\n1\nto facilitate the reproduction of results and future research.\n(3) We successfully discover previously unknown high-order\ntaintvulnerabilitiesinthekernelandreportthemtothedevelopers,\nincluding high-severity ones.\n1https://github.com/seclab-ucr/SUTURE00 struct data { int32_t a; char b[4]; } d;\n0102entry0\n(int cmd, char user_input ){\n03 switch(cmd) {04 case 0:05 d.b[0] = user_input ; break;\n06 default:07 foo(cmd,user_input );\n08 }09 }1011foo(int n, char c){\n12 if (n == 0)13 d.b[1] = c;\n14 }15entry1 () {\n16 bar((char*)& d);\n17 ...18 d.b[0] = 0;\n19 }2021bar(char * p){\n22 *( p+4) += 0xf0; // (1)\n23 }2425entry2\n() {\n26 char a[8];27 a[0] = d.b[1] + 0xf0; // (2)\n28 ...29 }\nLocal Taint Flows:entry0:\nentry2:\nuser_input Źd.b[0] d.b[1] Ź(2)\nentry1: d.b[1]Źa[0]\nd.b[0]Ź(1)\nCalling Sequences:\nentry0Æentry1 :Overflow\nentry0Æentry2 :\nentry1Æentry1 :\n…...\n*Red: Input directly provided by the user, Blue: Global variables.\nFigure 1: An Example of High-Order Bug Discovery\n2 OVERVIEW\nInthissectionwedescribethearchitectureandoverallworkflow\nof SUTURE, with a motivating example.\n2.1 The Motivating Example\nFig. 1 shows an abstracted example of high-order vulnerabilities.\nThere are three entry functions, i.e.,entry0() ,entry1() and\nentry2() ,thatcanbeinvokedinanyorder.First,wenoteabyte\noverflowatline22(site (1)).Totriggerit,however,oneneedsto\nfirst invoke entry0() with cmd=0, so that the user provided\nuser_input flows to the global variable d.b[0](line 5). Then, a\ndifferent entry function entry1() needs to be invoked, which\nsubsequently invokes bar(). At that point, the value of d.b[0]\n(previously set by the user input in entry0() whose address is\naliasedwith p+4)isretrievedandinvolvedinanoverflow-inducing\naddition operation (line 22).\nThe most important characteristic of this vulnerability is that\nthe taint flow from the original user input to the final overflow\nsiteisrelayedviaaglobalvariable,makingitahigh-order(more\nspecifically,second-order)taintstylevulnerability.Asmentioned\nin §1, it is difficult for existing tools to statically discover such\nvulnerabilities since they usually only reason about the local taint\nflowswithinasingle entry function.Forexample,fromthescope\nofonly entry1() ,wedonotknow d.b[0]isactuallycontrolledby\ntheuser,whileblindlyassumingitcancauseexcessivefalsealarms.\nConstructing high-order taint flows can be challenging, because\nanalyzing all possible permutations of entry invocations is not\nscalable.Moreover,anyanalysisimprecisioncanbeamplifiedwhen\nstitching results from individual entry functions. We illustrate a\nfew potential sources of imprecision below.\n(1)A path-insensitive analysis will wrongly conclude that\nentry0() , with a non-zero cmd, can propagate user_input to\nd.b[1]initscallee foo()(line13),whichisimpossiblesincethe\nconflicting path conditions at line 6 and line 12. Such\npath-insensitivitycaneventuallycreateafalsealarmthatline27in\nentry2() (when invoked after entry0()) can cause an overflow.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n812(2)To discover the potential overflow at line 22, the static analysis\nmustbeabletoaccuratelyresolvethepointerarithmeticandfigure\noutthat *(p+4)isanaliasto d.b[0],otherwiseafalsenegativewill\noccur.Additionally,theanalysisalsoneedstobeinter-procedural\nin order to figure out that argument pofbaraliases to d;\n(3)An index-insensitive analysis may issue a false alarm at line 27,\nfollowingthecallingsequence entry0(cmd=0,...) -> entry2() ,\nbecause d.b[0]andd.b[1]arenotdifferentiated.Ifcombinedwith\npath-insensitivityin (2),therewilllikelybemanymorefalsealarms\nafter line 27 under the calling sequence entry0(cmd=1,...) ->\nentry2,sincethewholearray acanbeover-taintedinsteadofonly\na[0]. Moreover, since dcontains d.bas an embedded array, the\nanalysis also needs to handle such nested structures;\n(4)The analysis must also correctly recognize that line 18 in\nentry1() kills the existing taint of d.b[0], so that additional\nentry1() invocations after the first one will no longer trigger the\noverflow at line 22. This requires a cross-entry flow-sensitivity.\nUnfortunately,toourbestknowledge,noexistingstaticanalysis\ntoolspossessalltheseprecisionwedesire(withmoremanifested\nlaterin§3).ThismotivatesSUTURE,ahighlyprecisestaticanalysis\ntool capable of discovering high-order taint vulnerabilities.\n2.2 Workflow\nWeprovideanoverviewofSUTUREinthissection.Thearchitecture\nof SUTURE is shown in Fig. 2. We briefly describe its workflow in\nfour stages:\n1. Input. SUTURE requires as input the LLVM bitcode file\ncompiledfromthetargetprogram,alongwithaconfigfilewhich\nspecifies the entry function information (e.g., function names,\nuser-controlledarguments).ForthemotivatingexampleinFig.1,\nentry0() ,entry1() , and entry2() will be listed as three entry\nfunctions in the config file, where the user_input argument of\nentry0() is specified as the user controllable input.\n2. Static Taint Analysis. SUTURE will then perform a precise\nstatic taint analysis and generate an independent summary for\neach entry function, which includes all the local taint flows within\nit. In this phase both user input and global variables are treated as\ntaint source, while the local taint flow to every variable used in the\nentryfunctionisrecorded.InFig.1weshowthelocaltaintflows\nof the three entry functions in the bottom left box (we omit the\nintermediatevariablesvisibleonlyatthebitcodelevelforsite (1)\nand (2).). It is worth noting that SUTURE analyzes each entry\nfunction only once in an order-insensitive way, e.g.,entry0() can\nbe analyzed either before or after entry1() ), avoiding the\nexpensive cost of repeatedly analyzing a same entry in different\ncalling sequences,however, SUTUREcan stilldiscover high-order\nvulnerabilities as detailed later.\n3. Vulnerability Discovery. In this stage, SUTURE tries to stitch\ntogether various entry functions with various vulnerabilitydetectors to pinpoint different types of bug-inducing programstatements (e.g., an arithmetic operation may cause integer\noverflow). For each such statement, SUTURE decides whether any\ncross-entry taint flows exist from user input to the problematicstatement. In the motivating example, the local taint flows of\nentry0() andentry1() arestitchedtoformthehigh-ordertaint\nflow of the vulnerability.OutputInput Static Taint Analysis\nVulnerability DetectionProgram LLVM \nBitcodeEntry Function \nSpecification\nFi\nTaint Summary\nFlow Constructor\nDetector 0\nDetector 1\nDetector n…...\nWarning Reports\nFigure 2: System Architecture of SUTURE\n4.Output. Foreachissuedwarning,SUTUREoutputsanyrelevant\ninformation such as the warning type and full cross-entry taint\nflow,SUTUREalsocalculatestheorderforeachwarning.Forthe\nmotivatingexample,SUTUREeventuallyfiresonevalidwarning\nwhosecallingsequenceisshownintherightbottom(asecond-order\nvulnerability), while avoidingall the false alarms asmentioned in\n§2.1.\n3 STATIC ANALYSIS DESIGN\nIn this section we describe the design of SUTURE, including the\nvarious enhancements made to make the precise and efficient high-\norder taint analysis possible.\n3.1 Positioning\nGiven theLLVM bitcodefiles andthe entry functionspecification,\nthe goal of static taint analysis is to construct a taint summary\n(detailedin§3.3)foreachentryfunction,toachievethisgoal,we\nindependentlyanalyzeeachentryfunctionandrecorditstaintfacts.Ourstatictaintanalysisfollowsthebasicdesignandreusesthemain\ndatastructuresofDr.Checker[ 26],whichmakesasoundyinter-\nproceduretraversalofeachentryfunctioninthetop-downstyleand\nforeachvisitedLLVMIR,performingthealiasandtaintanalysis,\nwhich updates the points-to and taint information associated with\nvariables involved in theIR. The rules for points-to record update\nandtaintpropagationarequitestandardasmanifestedin[ 26],so\nwe will not elaborate on them again. Basically, Dr. Checker’s static\nanalysisiscontext-,flow-,andfield-sensitive.However,asdetailedlater,allthesesensitivityarepartialorlimited(see§3.6.1and§3.6.3)\nwhich needs to be addressed in SUTURE. Moreover, SUTURE also\nhas many additional requirements for the static analysis compared\nto Dr. Checker. Throughout the section, we primarily focus on\ndescribing our enhancements over it.\nIn this section, we will first describe three novel features of\nSUTURE that are not found in other static analysis tools, including\ntheessentialtechniquestosupportscalablehigh-ordertaintflow\nconstruction(§3.3)andseveralinnovativetechniquestoimprove\nanalysis precision and efficiency (§3.4 and §3.5). Then we describe\nvarious other improvements in SUTURE (§3.6) that are although\nmostly well-known, but rarely packed together to achieve a highly\nprecisestaticanalysis,whichiscriticalforhigh-orderbugdiscovery\nsince mistakes can be amplified when multiple local taint flows\nconnect (§2.1).\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n8133.2 Definitions\nBeforewedelveintothedetails,westartwithasetofdefinitions\nto simplify the later description of the design.\nDef0Anentryfunction 𝜀ofaprogrammodule(e.g., akernelmod-\nule)servesasapartofthemoduleinterface,thusitdoesnothave\nanycallerswithinthesamemoduleandintendstobeinvokeddi-\nrectly by the user or other modules (e.g., top-level ioctl()func-\ntions of a driver).Def1\nThetaintsource Sincludesbothuser-providedargumentsof\nentry functions ( U) and all globally accessible variables or memory\nregions( Gwhichwerefer toasglobalmemory). Notethat Gcon-\ntains both explicitly defined global variables (e.g., a global integer)\nandtheonesreachablefromthem, e.g.,aglobalobjectcontaininga\npointerfieldpointingtoheapmemory.Thiscangoacrossarbitrary\nlayers of pointer indirection. Formally:\nS=U∪G\nU={𝑣|∃𝜀,𝑣is a user argument of 𝜀}\nG={𝑣|𝑣is globally accessible }\nDef 2A calling context /triangleis defined as a sequence of instructions:\n/triangle=[𝑖0,𝑖1,...,𝑖2𝑛]\nAninstructionwithanevensubscriptdenotestheentryinstruction\nof a caller function, while the odd denotes a call site instruction\nwithinthecaller(e.g., 𝑖2istheentryofthefunctionthatiscalledat\n𝑖1), the sequence always ends with the entry instruction of current\nexecuting function, so its length is always odd. This definition\nenablesustodifferentiatemultiplecalleesatasamecallsite(e.g.,\nan indirect call with multiple potential targets).Def3\nWe define an “instruction location” ( 𝐼𝑛𝑠𝑡𝐿𝑜𝑐for short in the\nremainingpaper)asaninstruction 𝑖plusthecallingcontext /triangle(Def\n2) it is executed in, we use 𝐼to denote an 𝐼𝑛𝑠𝑡𝐿𝑜𝑐to differentiate it\nwith a static instruction 𝑖:\n𝐼=(𝑖,/triangle)\nDef 4A taint flow 𝜏is basically an 𝐼𝑛𝑠𝑡𝐿𝑜𝑐sequence:\n𝜏=[𝐼0,𝐼1,...,𝐼 𝑛]\nThe first 𝐼𝑛𝑠𝑡𝐿𝑜𝑐𝐼 0initiates the taint propagation from one taint\nsourcevariable 𝑣∈S,whiletheremaining 𝐼𝑛𝑠𝑡𝐿𝑜𝑐spassthetaint\non.Def5\nWedefinetheconnectoperator ◦fortaintflowsasfollowing:\n𝜏0=[𝐼00,𝐼01,...,𝐼0𝑛],𝜏1=[𝐼10,𝐼11,...,𝐼1𝑛]\n𝜏0◦𝜏1=/braceleftBigg\n[𝐼00,...,𝐼0𝑛,𝐼10,...,𝐼1𝑛],if sink(𝐼0𝑛)==src(𝐼10)\n∅, else\nThis basically says that two taint flows can be sequentially\nconnected iffthe last𝐼𝑛𝑠𝑡𝐿𝑜𝑐of one taint flow propagates the\ntainttoavariablethatisusedasthetaintinitiatoratthebeginning\nof the other taint flow.Def 6\nWenowdefinethe“order”ofataintflowwiththe 𝑜𝑟𝑑𝑒𝑟()\nfunction,beforethat,weneedtofirstdefinethe 𝑟𝑒𝑎𝑐ℎ()function\nto test the reachability between two 𝐼𝑛𝑠𝑡𝐿𝑜𝑐s:\n𝑟𝑒𝑎𝑐ℎ(𝐼0,𝐼1)=/braceleftBigg\n𝑇𝑟𝑢𝑒,if∃𝜀,𝐼0can reach 𝐼1on𝐼𝐶𝐹𝐺(𝜀)\n𝐹𝑎𝑙𝑠𝑒,else𝐼𝐶𝐹𝐺(𝜀)meanstheinter-procedurecontrolflowgraphoftheentry\nfunction𝜀,𝐼0can reach 𝐼1on𝐼𝐶𝐹𝐺(𝜀)implies that there is at least\noneexecutionof 𝜀thatcanreachthe 𝐼𝑛𝑠𝑡𝐿𝑜𝑐𝐼 0andafterthat, 𝐼1.\nWith the 𝑟𝑒𝑎𝑐ℎ()definition:\n𝑜𝑟𝑑𝑒𝑟(𝜏)=|{𝑘|𝐼𝑘∈𝜏,𝐼𝑘+1∈𝜏,¬𝑟𝑒𝑎𝑐ℎ(𝐼𝑘,𝐼𝑘+1)}|\nIntuitively, 𝑜𝑟𝑑𝑒𝑟(𝜏)is the number of “break points” in 𝜏, where to\ncontinuefollowingthetaintflowwehavetomakeanotherentry\nfunctioninvocation.Weherebycallataintflow 𝜏high-ordertaint\nflowif𝑜𝑟𝑑𝑒𝑟(𝜏)>1.\nIt is worth noting that since 𝑟𝑒𝑎𝑐ℎ()is not transitive (e.g.,\n𝑟𝑒𝑎𝑐ℎ(𝐼0,𝐼1)∧𝑟𝑒𝑎𝑐ℎ(𝐼1,𝐼2)/notarrowright𝑟𝑒𝑎𝑐ℎ(𝐼0,𝐼2), because the path\nbetween𝐼0and𝐼1may pose conflicting constraintsto that between\n𝐼1and𝐼2), our definition of 𝑜𝑟𝑑𝑒𝑟()can underestimate the real\ntaintfloworder.Inotherwords,therecanbemore“breakpoints”\nin a taint flow than counted by 𝑜𝑟𝑑𝑒𝑟()(e.g.,𝑟𝑒𝑎𝑐ℎ(𝐼0,𝐼1)∧\n𝑟𝑒𝑎𝑐ℎ(𝐼1,𝐼2)results in no “break points” between 𝐼0and𝐼2by\n𝑜𝑟𝑑𝑒𝑟(), but there could be one.). However, it may be expensive to\ncalculate the real order due to the need of constraint solving.Besides, we find that the underestimation rarely happens in\npractice.Def 7\nWe define the local taint flow set of an entry function 𝜀as\n𝐿𝑇𝜀. It is the set ofall taint flows that can be produced within one\ninvocation of 𝜀, naturally, we have ∀𝜏∈𝐿𝑇𝜀,𝑜𝑟𝑑𝑒𝑟(𝜏)==1.\n3.3 Summary-Based High-Order Taint Flow\nConstruction\nTheforemostchallengeSUTUREneedstoaddressistoefficiently\nconstruct high-order taint flows in the face of the enormous space\nof the possible calling sequences of entry functions. To avoid\nrepeatedly analyzing a 𝜀in different sequences as a naive solution\nmight do, SUTURE employs a summary based method, where each\n𝜀only needs to be analyzed once for summary generation, then\nSUTURE can efficiently construct high-order taint flows, by\nconnectingthelocaltaintflowsasmentionedin Def 5.Notethat\nthe global variable acts as waypoints in connecting the local taint\nflows,e.g.,one local flow may propagate user input taint source to\na global variable and then another local flow may propagate the\nsameglobalvariable(assource)toacriticalsink.Wedetailthetwo\nmain steps of this process below.\n3.3.1 TaintSummaryGeneration. Thetaintsummaryofanentry\nfunction𝜀is basically its local taint flow set 𝐿𝑇𝜀(Def 7in §3.2), in\nother words,the summaryrecords alllocal taintflows originating\nfromS(Def1in§3.2)andsinkingtoeveryaccessedvariable(local\nor global) within 𝐼𝐶𝐹𝐺(𝜀). SUTURE organizes the local taint flows\nin𝐿𝑇𝜀bythesinkvariables-eachsinkvariableisassociatedwitha\nset of local taint flows ( 𝜏) reaching it, while the source variable can\nbe obtained from the taint tag (§3.6.5) associated with each 𝜏. This\nenablesaquickqueryof 𝜏bysink,aswellastheconnectoperation\n(Def 5in §3.2) for constructing high-order taint flows.\nConceptually, SUTURE’s taint summary is similar to those used\ninpriorbottom-upstaticanalysiswork[ 9,10,40].However,one\nimportant difference is that SUTURE relies on the summaries toconnectmultipletop-levelentryfunctioninvocations,insteadof\nconnectingacallertoacallee(e.g., byapplyingthecallee’ssummary\nat the call site). As such, SUTURE has a special focus on the shared\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n814typedef struct {int X;} foo; struct {foo *p;} G;f o oF;\ne0(u0) {\nG.p= malloc(...);\nG.p- > X=u 0 ;\n}\nIn Summary:G . p- > obj0 (solid)\nȉ0:u 0ŹREM0.X\ne2(u2) {\n  int a = G.p- > X+1 ;\nG.p- > X=u 2 ;\n}\nIn Summary:G . p- > obj2 (dummy)\nȉ2: obj2.;\u0003ŹD ;ȉ3:u 2ŹREM2.Xe1() {\nG.p=&F;\n  int a = G.p- > X+1 ;\n}\nIn Summary:G . p- > F(solid)\nȉ1:F .;\u0003ŹD\ne3(u3) {\n  int a = G.p- > X+1 ;\nG.p- > X=u 3 ;\n}\nIn Summary:G . p- > obj3 (dummy)\nȉ4: obj3.;\u0003ŹD; ȉ5:u 3ŹREM3.X\nFigure 3: Examples of Implicit Global Memory Matching\nstates in the taint summary, it comprehensively models the global\nmemory(see Def1in§3.2)ofarbitrarylayersofpointerindirection.\nSpecifically, whenever pointers are involved in global variables, it\ncanbechallengingtoresolvethembecausethememorytheypoint\ntocanintheorybechangedinany 𝜀.Itisthereforetrickytoreason\nabout such global pointers, which represents a unique challenge\nfor connecting local taint flows of top-level entry functions.\n3.3.2 High-OrderTaintFlowConstruction. Connectingtwolocal\ntaintflowsisrelativelystraightforward.However,todosocorrectly,\nwe discuss two important considerations below.\nGlobal MemoryMatching. As mentioned earlier, two local taint\nflowscan beconnectedonlywhen one’ssinkmatches theother’s\nsource (Def5in §3.2). Since high-order taint flows are relayed via\nglobal memory, the question becomes how to match the global\nmemory tainted in one flow with the one used in another flow. As\nmentionedin Def1,SUTUREhandlestwotypesofglobalmemory:\nexplicitlydefinedandthosereachablebyglobalpointers.Forthe\nformer, we can simply match them by their identifiers. However,\nthings get more complicated for the pointer case.\nConsider the example in Fig. 3, e0()ande1()each assigns G.p\n(a pointer field in a global object) to either a dynamically allocated\nheap object or statically defined one, while both e2()ande3()\ndirectly access whatever object pointed to by G.p. In this situation\nSUTURE must correctly “guess” the relationship between the\nobjectsvisitedinthefourentryfunctionsinordertoconnectthe\nlocal taint flows. For example, e0()ande1()obviously visit the\ndifferent object instances, so although u0flows to G.p->Xine0(),\nandtheseeminglysame G.p->Xflowsto aine1(),thereisnoway\nforu0to flow into a, because obj0in𝜏0(the heap object) cannot\nmatchFin𝜏1(statically defined). However, since e2()ande3()\ncan access either obj0orF(depends on whether e0()ore1()is\ncalled earlier), we should allow their local 𝜏to be connected to\neach other, or to those in e0()and e1(). For example, 𝜏3can\nconnect𝜏1becauseobj2can potentially be F. Similarly, 𝜏3can also\nconnect𝜏4becauseobj2andobj3can be identical).\nTo summarize, when objects are accessed but not defined in a\n𝜀(e.g., obj2 andobj3), we do not necessarily know which objects\nareused(e.g., canbeeither obj0orF),sowecreateaplaceholder\ndummy object. Instead, such bindings are instantiated by access-\npath matching (e.g., bothobj2andFcan be accessed via G.p) when\nconnecting local taint flows.Taint Overwrite. Another point worth discussing is that not all\n𝜏should be preserved for flow connection. For example, a global\nmemory may be tainted during the middle of a 𝜀invocation but\nlater untainted. Similarly, it may be tainted by different sources\natdifferentpointsinthefunction.Therefore,SUTUREfiltersout\nthose𝜏whose taint will be overwritten later. Note that this may\npreventSUTUREfromdiscoveringsometaint-styleconcurrency\nbugs, where an intermediate taint of a global memory in one 𝜀can\nbevisibletoanother.Infavoroflimitingthefalsetaintflows,we\nleave a better treatment of concurrency situations as future work.\n3.4 Opportunistic Path Sensitivity\nIt is well known that static analysis can follow infeasible paths\nduetounawarenessofconflictingpathconstraints,causingboth\ninaccuracy(e.g., impossibletaintpropagation)andinefficiency(e.g.,\nanalyzing unnecessary branches). The straightforward solution is\ntoadoptpath-sensitivity,however, a fully path-sensitiveanalysis\ncan be overly expensive, due to complex constraint solving and\npathexplosion.Wethusaimtoutilizepath-sensitivitywhenever\npossible,whileavoidinghavingtopaythehighcost.Tothisend,\nwe propose what we call opportunistic path-sensitive analysis. We\nmake the design based on two important observations:\n(1) A good fraction of the path constraints in the kernel are\nsimple, and yet collecting and solving them would allow us to\nprune a large number of infeasible paths.\n(2) It is possible to piggyback some form of path-sensitive analy-\nsis into the workflow of a flow-sensitive analysis.\nBased on the above, our idea is to opportunistically collect path\nconstraints during the flow-sensitive analysis and only in thefollowing simple forms:\n𝑣𝑜𝑝𝐶, where𝑣is a variable, 𝐶is a\nconstant (e.g., a literal number), and 𝑜𝑝∈{==,>,<,≥,≤}.\nSpecifically, whenever our flow-sensitive analysis enters a\nconditional branch, we collect the corresponding constraint if it is\nin such a simple form. Whenever branches merge, we remove the\nconstraints. At a first glance, no path-sensitive analysis is allowed\nif we piggybackthe flow-sensitive analysis in this way, since at the\nmerge point we lost the constraints for individual branches.\nHowever, we note that within one branch, it is possible that\nadditional conditional statements can occur (intra- or inter-\nprocedure),making itpossible forus totrim infeasiblepaths with\ntheopportunisticpath-sensitivity.Weshowarealworldexample\nin Fig. 4. As we can see, msm_lsm_ioctl() calls msm_lsm_ioctl_\nshared() at line 3, under one specific switch case with the cmd\nrestricted to SNDRV_LSM_REG_SND_MODEL_V2 , the same cmdis\npassed to the callee and used again as the switch conditional atline 8, since its value has already been restricted at the call site\n(line 3), there is actually only one valid switch case in the callee\n(line 9) under this calling context. Our opportunistic path-sensitive\nanalysis can collect the equality constraint on cmdat line 3 and\npropagateittothecallee.Thisallowsustofilterout16outof17infeasible switch cases due to the conflicting constraints,\nsimultaneously improving accuracy and efficiency.\n3.5 Multi-Source Multi-Sink Pairing\nOneuniquechallengeforstaticanalysisweidentifiedduringour\nstudy is the multi-source multi-sink pairing problem. If not\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n81500 static int msm_lsm_ioctl(..., unsigned int cmd, ...) {\n01 switch ( cmd){\n02 case SNDRV_LSM_REG_SND_MODEL_V2 :\n03 msm_lsm_ioctl_shared (...,cmd, ...); break;\n04 case …05 }06 }07 static int msm_lsm_ioctl_shared (..., unsigned int cmd, ...) {\n08 switch ( cmd){\n09 case SNDRV_LSM_REG_SND_MODEL_V2 : ……; break;\n10 case … //17 cases in total11 }12 }\nFigure 4: An Example of Opportunistic Path-Sensitivity\nproperly handled, explosion of points-to records and taints can\nhappen, leading to a massive number of false positives. Fig. 5\nillustrates the problem with a concrete example. When starting to\nanalyze the function start_endpoints() , the argument subsis a\npointer that points to two instances of snd_usb_substream\naccording to the previous static analysis results. Consequently, the\nleft side of the assignment at line 2 can be one of two memorylocations (i.e.,\ndata_subs field of snd_usb_endpoint , either\ninstance 0 or 1), while the right side subspoints to either instance\n0or1of snd_usb_substream .Inthissituation,thecommonway\ntoperformtheassignment(asusedinmanypopularstaticanalysis\ntools like Dr. Checker [ 26] and SVF [ 34]) is all to all (e.g.,\ndata_subs field of snd_usb_endpoint 0 will point to both\nsnd_usb_substream 0 and 1). However, it is obvious that in the\nreal program execution, data_subs can only point back to its own\nparent snd_usb_substream instance (e.g., 0t o0a n d1t o1 ) .W e\ncall this multi-source multi-sink pairing problem, failure to pair\nthetwosides(e.g., all-to-allupdate)willcreatemanysuperfluous\ndata flow facts.\nTo solve this problem, our key observation is that in the\naforementioned scenario, two sides of the assignment actuallyshare the same source of multiplicity (e.g., the left side\nep0->data_subs atline2hastwopossiblelocationsbecause ep0\ncanpointtotwostructureinstances,whichisagainbecause subs\nissoatline1,thesamereasonfortherightside),thus,aslongas\nthe unique source “collapses” to one of many possibilities in the\nruntime,bothsidesoftheassignment“collapse”aswell. Following\nthis observation, for every LLVM IR that can serve as a “source of\nmultiplicity”, e.g.,aphiinstruction can aggregate multiple\npoints-to/taint records from different paths to its receiver variable,\nSUTURE assigns each individual outcome record a unique label\n<𝐼𝑅,𝑖>(𝑖is a numeric value to differentiate multiple outcome\nrecords of the multiplicity 𝐼𝑅), which will also be propagated to all\nderived records. For example, in Fig. 5 the pointer ep0is derived\nfrom subs, and the latter’s two points-to records for\nsnd_usb_substream 0 and 1 have their labels respectively\ninherited by ep0’s two records for snd_usb_endpoint 0 and 1. By\nmatching these labels, when the multi-to-multi assignment\nhappens (e.g., line 2) we can precisely pair the source and the sink\nif they share the same source of multiplicity, bringing the 2 ∗2\nupdate to two 1 ∗1 ones in Fig. 5.00 static int start_endpoints(struct snd_usb_substream *subs) {\n01 struct snd_usb_endpoint *ep0 = subs->data_endpoint;02 ep0->data_subs = subs;03 …...04 }\ndata_endpoint\ndata_subs\nsnd_usb_substream 0 snd_usb_endpoint 0data_endpoint\ndata_subs\nsnd_usb_substream 1 snd_usb_endpoint 1\nFigure 5: An Example of Multi-Source Multi-Sink Pairing\n00 struct data {01 int a,b; } d;0203 foo(int c) {04 int r = 1;05 if (c>0) {06 r+= c;\n07 d.a+= r;\n0 8 }e l s e{09 r-= c;\n10 d.a-= r;\n11 }12 }if.then:\n%add = add 1, %c\n  %0 = load i32* GEP (%struct.data* @d, 0, 0)  %add1 = add %0, %add\nstore %add1, i32* GEP (%struct.data* @d, 0, 0)\n  br label %if.end\nif.else:\n%sub = sub 1, %c\n  %1 = load i32* GEP (%struct.data* @d, 0, 0)\n  %sub2 = sub %1, %sub\nstore %sub2, i32* GEP (%struct.data* @d, 0, 0)\n  br label %if.end\nFigure 6: Necessity of Memory SSA based Analysis\n3.6 Other Improvements in SUTURE\n3.6.1 Memory SSA based Analysis. One major source of\ninaccuracy of Dr. Checker (and many other LLVM based static\nanalysis) is the lack of memory SSA (Static Single Assignment)\nform [11]. While the top-level variables in LLVM IR are inherently\nput in the SSA form [ 28], the address-taken memory objects are\nnot, causing difficulties when implementing flow- and context-\nsensitiveanalysis.Forexample,inFig.6,tworedefinitionsofthe\nsame local variable r(line 6 and 9) results in two individual\ntop-level variables at the LLVM IR level (i.e., %addand%sub), so\nthe static analysis can easily associate the later usage with theunique definition simply by the LLVM variable identifier (e.g.,\n%add). Based on this built-in SSA form, Dr. Checker achieves the\nflow- and context- sensitivity for the top-level LLVM variables.However, multiple redefinitions of the address-taken memoryobject field (e.g.,\nd.aat line 7 and 10) do not result in different\nmemorycells,instead,theygotothesamememorylocation(e.g.,\nthe two storein Fig. 6), in other words, the SSA form for memory\nobjects is not enforced in LLVM IR. In this situation, the static\nanalysismustbeabletocorrectlycorrelatethe loadofamemory\ncelltooneof(potentially)many store,otherwise,itwilllostthe\nflow- and context- sensitivity for the widespread address-takenmemory objects, causing both false positives and negatives (e.g.,\nover- and under- taint), as happened in Dr. Checker.\nTo address this problem, SUTURE implements an on-the-fly\nmemorySSAanalysis.Specifically,weappendan 𝐼𝑛𝑠𝑡𝐿𝑜𝑐toeach\npoints-to/taint update of a memory cell to represent where the\nupdate happens (e.g., onestoreinstruction in Fig. 6, together with\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n816the calling context of foo()). Based on such information, SUTURE\ncan correctly figure out which points-to/taint records should be\npropagated to a certain use site of the same memory cell, byperforming an inter-procedure reachability test between the\nupdatesiteandtheusesite.Thereachabilitytestisimplemented\nbased on the topology and the dominance relationship of thecontrol flow graph (e.g., if a strong points-to update site\npost-dominates a previous one on a same memory cell, the oldpoints-to will be masked out from the new site), since the\nalgorithm is standard, we omit its details here.\n3.6.2 IndexSensitivity. Besidesbeingfield-sensitive,SUTUREis\nalso index-sensitive (i.e., the ability to differentiate individual array\nelements), whose importance has already been shown in the moti-\nvating example in §2.1. In principle, our design of index-sensitivity\nfollows two rules for array read/write respectively:\n(1) If an array element is read with a constant index (e.g., v=\na[2]),wereturnthepoints-to/taintrecordsrelatedtoexactlythat\nindex; If the index is a variable (e.g., v = a[i]), we conservatively\nmerge the records of all array elements and return them.\n(2)Ifanarrayelementiswrittenwithaconstantindex(e.g., a[2]\n=v),weperformastrongupdate(i.e., thenewrecordscanoverwrite\ntheoldones)forexactlythatindex;Iftheindexisavariable(e.g.,\na[i] = v), we conservatively update every array element, and the\nupdate is weak (i.e., new records co-exist with old ones).\n3.6.3 GeneralLanguageFeatureSupport. Inthissectionwediscuss\nourenhancementsinSUTUREfortwoClanguagefeaturesthatare\ncritical for analysis accuracy.NestedStructure\n.Nestedstructure(i.e., onestructureisembedded\nasafieldinaparentstructure)isawidelyusedlanguagefeature\nand failure to correctly handle it can significantly impact the field-\nsensitivity, for example, Dr. Checker only differentiates the top-\nlayerfieldsintheparentstructurebutnotthoseintheembedded\nones, which can cause issues like over-tainting.\nSUTUREaddressesthisproblembyrecursivelycreatinganew\nabstractmemoryobjectforeachembeddedfieldwhenitisaccessed,\nwhile maintaining the relationship between the new object and\nthe parentobject, thisway,SUTUREsupports nestedstructure of\narbitrary layers. We also carefully design the LLVM IR processing\nlogics inthe points-toand taintanalysis to takenested structureinto account, for example, SUTURE processes all indices of theGEPinstruction instead of only the first 2 since it is required for\naccessing the fields within the embedded structures.Pointer Arithmetic\n. It is well known that pointer arithmetic in\ntheClanguagefamilycanoftencauseinaccuraciesinstaticanalysis,sinceitisdifficulttokeeptrackoftheexactpointerlocationduring\nthe arithmetic calculation, e.g.,normally, LLVM IR accesses the\n2ndfieldofastructure bysimplyspecifyingthefieldnumber 2in\ntheGEPinstruction with the structure base pointer, however, in\nsome cases (e.g., optimization) the field can be accessed by directly\nsubtracting an offset (between the 2ndand5thfields) from the\npointer to the 5thfield. To handle such cases, SUTURE records the\ndetailedlayout(e.g., sizeandoffsetofeachfieldinbytes)ofeach\nstructure and faithfully calculates the new target field after pointer\narithmeticaccordingtothepointertype(e.g., pointerconversion\naware,like (char*)p-1 and(int32*)p-1 aredifferent),offsetto\nadd/sub,andthestructurelayout.ItisworthnotingthatourpointerDetector Description\nITDUD Tainted data usage in risky functions, e.g.,strcpy()\nTAD Tainted arithmetic operations, e.g.,integer overflow\nTLBD Tainted loop bound conditions, e.g.,infinite loops\nTPDD Tainted pointer dereference, e.g.,arbitrary mem write\nTable 1: Vulnerability Detectors used in SUTURE\narithmetic handling has a byte-level accuracy and we always tryto align to the field boundary, though rare, this may cause someinaccuracies (e.g., a pointer to the middle of a field, or bit-level\npointer arithmetic), we leave the handling of these cases as the\nfuture work.\n3.6.4 Kernel Code Pattern Handling. To better support the\nanalysis of the kernel code, SUTURE also takes care of somespecial kernel code patterns, of which the most important one isthe prevalent indirect calls. Dr. Checker uses the type-basedmethod to resolve indirect call targets, though being a common\nand standard solution, it can cause many false positives in practice.\nTo further improve the accuracy, SUTURE employs a method\nsimilar to PeX [ 42], which takes advantages of domain knowledge\non the kernel coding paradigm and resolves the indirect calltargets by matching the parent structure and field id of the\nfunction pointer.\n3.6.5 Multi-TagTaintAnalysis. Toconstructhigh-ordertaintflows\nwe must be able to differentiate multiple taint sources (see Def 1,5\nin §3.2),e.g.,in Fig. 1 we must know exactly that local taint flow\nofentry1() originates from the specific global variable d.b[0]\ntoconnectittothatof entry0() .Soinsteadofonlymaintaining\nthe binary “tainted or not” state, SUTURE associates a unique taint\ntag for∀𝑣∈S, the tag will also be propagated to all the tainted\nvariablesbytherelatedsource,enablingustoeasilyquerythetaint\nsources for each 𝜏.\n4 VULNERABILITY DISCOVERY AND\nWARNING GROUPING\nAftergeneratingthetaintsummaryforeach 𝜀,SUTUREcanthen\nproceed to discover the high-order taint vulnerabilities and output\nthe warning report. This process includes two steps: (1) identify\nthe instructions that can potentially trigger vulnerabilities (e.g., an\narithmetic instruction may cause an integer overflow), this is done\nbyvariousvulnerabilitydetectors.Foreachidentifiedinstruction,\nSUTURE confirms the existence of the vulnerability by deciding\nwhether any involved variable is tainted (can be through a\nhigh-order flow) by the user, and (2) fire and group warnings for\nconfirmedvulnerabilities.Inthissection,wedetailtheimportant\naspects of these two steps.\nVulnerability Detectors .Dr.Checkerhasacollectionofsimple\nbutwell-definedvulnerabilitydetectors,eachtargetsinstructionsofacertainpattern(e.g., conditionaljumpattheloopbound).Sinceour\ngoalistodiscovertaintstylevulnerabilities,wereuseDr.Checker’s\n4 detectors aiming at them. We list our selected detectors and a\nbriefdescriptionoftheirpurposesinTable1,moredetailscanbe\nfoundintheoriginalpaper[ 26].Weleavethedevelopmentofmore\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n817detectors asfuture work.As mentionedabove, SUTURE’snovelty\nmainly lies in its ability to construct high-order taint flows, which\nis independent of the detectors.\nOn-DemandQueryofTaintSummaries. Onewaytoapplythe\nvulnerability detector is to first construct the high-order taint\nsummaries by considering all permutations of entry functions,\nwhich can be overly expensive. Instead, we construct the\nhigh-order taint flows on demand in a backward fashion. In other\nwords, SUTURE provides a query utility (“Flow Constructor” in\nFig. 2) which takes a sink variable as input and taint flows from U\nto it (including high-order ones) as output. For instance, we first\napply the vulnerability detector on each individual entry function\nby looking at its local taint flows. If a warning is generated (e.g., a\npotential integer overflow happens due to an addition operation\ntakingataintedoperand),wecheckifthetaintsourceisuserinput\norsomeglobalmemory.Ifitisglobalmemory,weneedtoquerythe summaries of other entry functions with a matching sink\n(sameglobalmemorybeingthesink).There,ifthecorresponding\nsource is an user input, we conclude that it is a second-order\nwarning. We make this design choice because it is more flexible\n(e.g.,enablingustofocusonlyonsinkvariablesofinterest)andfits\nbetter into the workflows of many existing static bug finding\ntools [8,26], which first pinpoints potential vulnerable sites in the\nprogram with various detectors, and then take a closer look at the\ninvolved variables (e.g., decide whether it is tainted by user).\nIt is worth noting that although SUTURE is able to discover\nvulnerabilities of arbitrary orders by recursively performing the\naforementionedbackwardquery,weobservethatinpracticeitis\nhighlyunlikelytohavetruehigh-ordervulnerabilitiesabovetheorder of 4 (most likely false positives if it is longer than that). Infact, our evaluation shows most true positives are second-order.\nTherefore, we will stop searching for higher-than-4 order taint\nflows when the current query already takes too long a time.\nWarning Grouping. If an user tainted variable is detected in a\nsensitive instruction (defined by the vulnerability detector as\nmentioned in §4),a warning will be fired for it. SUTURE assembles\nall the warnings issued in the input program as its output. Each\nwarning specifies the warned instruction and its calling context,\nthe warning type (e.g., integer overflow), and the complete taint\nflow(s)fromtheuserinputtothesinksite.SUTUREalsocalculates\nthe𝑜𝑟𝑑𝑒𝑟of each taint flow and attaches it to each warning.\nOne important observation we have during the warning review\nprocessisthatmanywarningsoftenshareasame“prefix”inthe\ninitialtaintpropagationwhileareonlyslightlydifferentinthefinal\nwarningsitesortaintsinks.Forexample, 𝑎isthetaintedvariablein\nanoverflowinducinginstruction 𝑐=𝑎+𝑏,and𝑐,whichistaintedby\n𝑎, is then immediately used as a loop bound, in this situation, two\nrawwarningswillbegeneratedfortheoverflowandtheloopbound\nrespectively, obviously, instead of reviewing the two warnings one\nbyone,abetterwayistofirstinspectthecommontraceprefixfrom\nthe original userinput to 𝑎, and ifno problem, then thedifferent\nsinks (often close to each other).\nBased on this observation, to help the reviewers screen the\nwarnings more efficiently, SUTURE groups the similar warnings\ntogether from the data flow perspective, regardless of the warning\ntypes as listed in Table 1 (i.e., warnings of different types can be\nput in a same group.). More specifically, two warnings will begrouped together if i) their warning sites (i.e., the warned\ninstruction) locate in a same function 𝑓, and ii) their taint\npropagation traces share a same sub-trace starting from the entry\nof𝑓. With this grouping strategy, the reviewer can avoid studying\nthe shared taint trace over and over and quickly go through a\nwarning group by only carefully inspecting a small subset, greatly\nreducing the required review time. A real-world example of\nwarning grouping can be found in §6.7.\n5 IMPLEMENTATION\nAs mentioned before, SUTURE is built on top of Dr. Checker,\nhowever, to improve the accuracy of the static analysis and\nsupport high-order taint flow construction, we re-write most parts\nof Dr. Checker’s static analysis and implement many new\nfunctionalities(detailedin§3),intotal,comparedtoDr.Checker,\nSUTURE has 14,482 LOC added and 2,741 LOC removed in C++,plus 630 LOC of python scripts. In this section we discuss some\nimplementation details of SUTURE.LLVM Version\n. Dr. Checker is based on LLVM 3.8, which is too\noldtocompilenewerkernelversionsnowadays.Totestthelatest\nkernels, SUTURE is based on LLVM 9.0.Driver Module and Entry Function Identification\n.Wefollow\nDr. Checker’s approach [ 26] to identify the vendor driver modules\nand their entry functions. However, we make some improvements\nincluding (1) besides the modules identified by keyword searchin the kernel config file, we also review the kernel source treetoincludeanymissingones,and(2)weupdatesomeout-of-date\nkernelstructuredefinitionsintheDr.Checker’sentryidentification\nscript, as well as include some missing ioctl() functions.\nFalseAlarmsFiltering .Weusesomesimplebutreliableheuristics\ntofilteroutcertainobviousfalsealarms.Specifically,wecutoffthetaintflowsthrough(1)amodulooperationifthemodulusisasmallinteger(currentthresholdis64),and(2)alogical“and”operationif\nonly limited number of bits (current threshold is 6) are not cleared.\nBasically,thesesituationssuggestthatthetaintedvalueisawell\nbounded“index”or“flag”overwhichtheuserhasaverylimited\ncontrol, thus unlikely to cause security issues. We leave a more\nsystematicalandprinciplefalsealarmsfilteringasafuturework,\nas will be discussed in §7.\n6 EVALUATION\nIn this section we show the evaluation results of SUTURE as both\nastaticanalysisengine(e.g., theefficacyofourstaticanalysisim-\nprovementsin§3)andahigh-orderbugfindingtool(e.g., regard-\ning its accuracy, efficiency, and bug finding ability).\n6.1 Experiment Setup and Procedure\nDataset. We evaluate SUTURE on the driver modules extracted\nfrom a diverse set of kernels used in flagship Android devices,\nmanufactured by different vendors and based on different chipsets,\nwesummarizetheminTable2.Thelastcolumninthetableliststhe\nnumberofdrivermodulesweextractandtestforthecorresponding\nkernel. Besides the relatively new kernels in the table, we alsocompile older versions of the Qualcomm kernel modules which\ncontain4knownhigh-ordertaintvulnerabilities(asseeninTable5),\nto test whether SUTURE can successfully catch them.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n818No. Vendor Chipset Model Version #Modules\n0 Google Qualcomm Pixel 4 XL 4.14.150 37\n1 Samsung Exynos Galaxy S20 4.19.87 202 Huawei Hisilicon Mate 40 Pro 4.14.116 30\n3 Xiaomi MediatekRedmi K30\nUltra4.14.141 29\nTable 2: Tested Android Kernels\nHardwareConfiguration .Weruntheevaluationonaserverwith\nIntel Xeon E5-2695 v4 CPU @ 2.10GHz and 256 GB RAM.\nProcedure . For each selected kernel in Table 2, we first try to\nextractitsvendor-specificdrivermodulesandthenidentifytheir\nentryfunctions,asdescribedin§5.WiththeaboveinputwerunSUTURE for high-order taint vulnerability discovery, the output\nwarninggroups(§4)arethenmanuallyreviewedbyustodecidetrue\nandfalsepositives.ItisworthnotingthatalthoughSUTUREisalso\ncapable of discovering the simple first-order taint vulnerabilities\n(i.e.,only require one entry function invocation), in the evaluation\nwe focus on the high-order ones only.\n6.2 Efficacy of SUTURE’s Static Analysis\nImprovements\nTo achieve a highly precise analysis SUTURE ships with many\ndifferentstaticanalysisimprovementsasdetailedin§3.Tobetter\nunderstandwhetherandhowtheybenefittheanalysisprecisionandefficiency,werandomlypick20modulesfromtheQualcommkernel\nand run an instrumented SUTURE on them, collecting statisticsduring the process for each of SUTURE’s improvements. These\nstatistics can be categorized into three groups as shown in Table 3:\n(1)For opportunistic path-sensitivity ( PATH), we can see that it\nhelps SUTURE get rid of infeasible basic blocks and/or callees (a\ncallee can contain many more basic blocks that we do not count in\nTable3)in19outof20modules,boostingbothperformanceand\naccuracy.Forexample,wefindtheanalysistimeofonelargemodule\ndecreases from 54 hrs to 31 hrs by applying the opportunistic path-\nsensitivity.\n(2)For multi-source multi-sink pairing ( MSMS), memory-SSA\n(MEMSSA ), and index-sensitivity ( INDEX), our statistics show\nthattheycaneffectivelytrimfalsepositivepoints-torecordsand\ntaint flows. Specifically, besides the data in Table 3, MEMSSA also\ncaptures missing points-to records by Dr. Checker in all 20\nmodules(Min/Med/Max:10/44/1351),thoughDr.Checkeradopts\nan always weak taint update policy (e.g., no overwriting for old\ntaint records), missing points-to records will inevitably lead tofalse negative taint flows from the very beginning. It is worthnoting that both false positive and negative data flow facts will\naccumulateevenmore(possiblyexponentially)ifleftunrecognized\nastheanalysisproceeds,thus,ourstatisticsherearesignificantly\nunderestimated.\n(3)Forpointerarithmetic( POINTER )andnestedstructure( NEST),\nweobservethatinalltestedmodules,thereisaconsiderablesubset\nofGEPoperations(i.e., themainLLVMIRresponsibleforcalculating\nthe structure field offset) that need to handle them - otherwise,both false positive and negative analysis errors can happen and\naccumulate.Improvement#Affected\nModules#Infeasible BBs\n(Min/Med/Max)#Infeasible Callees\n(Min/Med/Max)\nPATH (§3.4) 19 9/153/115336 0/8/2414\n#Reduced Points-To\n(Min/Med/Max)#Reduced Taint Flows\n(Min/Med/Max)\nMSMS (§3.5) 18 8/174/852492 15/886/1024094MEMSSA (§3.6.1) 20 10/1789/547733 52/5139/2480710INDEX (§3.6.2) 20 0/14/17850 18/2922/276318\nRatio of Affected GEP Operations\n(Min/Med/Max)\nPOINTER (§3.6.3) 20 3%/13%/79%\nNEST (§3.6.3) 20 12%/27%/37%\nTable 3: Statistics on SUTURE’s Static Analysis Improve-\nments from 20 Randomly Selected Qualcomm Modules\nKernel\nNo.#Warning Groups#TP2#FPr3(R4)\nITDUD0TAD0TLBD0TPDD0Unified1\n0 0 188 87 277 488 30 22 (42.31%)1 0 137 41 147 281 17 12 (41.38%)2 0 201 63 171 365 22 22 (50.00%)3 0 240 62 280 469 10 27 (72.97%)\nSUM 0 766 253 875 1603 79 83 (51.23%)\n0: #groups of warnings issued by specific detectors (Table 1) only.1: #groups by standard grouping strategy regardless of warning types (§4);2: #groups manually confirmed by us as true positives.3: #false alarm groups as perceived by the reviewers. (§6.3)\n4:Reviewer perceived false positive rate: #FP\nr/(#FPr+#TP) (§6.3)\nTable 4: Vulnerability Discovery Accuracy of SUTURE\nWefurtherbuildabaselineversionofDr.Checkeraugmented\nonly with multi-tag taint analysis (§3.6.5) that is essential for taint\nflowconnection,butnotanyotherenhancements,toverifywhether\nit can identify the same high-order vulnerabilities as discovered by\nSUTURE.Theresultshowsthatnoneofour19vendorconfirmed\nwarningsareidentified(i.e., foreachhigh-orderwarningatleast\none component local taintflow isnot recognized), because i) the\nanalysis is stuck due to too many false positive points-to and taint\nrecords(e.g., theanalysisprogressofonemoduleisalmostfrozen\nafter329 hrs,aroundwhich pointeach LLVMvariablehas tensof\nthousandsofpoints-toandtaintrecordsonaverage),ii)failureto\nresolve correct indirect call targets (§3.6.4), and iii) missing taint\npropagation due to failure to handle pointer arithmetic and nested\nstructure. These results well justify the necessity and efficacy of\nSUTURE’s various static analysis improvements in §3.\n6.3 Vulnerability Discovery Accuracy\nWe show the evaluation results regarding the vulnerability\ndiscovery accuracy of SUTURE in Table 4. SUTURE in total fires\n1,603high-orderwarninggroups,where79areconfirmedastrue\npositivesbyourmanualinspection.Furthermore,19outofthe79\nhave been confirmed by the corresponding vendors. At the firstglance, this results in a very high false positive rate of 95.07%\n((1603-79)/1603) which seems completely unusable in practice.\nHowever,thisisfarfromthetruth.Intheremainingofthissection,\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n81900 int mtk_session_set_mode(..., unsigned int session_mode){\n01 ...\n02 if (session_mode >= MTK_DRM_SESSION_NUM) {\n03 goto error;04 }05 …06 mtk_crtc_path_switch(…, mode_tb[session_mode].ddp_mode[i], 1);\n07 …08 }\nFigure 7: A Taint Trace Segment Leading to False Alarms\nwewillfirstdescribetherootcausesbehindthesefalsealarms,and\nthenexplainwhytheactuallyperceivedfalsepositiveratebythe\nSUTURE users is much lower (i.e., 51.23%).\nFalse Positive Analysis .WesummarizethemajorcausesofSU-\nTURE’s false alarms as following.\n(1) Ignored Constraints for Tainted Variables. Except the simple false\nalarm filtering heuristics described in §7, SUTURE in general\nconservativelykeepsallthetaintflows,withoutreasoningabout\nthe constraints posed on the tainted variables, which can lead to\nfalse positivewarnings (e.g., the taintedvariable inthe vulnerable\nsitehasbeenproperlysanitized).Weshowaconcreteexamplein\nFig. 7.The argument session_mode ofmtk_session_set_mode()\nis user-controllable, which is then used to index the array mode_tb\natline 6.SUTUREthusdetermines thatthewhole retrievedarray\nelement mode_tb[session_mode] istainted, thisis truesince the\nuser does have the choice on which element to access. However,\nsession_mode is upper bound checked at line 2 and the array\nmode_tbis also predefined, so the user cannot really control the\ncontent of the obtained array element on desire. As a result,\ncontinuing the taint propagation from mode_tb[session_mode]\ncauses false alarms subsequently. So far, the ignored constraints is\nthe most common FP cause for SUTURE, as well as many other\nstatic analysis based bug detection works.\n(2) Recursive Data Structures. The recursive data structure ( e.g.,\nlinked lists) is another well-known difficulty for static analysis,\nsinceitishardtostaticallydifferentiatetheircontainedelements.\nTo be conservative, SUTURE does not differentiate the elements\ninthelinkedlistwhichiswidely-usedinkernel.Thoughbeinga\ncommon practice, it can cause false alarms in many cases, for anexample, a local taint flow\n𝜏0sinks to element 0 of a linked list\nwhile𝜏1sources from a different element 1, in theory, 𝜏0cannot\nbe connected to 𝜏1since𝑠𝑖𝑛𝑘(𝜏0)≠𝑠𝑜𝑢𝑟𝑐𝑒(𝜏1)(Def 5in §3.2), but\nSUTUREconnectsthemduetoelement-insensitivity,resultingin\ninvalid high-order taint flows.\n(3) Infeasible Paths. By nature, static analysis may follow infeasible\npaths, leading to false alarms. There are two reasons for SUTUREtoencounter withinfeasiblepaths: i)SUTURErecoversinfeasible\nindirectcall targets,andii) SUTUREfails torecognize conflicting\npath constraints with its opportunistic path-sensitivity (§3.4) be-\ncause they are too complicated. This FP cause is actually the least\ncommon out of the three.\nAs can be seen from the above analysis, the core problem behind\nthe false alarms is notthat SUTURE generates inaccurate local taint\nflows,on thecontrary, inalmost allcases, theselocalflows arevalid\nand precise ( e.g.,no over-taint), demonstrating SUTURE’s value as\na highly precise static taint analysis for a single entry function. InCVE Bug Type Severity1Order2Discovered\nCVE-2016-2068 Integer Overflow High 2 YesCVE-2016-5859 Integer Overflow High 2 YesCVE-2017-0608 Buffer Overflow High 2 Yes\nN/A\n3Buffer Overread N/A32Y e s\n1: Based on the CVSS score in the CVE entry. 2: Def 6 in §3.2.3: We cannot locate a CVE number, the patch can be found in [4].\nTable 5: Evaluation on Known High-Order Vulnerabilities\notherwords,bugfindingtoolsgobeyondtherequirementofprecise\ntaint flow tracking - they also need to rigorously reason about the\nconstraints (reason (1)and(3)) where SUTURE falls short.\nOther than the above, SUTURE’s false alarm count is greatly\nboosted by high-order taint flow construction. First, even if twolocal taint flows are both valid, connecting them incorrectly can\ncauseFPs(e.g., reason(2)),secondly,anyfalsepositivesencountered\nin one local taint flow will be “multiplied” by its connection to\npotentiallymanyotherlocalflows.However,thisalsomeansthat\nmany false alarms share exactly the same problematic sub- taint\ntrace. Exploitingthisfact,theactualfalsepositiverateperceived\nby reviewers is orders of magnitude smaller with the following\nreview procedure: i)the reviewer picks andinspects a warning,if\nit is a FP, then also identifies the problematic sub-trace which is\nbasically an instruction sequence in string format; ii) automaticallyfilteroutallotherwarningscontainingthesamesub-tracebystring\nmatch;iii)pickthenextwarningtoreviewfromthefilteredpool.\nAs a concrete example, once recognized, the taint trace in Fig. 7\nhelpsusimmediatelyexclude94warninggroupswithoutadditional\nreviewing efforts.\nWe hence define the reviewer perceived false positive rate\n𝑅as𝑅=#𝐹𝑃𝑟/(#𝐹𝑃𝑟+#𝑇𝑃), where # 𝐹𝑃𝑟is the number of false\nalarms thatactually needthe reviewer tocarefully inspectone by\none (e.g., does not include automatically filtered out ones) and the\n#𝑇𝑃is the count of valid warning groups. 𝑅represents SUTURE’s\nfalsepositiverateinthereal-worldreviewscenario,asshownin\nTable 4, SUTURE achieves an aggregated 𝑅of 51.23%, which is\nmuch more acceptable for a static analysis tool. We will discuss\npotential ways to further reduce the false positive rate in §7.\n6.4 Known High-Order Taint Vulnerabilities\nIt is usually difficult to test the false negative rate of a bug finding\ntoolduetothelackofgroundtruth,thisisespeciallytrueforSU-\nTUREsincethereisnoavailablelargedatasetofhigh-ordertaint\nbugs. Thus, as a small-scale validation, we assemble four known\nhigh-order taint vulnerabilities and confirm that SUTURE can suc-\ncessfullyre-discovertheminolderversionsofdrivermodules,asshowninTable5.Thoughnotbeingacomprehensiveevaluation,\nwe can still envision potential reasons for false negatives.\nFalse Negative Analysis. We summarize some potential false\nnegative causes as following.\n(1) Soundy Analysis. SUTURE is built on top of Dr. Checker and\ninherits its soundy but not sound static analysis (e.g., skip the\ngeneral kernel functions and limit the loop iteration times) forefficiency and accuracy [\n26], which can possibly lead to false\nnegatives. Moreover, since the general kernel functions are\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n8201234567891 0010203029.92\n18.89\n13.2311.518.215.875.594.882.791.6\nModule No.Time (hrs)Static Taint Analysis\nVulnerability Detection\nFigure 8: Time Breakdown for Qualcomm Modules (> 1 hr)\nskipped, Dr. Checker and SUTURE need to model the behaviors of\nsome importantutility functionssuch as copy_from_user() (e.g.,\nas a taint source), in this situation, it is possible for SUTURE to\nmiss some vulnerabilities due to the incomplete or incorrect\nmodeling. In fact, this has already happened in Dr. Checker due to\nthe lack of modeling of memdup_user() (another taint initiator\nfunction), which we add in SUTURE.\n(2)IncompleteCallChains. SUTUREcannotguaranteetoanalyze\nall possible call chains, mainly due to two reasons: i) SUTURE may\nmissindirectcalltargets,andii)SUTURElimitsthecallstackdepth\nwhenanalyzingeachentryfunctioninthetop-downmannerfor\nscalability, currently, the depth limit is 8, increased from 5 in Dr.\nChecker.\nWe will discuss possible fixes to some of these issues in §7.\n6.5 Efficiency\nSUTUREanalyzesonekernelmodulewithoneinstanceonasingle\nCPU core, so naturally, multiple modules can be concurrentlyanalyzed on multi-core systems that are widely availablenowadays (e.g., our evaluation server has 72 cores). Thus, the\nefficiency bottleneck is mainly those most demanding modules. In\nFig. 8, we show the time cost of all Qualcomm kernel modules\nwhich take more than 1 hr to analyze. The time cost covers two\nparts:i)thestaticanalysistogenerateper-entrytaintsummaries\n(§3), and ii) the vulnerability discovery involving on-demand taint\nflow construction (§4). Basically, SUTURE’s static analysis is\nsignificantly more costly than Dr. Checker’s - even the most costly\nmoduleinlatter’sevaluationtakesaboutonly16mins[ 26].This\nperformance,however,iswellexpectedduetoourimprovements\nonstaticanalysisprecision(§3).Thevulnerabilitydiscoverytime\nis generally not correlated to the static analysis time, because itmainly relies on the amount of cross-entry shared states - the\nmore of them, potentially the more high-order taint flows we need\nto construct during the vulnerability discovery process.\nDue to space limit, we only show the performance details of the\nQualcommkernelastheotherkernelsbearasimilarcharacteris-\ntic. As a conclusion, we believe SUTURE achieves a reasonable effi-\nciency(e.g., analyzesallQualcommmodulesconcurrentlywithin\n30 hrs) given its precision and capability.\n6.6 Discussion of Order\nOne interesting aspect of the warnings generated by SUTURE isthe\n𝑜𝑟𝑑𝑒𝑟(Def 6in §3.2), denoting the count of required entry\nfunction invocations to trigger the vulnerability. Though SUTURE\nby design is capable of discovering vulnerabilities of arbitraryorder,sofar,mostofourconfirmedtruepositivewarningsinthe\nevaluation are second-order, SUTURE generates one valid\nthird-orderwarning,however,thesamevulnerabilitycanalsobe\nreproduced by a simplified second-order taint flow. That beingsaid, we create some artificial benchmark programs that contain\nvulnerabilitiestriggerablebyhigher-ordertaintflowsonly(upto\nninth-order)andconfirmthatSUTUREcansuccessfullypinpoint\nthem. Based on these results, we envision that SUTURE can\ndiscover higher-order vulnerabilities with an extended scope (e.g.,\nmore kernel modules and user-space programs).\n6.7 Study of Discovered Vulnerabilities\nIn this section we discuss the vendor-confirmed high-order\nvulnerabilities discovered by SUTURE so far. By root cause, the 19\nconfirmed warning groups can be further categorized into 6 major\nissues (e.g., under the same root cause there can be different\nwarningsfordifferentcallingcontextsorinstructions).Wehave1\nissue rated as high severity and 3 as medium by the vendors,\nwhich can cause arbitrary memory read/write or privilege\nescalation. For the remaining 2, the developers confirmed that they\ncancauseout-of-boundmemoryaccess,butwithunclearsecurity\nimpact (e.g., the over-read data may not contain sensitive\ninformation), thus need further investigation. We are still in theprocess of reporting and waiting for confirmation of otherdiscovered issues. By nature, the high-order taint vulnerabilities\nhave security impacts as severe as the well-known first-order ones,\nhowever,theyaremorestealthy(andthusdangerous)duetothecomplicated control and data flows, making SUTURE a valuabletool. We will discuss SUTURE’s potential in discovering moresecurity vulnerabilities in §7. To better illustrate the discoveredhigh-order issues, in the remaining section we study two\nrepresentative cases in detail.Case 1.\nTo trigger the vulnerability in Fig. 9 we need two steps\n(i.e.,a second-order vulnerability). First, a user needs to invoke the\nentry function snd_ctl_ioctl() , which eventually reaches\nmsm_pcm_put_out_chs() thatpropagatesauserinput(inred)to\na global variable channel_mixer[fe_id].output_channel (in\nblue) at line 3. Then, after snd_ctl_ioctl() returns, another\nentryfunction snd_pcm_ioctl() needstobeinvoked.Following\nits callchain, channel_mixer+fe_id , which is equivalent to\n&channel_mixer[fe_id], is passed as an argument to a callee\nadm_programable_channel_mixer() at line 9, the corresponding\nformal argument, ch_mixer , is then used in the overflow inducing\noperation at line 17, to access ch_mixer->output_channel that\naliases to channel_mixer[fe_id].output_channel , which is the\nglobal variable controllable by the user in the first step (line 3).\nConsequently,theusercanoverflow param_size atline17or sz\nat line 22, since the latter is used as an allocation size (line 23), the\nallocated buffer can be much smaller than expected due to the\noverflow, causing out-of-bound access later.\nIt is worth noting that, besides the high-order nature, this\nvulnerabilityalsoinvolvesindirectcalls( snd_ctl_elem_write()\n->msm_pcm_put_out_chs() in step 1), pointer arithmetic (line 10),\nand nested structure (line 3), making it difficult to be staticallydiscovered. We also want to mention that SUTURE will group\nwarningsforthepotentialoverflowsatline17and22togetheras\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n821STEP 1 :\nCALLCHAIN: snd_ctl_ioctl -> snd_ctl_elem_write_user ->\nsnd_ctl_elem_write -> msm_pcm_put_out_chs\n00 static int msm_pcm_put_out_chs(struct snd_kcontrol *kcontrol,\n01   struct snd_ctl_elem_value *ucontrol ){\n02 ...03 channel_mixer[fe_id].output_channel =\n04 (unsigned int)( ucontrol->value.integer.value[0]);\n05 return 1;06 }\nSTEP 2\n:\nCALLCHAIN: snd_pcm_ioctl -> ... -> msm_pcm_routing_channel_mixer ->\nadm_programable_channel_mixer07 static int msm_pcm_routing_channel_mixer(int fe_id, …) {\n08 ...09 ret = adm_programable_channel_mixer(…, …, …, …,10 channel_mixer + fe_id, ...);\n11 ...12 }1314 int adm_programable_channel_mixer(…, …, …, …,15      struct msm_pcm_channel_mixer *ch_mixer ,… ){\n16 ...17 param_size =2*  ( 4+ch_mixer->output_channel +\n18 ch_mixer->input_channels[channel_index] +\n19 ch_mixer->input_channels[channel_index] *\n20 ch_mixer->output_channel); //potential overflow\n21 ...\n22 sz= ... + param_size ;//potential overflow\n23 adm_params = kzalloc( sz, GFP_KERNEL);\n24 ...\n25 }\nFigure 9: Case Study 1: A High-Order Vulnerability Discov-\nered by SUTURE\ndescribed in §4, leading to a more natural and easier review\nprocess for the auditors.Case 2.\nAs shown in Fig. 10, we again need two entry function\ninvocations to trigger the vulnerability. First, snd_ctl_ioctl() is\ninvoked with proper arguments so that iaxxx_put_pdm_bclk()\ncanbesubsequentlycalled,withinwhichtheusercansetthevalue\nof a global variable iaxxx->pdm_bclk (line 5). Then, unlike the\nfirst case study, we invoke the same entry function\nsnd_ctl_ioctl() again but with different arguments, so that this\ntime we follow a different call chain to eventually reach\niaxxx_pdm_port_setup() , which uses the same global variable\niaxxx->pdm_bclk unchecked to index a fixed-length array\npdm_cfg, causing out-of-bound accesses (line 13-15). This issue\nhas been rated as high severity by Google.\nThis case has some notable characteristics. First, even if there is\nonly one entry function (e.g., snd_ctl_ioctl() ), high-order taint\nanalysis is still necessary as some callees are mutually exclusive\nwithin one entry invocation (e.g., iaxxx_put_pdm_bclk() and\niaxxx_pdm_port_setup() ). Second, it is actually not so\nstraightforwardasitappearstomatchtheglobalstructure iaxxx\nused at line 5 and 12, because both iaxxxare local instead of\nexplicitly defined global variables (see line 4 and 10). In thissituation, SUTURE must rely on its implicit global memorymatching (covered in §3.3.2) to decide the identity of the twooccurrences ( e.g.,both\niaxxxcan be reached from a shared\nkcontrol object following a same access path).STEP 1 :\nCALLCHAIN: snd_ctl_ioctl -> snd_ctl_elem_write_user ->\nsnd_ctl_elem_write -> iaxxx_put_pdm_bclk\n00 static int iaxxx_put_pdm_bclk(struct snd_kcontrol *kcontrol,\n01                  struct snd_ctl_elem_value *ucontrol)\n02 {03 struct snd_soc_codec *codec = snd_soc_kcontrol_codec(kcontrol);04 struct iaxxx_codec_priv *iaxxx = dev_get_drvdata(codec->dev);05 iaxxx->pdm_bclk =ucontrol->value.enumerated.item[0];\n06 return 0;07 }\nSTEP 2\n:\nCALLCHAIN: snd_ctl_ioctl -> snd_ctl_elem_write_user ->\nsnd_ctl_elem_write -> iaxxx_pdm_portb_put -> iaxxx_pdm_port_setup08 static int iaxxx_pdm_port_setup(…) {\n09 struct snd_soc_codec *codec = snd_soc_kcontrol_codec(kcontrol);10 struct iaxxx_codec_priv *iaxxx = dev_get_drvdata(codec->dev);11 …12 pdm_bclk =iaxxx->pdm_bclk;\n13 port_sample_rate = pdm_cfg[pdm_bclk].sample_rate; //OOB\n14 words_per_frm = pdm_cfg[pdm_bclk ].words_per_frame; //OOB\n15 word_len = pdm_cfg[pdm_bclk ].word_length; //OOB\n16 …17 }\nFigure10:CaseStudy2:AHigh-OrderVulnerabilityDiscov-\nered by SUTURE\n7 LIMITATIONS AND DISCUSSIONS\nIn this section we summarize SUTURE’s limitations and discuss\npotential improvements in the future.Soundness\n. As mentioned in §6.4, SUTURE’s static analysis is not\nsound(e.g., nofixed-pointloopanalysis,limitedcallstackdepth).\nAlthough we intentionally sacrifice the soundness for a better per-\nformanceandaccuracysimilarasinDr.Checker[ 26],itcanlead\ntofalsenegativesregardingvulnerabilitydiscovery.Onepossible\nway to improve soundness is to adopt the bottom-up style static\nanalysis [ 9,10,40](i.e.,callees are analyzed and summarized be-\nforecallers)whenconstructingthetaintsummaryforeachentry\nfunction,whichalleviatesthelimitationsoncallstackdepthdueto\ntheimprovedefficiency(e.g., asamecalleewillnotberepeatedly\nanalyzed). We leave this as a future work.Recursive Data Structure Handling\n. SUTURE does not\ndifferentiate the elements inrecursive data structures (e.g., linked\nlists) to (1) be conservative, and (2) simplify the access path to ease\ntheglobalobjectmatching(§3.3.2)involvingrecursivestructures\n(e.g.,there can be numerous access paths from one linked list\nelement toanother). However, this designchoice alsocontributes\nsignificantly to false alarms as mentioned in §6.3. To better handle\ntherecursivedatastructuresandsuppressthefalsepositives,we\nenvisionamorefine-grainedstaticanalysiswhichcandifferentiate\ntheaccessedelements(e.g., byconsideringtheconditionsusedto\nselect a specific element, such as comparing the element id against\na desired value), or the integration of a dynamic analysis which\ncan help verify whether two element access are the same utilizing\nthe runtime information.Path Constraints Reasoning\n. Besides the simple path\nconstraints considered in opportunistic path-sensitivity (§3.4) to\nfilter out infeasible paths, SUTURE does not reason about the path\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n822constrains associated with feasible taint flows, resulting in the\nmajorbodyoffalse alarmsasmentionedin§6.3. Thereareexisting\nsolutions for this problem in previous works, Sys [ 8] and\nUBITECT [ 40] employ limited-scale symbolic execution to validate\nthe discovered vulnerabilities without introducing high\nperformance penalties, KINT [ 36] carefully reasons about the\nconstraints specifically for integer overflow vulnerabilities.\nThough not the focus of this paper, we believe these approaches\ncan be naturally combined with SUTURE to further reduce false\nalarms, which we leave as a future work.\nVulnerability Scope . To demonstrate the efficacy of SUTURE’s\nhigh-order analysis capability, in this paper we choose to reuse\nseveral of Dr. Checker’s detectors for discovering high-order taint\nvulnerabilitiesinthekernel(§4).However,thetechniquespacked\nin SUTURE can also be applied to discover a wider range of\nvulnerabilities in a broader set of software, for example, many\nuse-after-free vulnerabilities (e.g., [1,2]) have a cross-entry nature\n(e.g.,the “free” happens in one entry invocation while the “use”\nhappens in another), where SUTURE’s cross-entry data flow\nanalysis can be useful. Moreover, SUTURE can also scan general C\nprograms other than the kernel.\n8 RELATED WORK\nStatically Discovering Taint Vulnerabilities . There is a large\namount of work trying to statically discover taint style\nvulnerabilities, for different software written in different\nprogramminglanguagesandatdifferentlayers.Wediscusssome\nsignificant categories as following.\nFor Android Applications. FlowDroid [ 5] is a widely used precise\nstatic taint analysis designed for Android applications, similarly,many works utilize static taint analysis to detect information\nleakage in Android apps [17, 21].\nFor Web Applications. Many works focus on discovering taint style\nvulnerabilities in the web applications [ 6,14,23,24,33,35,37],\nwhichisverydifferentfromthemaintargetofSUTURE(i.e., the\nkernel written in C). However, it is worth noting that Dahse et\nal.[14] proposes to detect the second-order vulnerability in the\nweb applications, where the taint flows through some persistent\ndata stores (e.g., databases and files) on the server. Compared to it,\nSUTUREtargetsthemorecomplexkernelandthegeneralglobal\nstates as taint relays, supporting taint flows of arbitrary order.\nFor Binaries. iDEA [ 7] utilizes taint tracking to find vulnerabilities\nin Apple kernel driver binaries. Cova et al.[13], DTaint [ 10] and\nSaluki [18] perform binary level static taint analysis based on\nsymbolic execution to find vulnerabilities in the executable.\nSUTUREassumesthesourcecodeavailability,whichcanbenefit\nthe accuracy (e.g., the exact structure layout). Besides, symbolic\nexecution may not scale well for the large code base like the\nkernel, especially when hunting the high-order vulnerabilities.For Open-Source C Programs. This is the most relevant category to\nSUTURE due to the same target. Chen et al.[9] uses static taint\nanalysis to discover the implicit information leak in the kernelnetwork stack, Zhang et al.[\n41] and Unisan [ 25] try to discover\nuninitialized memory allocations, KINT [ 36] can detect the integer\nerrors in kernel and user programs. Dr. Checker [ 26] proposes a\nstatic analysis framework to discover different taint-stylevulnerabilities. Johnson etal.[22]andUBITECT[ 40]adopttype\ninference based methods to detect specific taint vulnerabilities.Compared to these works, SUTURE has multiple enhancements\n(§3)onthestatictaintanalysistomakeitmoreprecise,andmore\nimportantly,supportsthehigh-ordertaintanalysis.Yamaguchi et\nal.[39] and Shastry et al.[29] try to automatically infer the taint\nvulnerability patterns from known instances, and use them to\nsearch similar vulnerabilities. SUTURE on the other hand\ndiscovers new taint vulnerabilities from the ground.Improvements on Static Analysis\n. Many works focus on\nimproving the static analysis precision and/or efficiency, we\ndiscuss some of them as following.\nTaintAnalysis.TAINTINDUCE[ 12]automaticallyinfersthetaint\npropagation rules from dynamic analysis to avoid the inaccuracies\nof the human defined rules, for the same sake, Neutaint [ 30]\nemploys neural network to conduct the dynamic taint analysis.ConDySTA [\n43] uses dynamic analysis results to improve static\ntaint analysis accuracy. P/Taint [ 19] tries to unify the taint and\npoints-to analysis to ease the implementation.\nPath-Sensitivity. ESP [ 15] improves the scalability of the\npath-sensitive analysis by merging branches leading to sameprogram states of interest, for the same goal, Fusion [\n32] makes\ntheSMTsolverworkdirectlyontheprogramdependencegraph,\ntogether with the static analysis. Dillig et al.[16] improve\npath-sensitivitybyconsideringthevariableobservabilityandthe\nnecessary and sufficient conditions of original path constraints.\nSUTURE’s opportunistic path-sensitivity is more lightweight and\nmainly designed for trimming infeasible paths efficiently.\nOtherImprovements.Pearce etal.[27]extendstheset-constraints\nlanguage to support an efficient field-sensitive pointer analysis for\nC, Saturn [ 38] builds its static bug detection on boolean satisfiabil-\nity(SAT)forabetterprecisionandscalability.Heo etal.[20]uses\nmachine learning to guide the switch between sound and unsound\nstatic analysis, taking the best of both worlds. Pinpoint [ 31] defers\ntheinter-procedureflowconstructiontothebugdetectionphase\n(on-demand) for a better efficiency, analogously, SUTURE also con-\nstructs the cross-entry flows in an demand-driven way (§4).\nIngeneral,weconsidertheseworkscomplementarytoSUTURE,\nastheycanpotentiallyhelpimp rovethepre cisionandefficiencyof\nSUTURE’s static analysis.\n9 CONCLUSION\nInthiswork,wedevelopSUTURE,aprecisestaticanalysistoolthat\ncan be used to discover complex high-order taint vulnerabilities in\nlargecodebasesliketheLinuxkernel,agoalthatwaspreviouslynot\nattemptedvia staticanalysis.SUTURE successfullydiscoversnew\nseverehigh-ordervulnerabilitiesinthekernel,withareasonable\naccuracy as perceived by the warning reviewers and an acceptable\nperformance.\nACKNOWLEDGMENTS\nWethankourshepherdDeianStefanandanonymousreviewersfor\ntheirhelpfulcomments.WealsothankLingtongShenfortheuseful\ndiscussion on high-order vulnerabilities. This work is partially\nsupported by NSF grant #1652954.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n823REFERENCES\n[1] 2021. CVE-2020-7053. https://nvd.nist.gov/vuln/detail/CVE-2020-7053.\n[2] 2021. CVE-2020-8648. https://nvd.nist.gov/vuln/detail/CVE-2020-8648.[3] 2021. Syzkaller. https://opensource.google/projects/syzkaller.[4]\n2021. The patch for a high-order taint vulnerability in Qualcommdriver. https://review.lineageos.org/c/LineageOS/android_kernel_motorola_\nmsm8953/+/169169.\n[5]Steven Arzt, Siegfried Rasthofer, Christian Fritz, Eric Bodden, Alexandre Bartel,\nJacques Klein, Yves Le Traon, Damien Octeau, and Patrick McDaniel. 2014.\nFlowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint\nanalysis for android apps. Acm Sigplan Notices 49, 6, 259–269.\n[6]MichaelBackes,KonradRieck,MalteSkoruppa,BenStock,andFabianYamaguchi.\n2017. Efficientandflexiblediscoveryofphpapplicationvulnerabilities.In 2017\nIEEE european symposium on security and privacy (EuroS&P). IEEE, 334–349.\n[7]Xiaolong Bai, Luyi Xing, Min Zheng, and Fuping Qu. 2020. idea: Static analysis\nonthesecurityofapplekerneldrivers.In Proceedingsofthe2020ACMSIGSAC\nConference on Computer and Communications Security. 1185–1202.\n[8]Fraser Brown, Deian Stefan, and Dawson Engler. 2020. Sys: a static/symbolictool for finding good bugs in good (browser) code. In 29th\n{USENIX}Security\nSymposium ( {USENIX}Security 20). 199–216.\n[9]Qi Alfred Chen, Zhiyun Qian, Yunhan Jack Jia, Yuru Shao, and Zhuoqing Morley\nMao. 2015. Static detection of packet injection vulnerabilities: A case for\nidentifyingattacker-controlledimplicitinformationleaks.In Proceedingsofthe\n22ndACMSIGSACConferenceonComputerandCommunicationsSecurity.388–\n400.\n[10]Kai Cheng, Qiang Li, Lei Wang, Qian Chen, Yaowen Zheng, Limin Sun, and\nZhenkai Liang. 2018. DTaint: detecting the taint-style vulnerability in embedded\ndevice firmware. In 2018 48th Annual IEEE/IFIP International Conference on\nDependable Systems and Networks (DSN). IEEE, 430–441.\n[11]Fred Chow, Sun Chan, Shin-Ming Liu, Raymond Lo, and Mark Streich. 1996.\nEffective representation of aliases and indirect memory operations in SSA form.\nInInternational Conference on Compiler Construction. Springer, 253–267.\n[12]Zheng Leong Chua, Yanhao Wang, Teodora Baluta, Prateek Saxena, ZhenkaiLiang, and Purui Su. 2019. One Engine To Serve’em All: Inferring Taint Rules\nWithout Architectural Semantics.. In NDSS.\n[13]Marco Cova, Viktoria Felmetsger, Greg Banks, and Giovanni Vigna. 2006. Static\ndetection of vulnerabilities in x86 executables. In 2006 22nd Annual Computer\nSecurity Applications Conference (ACSAC’06). IEEE, 269–278.\n[14]Johannes Dahse and Thorsten Holz. 2014. Static detection of second-order\nvulnerabilities in web applications. In 23rd{USENIX}Security Symposium\n({USENIX}Security 14). 989–1003.\n[15]Manuvir Das, Sorin Lerner, and Mark Seigle. 2002. ESP: Path-sensitive program\nverification in polynomial time. In Proceedings of the ACM SIGPLAN 2002\nConference on Programming Language Design and Implementation. 57–68.\n[16]IsilDillig,ThomasDillig,andAlexAiken.2008. Sound,completeandscalable\npath-sensitiveanalysis. In Proceedingsof the29thACM SIGPLANConferenceon\nProgramming Language Design and Implementation. 270–280.\n[17]YuFeng,SaswatAnand,IsilDillig,andAlexAiken.2014. Apposcopy:Semantics-\nbased detection of android malware through static analysis. In Proceedings of\nthe 22nd ACM SIGSOFT international symposium on foundations of software\nengineering. 576–587.\n[18]IvanGotovchits,RijnardVanTonder,andDavidBrumley.2018. Saluki:finding\ntaint-style vulnerabilities with static property checking. In Proceedings of the\nNDSS Workshop on Binary Analysis Research, Vol. 2018.\n[19]Neville Grech and Yannis Smaragdakis. 2017. P/Taint: unified points-to and taint\nanalysis. Proceedings of the ACM on Programming Languages 1, OOPSLA (2017),\n1–28.\n[20]Kihong Heo, Hakjoo Oh, and Kwangkeun Yi. 2017. Machine-learning-guidedselectively unsound static analysis. In 2017 IEEE/ACM 39th International\nConference on Software Engineering (ICSE). IEEE, 519–529.\n[21]WeiHuang,YaoDong,AnaMilanova,andJulianDolby.2015. Scalableandprecise\ntaint analysis for android. In Proceedings of the 2015 International Symposium on\nSoftware Testing and Analysis. 106–117.\n[22]Rob Johnson and David Wagner. 2004. Finding user/kernel pointer bugs with\ntype inference.. In USENIX Security Symposium, Vol. 2. 0.\n[23]Nenad Jovanovic, Christopher Kruegel, and Engin Kirda. 2006. Pixy: Astatic analysis tool for detecting web application vulnerabilities. In 2006 IEEE\nSymposium on Security and Privacy (S&P’06). IEEE, 6–pp.[24]Nenad Jovanovic, Christopher Kruegel, and Engin Kirda. 2006. Precise alias\nanalysisforstaticdetectionofwebapplicationvulnerabilities.In Proceedingsof\nthe 2006 workshop on Programming languages and analysis for security. 27–36.\n[25]KangjieLu,ChengyuSong,TaesooKim,andWenkeLee.2016. Unisan:Proactivekernelmemoryinitializationtoeliminatedataleakages.In Proceedingsofthe2016\nACM SIGSAC Conference on Computer and Communications Security. 920–932.\n[26]Aravind Machiry, Chad Spensky, Jake Corina, Nick Stephens, Christopher\nKruegel, andGiovanni Vigna.2017. {DR}.{CHECKER }: Asoundy analysisfor\nlinux kernel drivers. In 26th{USENIX}Security Symposium ( {USENIX}Security\n17). 1007–1024.\n[27]DavidJPearce,PaulHJKelly,andChrisHankin.2007. Efficientfield-sensitive\npointeranalysisofC. ACMTransactionsonProgrammingLanguagesandSystems\n(TOPLAS) 30, 1 (2007), 4–es.\n[28]Barry K Rosen, Mark N Wegman, and F Kenneth Zadeck. 1988. Global value\nnumbers and redundant computations. In Proceedings of the 15th ACM SIGPLAN-\nSIGACT symposium on Principles of programming languages. 12–27.\n[29]BhargavaShastry,FedericoMaggi,FabianYamaguchi,KonradRieck,andJean-\nPierreSeifert.2017. StaticExplorationofTaint-StyleVulnerabilitiesFoundby\nFuzzing.. In WOOT.\n[30]DongdongShe,YizhengChen,AbhishekShah,BaishakhiRay,andSumanJana.\n2020. Neutaint:Efficientdynamictaintanalysiswithneuralnetworks.In 2020\nIEEE Symposium on Security and Privacy (SP). IEEE, 1527–1543.\n[31]QingkaiShi,XiaoXiao,RongxinWu,JinguoZhou,GangFan,andCharlesZhang.\n2018. Pinpoint: Fast and precise sparse value flow analysis for million linesof code. In Proceedings of the 39th ACM SIGPLAN Conference on Programming\nLanguage Design and Implementation. 693–706.\n[32]Qingkai Shi, Peisen Yao, RongxinWu,and Charles Zhang. 2021. Path-sensitive\nsparseanalysiswithoutpathconditions.In Proceedingsofthe42ndACMSIGPLAN\nInternationalConferenceonProgrammingLanguageDesignandImplementation .\n930–943.\n[33]Manu Sridharan, Shay Artzi, Marco Pistoia, Salvatore Guarnieri, Omer Tripp,\nandRyanBerg.2011. F4F:taintanalysisofframework-basedwebapplications.\nInProceedings of the 2011 ACM international conference on Object oriented\nprogramming systems languages and applications. 1053–1068.\n[34]YuleiSuiandJinglingXue.2016.SVF:interproceduralstaticvalue-flowanalysisinLLVM.In Proceedingsofthe25thinternationalconferenceoncompilerconstruction.\nACM, 265–266.\n[35]Omer Tripp, Marco Pistoia, Stephen J Fink, Manu Sridharan, and Omri Weisman.\n2009. TAJ: effective taint analysis of web applications. ACM Sigplan Notices 44, 6\n(2009), 87–97.\n[36]Xi Wang, Haogang Chen, Zhihao Jia, Nickolai Zeldovich, and M Frans Kaashoek.\n2012. Improvingintegersecurityforsystemswith {KINT}.In10th{USENIX}\nSymposiumonOperatingSystemsDesignandImplementation( {OSDI}12).163–\n177.\n[37]GaryWassermannandZhendongSu.2008. Staticdetectionofcross-sitescripting\nvulnerabilities. In 2008 ACM/IEEE 30th International Conference on Software\nEngineering. IEEE, 171–180.\n[38]YichenXieandAlexAiken.2007.Saturn:Ascalableframeworkforerrordetection\nusingbooleansatisfiability. ACMTransactionsonProgrammingLanguagesand\nSystems (TOPLAS) 29, 3 (2007), 16–es.\n[39]Fabian Yamaguchi, Alwin Maier, Hugo Gascon, and Konrad Rieck. 2015.\nAutomaticinferenceofsearchpatternsfortaint-stylevulnerabilities.In 2015IEEE\nSymposium on Security and Privacy. IEEE, 797–812.\n[40]YizhuoZhai,YuHao,HangZhang,DaimengWang,ChengyuSong,ZhiyunQian,MohsenLesani,SrikanthVKrishnamurthy,andPaulYu.2020. UBITect:aprecise\nandscalablemethodtodetectuse-before-initializationbugsinLinuxkernel.In\nProceedings of the 28th ACM Joint Meeting on European Software Engineering\nConference and Symposium on the Foundations of Software Engineering. 221–232.\n[41]HangZhang,DongdongShe,andZhiyunQian.2016. Androidionhazard:The\ncurseofcustomizablememorymanagementsystem.In Proceedingsofthe2016\nACM SIGSAC Conference on Computer and Communications Security. 1663–1674.\n[42]Tong Zhang, Wenbo Shen, Dongyoon Lee, Changhee Jung, Ahmed M Azab, and\nRuowen Wang. 2019. Pex: A permission check analysis framework for linuxkernel. In 28th\n{USENIX}Security Symposium ( {USENIX}Security 19). 1205–\n1220.\n[43]XuelingZhang,XiaoyinWang,RockySlavin,andJianweiNiu.2021. ConDySTA:\nContext-Aware Dynamic Supplement to Static Taint Analysis. In 2021 IEEE\nSymposium on Security and Privacy (SP). IEEE, 796–812.\nSession 3B: Operating Systems\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n824"}
{"title": "TokenScope: Automatically Detecting Inconsistent Behaviors of Cryptocurrency Tokens in Ethereum", "content": "TokenScope: Automatically Detecting Inconsistent Behaviors of\nCryptocurrency Tokens in Ethereum\nTing Chen\nUniversity of Electronic Science and\nTechnology of China (UESTC)\nChina\nbrokendragon@uestc.edu.cnYufei Zhang\nUESTC\nChina\n2235285714@qq.comZihao Li\nUESTC\nChina\ngforiq@qq.com\nXiapu Luo∗\nThe Hong Kong Polytechnic\nUniversity\nHong Kong\ndaniel.xiapu.luo@polyu.edu.hkTing Wang\nPennsylvania State University\nUSA\ninbox.ting@gmail.comRong Cao\nUESTC\nChina\nXiuzhuo Xiao\nUESTC\nChinaXiaosong Zhang\nUESTC\nChina\nABSTRACT\nMotivated by the success of Bitcoin, lots of cryptocurrencies have\nbeen created, the majority of which were implemented as smart\ncontracts running on Ethereum and called tokens. To regulate the\ninteraction between these tokens and users as well as third-party\ntools (e.g., wallets, exchange markets, etc.), several standards have\nbeen proposed for the implementation of token contracts. Although\nexisting tokens involve lots of money, little is known whether or\nnot their behaviors are consistent with the standards. Inconsistent\nbehaviors can lead to user confusion and financial loss, because\nusers/third-party tools interact with token contracts by invoking\nstandard interfaces and listening to standard events. In this work,\nwe take the first step to investigate such inconsistent token behav-\niors with regard to ERC-20, the most popular token standard. We\npropose a novel approach to automatically detect such inconsis-\ntency by contrasting the behaviors derived from three different\nsources, including the manipulations of core data structures record-\ning the token holders and their shares, the actions indicated by\nstandard interfaces, and the behaviors suggested by standard events.\nWe implement our approach in a new tool named TokenScope and\nuse it to inspect all transactions sent to the deployed tokens. We\ndetected 3,259,001 transactions that trigger inconsistent behaviors,\nand these behaviors resulted from 7,472 tokens. By manually exam-\nining all (2,353) open-source tokens having inconsistent behaviors,\nwe found that the precision of TokenScope is above 99.9%. Moreover,\nwe revealed 11 major reasons behind the inconsistency, e.g., flawed\n∗The corresponding author.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than ACM\nmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,\nto post on servers or to redistribute to lists, requires prior specific permission and/or a\nfee. Request permissions from permissions@acm.org.\nCCS ’19, November 11–15, 2019, London, United Kingdom\n©2019 Association for Computing Machinery.\nACM ISBN 978-1-4503-6747-9/19/11. . . $15.00\nhttps://doi.org/10.1145/3319535.3345664tokens, standard methods missing, lack of standard events, etc. In\nparticular, we discovered 50 unreported flawed tokens.\nCCS CONCEPTS\n•Security and privacy →Software security engineering ; Use\nhttps://dl.acm.org/ccs.cfm to generate actual concepts section for\nyour paper;\nKEYWORDS\nEthereum, token, ERC-20, inconsistent behavior\nACM Reference Format:\nTing Chen, Yufei Zhang, Zihao Li, Xiapu Luo, Ting Wang, Rong Cao, Xi-\nuzhuo Xiao, and Xiaosong Zhang. 2019. TokenScope : Automatically De-\ntecting Inconsistent Behaviors of Cryptocurrency Tokens in Ethereum. In\n2019 ACM SIGSAC Conference on Computer and Communications Security\n(CCS’19), November 11–15, 2019, London, United Kingdom. ACM, 18 pages.\nhttps://doi.org/10.1145/3319535.3345664\n1 INTRODUCTION\nMotivated by the success of Bitcoin, lots of cryptocurrencies have\nbeen created. Since only a few cryptocurrencies are native assets\n(e.g., Bitcoin) of blockchains, the majority of them, so-called token s,\nare implemented as smart contracts running on Ethereum [ 16],\nbecause Ethereum is the largest blockchain that supports smart\ncontracts. We will use the terms token and token contract inter-\nchangeably. These tokens usually involve lots of money. For exam-\nple, the top 10 tokens on Ethereum are worth more than 2.8 billion\nUSD [ 16]. To regulate the interactions between token contracts and\nusers as well as the third-party tools (e.g., wallets, exchange mar-\nkets, blockchain explorers), several standards have been proposed\nfor the implementation of token contracts.\nThese standards usually specify standard interfaces (i.e., methods)\nas well as their functionalities, which should be implemented by\ntoken contracts, and standard events that should be emitted by token\ncontracts to notify other applications. For example, ERC-20, the\nmost popular token standard, defines 6 standard interfaces (we do\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1503not consider the optional standard interfaces) and two standard\nevents [62].\nUsers usually employ third-party tools to manipulate tokens. For\nexample, they use wallets to transfer tokens, leverage exchange\nmarkets to purchase/sell tokens, and employ blockchain explorers\nto check transactions. These tools interact with tokens through\nthe standard interfaces and standard events defined in the token\nstandards. For example, by investigating the source code of 10\npopular third-party tools, we find that all of them recognize to-\nken behaviors by monitoring standard interfaces and/or standard\nevents. More specifically, 3 blockchain explorers (i.e., EthVM [ 8],\ntoy-block-explorer [ 7] and ETCExplorer [ 13]) and 1 wallet (i.e.,\nMetaMask [ 37]) monitor standard methods. Ethereum ETL [ 22], a\ndata collection tool, recognizes tokens by detecting standard inter-\nfaces, and captures token transfer behaviors by monitoring standard\nevents. Moreover, 1 blockchain explorer (i.e., BlockScout [ 47]), 2\nwallets (i.e, MyEtherWallet [ 38] and Etherwall [ 18]), and 2 exchange\nmarkets (i.e., EtherEx [ 15] and openANX [ 41]) monitor both stan-\ndard methods and standard events.\nHowever, if the implementation of token contracts is not consis-\ntent with the standards, third-party tools can neither interact with\ntokens properly nor even recognize tokens.\nUnfortunately, little is known whether the behaviors of the de-\nployed tokens are consistent with the standards. Inconsistent behav-\niors can lead to user confusion and financial loss. For instance,\nthe token named blockwell.ai KYC Casper Token emitted standard\nevents informing others that the tokens have been transferred. How-\never, it did not really transfer the token and thus cheat users [ 64].\nAs another example, the token named USDT made fake deposits\nby invoking standard interfaces but did not transfer the tokens.\nThe exchange markets mistakenly thought that some tokens were\ndeposited because they detect token transfers by monitoring the\ninvocation of standard interfaces [40].\nIn this work, we take the first step to investigate such inconsis-\ntent token behaviors with regard to ERC-20, the most popular token\nstandard. Although some formal verification techniques have been\nproposed for checking the properties of smart contracts [ 2,32,49], it\nis very challenging for them to conduct such automated inspection,\nbecause they require developers to manually define the correct prop-\nerties and specify all the code that is responsible for such properties\nin smart contracts. Unfortunately, since only less than 1% deployed\nsmart contracts are open-source [ 19], it is difficult for analysts to\nlocate all the code relevant to the defined properties. To the best\nof our knowledge, none of the existing studies on smart contracts\nexamines the inconsistent token contracts [ 3,20,23,36,39,57–60].\nThe closest work is from Fröwis et al. who propose two methods to\nrecognize token contracts by analyzing Ethereum virtual machine\n(EVM) bytecode [ 20]. The first method relies on the method IDs of\nstandard interfaces. However, they acknowledged that this method\nis prone to both false positives and false negatives [ 20]. For example,\na false positive will be generated if a constant in the smart contract\nis equal to the ID of a standard interface [ 20]. Moreover, a false\nnegative will be raised if a token implements standard methods in\nmultiple contracts. The second method applies symbolic execution\nand taint analysis to detect the pattern of token transfers [ 20]. If a\npattern is detected, a token contract is recognized [ 20]. More pre-\ncisely, it applies taint analysis to check whether storage operationsare determined by inputs, and uses symbolic execution to match\npath constraints with the symbolic expressions of the written val-\nues [ 20]. Unfortunately, this approach suffers from the limitations\nof symbolic execution and their pattern definition, which lead to\nfalse negatives [ 20]. Moreover, these two methods cannot detect\ntoken transfer behaviors realized by the cooperation of multiple\ncontracts [ 20]. It is worth noting that their work aims to recognize\ntokens, but our work focuses on detecting inconsistent behaviors.\nWe propose a novel approach to automatically detect the in-\nconsistent behaviors by contrasting the information from three\ndifferent sources, including the manipulations of core data struc-\ntures recording the token holders and their shares, the actions\nindicated by standard interfaces, and the behaviors suggested by\nthe standard events. If any two of them do not match, an inconsis-\ntent behavior is detected. For example, an inconsistency happens\nif the token balance of a token holder is decreased by 10 whereas\nthe standard Transfer event suggests a different amount. It is non-\ntrivial to realize this approach because of two challenges: (1) how\nto automatically identify the core data structures that store each\ntoken holder’s identifier and balance; (2) how to recognize token\ntransfers that are triggered through inter-contract invocations. For\nexample, when user1 wants to transfer tokens to user2, the token\ncontract can realize such functionality by calling one smart contract\nto decrease the balance of user1 and then invoking another smart\ncontract to increase the balance of user2. Such contract interaction\nhinders existing static analysis approaches from recognizing the\ntoken behaviors because it is difficult to know which contract will\nbe invoked without runtime information.\nTo address these challenges, our trace-based approach leverages\nthe salient feature of blockchain that the execution of all smart\ncontracts can be restored from the blockchain. First, we recover\nthe execution traces of token contracts by node instrumentation\n(§4.2) for investigating contract interactions. Second, we locate the\ncore data structure that maintains each token holder’s identifier and\nbalance, and recognize the token behaviors in terms of manipulating\nthe core data structure by exploiting how EVM accesses the data\nstructures (§4.3). Third, we collect the token behaviors indicated by\nstandard interfaces and the behaviors suggested by the standard\nevents through parsing traces, and detect inconsistent behaviors\nby contrasting the information from the three sources (§4.4).\nWe implement our approach in a new tool named TokenScope\nand use it to inspect all transactions sent to all deployed tokens.\nTokenScope detects 3,259,001 transactions that trigger inconsistent\nbehaviors, which are produced by 7,472 inconsistent tokens (§5).\nBy manually examining all open-source (2,353) tokens exposing\ninconsistent behaviors, we find only 1 false positive, and thus the\nprecision of TokenScope is above 99.9% (§5). Besides, we obtain sev-\neral interesting observations from the experimental results. For\nexample, 81% of inconsistent tokens were deployed after the final-\nization of ERC-20 standard, 1/3 of traded tokens are inconsistent\ntokens, and 17.6% of inconsistent tokens are traded in exchange\nmarkets. Moreover, we conduct a thorough investigation to reveal\n11 major reasons behind inconsistent behaviors, including flawed\ntokens, standard methods missing, lack of standard events, etc (§6).\nIn particular, we discover 50 unreported flawed tokens.\nIn summary, this work has three major contributions.\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1504•To the best of our knowledge, it is the first work on detecting\ninconsistent token behaviors with regard to token standards. Our\nnovel approach automatically detects the inconsistent behaviors by\ncontrasting the information obtained from three different sources.\n•We implement our approach in a new tool named TokenScope\nafter tackling several challenging issues.\n•Using TokenScope to inspect all transactions sent to all deployed\ntoken contracts, we found 3,259,001 inconsistent behaviors that\nresulted from 7,472 tokens and obtained many interesting obser-\nvations. By manually examining all open-source tokens exposing\ninconsistent behaviors, we discover 11 major reasons for inconsis-\ntency and find that TokenScope has a very high precision.\n2 BACKGROUND\nAccount. There are two types of accounts in Ethereum: external\nowned account (EOA) and smart contract. Only the smart contract\naccounts have executable code and they can be created by an EOA\nor another smart contract.\nSmart contract. After being developed by any high-level lan-\nguages (e.g., Solidity) and compiled into EVM bytecode, smart con-\ntracts will be deployed to the blockchain and executed by EVM\naccording to the predefined program logic [ 63]. After deployment,\na smart contract cannot be modified [ 63]. A smart contract can\nprovide methods to be invoked by others, and emit events to in-\nform other applications. When executing a smart contract, EVM\nmaintains a runtime stack, the memory which is a transient space,\nand the storage which is a permanent space for storing data [ 63].\nTo prevent abusing resources, the deployment and invocation of a\nsmart contract will charge money from transaction senders [63].\nTransaction. A transaction is a message sent by an account. To\ninvoke a smart contract, an account sends a transaction to the con-\ntract, which specifies the invoked method and carries parameters.\nThere are two types of transactions depending on the senders of\ntransactions, namely external transactions whose senders are EOAs,\nandinternal transactions whose senders are smart contracts. Note\nthat only the external transactions are stored in the blockchain.\nAlthough a smart contract can be called by another one, the first\nsmart contract in this call chain should be invoked by an EOA.\nToken A token is a smart contract which records the information\nof token holders and their shares, and supports token activities,\ne.g., query the balance of a token holder, transfer tokens to another\nholder. A token contract should implement standard interfaces and\nstandard events so that other applications can interact with it. As\nthe semantics of standard interfaces and standard events are well-\nspecified in token standards, users know which standard method\nshould be invoked to accomplish a task and can get the execution\nresult by monitoring standard events.\nToken contracts can also have non-standard interfaces and non-\nstandard events, whose semantics are not specified in token stan-\ndards. Like fiat money, a token has a total amount in circulation. To-\nken minting/burning means increasing/decreasing the total amount,\nrespectively.\nERC-20 standard. There are various token standards and the\nmost popular standard is ERC-20 [ 62] which defines 6 standard\nmethod interfaces and 2 standard events. For example, the standard\nmethod transferFrom , declared as “function transferFrom(address\n_from, address _to, uint256 _value) public returns (bool success)”,transfers _value tokens from address _from to address _to[62]. Be-\nsides, transferFrom () must fire the standard event, Transfer [62].\nThis event is declared as “event Transfer(address _from, address\n_to, uint256 _value)”, denoting that address _from transfers _value\ntokens to address _to[62]. Moreover, ERC-20 requires that the\nTransfer event should be emitted whenever tokens are transferred\n(no matter by standard methods or non-standard methods) [ 62].\nThis work focuses on 2 standard interfaces (i.e., transfer () and\ntransferFrom ()) and 1 standard event (i.e., Transfer ) because they\nare related to the change of token balances.\nNode & synchronization. The underlying structure of a blockchain\nis a P2P overlay that consists of multiple nodes. We only consider a\nfullnode because it implements all functionalities of Ethereum [ 63].\nEach Ethereum node runs an EVM, and maintains the same copy of\nblockchain by synchronization. To reach the consensus with other\nnodes, besides downloading blocks from other nodes, each node\nreplays all historical transactions to reach the same state. Hence,\nfor each transaction sent to a contract, the contract will be executed\nin the node’s EVM during its synchronization with other nodes.\n3 MOTIVATING EXAMPLES\nThis section present two inconsistent tokens, one legitimate token,\nUGToken and one malicious token as motivating examples.\nUGToken Fig. 1 shows the code of three functions in UGToken.\nAll code in this paper are in Solidity, the most popular language\nfor developing Ethereum smart contracts. UGToken uses a map-\nping variable, balances, to store the information of token holders,\nwhich maps the address of a token holder to the amount of the\nholder’s tokens. Each function leads to an inconsistent behavior.\nLine 2 checks if the token holder _from has sufficient tokens to\nsend. If not, the execution of the smart contract halts. However,\nLine 2 contains an integer overflow bug so that it can be bypassed\nif_f eeU дt+_value >2255−1, because both _feeUgt and_value\nare 256-bit unsigned integers. If integer overflow happens, the two\ntoken recipients (i.e., _toat Line 3, msg.sender at Line 5) will re-\nceive much more tokens than the amount sent by the token sender\n(i.e., _from at Line 7). Therefore, an inconsistency happens because\nthe behavior indicated by the standard events (Lines 4, 6) does\nnot reflect the real token behavior. Specifically, Lines 4 and 6 sug-\ngest that a huge number of tokens are sent by _from, however,\n_from just sends a few tokens due to integer overflow. The func-\ntion transfer () will incur an inconsistent behavior after Line 10\nexecutes, because transfer () is a standard interface suggesting that\nthe account msg.sender will send _value tokens to _to, but no token\nwill be transferred in practice. Such inconsistency is called fake\ndeposit that could cheat exchange markets [ 40]. The function allo-\ncateToken() also leads to an inconsistency since Line 12 increases\nthe balance of owner, but no Transfer event is emitted to announce\nsuch token minting behavior. Lacking of standard events can con-\nfuse third-party tools such as wallets, exchange markets, blockchain\nexplorers, because they will not be informed when token transfers.\nBy replacing Lines 2, 3, 5, 7, 10, and 12 with 2*, 3*, 5*, 7*, 10*, and\n12*, respectively, we can remove the inconsistency and the revised\ntoken contract complies with ERC-20. To fix the integer overflow,\nwe import the SafeMath library which halts execution if an integer\noverflow happens [ 42]. To fix transfer (), we throw an exception\nto halt execution if no token is transferred. Note that the effect of\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n15051  function transferProxy(address _from, address _to, \nuint256 _value, uint256 _feeUgt, ...)...{ \n2    if(balances[_from] < _feeUgt + _value) throw;  \n//2* if(balances[_from] < SafeMath.safeAdd(_feeUgt , _value)) throw;  \n  ... \n3 balances[_to] += _value;  \n//3* balances[_to] = SafeMath.safeAdd(balances[_to], _value);  \n4 Transfer(_from, _to, _value);  \n5 balances[msg.sender] += _feeUgt;  \n//5* balances[msg.sender] = SafeMath.safe Add(balances[msg.sender], _feeUgt);  \n6 Transfer(_from, msg.sender, _feeUgt);  \n7 balances[_from] -= _value + _feeUgt;  \n//7* balances[_from] = SafeMath.safe Sub(balances[_from], \nSafeMath.safeAdd(_feeUgt , _value) ); \n  ...} \n8   function transfer(address _to, uint256 _value) returns(bool success) {  \n9 if(...) \n... \n10 else {return false ;}} \n//10* else {throw;}}  \n11  function allocateTokens(...){  \n... \n12   balances[owner] += value;}  \n//12* balances[owner] = SafeMath.safeAdd (balances[owner] , value); \nTransfer(0, owner, value);}  Figure 1: An inconsistent token, the UGToken\nexecuting a smart contract will be canceled if the execution halts\nabnormally [ 63], and hence the revised functions transferProxy()\nand transfer () do not produce inconsistent behaviors. To fix allo-\ncateTokens(), we first use the SafeMath library to prevent potential\ninteger overflow, and then emit a Transfer event to announce to-\nken minting (i.e., “Transfer(0, owner, value)” meaning that owner\nreceives value tokens and nobody’s balance decreases).\nDue to page limit, we just demonstrate how TokenScope detects\nthe inconsistent behavior incurred by the integer overflow in three\nsteps. First, it locates the core data structure (i.e., balances ) that\nstores the information of token holders. Then, it monitors the mod-\nification of balances (Lines 3, 5, and 7) to learn real token behav-\niors. That is, the balance of _toincreases by _value, the balance of\nmsg.sender increases by _feeUgt, and the balance of _from decreases\nby_value+_f eeU дt−2256due to integer overflow. Moreover, it\nmonitors the standard event emissions (Lines 4 and 6) to obtain the\ntoken behaviors indicated by the event Transfer : the balance of _to\nincreases by _value, the balance of msg.sender increases by _feeUgt,\nand the balance of _from decreases by _value+_f eeU дtwhich is\nlarger than 2256. By comparing the real token behaviors with the\nbehaviors indicated by Transfer, we detect the inconsistency.\nA Malicious Token. We craft a token whose implementation (Fig.\n2) violates ERC-20, to illustrate how the token can steal tokens\nfrom token holders without being noticed. This token contract uses\na mapping variable, balances, to store the information of token\nholders (Line 2). balances maps the address of a token holder to\nthe amount of tokens possessed by the holder. Line 4 declares the\nstandard event, Transfer . Lines 7 to 13 implement the standard in-\nterface, transfer() . Both the transfer() interface and the Transfer\nevent (Line 13) indicate that the transaction sender msg.sender trans-\nfers_value tokens to _to. However, the contract steals feetokens\nfrom msg.sender and sends them to a hacker (Lines 9, 11). It also\ndefines another mapping variable, victim, to record the amount\nof tokens that have been stolen from token holders (Lines 3, 12).The standard method, balanceOf() (Line 14) is expected to return\nthe amount of tokens possessed by the queried account. However,\nit deliberately returns a fake value that is the summation of the\nreal value and the amount of stolen tokens (Line 15) to hide its\nactivity of stealing tokens. Hence, users cannot notice it by invok-\ning balanceOf() . Inconsistent behaviors happen when invoking\ntransfer() and balanceOf() , because the standard interfaces and\nthe standard event do not reflect the real token behaviors.\n1 contract simpleToken{  \n2 mapping (address => uint256) public balances;  \n3 event Transfer(address, address, uint256);  \n4 function balanceOf(address _owner) constant returns ( uint) {  \n5 return balances[_owner];  \n} \n6 function transfer(address _to, uint256 _value) returns(bool){  \n7 balances[msg.sender] -= _value;  \n8 balances[_to] += _value;  \n9 Transfer(msg.sender, _to, _value);  \n} \n} \n1 contract malToken  { \n2 mapping (address => uint256) public balances;  \n3 mapping (address => uint256) public victim ; \n4 event Transfer(address, address, uint256);  \n5 uint public fee = 1;  \n6 address hacker = 0xa49f0136194b7cb37a0ebc18fb840ce64c75091d;  \n7 function transfer( address _to, uint256 _value) returns(bool){  \n8 require (balances[msg.sender] >= _value  + fee); \n9 balances[msg.sender] -= _value  + fee; \n10  balances[_to] += _value;  \n11  balances[hacker] += fee;  \n12  victim [msg.sender] +=  fee; \n13  Transfe r(msg.sender, _to, _value);}  \n14 function balanceOf(address _owner) constant returns (uint) {  \n15 return balances[_owner]  + victim [_owner] ;}} \nFigure 2: An inconsistent token that steals tokens\nThis contract can mislead Ethereum wallets (e.g., MetaMask [ 37])\nand explorers (e.g., Etherscan [ 14]). We find that MetaMask returns\nthe fake value computed by Line 15 instead of the real token balance.\nTherefore, users cannot notice token stolen using MetaMask. By\nexamining the source code of Metamask, we observe that it invokes\nthe method balanceOf() to query token balance. We also notice\nthat Etherscan, which discloses neither its source code nor the\ntechnical details, returns the fake value of token balance. Moreover,\na user cannot detect token stolen by checking the transactions\ndisplayed in Etherscan, because Etherscan just shows the value\nthat the user expects to send. We find that Etherscan learns token\ntransfer activities by listening to the Transfer event and hence it\ncan be misled.\nOur approach detects such inconsistent behaviors in three steps,\nand thus our approach can help pinpoint such token stolen be-\nhavior. First, it locates the core data structure (i.e., balances, Line\n2) for storing the information of token holders. Then, it monitors\nthe manipulation of balances (Lines 8 to 11) to learn real token\nbehaviors. More precisely, the balance of msg.sender decreases by\n_value +fee, and the balance of _toandhacker increase by _value\nandfee, respectively. After that, by monitoring method invocations\nand event emissions, our approach obtains the token behaviors\nindicated by the method transfer() and the event Transfer . More\nprecisely, the balance of msg.sender decreases by _value +fee, and\nthe balance of _toandhacker increase by _value andfee, respec-\ntively. After that, by monitoring method invocations and event\nemissions, our approach obtains the token behaviors indicated by\nthe method transfer() and the event Transfer . That is, the balance\nofmsg.sender should be decreased by _value and the balance of\n_toshould be increased by _value. By comparing the real token\nbehaviors with the behaviors indicated by transfer() and Transfer ,\nwe detect the inconsistency.\n4TOKENSCOPE\n4.1 Overview\nInconsistency. We let Mrepresent the core data structure in a token\ncontract for recording the information of token holders. Since the\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1506token balance of a token holder denotes her asset, we focus on\nthe token behaviors that change token balances. Let Bdenote such\ntoken behaviors, which consists of a series of tuples <t_holder,\n∆value >. Each tuple means that the balance of the token holder\nt_holder changes by ∆value. We let BmandBedenote the token\nbehaviors learned from the standard interfaces and the standard\nevents, respectively, and let Brdenote the real token behaviors\nthat modify M.Bmis∅, if an external transaction invokes a non-\nstandard method, because the semantics of a non-standard method\nis unknown. Beis∅, if the execution of a token contract does not\nemit a standard event. Bris∅, if the execution of a token contract\ndoes not modify M. If an external transaction invokes a standard\nmethod, an inconsistency happens when any two of Bm,Be, and Br\ndo not match. On the other hand, if an external transaction invokes\na non-standard method, we detect an inconsistency when Be,Br\nwithout considering Bmdue to its unknown semantics.\nInconsistent token. Once an inconsistent behavior is detected, we\nfirst locate the smart contracts recorded in the trace. Note that each\ntrace records the execution of all smart contracts triggered by one\nexternal transaction (§4.2). For each of such contracts, if it invoked\nthe standard methods or emitted the standard events or modified M\nor stored M, we regard it as an inconsistent token. Such definition\nincludes both the case of individual inconsistent contracts and the\ncase where several contracts interact to realize the token behaviors.\nStage 1\ntrace recording\nmapping \nrecognition\nMrecognition\ntoken behavior \nrecognition\ncomparisonStage 2\nStage 3Mtrace\nblockchain\ninconsistent\ntokenmapping\nevent \nparsing\nmethod \nparsing\nBe BmBm Be\nBrBm Be Br\nFigure 3: Architecture of TokenScope\nWorkflow. TokenScope consists of three stages (Fig. 3). It takes\nin the data from Ethereum, and outputs Bm,Be,Brfor inconsis-\ntent token behaviors and the corresponding tokens. The first stage\nrecovers the execution traces of all deployed smart contracts by\ninstrumenting a full node. The second stage takes in the traces\nto recognize Bm,Beby monitoring the invocations of standard\nmethods and the emission of standard events, respectively, and\nthen identifies Mfrom the traces. This stage outputs M,Bm, and\nBeas the input of the next stage. For each trace, the last stage\nrecognizes Brby monitoring the modification of M, and compares\nBm,BeandBrto detect inconsistency. Note that the current imple-\nmentation of TokenScope focuses on the change of token balances.\nThat is, TokenScope detects the modification of Mand monitors the\nemission of Transfer as well as the invocations of transfer() and\ntransferFrom() . We will extend TokenScope to recognize other to-\nken behaviors (e.g., set the allowable amount of tokens that can be\nwithdrawn by another account) in future work.\n4.2 Stage 1: Trace Recording\nAtrace contains the execution log of smart contracts. An external\ntransaction can trigger the execution of a smart contract, which\nmay send several internal transactions to invoke other smart con-\ntracts. By recording the trace for each external transaction sent toa contract, we can get its execution log and that of internal transac-\ntions (as well as how a contract invokes others) if any. Each trace\nincludes four parts, namely the hash of the corresponding external\ntransaction, the address of the transaction receiver (i.e., the invoked\nsmart contract), the data carried by the transaction which specifies\nthe invoked method and parameters, and the executed EVM opera-\ntions of all invoked smart contract in order. TokenScope instruments\nan Ethereum node to record traces since each node will download\nall blocks and replay all transactions during synchronization [63].\nAn approach to obtain traces is invoking the API, debug.traceTr-\nansaction() provided by an Ethereum full node, which takes in the\nhash of a transaction and outputs the trace triggered by that trans-\naction [ 11]. However, there is no easy way to obtain all transaction\nhashes. Moreover, the API runs slowly because before executing\nthe queried transaction it has to initialize the runtime environ-\nment, construct the correct state before the execution of the block\ncontaining the queried transaction, and then replay the preced-\ning transactions before the queried transaction in the same block.\nBesides, APIs use Remote Procedure Calls to communicate with\nan Ethereum node, which introduces further delay. We compare\nthe time required to collect traces between TokenScope with de-\nbug.traceTransaction(). The result is shown in Fig. 4. The x-axis\nmeans that we synchronize 200,000 blocks from the genesis block in\nthe experiment. The cross in black color is the number of collected\ntraces. Therefore, there are 8,674 traces collected from the first\n200,000 blocks. The triangle in red color is the time consumption\nby invoking debug.traceTransaction(), and the point in blue color\nis the time consumption of TokenScope . We find that the difference\nbetween the time consumptions becomes larger when more blocks\nare downloaded. In particular, the API debug.traceTransaction()\nneeds 8.7x time than TokenScope to collect the first 8,674 traces.\n02468101214161820\nblock×1040.01.53.04.56.0time(s)×103\n476.14,126.6\n0246810\n# of traces×103\n8,674TokenScope\nAPI\nTraces\nFigure 4: Time consumption to collect traces\nInstead of using debug.traceTransaction(), TokenScope instru-\nments an Ethereum node to record traces since each node will\ndownload all blocks and replay all transactions during synchro-\nnization [ 63]. To record the first three parts of a trace, we process\nexternal transactions and internal transactions in different ways.\nMore precisely, to process an external transaction which starts the\nexecution of a smart contract, we insert recording code into the\nfunction ApplyTransaction(), which is responsible for executing\nexternal transactions. Since each Ethereum node provides a han-\ndler for interpreting each EVM operation, to process an internal\ntransaction that invokes a smart contract, we insert recording code\ninto the handlers of CALL, CALLCODE, DELEGATECALL, and STATICCALL\nbecause these four operations generate internal transactions for\ninvoking other smart contracts [ 63]. To record the last part (i.e.,\nall executed EVM operations) of a trace, we insert logging code\ninto the interpretation handler of each EVM operation to record\nthe operation, values read by the operation, original values and\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1507new values of the variables written by the operation. Taking the\naddition operation ADD[63] as an example, we record the operation,\ntwo addends, and the addition result.\nTo record contract interaction, we need to identify the address,\nthe start and the end of each executed smart contract in the trace.\nWe achieve this goal by maintaining a call stack. Specifically, when\none of the handlers of CALL, CALLCODE, DELEGATECALL and STATICCALL\nis invoked, we obtain the address of the executed smart contract,\nwhich is the second item of the EVM stack, and then push the\naddress on the call stack. When the handler returns, TokenScope\npops the top item of the call stack. Therefore, we know the smart\ncontract to which an executed EVM operation belongs by checking\nthe top item of the call stack.\n4.3 Stage 2: Locating Core Data Structure\nBasic idea. The process of locating the core data structure for\nrecording token information is presented in Algorithm 1. This stage\ntakes in a trace, and outputs the core data structure M, token be-\nhaviors (i.e., Bm,Be) suggested by standard methods and standard\nevents, respectively. Mapping is a data structure that maps keys to\nvalues. It is a natural choice for storing the information of token\nholders, where the key is the identifier of a token holder and the\nvalue records the amount of tokens possessed by the token holder.\nThis stage consists of 4 steps. First, TokenScope locates all map-\nping variables in a contract, MAP ( Step 1 ). Then, it recognizes the\ntoken behaviors learned from standard methods( Bm) (Step 2 ) and\nstandard events ( Be) (Step 3 ) through trace analysis. Since a con-\ntract may use mapping variables to store other information, we\nexclude irrelevant mapping variables by correlating MAP with Bm\nandBe. More precisely, we regard a mapping variable as Mif two\nmapping items, whose keys are the two token holders specified by\nthe standard methods or the standard events, are modified ( Step\n4), because standard methods and standard events reflect token\ntransfer behaviors.\nAlgorithm 1:  M recognition  \nInputs:  trace, t. \nOutput: Core data  structure for maintaining token information, M;  \nToken behaviors suggested by standard methods, B m; \nToken behaviors suggested by standard events, B e. \nMAP = LocMap(t)  //step1  \nBm = ParseStandardMethods(t)  //step2  \nBe = ParseStandardEvents(t)   //step3  \nM = RecognizeM(MAP, B m, Be) //step4  \nreturn  (M, B m, Be) \nAlgorithm 2: Inconsistency Detection  \nInputs:  trace, t; \nCore datastructure for maintaining token information, M;  \nToken behaviors suggested by standard methods, B m; \nToken behaviors suggested by standard events, B e. \nOutput: Whether an inconsistency happens, bin.  \nBr = TokenBehavior(t, M)    //step1  \nif Bm == null: bin = Match(B e, Br) \n  else bin = Match(B m, Be, Br) \nreturn  bin //step2  \nStep 1: Locating Mapping variables . Without source code, locat-\ning mapping variables is challenging because there is no explicit\nmapping structure in EVM bytecode. To tackle the challenge, we\nexploit how a mapping variable is stored in EVM bytecode and\nhow a mapping variable is manipulated by EVM operations. Note\nthat all mapping variables are stored in the storage [ 63], and every\nvariable stored in the storage has a unique 32-byte identity [ 23].\nThe EVM operations SLOAD and SSTORE are used to read and write\ndata in the storage, respectively [ 63]. To access a mapping item\nwhich is a <key, value >pair, a SHA3 operation takes in the identity\nand the key to compute the location of the value. When executing a\nSHA3 operation, the identity is stored in a place specified by a stack\nitem, and the key is stored before the identity.We identify 4 types of mapping variables after manually in-\nspecting all 16,248 open-source tokens that have been deployed on\nEthereum and emitted the Transfer events. Although these 4 types\nmight not cover all deployed tokens, how to automatically identify\nall types of mapping variables from the bytecode of smart contracts\ndeserves another paper. We discuss a possible approach in §8 and\nwill work on it in future work. In the following, we describe the 4\ntypes of mapping variables and their accessing patterns.\nType-I. <key: addr, value: amount >This type of mapping associates\nthe address of an account to the amount of her tokens. Fig. 5 shows\nhow to read the amount from such a mapping variable with the\nsource code (i.e., “amount = balances[addr];”) and the corresponding\nEVM operations. The location of the value (amount ) is the result\nof a SHA3 operation on the identity of balances and the key (addr ).\nAfter that, the amount is read from the storage by a SLOAD.\nlocation\nSHA3\n SLOAD amount addr identityamount = balances[ addr ];\nFigure 5: Read amount from <key: addr, value: amount >\nType-II. <key: addr, value: struct >This type of mapping associates\nthe address of an account to a struct that records the amount of\ntokens possessed by the account. Fig. 6 illustrates how to read the\namount from such a mapping with the source code (i.e., “amount\n= balances[addr].amount;”) as well as the corresponding EVM op-\nerations. The location of the value (struct ) is the result of a SHA3\noperation on the identity of balances and the key (addr ). We dis-\ncover that the struct is stored contiguously in the storage. Hence,\nanADDoperation is used to compute the location of amount, which\nis equal to the location of struct plus an offset. Finally, the amount\nis read by a SLOAD. If the amount is the first item of a struct, the\nADD operation is not needed because the offset is 0 and the data\nstructure becomes the same as Type-I shown in Fig. 5.\nSHA3\nSLOAD amountoffset\nADDlocationamount = balance[ addr ].amount;\naddr identity\nFigure 6: Read amount from <key: addr, value: struct >\nType-III. <key: addr, value: struct []>. This type of mapping asso-\nciates an array of struct to a token holder for recording all historical\nbalances and the last item records her current token balance. We\nname such data structures as checkpoints and each item of check-\npoints (i.e., a struct ) as a Checkpoint. The array checkpoints is a\nglobal variable that has an identity and is stored in the storage [ 63].\nBy inspecting how EVM stores an array, we reveal that the identity\nrefers to a storage location that stores the length of the array. Array\nitems are stored contiguously, and the location of the first array\nitem is the result of a SHA3 operation on the array’s identity.\nFig. 7 presents the EVM operations of the source code “amount =\nbalances[addr][balances[addr].length-1].amount;” for reading the\ncurrent token balance. To ease the presentation, we use subscripts\nto differentiate multiple operations with the same opcode. The\nidentity of the array checkpoints is the result of a SHA3 1operation on\nthe identity of balances and the address of a token holder. Since the\narray identity suggests the location that stores the array length, we\nget the length of checkpoints by a SLOAD 1. Since the array items are\nstored contiguously, the item offset of the latest struct Checkpoint\nfrom the first one is (length-1) ×sizeof(Checkpoint). The size of\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1508Checkpoint is a constant pre-computed during compilation of smart\ncontracts. By adding the item offset to the location of the first struct\nwhich is the SHA3 2result of the array identity, we get the location\nof the latest struct. By adding the offset, we pinpoint the location of\nthe token balance, which is read by a SLOAD 2.\nOur approach can also handle three special cases. First, to access\nthe first struct ofcheckpoints, SLOAD 1,SUBand MUL are not needed\nbecause the item offset is 0. Second, when the balance of a token\nholder is modified, a new struct recording the latest token balance\nwill be added to the array. In this case, the SUBis not needed because\ntheitem offset of the new struct is length×sizeof(Checkpoint).\nThird, if the amount is the first item of the struct, the ADD 2is not\nneeded because the offset is 0.\namount = balances[ addr ][balances[ addr ].length -1].amount;\nSHA31\nSLOAD1 length addr identity\nSHA32size 1\nSUB\n MUL item offset\nADD1\n ADD2\noffset\nSLOAD2amountloc of 1st item struct_locid_array\nid_array\nFigure 7: Read amount from <key: addr, value: struct []>\nType-IV. Two maps. A smart contract can manage multiple kinds of\ntokens simultaneously, and one kind of token is associated with a\nstruct, which is named as Asset. Such contract usually uses a map-\nping variable to associate the address of a token holder with an\nindex, and we call this map variable as holderIndex. Asset contains a\nmapping variable that associates an index with a struct that records\nthe token balance. We call the mapping variable as wallets and the\nstruct asWallet. Fig. 8 demonstrates how to access the balance with\nthe source code “amount = Asset.wallets[holderIndex[addr]].amount;”.\nThe location of the index is the result of a SHA3 1operation on the\nidentity of holderIndex (identity 1) and the address of a token holder.\nThen, the index is read by a SLOAD 1. Similarly, the location of a\nWallet is the result of a SHA3 2operation on the identity of wallets\n(identity 2) and the index read from previous operations. The loca-\ntion of the amount is computed by adding an offset to the location\nofWallet. Finally, the amount is read by a SLOAD 2. Our approach\nalso handles a special case that the amount is the first item of the\nstruct. In this case, the ADDis not needed because the offset is 0.\nSHA31\n SLOAD1indexlocationamount = Asset.wallets [holderIndex [addr ]].amount;\naddr identity1\nSHA32\nSLOAD2amount\noffset\nADDlocationindex identity2use\nFigure 8: Read amount from two maps\nFinding the identities of mappings. To locate a mapping variable, we\nneed its identity. We locate it by conducting the def-use analysis [ 51]\nand leveraging the accessing pattern of mapping variables instead\nof searching the trace for SHA3 operations, because SHA3 can be used\nin other scenarios. We present the algorithm for finding mapping\nidentities in more detail.\nAlgorithm 2 locates the 4 types of mapping variables from EVM\nbytecode, which takes in a trace and outputs the identities of map-\nping variables operated in the trace. We use the accessing pattern\nAlgorithm  2 : Map ping variables recognition\nInputs:  trace, t.  \nOutput: Identit ies of mapping variable s and their types , ids. \n1   for each  op in t:  \n2    switch  op: \n3 case SHA3:  \n4 dep = isPara(t, op, res_manipulate)  \n5 if dep == true:  \n6 res_sha3_2 = getRes(t, op)  \n7 ids.remove (id); \n8 id = getId(t, op)  //the identity of wallets ( Type-IV) \n9 break  \n10 dep = isPara(t, op, res_sha3)  \n11 if dep == true:  res_sha3_3 = getRes(t, op) ; \n12    else:  \n13 reset();  \n14 res_sha3 = getRes(t, op) ;  \n15   id = getId(t, op) //the identity of the other 3 types  \n16 case SLOAD | SSTORE:  \n17 dep = isPara(t, op, res_add_2)  \n18 if dep == true:  ids.append (id, 4); // Type-IV \n19 dep = isPara(t, op, res_ sha3 _2) \n20 if dep == true: ids.append (id, 4); // Type-IV   \n21 dep = isPara(t, op, res_add_4)  \n22 if dep == false: ids.changeType (id, 3); // Type-III   \n23 dep = isPara(t, op, res_add_ 3)  \n24 if dep == true:  ids.changeType (id, 3); // Type-III  \n25 dep = isPara(t, op, res_add)  \n26 if dep == true:  ids.append(id , 2); // Type-II  \n27 dep = isPara(t, op, res_sha3)  \n28 if dep == true:  ids.append(id , 1); // Type-I, can be removed    \n29 res_manipulate = getRes(t, op)   \n30 case ADD: \n31 dep = isPara(t, op, res_add_3)  \n32 if dep == true:  \n33 res_add_4 = getRes(t, op)  \n34   break  \n35 dep = isPara(t, op, res_sha3_3)  \n36 if dep == true:  \n37 dep = isPara(t, op, res_mul)  \n38 if dep == true: res_add_3 = getRes(t, op)  //not first array item  \n39 else: res_add_4 = getRes(t, op)  //first array item  \n40 break  \n41   dep = isPara(t, op, res_sha3_2)  \n42 if dep == true:  \n43 res_add_2 = getRes(t, op)  \n44    break  \n45 dep = isPara(t, op, res_sha3)  \n46   if dep == true:  res_add = getRes(t, op)  \n47 case SUB: \n48 dep = isPara(t, op, res_manipulate)  \n49 if dep == true: res_sub = getRes(t, op) ; \n50 case MUL : \n51 dep = isPara(t, op, res_sub)  \n52 if dep == true:  res_mul = getRes(t, op)  //do not add one item  \n53 else:  \n54 dep = isPara(t, op, res_manipulate)  \n55   if dep == true: res_mul = getRes(t, op) ; //add one  array item  \n56  return  ids \ngetRest(t, op): get the result of op. \nisPara( t, op, res): whether a parameter of op is res. If res is null, this function returns false.  \ngetId(t, op): get identity from a SHA3 operation . \nreset(): delete all temporary variables (e.g., dep).  of Type-III shown in Fig. 7, which involves the most number of\nEVM operations compared to the other patterns, to explain the algo-\nrithm. For each EVM operation opin the trace t, if the operation is\nSHA3, Line 4 executes. The function isPara(t, op, res) applies def-use\nanalysis to check whether resis a parameter of opin the trace t. If\nresis null, isPara() returns false. Hence, we skip Lines 5 – 11, since\nres_manipulate andres_sha3 are null. The function reset() deletes\nall temporary variables (e.g., dep). If a mapping variable is found,\nwe start to detect another mapping variable after executing reset()\n(Line 13). The result of SHA3, denoted by res_sha3, is obtained by\nthe function getRes() (Line 14). A possible identity of a mapping\nvariable, denoted by id, is obtained by the function getId() (Line\n15). Whether idis a real identity will be checked in the following\nsteps. Note that getRes() and getId() just parse the trace, because\nthe parameters and results of all execution EVM operations have\nalready been recorded in the trace.\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1509When a SLOAD is executed (Line 16), the algorithm conducts\nseveral checks. We skip Lines 17 – 26 since res_add_2, res_sha3_2,\nres_add_4, res_add_3, and res_add are null. Since res_sha3 is a pa-\nrameter of the SLOAD, the check at Line 27 returns true. Then, id\nand the Type-I is added into the list ids(Line 28), indicating that\nwe have found a mapping variable of Type-I. The result of SLOAD,\nres_manipulate is obtained at Line 29. When a SUBis executed\n(Line 47), our algorithm checks whether one of its parameters is\nres_manipulate (Line 48). If so, we get the result of the SUB, res_sub\nat Line 49. When a MULis executed (Line 50), our algorithm checks\nwhether res_sub is one of its parameters (Line 51). If so, the result\nof the MUL, res_mul, is obtained at Line 52. res_mul is actually the\noffset from the first item of the array.\nWhen a SHA3 is executed (Line 3), the algorithm checks whether\none of its parameters is the result of another SHA3 (Line 10). If so, the\nresult of the SHA3, res_sha3_3 (Line 11) should be the location of the\nfirst item of the array. When an ADDis executed (Line 30), several\nchecks are conducted. We skip Lines 31 – 34, since res_add_3 is\nnull. Then, the algorithm checks whether the two parameters of\ntheADDareres_sha3_3 andres_mul (Lines 35 – 37). If so, the result\nof the ADD, res_add_3 is the location of the array item that should\nbe read (Line 38). Then, an ADDis executed again. Our algorithm\nchecks whether res_add_3 is one of its parameters (Line 31). If so,\nthe result of the ADD, res_add_4, is the location of token balance\n(Line 33). Finally, a SLOAD is executed to read the token balance. The\nalgorithm checks whether res_add_4 is one of the parameters of\ntheSLOAD (Line 21). If so, the accessing pattern of Type-III is found,\nand we change the type of idfrom 1 to 3 (Line 22). The reason for\nchanging the type is that the pattern of Type-I is a sub-pattern of\nType-III. Hence, the algorithm first identifies the pattern of Type-I\ninside the pattern of Type-III.\nStep 2: Parsing standard methods. We analyze transfer() and\ntransferFrom() , which are used to transfer tokens, according to\ntheir semantics defined in ERC-20 [ 62]. Other token standards\nare discussed in §8. We detail how to monitor the invocation of\ntransfer() and omit the processing of transferFrom() as it is sim-\nilar. transfer() is defined as “function transfer(address _to, uint\n_value) public returns (bool success);”, which allows the transaction\nsender to transfer _value tokens to the token holder _to[62]. There-\nfore, Bmhas two tuples, <sender, -_value >and <_to,_value >. Since\nboth external and internal transactions can invoke smart contracts,\nwe handle them separately.\nTo handle external transactions, we insert recording code to\nthe function TransitionDb(), which calls vmenv.Call() to execute a\nsmart contract. Then, we obtain the transaction sender from the\nfirst parameter of vmenv.Call(), and get _toand _value that are\nplaced together in the third parameter. To handle internal transac-\ntions, we instrument the interpretation handlers of CALL, CALLCODE,\nDELEGATECALL and STATICCALL. We only describe the instrumenta-\ntion of opCall(), the interpretation handler for CALL, because other\nhandlers are instrumented in a similar way. Since opCall() invokes\nenv.Call() to execute a smart contract, we obtain the transaction\nsender from the first parameter of env.Call(), and acquire _toand\n_value from the third parameter.\nStep 3: Parsing standard events. TokenScope interprets the Transfer\nevent according to its semantics defined in ERC-20. First, we look\nfor all logging operations (i.e., LOG0, LOG1, LOG2, LOG3, LOG4) fromthe trace since logging operations are responsible for emitting\nevents [ 63]. For each logging operation, we get the third 32-byte\nvalue read by the operation because it is the event ID. Since each\nevent has a unique ID that is the hash of the event signature [ 63],\nwe locate the Transfer event according to its ID. After recognizing\naTransfer event, we record Bewhich includes two tuples <_from,\n-_value >and <_to,_value >._from, _toand_value are the 4th – 6th\nvalues read by the logging operation, respectively.\nStep 4: Recognizing the core data structure M.Since a token\ncontract may have multiple mapping variables, we need to dis-\ntinguish M, which stores the information of token holders, from\nirrelevant mapping variables. Our idea is to correlate the modifi-\ncation of a mapping variable with the standard interfaces and the\nTransfer event. More precisely, if there exists a trace where the\nmodification of a mapping variable is accordant with the standard\ninterfaces or the Transfer event, we regard the mapping variable\nasM. We detail how to correlate with the Transfer event as follows,\nand omit the correlation with the standard interfaces because they\nhave a similar process. Since the Transfer event records two ad-\ndresses (i.e., the sender and the receiver of tokens), we look for a\nmapping variable whose two items corresponding to the two ad-\ndresses are modified. If found, the mapping variable is M. We use the\ntoken contract in Fig. 2 to illustrate how TokenScope distinguishes M\n(balances ) from the irrelevant mapping variable (victim ). From the\nTransfer event (Line 13), we get two addresses, msg.sender and_to.\nThere are two mapping variables, balances (Line 2) and victim (Line\n3). For balances, the two mapping values whose keys are msg.sender\nand_to, respectively, are updated (Lines 9, 10) when the method\ntransfer() is executed. Therefore, we regard balances asM. In con-\ntrast, for victim, since only one mapping value corresponding to\nthe key msg.sender is updated (Line 12), victim is not M.\nAlgorithm 1:  M recognition  \nInputs:  trace, t. \nOutput: Core data  structure for maintaining token information, M;\nToken behaviors suggested by standard methods, B m; \nToken behaviors suggested by standard events, B e.\nMAP = LocMap(t) //step1  \nBm= ParseStandardMethods(t) //step2  \nBe= ParseStandardEvents(t) //step3  \nM = RecognizeM(MAP, B m, Be) //step4  \nreturn (M, B m, Be) \nAlgorithm 3: Inconsistency Detection \nInputs:  trace, t; \nCore datastructure for maintaining token information, M;  \nToken behaviors suggested by standard methods, B m; \nToken behaviors suggested by standard events, B e. \nOutput: Whether an inconsistency happens, bin.  \nBr = TokenBehavior(t, M)    //step1  \nif Bm == null: bin = Match(B e, Br) \n  else bin = Match(B m, Be, Br) \nreturn  bin //step2  \n4.4 Stage 3: Detecting Inconsistent Behaviors\nAs shown in Algorithm 3, taking in a trace and the outputs of\nstage 2, this stage detects inconsistency through two steps, namely\nrecognizing real token behaviors Brby monitoring the modification\nofM(Step1) and comparing Bm,Be, and Br(Step 2).\nStep1: Token behavior recognition. Bris a set of tuples, <t_holder,\n∆value >for every trace. This step is similar to the first step in\nstage 2, because we locate mapping variables by exploiting their ac-\ncessing patterns. For the ease of presentation, we describe this step\nby using the example in Fig. 2. After the execution of transfer() ,\nTokenScope records three tuples, <msg.sender, -(_value +fee)>,<to,\n_value >, and <hacker, fee>. To detect the balance change of a token\nholder, we first look for a SHA3 operation, which reads the identity\nofMand the address of a token holder (i.e., the key), from each trace.\nThen, we check if the result of the SHA3 is read by a SSTORE through\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1510the def-use analysis [ 51]. If so, we get the tuple <balold,balnew>,\nwhere baloldandbalneware the original value and the new value\nwritten by the SSTORE, respectively. Since the balance of an ac-\ncount can be modified several times in a trace, we may find several\nsuch SHA3, and thus get ntuples, <balold\ni,balnew\ni>,1≤i≤n.\n∆value =balnewn−balold\n1, because the trace records the modifica-\ntions of an account balance in order.\nStep2: Comparison. We consider two cases. First, if Bm,∅indi-\ncating that an external transaction invokes a standard method, we\ncompare Bm,Be, and Br. We find an inconsistency if any two of\nthem do not match. Second, if Bm=∅indicating that an external\ntransaction invokes a non-standard method, we only compare Be\nandBrbecause the semantics of the non-standard method are un-\nknown, and we find an inconsistency if Be,Br. Reconsider the\nexample in Fig. 2, assuming that an external transaction invokes the\nstandard method transfer() ,BmandBeare the same, which are\n<msg.sender, -_value >and <_to,_value >. However, Bris different\nfrom them, which are <msg.sender, -(_value +fee)>,<_to,_value >,\nand <hacker, fee>. Therefore, TokenScope detects the inconsistent\nbehavior and the token is considered as an inconsistent token.\nSpecial addresses handling. The Transfer event uses special ad-\ndresses to indicate special token behaviors. There are three special\naddresses, including 0, the address of the token contract, and the\naddress of the account who creates the token contract (i.e., token\ncreator). Consider a Transfer event “event Transfer(address _from,\naddress _to, uint256 _value)”, a token contract often sets _from to\none of the special addresses to indicate token minting [ 12]. Simi-\nlarly, a token contract often sets _toto one of the special addresses\nto indicate token burning [ 12]. In both cases, Mwill not be modified\nif the balances possessed by the special addresses are not recorded\ninM. To avoid false positives in detecting inconsistent behaviors,\nafter finding a mismatch between BeandBr, we check whether it is\nbecause Brdoes not contain the balance change of special addresses.\nIf so, we do not consider such mismatch as inconsistency.\n5 EXPERIMENTS\n5.1 Results\nTo evaluate TokenScope , we download all 6,066,793 blocks from the\nlaunching of Ethereum (Jul. 30, 2015) to Aug. 1, 2018. We obtain all\n7,123,729 deployed smart contracts as well as all 282,342,715 external\ntransactions, and record 119,245,201 traces for all transactions sent\nto smart contracts.\nTable 1 lists the numbers (before ‘/’) of tokens, inconsistent to-\nkens adopting different Mtypes, and transactions triggering incon-\nsistent behaviors. The figures after ‘/’ denote the numbers of open-\nsource tokens, open-source inconsistent tokens and the numbers\nof transactions triggering inconsistent behaviors of open-source\ninconsistent tokens. TokenScope detects 57,411 tokens, where 7,472\n(13%) tokens are inconsistent and their inconsistent behaviors are\ntriggered by 3,259,001 transactions. We find that 2,353 inconsistent\ntokens open their source code in Etherscan. Most tokens adopt M\nof Type-I, and 500+ tokens choose the other types. We find that\n3,334 tokens present inconsistency when executing standard meth-\nods while 4,700 tokens show inconsistency when executing non-\nstandard methods. Moreover, 562 tokens present inconsistency in\nboth standard methods and non-standard methods.Table 1: Tokens with different types of M\nReason  Token name  Token address  \n1 Bodhi Ethereum  0x47c171cE16c1C06AaE6E785Ba3c518C42235da0F  \nWubCoin  0x2664877980f2684c9e9be07a50330e85847c5241  \nTablow Club  0xeab447c1e2b5a76b57f15e55eab504801aa6ceb0  \nEIB 0x314d759476c5a3a02c0c6b1f1e213949084e277b  \nAnythingApp T oken  0x36f74e50de0b79f9b0bbeb644af9d40e3cc26433  \neDogeCoin  0x44cba3a62a15ac8f66ff75bf7abd058dcca7d7ed  \nCoinvest COIN Token  0x4306ce4a5d8b21ee158cb8396a4f6866f14d6ac8  \nEthereum Lendo Token  0x45d0bdfDFBfD62E14b64b0Ea67dC6eaC75f95D4d  \n2 MiniApps  0x0f587d0b 7b1c1ef68b432936b75c4d6c4d12b647  \n1. Another standard event of ERC -233 standard 2. Hardcoded key of M in optimized bytecode\nToken name  Token address  \nBodhi Ethereum  0x47c171cE16c1C06AaE6E785Ba3c518C42235da0F  \nWubCoin  0x2664877980f2684c9e9be07a50330e85847c5241  \nTablow Club  0xeab447c1e2b5a76b57f15e55eab504801aa6ceb0  \nEIB 0x314d759476c5a3a02c0c6b1f1e213949084e277b  \nAnythingApp T oken  0x36f74e50de0b79f9b0bbeb644af9d40e3cc26433  \neDogeCoin  0x44cba3a62a15ac8f66ff75bf7abd058dcca7d7ed  \nCoinvest COIN Token  0x4306ce4a5d8b21ee158cb8396a4f6866f14d6ac8  \nEthereum Lendo Token  0x45d0bdfDFBfD62E14b64b0Ea67dC6eaC75f95D4d  \nTest Toke n 0xfa74f89a6d4a918167c51132614bbbe193ee8c22  \nAuctus Toke n 0xfd89de68b246eb3e21b06e9b65450ac28d222488  \nType  # of tokens  # of inconsistent tokens  # of transactions  \nI 56,864/16,248  7,329/2,329  3,199,583/2,069,581 \nII 58/30  21/16  13,085/12,550 \nIII 227/92  60/3 38,712/872 \nIV 262/92  62/5 7,621/465 \nsum 57,411/16,462  7,472/2,353  3,259,001/2,083,468 \nDeployment time. Fig. 9 shows the deployment time of incon-\nsistent tokens, where each cross ( x,y) indicates that there are y\ninconsistent tokens deployed in the period of xweeks after the\ndeployment of the first inconsistent token. We find that the first\ninconsistent token was deployed on Nov. 26, 2015, nearly 3 months\nafter the debut of Ethereum. ERC-20 was proposed on Nov. 19, 2015\nand formally adopted on Sep. 11, 2017 after several revisions [ 54].\nWe observe that 81% ( (7,472−1,420)/7,472) of inconsistent to-\nkens were deployed after the finalization of ERC-20. Moreover, the\nnumber of inconsistent tokens increases steadily over time.\nRemark1: there are still many inconsistent tokens after finaliz-\ning ERC-20. The gap between the description of ERC-20 and the\nunderstanding of token developers may be one root cause.\n0 20 40 60 80 100 120 140\nweek02468# of inconsis tokens×103\nNov 26, 2015Sep 11, 2017\n1,420Aug 1, 2018\nFigure 9: Deployment time of inconsistent tokens\nExchange markets. Table 2 lists the numbers of tokens traded in\n5 centralized exchange markets and 4 decentralized exchange mar-\nkets. The 2nd row shows market names and the 3rd row displays\nthe number of tokens traded in each market. The 4th row aggre-\ngates the results of centralized markets and decentralized markets,\nseparately, and the last row lists the aggregated result from these\n9 markets. The numbers before and after ‘/’ denote the number\nof tokens and the number of inconsistent tokens, respectively. We\nobtain the number of tokens traded in each centralized market by\nvisiting its website because centralized markets usually maintain a\nlist of traded tokens. We then get the number of inconsistent tokens\ntraded in each centralized market by searching its website for the\nnames and addresses of inconsistent tokens.\nWe adopt a different way to get the numbers for decentralized\nexchange markets (DEXs) because DEXs do not maintain the list of\ntraded tokens. More precisely, we crawl the webpages of the decen-\ntralized exchange order tracker [ 17] that presents all transactions\nof DEXs, and then parse the collected transactions to get the ad-\ndresses of all tokens traded in each decentralized exchange market.\nAfter that, we get the number of inconsistent tokens traded in each\ndecentralized exchange market by matching the addresses of all\ntraded tokens with the addresses of all inconsistent tokens. Results\nshow that 1/3 (1 ,314/3,947) of traded tokens are inconsistent and\n17.6% (1 ,314/7,472) of inconsistent tokens are traded in exchange\nmarkets. Note that all 348 tokens traded in centralized markets are\nalso traded in decentralized markets.\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1511Remark2: inconsistent tokens can incur severe financial conse-\nquences because many inconsistent tokens are traded in markets.\nTable 2: Number of tokens traded in exchange markets\nCentralized exchange market  Decentralized exchange market  \nBinance  Bitfinex  Poloniex  Kucoin  Huobi  IDEX EtherDelta  Token Store  Kyber Network  \n177/19  99/16  19/10  172/9  25/3 1,349/499  3,848/1,248  219/91  52/20  \n∪ 348/24  3,947/1,314  \n∪ 3,947/1,314  \n0 1 2 3 4 5 6\n# of standard methods100101102103104105# of tokens (log-scaled)683\n689052,163\n687 82452,081inconsistency\nopen-source inconsistency\nall\nopen-source all\nFigure 10: Number of standard methods realized in tokens\n5.2 Token Transfers via Multiple Contracts\nWe classify tokens, open-source tokens, inconsistent tokens and\nopen-source inconsistent tokens according to the number of stan-\ndard methods implemented by them, and present the results in Fig.\n10. ERC-20 requires to implement all six standard interfaces [ 62],\nbut this figure shows that about 9.3% (5 ,330=683+68+905+\n2,163+687+824) tokens implement fewer standard methods.\nIt is interesting that 1.2% (683) tokens implement 0 standard\nmethods. By investigating their source code (if any), bytecode and\ntraces, we find that all of them transfer tokens via multiple con-\ntracts. For example, some developers deploy a token contract that\nimplements standard token interfaces as a library (termed by lib).\nThen, other developers write a token contract (termed by tc) with\ncustomized functionality that loads liband invokes the standard\ninterfaces implemented by libto transfer tokens. TokenScope can rec-\nognize such tokens that transfer tokens through multiple contracts,\nbecause it handles contract interaction by trace analysis. Moreover,\n88% (601) of the tokens with 0 standard methods are inconsistent\ntokens. A possible reason is that it is more difficult to develop the\ntokens consisting of multiple contracts. Fig. 11 lists two inconsis-\ntent tokens detected by TokenScope where the contract (0x38cD)\nloads another contract (0x2a21) as a library. 0x2a21 implements all 6\nstandard interfaces while 0x38cD stores Mand executes the code in\n0x2a21 to manipulate M.TokenScope detects an inconsistency since\n0x2a21 does not emit the Transfer event after transferring tokens.\nTokenScope considers both contracts as inconsistent tokens because\nthe former stores Mwhile the latter modifies M.\nBesides loading library, token transfer can also be completed by\ninter-contract invocations. As an example, Fig. 12 presents 4 incon-\nsistent tokens (in gray boxes) from a trace recording the execution\nof 5 smart contracts. In particular, an EOA Ainvokes the method\nwithdrawToken() of the contract Etherdelta_2, then withdrawTo-\nken() invokes the method transfer() of the contract FunFair_Old.\nThis method emits the Transfer event. Besides, this method in-\nvokes the method transfer() of the contract Controller, in which\ntc\n0x38cD3450Fe4EafC2BF79\neb4b4B357D1E9DBdED0D\n0standard method s\nlib \n0x2a21d90745dfed999aa\n0b6e08d648855c5f14663\n6standard method sloadlib \n0x2a21d90745dfed999aa\n0b6e08d648855c5f14663\n6standard method sFigure 11: Two interacted inconsistent tokens\nthe method transfer() of the contract ledger is called. The lat-\ntertransfer() manipulates M. After the execution of the contract\nledger, the Controller calls the method controllerTransfer() of the\ncontract FunFair, which also emits the Transfer event. A recent\nonline discussion disclosed that FunFair is a new version of Fun-\nFair_Old, and each version emits the Transfer event when tokens\nare withdrawn from Etherdelta_2 [ 21]. Our approach discovers the\ninconsistency because the Transfer event is emitted twice.\nAEtherdelta_2\nwithdrawToken ()FunFair_Old\ntransfer()\nTransferController\ntransfer()ledger\ntransfer()\nM\nFunFair\ncontrollerTransfer ()\nTransfer1 2 3 4\n5\nFigure 12: An inconsistency found by cross-contract analysis\n5.3 Precision of TokenScope\nWe define precision as the ratio of the number of real inconsis-\ntent tokens to the number of inconsistent tokens discovered by\nTokenScope . A false positive refers to a token contract that complies\nwith ERC-20 but is regarded as an inconsistent one by TokenScope\nmistakenly due to incorrect computation of either Bm,Be, orBr.\nTo evaluate the precision of TokenScope , we manually check all\n2,353 open-source inconsistent tokens detected by TokenScope , and\nfind only 1 false positive (i.e., MiniApps). Hence, the precision is\n99.9% =(2,353−1)/2,353. Manual inspection reveals that MiniApps\nhardcodes an address in the contract and uses the address as the key\nto access M. Note that the location of the mapping value, whose key\nis the hardcoded address, will be pre-computed during compilation\nif full optimization is used. Consequently, SHA3 is not needed in the\ncontract’s bytecode to compute the location. TokenScope can locate M\nbecause MiniApps also accesses the balances of other token holders\n(not the hardcoded one). But it mistakenly reports an inconsistency\nwhen the balance of the hardcoded address is modified, because\nBr=∅due to the lack of SHA3.\nScreening through whitepapers. If the whitepaper of an incon-\nsistent token describes the inconsistency, such inconsistency may\nnot cause severe consequences because users can get aware of the\ninconsistency by reading the whitepaper. We further evaluate how\nmany inconsistent tokens detected by TokenScope can be filtered\nout by their whitepapers. Without considering the false positive\nmentioned above, we search for the whitepapers of all 2,352 open-\nsource inconsistent tokens from the Internet including the official\nwebsites of tokens, whitepaper collection websites and forums, and\nsuccessfully download 752 whitepapers. After reading them, we\nfind that only 31 whitepapers describe token behaviors in detail\n(e.g., how many tokens will be charged as fee) and only 1 token’s\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1512(i.e., Krown) whitepaper mentions the inconsistency: “An Event\n‘Authority Notified’ is generated on the blockchain to notify Central\nAuthority” [ 46] instead of the Transfer event. Note that TokenScope\nconsiders Krown as an inconsistent token because Be,Br. This\nanalysis shows that existing whitepapers pay little attention to\ndescribing inconsistency.\nScreening through other standards. TokenScope may detect an\ninconsistency if a token contract emits a standard event defined by\nother token standards, because that event is a non-standard event\nwhose semantics is not defined in ERC-20. Such inconsistency may\nnot introduce serious problems because users can get aware of the\ninconsistency by reading the other token standards. By checking all\n2,353 open-source inconsistent tokens, we find that TokenScope de-\ntects 681 (0 .017% =681/3,259,001) inconsistent behaviors resulted\nfrom 10 (0.4%=10/2,353) tokens. These 10 tokens emit both the ERC-\n20Transfer event and a new type of Transfer event defined by\nthe ERC-223 standard, whose prototype is “event Transfer(address\n_from, address _to, uint256 _value, bytes _data)” [ 10]. Note that\nthe ERC-223 Transfer event is different from the ERC-20 Transfer\nbecause they have different event prototypes. TokenScope identifies\nthese 10 tokens since they emit ERC-20 Transfer events, and it\ndetects inconsistent behaviors when these tokens emit ERC-223\nTransfer events. These 10 tokens are listed in Table 3. We plan to\nextend TokenScope to support other token standards in future.\nTable 3: Ten Inconsistent Tokens due to the Event Defined\nin ERC-223\nReason  Token name  Token address  \n1 Bodhi Ethereum  0x47c171cE16c1C06AaE6E785Ba3c518C42235da0F  \nWubCoin  0x2664877980f2684c9e9be07a50330e85847c5241  \nTablow Club  0xeab447c1e2b5a76b57f15e55eab504801aa6ceb0  \nEIB 0x314d759476c5a3a02c0c6b1f1e213949084e277b  \nAnythingApp T oken  0x36f74e50de0b79f9b0bbeb644af9d40e3cc26433  \neDogeCoin  0x44cba3a62a15ac8f66ff75bf7abd058dcca7d7ed  \nCoinvest COIN Token  0x4306ce4a5d8b21ee158cb8396a4f6866f14d6ac8  \nEthereum Lendo Token  0x45d0bdfDFBfD62E14b64b0Ea67dC6eaC75f95D4d  \n2 MiniApps  0x0f587d0b 7b1c1ef68b432936b75c4d6c4d12b647  \n1. Another standard event of ERC -233 standard 2. Hardcoded key of M in optimized bytecode\nToken name  Token address  \nBodhi Ethereum  0x47c171cE16c1C06AaE6E785Ba3c518C42235da0F  \nWubCoin  0x2664877980f2684c9e9be07a50330e85847c5241  \nTablow Club  0xeab447c1e2b5a76b57f15e55eab504801aa6ceb0  \nEIB 0x314d759476c5a3a02c0c6b1f1e213949084e277b  \nAnythingApp T oken  0x36f74e50de0b79f9b0bbeb644af9d40e3cc26433  \neDogeCoin  0x44cba3a62a15ac8f66ff75bf7abd058dcca7d7ed  \nCoinvest COIN Token  0x4306ce4a5d8b21ee158cb8396a4f6866f14d6ac8  \nEthereum Lendo Token  0x45d0bdfDFBfD62E14b64b0Ea67dC6eaC75f95D4d  \nTest Toke n 0xfa74f89a6d4a918167c51132614bbbe193ee8c22  \nAuctus Toke n 0xfd89de68b246eb3e21b06e9b65450ac28d222488  \nType  # of tokens  # of inconsistent tokens  # of transactions  \nI 56,864/16,248  7,329/2,329  \nII 58/30  21/16  \nIII 227/92  60/3 \nIV 262/92  62/5 \nsum 57,411/16,462  7,472/2,353  \n5.4 Vetting Tokens before Deployment\nAlthough TokenScope focuses on detecting inconsistent behaviors\nthat have been happened in Ethereum, it can be easily extended\nto discover inconsistent tokens before deployment by equipping\nit with any path exploration techniques (e.g., symbolic execution,\nfuzzing) to generate traces. To demonstrate the feasibility, we de-\nvelop a tool named TokenFuzzer that integrates TokenScope with\nContractFuzzer , which is an open-source fuzzing tool for discov-\nering security vulnerabilities of smart contracts [ 30], to detect in-\nconsistent tokens. ContractFuzzer instruments the EVM to check\nwhether security vulnerabilities are triggered, and runs the target\nsmart contracts with generated inputs (i.e., transactions) in a private\nchain equipped with the customized EVM. TokenFuzzer reuses the\ncode for generating transactions from ContractFuzzer , replaces the\nEVM instrumented by ContractFuzzer with the EVM instrumented\nbyTokenScope for recording traces, and reuses the code for locating\nMand detecting inconsistent behaviors from TokenScope.\nTo evaluate TokenFuzzer , we first manually identify 20 incon-\nsistent tokens from all open-source tokens that have not exposedinconsistent behaviors yet. That is, TokenScope has not discovered\ntheir inconsistent behaviors. It is worth mentioning that we do\nnot select many inconsistent tokens to test TokenFuzzer due to two\nreasons. First, ContractFuzzer needs to run a private chain which\nis very time consuming. Second, the purpose of this experiment\nis to demonstrate that TokenScope can be extended to vet token\ncontracts before their deployment, and we will further enhance\nTokenFuzzer ’s capability and boost its performance in future work.\nThe experimental results show that TokenFuzzer discovers 7\n(35% =7/20) inconsistent tokens, where 2 tokens have integer over-\nflow bugs and the other 5 tokens do not emit standard events when\nMis modified (reasons are detailed in §6). After manually inspect-\ning the 13 undiscovered inconsistent tokens, we find 3 issues: (1)\nsome code can only be triggered by certain accounts; (2) some code\ncan only be triggered when another method has already executed;\n(3)ContractFuzzer randomly generates inputs which are difficult\nto trigger integer overflow. To evaluate whether TokenFuzzer can\ndiscover such inconsistent tokens if these 3 issues are solved, we\nuse proper accounts to invoke token contracts, properly arrange\nthe order of the tested methods, and modify the input generation\nstrategy of ContractFuzzer to produce desired values. After that,\nwe re-run TokenFuzzer and find that it can successfully discover all\nthese inconsistent tokens.\nRemark3: TokenScope can be easily extended to discover inconsis-\ntent tokens before token deployment (i.e., inconsistent behaviors\nhave not been trigger yet) if it is equipped with a proper path\nexploration component. We will investigate it in future work.\nTable 4: 11 major reasons for inconsistency\nReason  # Description  \nFlawed tokens  88 Incorrect implementation of standard event emission or M manipulation.  \nIncorrect method \ninvocation  34 The unnamed method rather than the standard methods is invoked.  \nLack of event/M \nmodification  2,097 The token contract does not emit the standard event or modify M.  \nFee 51 The code of fee charging is implemented in a standard meth od, or in a non -\nstandard method without proper implementation of standard events.  \nToken minting  654 The code of token minting  is implemented in a standard meth od, or in a \nnon-standard method without proper implementation of standard events.  \nToken burning  463 The code of token bur ning  is implemented in a standard meth od, or in a \nnon-standard method without proper implementation of standard events.  \nToken purchase  246 An account buys tokens in ETH  by invoking a standard method, or a non -\nstandard method without proper implementation of standard events . \nToken sell 18 An account sells tokens for ETH by invoking a standard method, or a non -\nstandard method without proper implementation of standard events .  \nUnit conversion  19 Converting the token into a much smaller basic u nit, and the code of unit \nconversion  is implemented in a standard meth od, or in a non -standard \nmethod without proper implementation of standard events.  \nAccount changed  50 The balance of a specified account, rather than the account indicated by \nstandard method interfaces or standard events, is modified.  \nAmount changed  6 The specified amount of tokens, rather than the amount indicated by \nstandard met hod interfaces or standard events, are transferred.  \n1 https://eips.ethereum.org/EIPS/eip -777 \n2 https://github.com/ethereum/ EIPs/issues/1404  \n3 https://github.com/ethereum/EIPs/issues/223  \n4 https://github.com/ethereum/EIPs/issues/965  \n5 https://github.com/ethereum/EIPs/issues/827  \n6 https://github.com/ethereum/EIPs/issue s/1003  \n7 https://github.com/ethereum/EIPs/issues/677  \n8 https://github.com/ ethereum/EIPs/pull/621  Standard  # of ERC-20 standard interfaces \nsupport (must/optional)  # of new standard \ninterfaces  # of standard \nevents  # of new standard \nevents  \n7771 2/2 9 0 5 \n14042 6/0 2 2 0 \n2233 3/3 1 0 1 \n9654 2/2 12 0 5 \n8275 6/3 2 2 0 \n10036 6/3 1 2 0 \n6777 6/3 1 2 0 \n6218 6/3 2 2 0 \n6 REASONS OF INCONSISTENT BEHAVIORS\nWe manually investigate all 2,352 open-source inconsistent tokens\nto reveal the reasons behind inconsistency. Table 4 lists the 11 major\nreasons, some of which have several sub-categories. For each reason,\nwe explain it and show the number of inconsistent tokens. Note\nthat one inconsistency can be caused by several reasons. The most\nnumber of reasons we find for an inconsistent token is 3, and we\nfind 68 such kind of inconsistent tokens. The figures in “<>” denote\nthe numbers of tokens in the corresponding categories. Note that\nall inconsistent tokens presented in this section have been deployed\nin Ethereum and invoked (e.g., purchase/sell/transfer) by accounts.\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n15136.1 Flawed tokens\nFlawed tokens implement the standard event emission or Mmanip-\nulation incorrectly. We found 88 flawed tokens and classified them\ninto four groups. To the best of our knowledge, 50 flawed tokens are\nunreported. All flawed tokens are listed in http://bit.ly/Tokenscope\ndue to page limit.\n(1)Incorrect implementation of Transfer <24>. We find various er-\nrors in implementing the Transfer event, such as incorrect accounts,\nand duplicated events. The consequence is the confusion of users be-\ncause they cannot know the real token behaviors from the Transfer\nevent. Fig. 13 presents a flawed token that sets an incorrect account\ninTransfer (Line 5). Both the semantics of transferFrom() (Line 1)\nand the modification of M(Lines 2, 3) indicate that the token sender\nis_from. Therefore, the correct implementation of the Transfer\nevent should be “Transfer(_from, _to, _value);” instead of the one\non Line 5. As another example, Fig. 14 shows a token that emits the\nTransfer event twice (Lines 2, 6) for each invocation of transfer() .\nA token holder will be confused since the Transfer events suggest\nthat 2×_value tokens are transferred by invoking transfer().\n1functiontransfer(address_to,uint256_value)publicvalidAddress(_to)...{\n2if(balanceOf[msg.sender]>=_value&&_value>0){\n3balanceOf[msg.sender]=sub(balanceOf[msg.sender],_value);\n4balanceOf[_to]=add(balanceOf[_to],_value);\n5Transfer(msg.sender,_to,_value);\n6returntrue;}\n7else{returnfalse;}}\n1functiontransferFrom(address_from,address_to,uint256_value)returns(boolsuccess){\n......\n2balanceOf[_from]-=_value;\n3balanceOf[_to]+=_value;\n4spentAllowance[_from][msg.sender]-=_value;\n5Transfer(msg.sender,_to,_value);}\n1functiontransfer(address_to,uint256_value)returns(boolsuccess){\n2Transfer(msg.sender,_to,_value);\n3if(balances[msg.sender]>=_value&&_value>0){\n4balances[msg.sender]-=_value;\n5balances[_to]+=_value;\n6Transfer(msg.sender,_to,_value);\n7returntrue;\n8}else{returnfalse;}}\n1functiontransferFrom(address_from,address_to,uint256_value)...{\n2balanceOf[_from]=SafeMath.sub(balanceOf[_from],_value);\n3balanceOf[_to]=SafeMath.add(balanceOf[_to],_value);\n4TransferFrom(_from,_to,_value);\n5returntrue;}\n1functiontransfer(address_receiver,uint256_amount)...{\n2require(_transferCheck(msg.sender,_receiver,_amount));\n3UserBalances[msg.sender]=Sub(UserBalances[msg.sender],_amount);\n4UserBalances[_receiver]=Add(UserBalances[msg.sender],_amount);\n5Transfer(msg.sender,_receiver,_amount);\n6returntrue;}\n1functiontransfer(address_toAddress,uint256_amountOfTokens)...{\n......\n2tokenBalanceLedger_[_customerAddress]=SafeMath.sub(\ntokenBalanceLedger_[_customerAddress],_amountOfTokens);\n3transferFrom(_customerAddress,_toAddress,_amountOfTokens);...}\nFigure 13: Incorrect implementation of Transfer event\n1  function transfer(addr ess _to, uint256 _value)  public validAddress(_to)  ... { \n2    if(balanceOf[msg.sender] >= _value && _value > 0) { \n3 balanceOf[msg.sender]  = sub( balanceOf[msg.sender] , _value);  \n4 balance Of[_to] = add( balance Of[_to] , _value);  \n5 Transfer(msg.sender, _to, _value);  \n6      return true;}  \n7    else{return false; }} \n1  transferFrom(address _from, address _to, uint256 _value)  returns (bool success){  \n   ...... \n2    balanceOf [_from] -= _value;  \n3    balanceOf[_to]  += _value;  \n4    spentAllowance[_from][msg.sender] += _value;  \n5    Transfer(msg.sender, _to, _value);}  \n1 function transfer(address _to, uint256 _value) returns (bool success) {  \n2 Transfer(msg.sender, _to, _value);  \n3 if (balances[msg.sender] >= _value && _value > 0) {  \n4 balances[msg.sender] -= _value;  \n5 balances[_to] += _value;  \n6 Transfer(msg.sender, _to, _value);  \n7 return true;  \n8 } else { return false; } } \nFigure 14: A flawed token that emits the Transfer event twice\n(2)Informing ETH transfer instead of token transfer <2>. The event\nTransfer is used to inform token transfer, but we found 2 token con-\ntracts that use it to inform ETH transfer (i.e., an account transfers\nsome ETH to another account). Users could be confused because\nthere is no token transfer when they receive the Transfer event.\n(3)Incorrect implementation of Mmanipulation <14>. Such flawed\ntokens will incur serious consequences including financial loss, be-\ncause the flawed manipulation of Mmay set an incorrect balance to\nan unexpected account. Fig. 15, Fig. 16 and Fig. 17 present three such\nflawed tokens. The token contract shown in Fig. 15 sets the balance\nof_receiver to an incorrect value (Line 4) because the balance of _re-\nceiver rather than that of msg.sender should be added. Hence, Line 4\nshould be “UserBalances[_receiver] = Add(UserBalances[_receiver],\n_amount);”. The token contract shown in Fig. 16 reduces the bal-\nance of the token sender twice for each invocation of the standard\nmethod transfer() . Specifically, the balance is reduced at Line 2,\nand then the standard method transferFrom() is invoked (Line 3),\nwhich reduces the balance again. Fig. 17 shows a token containing\na subtle flaw. The variable balanceFrom is set to the token balance\nof_from (Line 2). Then, the token balance of _from is set to the\nsubtraction of _value from balanceFrom (Line 4). The balance should\nnot be changed if _from is_to. However, the token balance of _from\nwill decrease by _value due to the subtle implementation error, if\n_from is_to.\n1  function transfer(addr ess _to, uint256 _value)  public validAddress(_to)  ... { \n2    if(balanceOf[msg.sender] >= _value && _value > 0) { \n3 balanceOf[msg.sender]  = sub( balanceOf[msg.sender] , _value);  \n4 balance Of[_to] = add( balance Of[_to] , _value);  \n5 Transfer(msg.sender, _to, _value);  \n6      return true;}  \n7    else{return false; }} \n1  transferFrom(address _from, address _to, uint256 _value)  returns (bool success){  \n   ...... \n2    balanceOf [_from] -= _value;  \n3    balanceOf[_to]  += _value;  \n4    spentAllowance[_from][msg.sender] += _value;  \n5    Transfer(msg.sender, _to, _value);}  \n1 function transfer(address _to, uint256 _value) returns (bool success) {  \n2 Transfer(msg.sender, _to, _value);  \n3 if (balances[msg.sender] >= _value && _value > 0) {  \n4 balances[msg.sender] -= _value;  \n5 balances[_to] += _value;  \n6 Transfer(msg.sender, _to, _value);  \n7 return true;  \n8 } else { return false; } } \n1 function transferFrom(address _from, address _to, uint256 _value) ...{ \n2 balanceOf[_from] = SafeMath.sub(balanceOf[_from], _value);  \n3 balanceOf[_to] = SafeMath.add(balanceOf[_to], _value);  \n4 TransferFrom(_from, _to, _va lue); \n5 return true; } \n1 function transfer(address _receiver, uint256 _amount) ...{ \n2 require(_transferCheck(msg.sender, _receiver, _amount));  \n3 UserBalances[msg.sender] = Sub(UserBalances[msg.sender], _amount);  \n4 UserBalances[_receiver] = Add(UserBalances[msg.sender], _amount);  \n5 Transfer(msg.sender, _receiver, _amount);  \n6 return true;  } Figure 15: A flawed token that sets an incorrect balance\n1  function transfer(addr ess _to, uint256 _value)  public validAddress(_to)  ... { \n2    if(balanceOf[msg.sender] >= _value && _value > 0) { \n3 balanceOf[msg.sender]  = sub( balanceOf[msg.sender] , _value);  \n4 balance Of[_to] = add( balance Of[_to] , _value);  \n5 Transfer(msg.sender, _to, _value);  \n6      return true;}  \n7    else{return false; }} \n1  transferFrom(address _from, address _to, uint256 _value)  returns (bool success){  \n   ...... \n2    balanceOf [_from] -= _value;  \n3    balanceOf[_to]  += _value;  \n4    spentAllowance[_from][msg.sender] += _value;  \n5    Transfer(msg.sender, _to, _value);}  \n1 function transfer(address _to, uint256 _value) returns (bool success) {  \n2 Transfer(msg.sender, _to, _value);  \n3 if (balances[msg.sender] >= _value && _value > 0) {  \n4 balances[msg.sender] -= _value;  \n5 balances[_to] += _value;  \n6 Transfer(msg.sender, _to, _value);  \n7 return true;  \n8 } else { return false; } } \n1 function transferFrom(address _from, address _to, uint256 _value) ...{ \n2 balanceOf[_from] = SafeMath.sub(balanceOf[_from], _value);  \n3 balanceOf[_to] = SafeMath.add(balanceOf[_to], _value);  \n4 TransferFrom(_from, _to, _va lue); \n5 return true; } \n1 function transfer(address _receiver, uint256 _amount) ...{ \n2 require(_transferCheck(msg.sender, _receiver, _amount));  \n3 UserBalances[msg.sender] = Sub(UserBalances[msg.sender], _amount);  \n4 UserBalances[_receiver] = Add(UserBalances[msg.sender], _amount);  \n5 Transfer(msg.sender, _receiver, _amount);  \n6 return true;  } \n1  function tran sfer(address _toAddress, uint 256 _amountOfTokens) ...{ \n  ...... \n2 tokenBalanceLed ger_[_customerAddress] = SafeMath.sub(  \n     tokenBalanceLed ger_[_customerAddress] , _amountOfTokens);  \n3    transferFrom( _customerAddress , _toAddress , _amountOfTokens ); ...} \nFigure 16: A flawed token that reduces token balance twice\n1 function transferFrom(address _from, address _to, uint256 _value) ... { \n   ...... \n2 uint256 balanceFrom = balances[_from];  \n   ...... \n3    balances[_to] = safeAdd(balances[_to], _value);  \n4 balances[_from] = safeSub(balanceFrom, _value); ...... } \nFigure 17: A flawed token with a subtle error\n1 function transferFrom(address _from, address _to , uint256 _value) ... { \n   ...... \n2 uint256 balanceFrom = balances[_from];  \n   ...... \n3 balances[_to] = safeAdd(balances[_to], _value);  \n4 balances[_from] = safeSub(balanceFrom, _value); ...... } \n1  function transfer(address to, uint256 value) public returns (bool) {  \n2 tokens  = value * 10 ** decimals;  \n3 balance[to]  = balance[to] + tokens;  \n4 balance[owner]  = balance[owner] - tokens;  \n5 emit Transfer(owner, to, tokens);  } \nFigure 18: A flawed token with an integer overflow bug\n(4)Integer overflow <50>. In EVM, an integer has a maximum value\nso that an integer overflow happens if an operation results in a\nvalue greater than the maximum value, causing the value to wrap-\naround [ 61]. A token contract often uses “uint256”, a 256-bit un-\nsigned integer which is the longest number supported by EVM [ 63],\nto store token balance, and this value will be incorrect if integer\noverflow happens. Integer overflow has become a major threat to\nthe security of smart contracts, leading to severe consequences (e.g.,\nthe market prices of tokens drop, exchange markets suspend token\ndeposits and withdraws) [ 33,45,53]. Fig. 18 presents an inconsis-\ntent token having an integer overflow bug (Line 4). When invoking\ntransfer() with a large value, the result of balance[owner] - tokens\ncould be overflowed. Consequently, the token balance of owner\nincreases after subtraction (Line 4).\n6.2 Incorrect method invocation\nFor 34 inconsistent tokens, users attempt to invoke standard inter-\nfaces, however, the unnamed method is invoked since the standard\nmethods are not implemented. Note that in EVM the unnamed\nmethod will be invoked if the transaction does not specify the in-\nvoked method, or the invoked method is not implemented in the\ncontract [ 63]. Consequently, users may be confused because they\nintend to call standard methods, rather than the unnamed method.\nThis kind of inconsistency can incur serious security problems,\nsuch as token stolen, token frozen (detailed in §7).\n6.3 Lack of Transfer event and/or Mmodification\nSince TokenScope detects inconsistent tokens by comparing Bm,Be\nandBrifBm,∅, or comparing BeandBrotherwise, the lack of\nBeorBrresults in inconsistency. 2,097 inconsistent tokens resulted\nfrom this reason, which can be divided into three groups.\n(1)Be=∅<1,405>. The lack of standard event emission hinders\nthe third-party tools from knowing token behaviors. In particular,\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1514users do not know where their tokens come from or go to, even if\nthey could call balanceOf() to check their token balances.\n(2)Br=∅<44>. The lack of Mmanipulation indicates that no token\ntransfers happen in practice. Consequently, users may be confused\nbecause the Transfer event informs token transfers. KYC Casper\nToken reported by a recent news belongs to this category [64].\n(3)Be=Br=∅<833>. We find 833 inconsistent tokens that\nneither manipulate Mnor emit the Transfer event, when executing\nstandard methods. As a result, the third-party tools (e.g., exchange\nmarkets) that detect token behaviors by monitoring the invocation\nof standard interfaces will incorrectly think that token transfer\nhappens. This issue will cause “fake deposit” [ 40]. Fig. 19 shows\nan example detected by TokenScope . Line 7 will be executed if the\ncomparison in Line 2 returns false. In this case, the standard method\ntransfer() executes without modifying Mand emitting the standard\nevent.\n1  function transfer(addr ess _to, uint256 _value)  public validAddress(_to)  ... { \n2    if(balanceOf[msg.sender] >= _value && _value > 0) { \n3 balanceOf[msg.sender]  = sub( balanceOf[msg.sender] , _value);  \n4 balance Of[_to] = add( balance Of[_to] , _value);  \n5 Transfer(msg.sender, _to, _value);  \n6      return true;}  \n7    else{return false; }} \nFigure 19: An inconsistency because Be=Br=∅\n6.4 Fee\nA token contract can charge fee from any token holder, and the\nfee is sent to the token contract, the token creator, or any account\nspecified by the token creator. An inconsistent behavior happens if\nthe code of fee charging is written (1) in a standard method, or (2) in\na non-standard method without proper implementation of standard\nevents. 51 inconsistent tokens are due to this reason, and Fig. 20\npresents one. A token holder, msg.sender intends to transfer _value\ntokens to a token holder _toby invoking transfer() (Line 1). The\nbalance of msg.sender is decreased by _value (Line 3), however, only\n_value−_value×fee/10,000 tokens are transferred to _to(Line 4).\nThe remaining tokens are charged as fee and sent to another token\nholder, _feeWallet (Line 5). The token emits two Transfer events\nthat faithfully reflect token behaviors (Lines 6, 7). Our approach\ndetects the inconsistency because Bmis different from BeandBr.\nNote that the account who invokes transfer() may not intend to\ntransfer money to _feeWallet.\n1 function  transfer(address _to, u int256  _value)  public returns (bool) { \n2 require(_to != address(0));  \n3 balances[m sg.sender] = b alances[msg.sender].sub (_value);  \n4 balances[_to ] = balances[_to].add(_value.sub(_value * fee / 10000));  \n5 balances[_ feeWallet] = balances[feeWallet].add(_value * fee / 10000);  \n6 Transfer(msg.sender, _to, (_value.sub(_value * fee / 10000 ))); \n7 Transfer(msg.sender, feeWalle t, (_value * fee / 10000));  \n8 return tru e;} \nFigure 20: The inconsistency incurred by charging fee\n6.5 Token minting\nToken minting means increasing the total amount of tokens in cir-\nculation. If the code of token minting is written (1) in a standard\nmethod, or (2) in a non-standard method without proper imple-\nmentation of standard events, an inconsistency happens. We detect\ntoken minting according to Br. More precisely, for every trace, we\nsum the token changes of all token holders whose balances areincreased. Similarly, we sum the (absolute value) token changes of\nall token holders whose balances are decreased. Then, we check\nwhether the first summation is larger than the second one. If so, we\nthink that token minting happens. Please reconsider the contract\nin Fig. 2, the balances of _toand hacker are increased by _value\nandfee, respectively and then the first summation is _value +fee.\nThe balance of msg.sender is decreased by _value−fee. Hence, the\nfirst summation is equal to the second, and thus no token minting\nhappens in this contract. 654 inconsistent tokens are due to token\nminting. We classify those 654 tokens into five minor categories,\nand the figures in “<>” stand for the numbers of inconsistent tokens\nbelonging to the sub-categories.\n(1) Reward <635>. A token contract can implement various strate-\ngies to reward users with some amount of tokens. For example, a\ntoken rewards the accounts who produce the block or call the token\ncontract for the first time.\n(2) Subsidy <2>. Ethereum requires transaction senders to pay trans-\naction fee in ETH to prevent resource abusing [ 6]. To attract users\nto invoke token contracts, many token contracts send users some\namount of tokens as the subsidy for transaction fee.\n(3) Donation <4>. We find that 4 token contracts donate some\namount of tokens to specified accounts for each invocation of the\ntoken contracts.\n(4) Token migration <8>. Token developers will deploy a new ver-\nsion of token contract on the blockchain to substitute the old version\nfor some reasons (e.g., fix bugs). After the deployment of the new\ncontract, the new contract should migrate some data from the old\ncontract, e.g., the addresses of token holders, the amount of tokens\npossessed by token holders. Without migration, users’ tokens will\nbe lost.\n(5) Unlocking <9>. The founders of a token contract can lock their\nproportions of tokens to increase the confidence of other users. The\nlocked tokens cannot be circulated because they are not recorded in\nM. In other words, they can be neither sold nor transferred to other\nusers. The locked tokens will be unlocked when some conditions\nare met, e.g., the locking period is expired. Token unlocking results\nin token minting, because the unlocked tokens will be added in M.\nFig. 21 presents a deployed inconsistent token due to both subsidy\nand donation. A token holder intends to transfer tokens tokens to\nthe holder toby invoking transfer() (Line 1), and the Transfer\nevent is accordant with transfer() (Line 6). The token contract\nsends 5,000 tokens to msg.sender as subsidy (Line 3), and it donates\n5,000 tokens to an account, donation (Line 5). The contract emits a\nnon-standard event Donation (Line 7), however, the semantics of\nDonation is unclear. Consequently, the transaction sender may not\nknow the occurrence of token donation. By leveraging a wallet, the\nsender knows that the balance of msg.sender decreases by tokens -\n5,000. Hence, the transaction sender could be confused because the\nsender intends to send tokens tokens to toby invoking transfer() .\n1 function transfer(address _to, uint256 _value)  public returns (bool){  \n2 require(_to != address(0));  \n3 balances[msg.sender] = balances[msg.sender].sub(_value);  \n4 balances[_to] = balances[_to].add(_value.sub(_value * fee / 10000));  \n5 balances[_feeWallet] = balances[feeWallet].add(_val ue * fee / 10000);  \n6 Transfer(msg.sender, _to, (_value.sub(_value * fee / 10000 ))); \n7 Transfer(msg.sender, feeWallet, (_value * fee / 10000));  \n8 return true; } \n1  function transfer(address to, uint tokens) public returns (bool suc cess) { \n2    address donation = donationsTo [msg.s ender];  \n3    balances[msg.sender] = (balances[msg.sender].sub(tokens)).add(5000);  \n4    balances[t o] = balances[to].add(tokens);  \n5 b alances[donation] = b alances[donation].add(5000);  \n6    emit Transfer(msg.sender, to, tokens);  \n7 emit Donation(donation);  \n8    return true;} \nFigure 21: The inconsistency due to subsidy and donation\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n15156.6 Token burning\nToken burning means decreasing the total amount of tokens in\ncirculation. We detect an inconsistency if the code of token burn-\ning is written (1) in a standard method, or (2) in a non-standard\nmethod without proper implementation of standard events. We\ndetect token burning using a similar approach for detecting token\nminting, except that token burning happens if the first summation\nis smaller than the second one. 463 inconsistent tokens are due to\ntoken burning. We classify them into two sub-categories.\n(1) Wear <9>. Some token contracts charge fee, but the fee is not\nsent to any account so that the fee disappears during token transfer.\n(2) Reclaim <454>. Some token contracts burn tokens when some\ntokens are sent to the address 0, the addresses of token contracts,\nthe addresses of token creators or any accounts specified by to-\nken creators. In such case, token contracts intend to reclaim those\ntokens.\nFig. 22 presents a deployed inconsistent token due to reclaim. The\ntoken contract first calls super. transferFrom() to transfer _value\ntokens from the account _from to the account _to(Line 2). Then,\nthe token contract checks whether the tokens are sent to the token\ncontract (Line 3). If so, the transferred tokens are burned (Line 4).\nAlthough the token contract emits a non-standard event, Destruc-\ntion (Line 6), the semantics of this event are unclear and thus the\ntransaction sender may not know token burning.\n1 function transfer(address _to, uint256 _value)  public returns (bool){  \n2 require(_to != address(0));  \n3 balances[msg.sender] = balances[msg.sender].sub(_value);  \n4 balances[_to] = balances[_to].add(_value.sub(_value * fee / 10000));  \n5 balances[_feeWallet] = balances[feeWallet].add(_val ue * fee / 10000);  \n6 Transfer(msg.sender, _to, (_value.sub(_value * fee / 10000 ))); \n7 Transfer(msg.sender, feeWallet, (_value * fee / 10000));  \n8 return true; } \n1  function transferFrom(address  _from, address _to, uint256 _value) ... { \n2 assert(super.transferFrom(_from, _to, _value));  \n3 if (_to == address(this)) {  \n4 balanceOf[_to] -= _value;  \n5 totalSupply -= _value;  \n6 Destruction(_value);  \n} \n7    return true;  \n} \nFigure 22: The inconsistency incurred by reclaim\n6.7 Token purchase\nSome token contracts allow automatic token purchase without\nthe interference of exchange markets. These token contracts send\nsome amount of tokens to the accounts who send ETH to the token\ncontracts according to the exchange rate implemented in the token\ncontracts. An inconsistent behavior occurs if the code of token\npurchase is written (1) in a standard method, or (2) in a non-standard\nmethod without proper implementation of standard events. 246\ninconsistent tokens are due to token purchase. Fig. 23 presents an\ninconsistent token due to token purchase. The transaction sender\npays msg.value ETH to purchase qiuAmount tokens (Line 2). The\ntoken contract sends qiuAmount tokens to msg.sender (Lines 4, 5),\nand then emits a non-standard event (Line 6). The consequence\nof the inconsistency is that although users can check their token\nbalances by invoking the standard method balanceOf() , they may\nnot know why their balances increase because the semantics of the\nnon-standard events are unclear.\n6.8 Token sell\nSome token contracts check whether the ETH possessed by an\naccount is smaller than a threshold. If so, token contracts charge\nsome amount of tokens from the account and send some amount of\nETH to that account according to the exchange rate implemented in\n1 function transfer(address _to, uint256 _value)  public returns (bool){  \n2 require(_to != address(0));  \n3 balances[msg.sender] = balances[msg.sender].sub(_value);  \n4 balances[_to] = balances[_to].add(_value.sub(_value * fee / 10000));  \n5 balances[_feeWallet] = balances[feeWallet].add(_val ue * fee / 10000);  \n6 Transfer(msg.sender, _to, (_value.sub(_value * fee / 10000 ))); \n7 Transfer(msg.sender, feeWallet, (_value * fee / 10000));  \n8 return true; } \n1  function transferFrom(address  _from, address _to, uint256 _value) ... { \n2 assert(super.transferFrom(_from, _to, _value));  \n3 if (_to == address(this)) {  \n4 balanceOf[_to] -= _value;  \n5 totalSupply -= _value;  \n6 Destruction(_value);  \n} \n7    return true;  \n} \n1  function exchangeForQIU() payable public retu rns (bool){  \n2    uint qiuAmount = msg.value * eth2qiuRate / 1 000000000000000000;  \n3    require(qiuAmount <= b alances[this]);  \n4    balances[this] = b alanc es[this].sub(q iuAmount);  \n5    balances[msg.sender] = b alances[msg.sender].add(qiuAmount);  \n6    ExchangeForQIU(this, msg.sender, q iuAmount, msg.value);  \n7    return t rue; \n  } Figure 23: The inconsistency incurred by token purchase\nthe token contracts. Token sell will incur inconsistency if the code\nof token sell is written (1) in a standard method, or (2) in a non-\nstandard method without proper implementation of standard events.\n18 inconsistent tokens are due to token sell. Fig. 24 shows a deployed\ninconsistent token due to token sell. If the ETH possessed by the\ntoken receiver _tois less than a threshold, minBalanceForAccounts\n(Line 2), the amount of tokens, amountinBoss is computed according\nto the exchange rate, sellPrice (Line 3). Then, amountinBoss tokens\nare transferred to the account specified by the token creator (Line\n4), and the account _toreceives amountinBoss / sellPrice ETH (Line\n5). Such token sell behavior may be troublesome, since any account\nAcould convert the tokens of another account Binto ETH by\ntransferring some tokens to B.\n1 function transfer(address _to, uint256 _value)  public returns (bool){  \n2 require(_to != address(0));  \n3 balances[msg.sender] = balances[msg.sender].sub(_value);  \n4 balances[_to] = balances[_to].add(_value.sub(_value * fee / 10000));  \n5 balances[_feeWallet] = balances[feeWallet].add(_val ue * fee / 10000);  \n6 Transfer(msg.sender, _to, (_value.sub(_value * fee / 10000 ))); \n7 Transfer(msg.sender, feeWallet, (_value * fee / 10000));  \n8 return true; } \n1 function transferFrom(address _from, address _to, uint256 _value) ... { \n2 assert(super.transferFrom(_from, _to, _value));  \n3 if (_to == address(this)) {  \n4 balanceOf[_to] -= _value;  \n5 totalSupply -= _value;  \n6 Destruction(_value);  \n} \n7    return true;  \n} \n1  function exchangeForQIU() payable public returns (bool){  \n2    uint qiuAmount = msg.value * eth2qiuRate / 1 000000000000000000;  \n3    require(qiuAmount <= balances[this]);  \n4    balances[this] = balances[this].sub(qiuAmount);  \n5    balances[msg.sender] = balances[msg.sender].add(qiuAmount);  \n6    ExchangeForQIU(this, msg.sender, qiuAmount, msg.value);  \n7 return true;  \n  } \n1  function _transfer(address _from, address, _to, u int _value) internal { \n...... \n2    if(_to.balance < minBalanceForAccounts){  \n3 uint256 amountinB oss = ( minBalanceForAccounts  - _to.balance) * sell Price;  \n4 _transfer (_to, owner, amountinBoss);  \n5 _to.transfer(amountinBoss / sellPrice); } \n6    Transfer(_from, _to, _value); } \nFigure 24: The inconsistency incurred by token sell\n6.9 Unit conversion\nSome token contracts specify a basic unit of tokens, which is much\nsmaller than one token. Unit conversion will lead to inconsistency\nif the code of unit conversion is written (1) in a standard method,\nor (2) in a non-standard method without proper implementation\nof standard events. We detect 19 inconsistent tokens due to such\nreason. Fig. 25 presents a real case. The Transfer event informs\nthat the user userAddress[myid] receives no_of_token tokens (Line\n4). However, the tokens are converted into the basic unit before\ntoken transfer (Lines 2, 3). The basic unit is 1/1010of one token.\nConsequently, the user may be confused because the user will\nfind that the token balance is significantly larger than the amount\ninformed by the Transfer event, when checking the balance by\ninvoking balanceOf() (Lines 5, 6).\ncategory  name address  # tx method  invoked  description  USD involved  \n1 function __callback(bytes32 myid, string result) { \n   ...... \n2    balances[ owner] -= (no_of_token * 10000000000);  \n3    balances[userAddress[myid]] += (no_of_token * 10000000000 ); \n4    Transfer(ow ner, userAddress[myid], no_of_token);  \n  ......} \n5 function balanceOf(address sender) constant returns (uint256 balance) {  \n6 return balances[sender]; } \nFigure 25: The inconsistency incurred by unit conversion\n6.10 Account changed\nWe find 50 token contracts that change the accounts to send or\nreceive tokens instead of using the account specified by the standard\ninterfaces or standard events. Fig. 26 presents a real case due to this\nreason. The transaction sender intends to transfer some tokens to\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1516the account _toby invoking transfer() (Line 1), but _tois changed\nto another account (Line 5) when some conditions are satisfied\n(Lines 3, 4). Consequently, the transaction sender may feel upset\nsince tokens are sent to a different account rather than the intended\none.\ncategory  name address  # tx method  invoked  description  USD involved  \n1 function __callback(bytes32 myid, string result) { \n   ...... \n2    balances[ owner] -= (no_of_token * 10000000000);  \n3    balances[userAddress[myid]] += (no_of_token * 10000000000 ); \n4    Transfer(ow ner, userAddress[myid], no_of_token);  \n  ......} \n5 function balanceOf(address sender) constant returns (uint256 balance) {  \n6 return balances[sender]; } \n1 function transfer(address _to, uint256 _value) onlyPayloadSize(2  * 32) { \n   ...... \n2    if(_to == deposit_address){  ......} \n3    else{ \n4    if(isLeading4FF(_to)){  \n  ...... \n5   _to = shopStoreAddress[uint(storeid)];  \n  ......}} \n6    Transfer(msg.sender, _to, _value); } \nFigure 26: The inconsistency incurred by account specifying\n6.11 Amount changed\nSome token contracts change the amount of transferred tokens\nrather than the amount indicated by standard interfaces or standard\nevents before token transfers. However, users cannot know the\nchange by monitoring the invocation of standard method interfaces.\n6 inconsistent tokens are due to amount specifying. Fig. 27 shows a\nreal case. The transaction sender intends to transfer _value tokens\n(Line 1). However, the real transferred amount is restricted to _value\n-maxGoalInICO (Line 6) if some conditions are satisfied (Lines 2, 5).\nConsequently, the transaction sender may be confused since the\nreal transferred amount is less than the intended amount.\ncategory  name address  # tx method  invoked  description  USD involved  \n1 function __callback(bytes32 myid, string result) { \n   ...... \n2    balances[ owner] -= (no_of_token * 10000000000);  \n3    balances[userAddress[myid]] += (no_of_token * 10000000000 ); \n4    Transfer(ow ner, userAddress[myid], no_of_token);  \n  ......} \n5 function balanceOf(address sender) constant returns (uint256 balance) {  \n6 return balances[sender]; } \n1 function transfer(address _to, uint256 _value) onlyPayloadSize(2  * 32) { \n   ...... \n2    if(_to == deposit_address){  ......} \n3    else{ \n4    if(isLeading4FF(_to)){  \n  ...... \n5   _to = shopStoreAddress[uint(storeid)];  \n  ......}} \n6    Transfer(msg.sender, _to, _value); } \n1 function transferFrom(address _from, address _to, uint256 _value) ... { \n   ...... \n2 if (now < startTime){  \n3 if(_value < maxGoalInICO ) {  \n4   tokensSoldToInvestors = safeAdd(tokensSoldToInvestors, _value);  \n5 } else {  \n6 _value = safeSub(_value, maxGoalInICO );}} \n..... \n7 Transfer(_from, _to, _value);  \n8 return true; } \nFigure 27: The inconsistency incurred by amount specifying\nWe also show the cumulative distribution function plots of open-\nsource inconsistent tokens and flawed tokens in Fig. 28. Each ×\n(x,y)/◦(x,y) indicates that there are yinconsistent/flawed tokens,\nand there are no more than xexternal transactions trigger/exploit\nthe inconsistencies/flaws. For about 19% ( (2,352−1,908)/2,352) of\ninconsistent tokens and about 10% ( (88−79)/88) of flawed tokens,\nthere are at least 100 (i.e., more than 99) external transactions that\ntrigger/exploit the inconsistencies/flaws. That is, many inconsis-\ntent tokens executed inconsistent behaviors frequently, and many\nflawed tokens have been exploited frequently. For example, the\ninconsistent behaviors of IdleEth have been triggered by the most\nnumber of external transactions (i.e., 269,204), and the HYDRO to-\nken is the flawed token that has been exploited by the most number\nof external transactions (i.e., 15,032) (detailed in §7).\n7 CASE STUDIES\nThis section presents case studies of six inconsistent tokens: HY-\nDRO, SMT, ZXBT, GTN, Tablow Club, and MCRT. HYDRO has an\nimplementation flaw in transferFrom() . SMT contains an integer\noverflow bug. The other four inconsistent tokens are due to incor-\nrect method invocation. We find that all of them have been attacked\n100\n101\n102\n103\n104\n105\n# of transactions0.51.01.52.02.5# of inconsistent tokens×103\n(99, 1,908)(269,204, 2,352)\n20406080100\n# of flawed tokens\n(99, 79)\n(15,032, 88)inconsistency\nflawFigure 28: CDFs of open-source inconsistent/flawed tokens\naccording to our trace analysis, leading to serious consequences,\nincluding incorrect token balance, token frozen, or token stolen.\nGTN. 26,097 external transactions have been sent to the HYDRO\ntoken contract, and 12,705 accounts possess HYDRO Token. We\nshow below how an attacker can steal HYDRO tokens from an\nexchange market. The standard method transferFrom() (Fig. 29)\ncontains a bug resulting in inconsistency. The token behavior of\nthe standard method is that _from transfers _value tokens to _to.\nHowever, the real token behavior is that the account who invokes\ntransferFrom() (msg.sender ) transfers the tokens to _to. (Lines 2, 5\n- 7).\n1 function transferFrom (address _from, address _to, uint256 _value) ... { \n   ...... \n2 uint256 balanceFrom = balances[_from];  \n   ...... \n3 balances[_to] = safeAdd(balances[_to], _value);  \n4 balances[_from] = safeSub(balanceFrom, _value); ...... } \n1  function transfer(addr ess to, uint256 value) public returns (bool) {  \n2 tokens  = value * 10 ** decimals;  \n3 balance[to]  = balance[to] + tokens;  \n4 balance[owner]  = balance[owner] - tokens;  \n5 emit Transfer(owner, to, tokens);  } \n1 function transferProxy(address _from, address _to, \nuint256 _value, uint256 _feeSmt ... { \n2 if(balances[_from] < _feeSmt + _value) revert();  \n3    balances[_to] += _value;  \n4 Transfer(_from, _to, _value);  \n5 balances[msg.sender] += _feeSmt;  \n6 Transfer(_from, msg.sender, _feeSmt);  \n7 balances[_from] -= _value + _feeS mt;...} \n1 function transferFrom(address _from, address _to, uint256 _value) ...{ \n  ...... \n2    _transfer(msg.sender, _to, _value); \n3    Transfer(msg.sender, _to, _value); \n4    return true; } \n5 function _transf er(address _from, address _to, uint _value) internal {  \n6 balances[_from] -= _value; \n7    balances[_to] += _value; } \nFigure 29: Code snippet of HYDRO token.\n1 function depositToken(address token, uint amount) {  \n2 if (token  == 0) throw;  \n3 if (!Token(token).transf erFrom(msg.sender, this, amount)) throw;  \n4 tokens [token][msg.se nder] = saf eAdd(tokens[token][msg.sender], amount);  \n5 Depo sit(token, msg.sender, amount, tokens[token][msg.sender]);  } \n6  function withdrawToken(address token, uint amount) {  \n7 if(token == 0) throw;  \n8    if(tokens[token] [msg.s ender] < amount) thro w; \n9    tokens[token][msg.sender]  = safeSub(tokens[token] [msg.sender], amo unt); \n10   if (!Token(token).transfer(msg.sender, amount)) throw;  \n11 Withdraw(token, msg.s ender, amount, tokens[token][msg.sender]); } \nFigure 30: Code snippet of Etherdelta_2\nWe find 15,032 invocations of transferFrom() from another smart\ncontract, EtherDelta_2 which belongs to EtherDelta [ 9]. EtherDelta\nis a popular exchange market, and we observe more than 10 million\nexternal transactions sent to EtherDelta_2. Users can deposit and\nwithdraw various kinds of tokens by invoking depositToken() and\nwithdrawToken() in EtherDelta_2, receptively (Fig. 30). The kind\nof token to be deposited or withdrawn is specified by its address,\nand the amount is specified by amount. depositToken() invokes\ntransferFrom() in the HYDRO token contract to transfer amount\ntokens from the account who invokes depositToken() (msg.sender )\nto the EtherDelta_2 contract (this ) (Line 3). Due to the flawed im-\nplementation of the HYDRO token contract (Fig. 29), the real token\nbehavior is that the EtherDelta_2 contract (rather than the account\nwho deposits the HYDRO tokens) transfers amount tokens to the\nEtherDelta_2 contract. We find 23 accounts who sent 15,032 transac-\ntions to invoke depositToken() of the EtherDelta_2 contract which\nin turn call transferFrom() of the HYDRO token contract. Those\n15,032 transactions deposit more than 2.6 billion HYDRO tokens.\nTo withdraw tokens, a user invokes withdrawToken() to trans-\nferamount tokens from the EtherDelta_2 contract to the user. An\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1517Etherdelta_2 HYDRO\nM<Etherdelta_2, x>\nstorage<HYDRO, attacker, v>storage\nM<Etherdelta_2, x>\nstorage<HYDRO, attacker, 0>\nM<Etherdelta_2, x -v>\n<attacker, v>No token transfer\nToken stealattackerBefore attack\ndepositToken (HYDRO, v)\nattackerwithdrawToken (HYDRO, v)Figure 31: The process of stealing HYDRO.\nattacker steals HYDRO tokens from the EtherDelta_2 contract (i.e.,\nthe EtherDelta exchange market) by first invoking depositToken()\nand then invoking withdrawToken(). We found that more than 2.5\nmillion HYDRO tokens were stolen by 25 external transactions sent\nfrom 11 accounts. Fig. 31 shows the attack process. We assume\nthat the attacker does not hold HYDRO tokens and EtherDelta_2\nholds xHYDRO tokens before attacks. The Mof HYDRO contains\nan item corresponding to EtherDelta_2. An attacker invokes de-\npositToken() with parameters HYDRO and vto transfer vHYDRO\ntokens from the attacker to EtherDelta_2. EtherDelta_2 records\nsuch token deposit behavior in its storage. Due to the implemen-\ntation flaw in transferFrom() as shown in Fig. 29, EtherDelta_2\ninstead of the attacker transfers vHYDRO tokens to EtherDelta_2,\nand thus no token transfer happens. After that, the attacker invokes\nwithdrawToken() to withdraw vHYDRO tokens from EtherDelta_2.\nEtherDelta_2 updates the corresponding record and the HYDRO\ncontract transfers vtokens from EtherDelta_2 to the attacker. Con-\nsequently, the attacker steals vHYDRO tokens from EtherDelta_2.\nSMT. SMT has an integer overflow bug and was deployed to the\nblockchain on Dec. 09, 2017. The first attack exploiting the bug\nhappened on Apr. 24, 2018 and the first report about this attack\nwas published on Apr. 25, 2018 [ 44]. Fig. 32 shows the method\ntransferProxy() that contains the integer overflow bug. The token\nbalance of _from will be decreased by _value +_feeSmt (Line 7), and\nLine 2 checks whether _from possesses sufficient tokens. However,\nthe summation _feeSmt +_value can be overflowed providing a\nbig_feeSmt or a big _value. Consequently, the check can be passed\nbecause the summation is a small value due to integer overflow,\nand the account _toormsg.sender will receive a great amount of\ntokens (Lines 3, 5).\n1 function transferFrom (address _from, address _to, uint256 _value) ... { \n   ...... \n2 uint256 balanceFrom = balances[_from];  \n   ...... \n3 balances[_to] = safeAdd(balances[_to], _value);  \n4 balances[_from] = safeSub(balanceFrom, _value); ...... } \n1  function transfer(addr ess to, uint256 value) public returns (bool) {  \n2 tokens  = value * 10 ** decimals;  \n3 balance[to]  = balance[to] + tokens;  \n4 balance[owner]  = balance[owner] - tokens;  \n5 emit Transfer(owner, to, tokens);  } \n1 function transferProxy(address _from, address _to, \nuint256 _value, uint256 _feeSmt ... { \n2 if(balances[_from] < _feeSmt + _value) revert();  \n3    balances[_to] += _value;  \n4 Transfer(_from, _to, _value);  \n5 balances[msg.sender] += _feeSmt;  \n6 Transfer(_from, msg.sender, _feeSmt);  \n7 balances[_from] -= _value + _feeS mt;...} \nFigure 32: Code snippet of SMT token.\nTokenScope detects a transaction (transaction hash: 0x1abab4c8\ndb9a30e703114528e31dee129a3a758f7f8abc3b6494aad3d304e43f) w-\nhich exploited the vulnerability. In this attack, _from and_toare the\nsame account, and _msg.sender is a different account. The balances\nof the two accounts before the attack are 0. The attacking transac-\ntion sets _value and_feeSmt to two big integers, 0x8ffffffffffffffff\nfffffffffffffffffffffffffffffffffffffffffffffff and 0x700000000000000000\n0000000000000000000000000000000000000000000001, respectively.\nHence, the summation of _value and_feeSmt is 0 due to integer\noverflow. After the attack, the balance of _from (or_to) becomes0x8fffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff, and the bal-\nance of _msg.sender is 0x700000000000000000000000000000000000\n0000000000000000000000000001.\nZXBT . Its token contract does not implement the standard method\ntransfer() . Consequently, when a user attempts to invoke transfer() ,\nthe unnamed method will be invoked instead. ZXBT can be traded\non EtherDelta [ 9], which deploys EtherDelta_2 to manage this to-\nken. Due to the implementation issue of ZXBT, user’s token will be\nfrozen. That is, the user can neither withdraw nor sell ZXBT. Fig.\n30 shows the code of EtherDelta_2. A user invokes depositToken()\n(Line 1) to deposit ZXBT to EtherDelta_2, and then invokes with-\ndrawToken() (Line 6) to withdraw ZXBT from EtherDelta_2. Since\nthe implementation of transferFrom() in this token contract is cor-\nrect, the user successfully deposits ZXBT to EtherDelta_2. However,\nthe user cannot withdraw ZXBT because EtherDelta_2 invokes the\nunnamed method, which does not transfer tokens, rather than the\ntransfer() (Line 10). We found that 7,115,006 ZXBT is frozen which\nwas worth about 3,000 USD when ZXBT was deposited.\nGTN. Its contract does not implement the standard method transf-\nerFrom() . Therefore, when a user attempts to invoke its transferFrom() ,\nthe unnamed method will be invoked. We find that the GTN token\ncan also be traded on EtherDelta. Consequently, the method deposit-\nToken() does not transfer GTN to Etherdelta_2 (shown in Fig. 30)\nbecause it invokes the unnamed method rather than transferFrom()\n(Line 3). However, Etherdelta_2 is not aware of the implementation\nissue in the token contract of GTN, and hence it mistakenly records\nthat a user deposits GTN to Etherdelta_2 (Line 4). By invoking\nwithdrawToken(), a user can withdraw GTN (Line 10), although\nthe user does not deposit GTN. Hence, an attacker can exploit this\nimplementation flaw to steal GTN from Etherdelta_2. We observe\nthat two accounts successfully exploited the issue to steal 3,000,000\nGTN from Etherdelta_2. Besides GTN, attackers stole Tablow Club\nand MCRT from Etherdelta_2 due to the same reason.\n8 DISCUSSION\nWe discuss the limitations of TokenScope and potential solutions.\nOther token standards. We focus on 2 standard interfaces transfer()\nand transferFrom() and 1 standard event Transfer defined in ERC-\n20. Fortunately, to be compatible with ERC-20 or at least avoid con-\nflicting with ERC-20, other standards typically support transfer() ,\ntransferFrom() and Transfer defined in ERC-20. We will extend\nTokenScope to support other standard methods and events of ERC-\n20 as well as other token standards in future work.\nDeliberate evasion. Smart contracts can deliberately evade the de-\ntection of TokenScope by using other data structures instead of those\nrecognized by TokenScope . However, using a deliberately crafted\ndata structure for Mmay lead to a more complicated implemen-\ntation of the token contract, and thus increase the cost (i.e., gas)\nof deploying and invoking the token. We will investigate how to\nautomatically infer the data structures and accessing patterns of M\nin future work. Such automatic inference is possible because the\ntwo storage locations (i.e., the space to store balances) derived from\nthe two addresses (i.e., the token sender and the token receiver)\nwill be written when token transfers. By monitoring the access\nto the two storage locations, we can learn the access pattern and\nthen infer the data structure. In particular, we will first conduct pro-\ngram slice to extract the operations that are related to the storage\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1518modifications, and then identify the access patterns from the slices.\nAnother possible evasion approach to disperse a typical token be-\nhavior (e.g., token transfer) into several methods and then perform\nthe token behavior by sending several external transactions to in-\nvoke those methods (i.e., one external transaction just triggers part\nof a typical token behavior). Thus, TokenScope may produce false\npositives because it detects inconsistency per trace which is corre-\nsponding to one external transaction. We will improve TokenScope\nby conducting cross-transaction analysis in future work.\n9 RELATED WORK\nToken analysis. Somin et al. identify token transfers by parsing\nthe Transfer event [ 56], which does not necessarily reflect real\ntoken behaviors. The differences between our work with Fröwis\net al.’s work [ 20] are described in §1. SECBIT maintains a collection\nof buggy ERC-20 tokens [ 52], but it mainly focuses on common\ntoken problems (e.g., weak access control) rather than inconsistency,\nand we find that about 95.7% of inconsistent tokens detected by\nTokenScope are not disclosed in its list.\nVulnerability discovery. SmartCheck detects 21 kinds of bugs in\nSolidity source code by searching for bug patterns [ 57]. It cannot be\neasily extended to detect inconsistency in EVM bytecode because (1)\nit needs the source code of smart contracts; and (2) the detection of\ninconsistency needs to understand program semantics but pattern\nsearching does not support it. EtherTrust [24] detects two kinds\nof security bugs based on formal semantics of EVM bytecode [ 25].\nVandal decompiles EVM bytecode into semantic logic relations and\ndetects five kinds of security problems which are expressed by logic\nspecifications [ 3].MadMax detects security problems using Vandal for\nbytecode decompilation [ 23].Sereum builds on-line taint analysis\ninto EVM to protect smart contracts from reentrancy attacks [48].\nteEther produces transactions by symbolic execution (SE) to\nfind and exploit the vulnerabilities of a smart contract [ 35].Osiris\ncombines SE and taint analysis to discover integer overflow bugs in\nEVM bytecode [ 58].EthRacer integrates fuzzing of event sequences\nand SE to check whether a contract produces different outputs by\nre-ordering event sequences [ 34].sCompile applies SE to critical\npaths which involve money transfer, and leaves the other paths\nunexplored [ 4]. Huang detects security problems in EVM bytecode\nvia deep learning [ 29]. Parizi et al. study four tools about their\ncapabilities to discover security bugs [ 43], and find that SmartCheck\nachieves the highest accuracy [ 43].ContractFuzzer applies fuzzing\nto discover seven kinds of security problems [ 30]. Grossman et\nal. detect the reentrancy bug by focusing on the callback nature\nof smart contracts [ 26]. In summary, these techniques focus on\nvulnerability discovery, especially security vulnerabilities rather\nthan inconsistent token behaviors violating ERC-20.\nGeneral analysis platforms. Kframework [ 49,50] is based on\nthe formal semantic of KEVM [27] and is possible to detect the in-\nconsistency happened in standard methods because the semantics\nof standard methods interfaces are known. However, Kframework\nis not fully automated. For example, to apply it for checking in-\nconsistency, users have to provide the identity of Min the specifi-\ncation. Differently, our approach locates Mautomatically. Second,\nKframework requires the developers of token contracts to write\nspecifications for analyzing non-standard methods since their se-\nmantics are unknown. Differently, our approach can automaticallydetect the inconsistency in non-standard methods. Chatterjee et al.\npropose to infer the lower bound and upper bound of a variable in\ntheir proposed language [ 5]. The contract is considered as an incor-\nrect one if the expected value does not fall into the interval [lower\nbound, upper bound] [ 5]. However, their method may suffer from\nfalse negatives, e.g., an incorrect value can also fall into the interval.\nMoreover, inference of the expected value is non-trivial because it\nrequires a deep understanding of the analyzed contract and the se-\nmantics of EVM operations. A few works propose formal semantics\nof EVM and EVM bytecode [ 1,25,28,31] to facilitate correctness\nverification, but they do not provide an automated verifier.\nSecurify [59] decompiles EVM bytecode, and uses a domain-\nspecific language (DSL) to express several security properties. Then,\nit analyzes smart contracts to check those security properties. Securify\ndoes not recover the types of variables during decompilation, and\nhence it cannot locate Min a token contract. Besides, whether DSL\ncan express inconsistency is unknown. Zeus [32] is a security ver-\nifier that needs the source code of smart contracts. It converts\nthe specification written in XACML [ 55] into checking code, and\nthen inserts the checking code into the source code of smart con-\ntracts. After that, Zeus translates the modified source code into\nan intermediate language, and then applies abstract interpretation\nand symbolic model checking to check security properties. The\napplicability of Zeus is restricted since open-source smart contracts\nonly account for less than 1% of all contracts [ 19]. In contrast, our\napproach directly processes EVM bytecode. Moreover, whether\nXACML is able to express inconsistency is unknown.\n10 CONCLUSION\nInconsistent behaviors can mislead users and cause severe financial\nloss, such as money frozen and money stolen. We propose a novel\napproach and develop a new tool named TokenScope to automati-\ncally detect inconsistent behaviors resulted from tokens deployed\nin Ethereum by comparing the information from three different\nsources, including the manipulations of core data structures, the ac-\ntions indicated by standard interfaces, and the behaviors suggested\nby standard events. Applying TokenScope to inspect all transactions\nsent to all deployed tokens, we find 3,259,001 transactions which\ntrigger inconsistent behaviors, and 7,472 inconsistent tokens with\na very high precision. The investigation of all open-source incon-\nsistent tokens reveals 11 major reasons behind the inconsistency,\nincluding 50 unreported flawed tokens.\nACKNOWLEDGEMENT\nTing Chen is partially supported by National Natural Science Foun-\ndation of China (61872057) and National Key R&D Program of\nChina (2018YFB0804100). Ting Wang is partially supported by the\nNational Science Foundation under Grant No. 1718787 and 1846151.\nREFERENCES\n[1]Sidney Amani, Myriam Bégel, Maksym Bortin, and Mark Staples. 2018. Towards\nverifying ethereum smart contract bytecode in Isabelle/HOL. In ACM SIGPLAN\nInternational Conference on Certified Programs and Proofs.\n[2]Karthikeyan Bhargavan, Antoine Delignat-Lavaud, Cédric Fournet, Anitha Gol-\nlamudi, Georges Gonthier, Nadim Kobeissi, Natalia Kulatova, Aseem Rastogi,\nThomas Sibut-Pinote, Nkhil Swamy, and Santiago Zanella-Béguelin. 2016. Formal\nverification of smart contracts: Short paper. In ACM Workshop on Programming\nLanguages and Analysis for Security.\n[3]Lexi Brent, Anton Jurisevic, Michael Kong, Eric Liu, Francois Gauthier, Vincent\nGramoli, Ralph Holz, and Bernhard Scholz. 2018. Vandal: A Scalable Security\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1519Analysis Framework for Smart Contracts. https://arxiv.org/pdf/1809.03981.pdf.\n(2018).\n[4]Jialiang Chang, Bo Gao, Hao Xiao, Jun Sun, and Zijiang Yang. 2018. sCompile:\nCritical Path Identification and Analysis for Smart Contracts. https://arxiv.org/\npdf/1808.00624.pdf. (2018).\n[5]Krishnendu Chatterjee, Amir Kafshdar Goharshady, and Yaron Velner. 2018.\nQuantitative Analysis of Smart Contracts. In European Symposium on Program-\nming.\n[6]Ting Chen, Xiaoqi Li, Xiapu Luo, and Xiaosong Zhang. 2017. Under-optimized\nsmart contracts devour your money. In International Conference on Software\nAnalysis, Evolution and Reengineering.\n[7]Curvegrid. 2018. toy-block-explorer. https://github.com/curvegrid/toy-block-e\nxplorer. (2018).\n[8]enkrypt. 2018. EthVM: Open Source Ethereum Blockchain Explorer. https:\n//github.com/enKryptIO/ethvm. (2018).\n[9] EtherDelta. 2018. EtherDelta. https://etherdelta.com/. (2018).\n[10] Ethereum. 2017. ERC223 token standard. https://github.com/ethereum/EIPs/iss\nues/223. (2017).\n[11] Ethereum. 2017. Management APIs. https://github.com/ethereum/go-ethereum/\nwiki/Management-APIs. (2017).\n[12] Ethereum. 2017. Token Standard Extension for Increasing & Decreasing Supply.\nhttps://github.com/ethereum/EIPs/pull/621. (2017).\n[13] Ethereum. 2018. ETCExplorer. https://github.com/ethereumclassic/explorer.\n(2018).\n[14] Ethereum. 2018. Etherscan — The Ethereum Block Explorer. https://etherscan.io/.\n(2018).\n[15] EtherEx. 2018. EthEx: Decentralized exchange built on Ethereum. https://github\n.com/etherex/etherex. (2018).\n[16] Etherscan. 2018. Token Tracker. https://etherscan.io/tokens. (2018).\n[17] Etherscan. 2019. Decentralized Exchange Order Tracker. https://etherscan.io/d\nextracker. (2019).\n[18] Etherwall. 2018. Etherwall: The first Ethereum desktop wallet. https://www.et\nherwall.com/. (2018).\n[19] Michael Fröwis and Rainer Böhme. 2017. In Code We Trust? Measuring the Con-\ntrol Flow Immutability of All Smart Contracts Deployed on Ethereum. In Interna-\ntional Workshops on Data Privacy Management, Cryptocurrencies and Blockchain\nTechnology.\n[20] Michael Fröwis, Andreas Fuchs, and Rainer Böhme. 2018. Detecting Token\nSystems on Ethereum. https://arxiv.org/pdf/1811.11645.pdf. (2018).\n[21] FunFairTech. 2017. Funfair token contract update. https://www.reddit.com/r/F\nunfairTech/comments/6nadvm/funfair_token_contract_update/. (2017).\n[22] Google. 2019. Ethereum ETL. https://github.com/blockchain-etl/ethereum-etl.\n(2019).\n[23] N. Grech, M. Kong, A. Jurisevic, L. Brent, B. Scholz, and Y. Smaragdakis. 2018.\nMadMax: Surviving Out-of-Gas Conditions in Ethereum Smart Contracts. In ACM\ninternational conference on Object-oriented Programming, Systems, Languages, and\nApplications.\n[24] Ilya Grishchenko, Matteo Maffei, and Clara Schneidewind. 2018. EtherTrust:\nSound Static Analysis of Ethereum bytecode. https://www.netidee.at/sites/def\nault/files/2018-07/staticanalysis.pdf. (2018).\n[25] Ilya Grishchenko, Matteo Maffei, and Clara Schneidewind. 2018. A Semantic\nFramework for the Security Analysis of Ethereum smart contracts. In International\nConference on Principles of Security and Trust.\n[26] Shelly Grossman, Ittai Abraham, Guy Golan-Gueta, Yan Michalevsky, Noam\nRinetzky, Mooly Sagiv, and Yoni Zohar. 2017. Online detection of effectively\ncallback free objects with applications to smart contracts. In ACM SIGPLAN\nSymposium on Principles of Programming Languages.\n[27] Everett Hildenbrandt, Manasvi Saxena, Xiaoran Zhu, Nishant Ro-\ndrigues, Philip Daian, Dwight Guth, , and Grigore Rosu. 2017.\nKEVM: A Complete Semantics of the Ethereum Virtual Machine.\nhttps://www.ideals.illinois.edu/bitstream/handle/2142/97207/hildenbrandt\n-saxena-zhu-rodrigues-guth-daian-rosu-2017-tr.pdf?sequence=2. (2017).\n[28] Yoichi Hirai. 2017. Defining the ethereum virtual machine for interactive theorem\nprovers. In International Conference on Financial Cryptography and Data Security.\n[29] TonTon Hsien-De Huang. 2018. Hunting the Ethereum Smart Contract: Color-\ninspired Inspection of Potential Attacks. https://arxiv.org/pdf/1807.01868.pdf.\n(2018).\n[30] Bo Jiang, Ye Liu, and W. K. Chan. 2018. ContractFuzzer: fuzzing smart contracts\nfor vulnerability detection. In ACM/IEEE International Conference on Automated\nSoftware Engineering.\n[31] Jiao Jiao, Shuanglong Kan, Shang-Wei Lin, David Sanan, Yang Liu, and Jun Sun.\n2018. Executable Operational Semantics of Solidity. https://arxiv.org/pdf/1804.0\n1295.pdf. (2018).\n[32] Sukrit Kalra, Seep Goel, Mohan Dhawan, and Subodh Sharma. 2018. Zeus:\nAnalyzing safety of smart contracts. In The Network and Distributed System\nSecurity Symposium.\n[33] Kaustav. 2018. The Effects of the ERC20 Batch Overflow Bug. https://globalcoin\nreport.com/the-effects-of-the-erc20-batch-overflow-bug/. (2018).\n[34] Aashish Kolluri, Ivica Nikolic, Ilya Sergey, Aquinas Hobor, and Prateek Saxena.\n2018. Exploiting The Laws of Order in Smart Contracts. https://arxiv.org/pdf/1810.11605.pdf. (2018).\n[35] Johannes Krupp and Christian Rossow. 2018. teEther: Gnawing at ethereum to\nautomatically exploit smart contracts. In USENIX Security Symposium.\n[36] Loi Luu, Duc-Hiep Chu, Hrishi Olickel, Prateek Saxena, and Aquinas Hobor. 2016.\nMaking smart contracts smarter. In ACM SIGSAC Conference on Computer and\nCommunications Security.\n[37] METAMASK. 2018. METAMASK — Brings Ethereum to your browser. https:\n//metamask.io/. (2018).\n[38] MyEtherWallet. 2018. MyEtherWallet. https://www.myetherwallet.com/. (2018).\n[39] Mythril. 2018. Mythril Platform enables a secure and thriving ecosystem of\nEthereum dapps & smarts contracts. https://mythril.ai/. (2018).\n[40] OKCoin. 2018. OKEx Safe from USDT \"Fake Deposit\" Issue.\nhttps://support.okex.com/hc/en-us/articles/360006305532-OKEx-Safe-fro\nm-USDT-Fake-Deposit-Issue. (2018).\n[41] openANX. 2017. openANX: Decentralised Exchange Token Sale Smart Contract.\nhttps://github.com/openanx/OpenANXToken. (2017).\n[42] OpenZeppelin. 2019. SafeMath Library. https://github.com/OpenZeppelin/open\nzeppelin-solidity/blob/master/contracts/math/SafeMath.sol. (2019).\n[43] Reza M. Parizi, Ali Dehghantanha, Kim-Kwang Raymond Choo, and Amritraj\nSingh. 2018. Empirical Vulnerability Analysis of Automated Smart Contracts\nSecurity Testing on Blockchains. In Annual International Conference on Computer\nScience and Software Engineering.\n[44] peckchield. 2018. New proxyOverflow Bug in Multiple ERC20 Smart Contracts\n(CVE-2018-10376). https://blog.peckshield.com/2018/04/25/proxyOverflow/.\n(2018).\n[45] PeckShield. 2018. New proxyOverflow Bug in Multiple ERC20 Smart Contracts\n(CVE-2018-10376). https://blog.peckshield.com/2018/04/25/proxyOverflow/.\n(2018).\n[46] Plutocracy. 2019. Krown whitepaper. https://plutocracy.co/resources/pdf/Plutoc\nracy_Whitepaper.pdf. (2019).\n[47] POA. 2018. BlockScout, Blockchain Explorer for inspecting and analyzing EVM\nChains. https://github.com/poanetwork/blockscout. (2018).\n[48] Michael Rodler, Wenting Li, Ghassan O. Karame, and Lucas Davi. 2019. Sereum:\nProtecting Existing Smart Contracts Against Re-Entrancy Attacks. In The Network\nand Distributed System Security Symposium.\n[49] Grigore Rosu. 2017. K: A Semantic Framework for Programming Languages and\nFormal Analysis Tools.\n[50] Grigore Rosu. 2018. Formal Design, Implementation and Verification of\nBlockchain Languages (Invited Talk). In Leibniz International Proceedings in\nInformatics.\n[51] Amitabha Sanyal, Bageshri Sathe, and Uday Khedker. 2009. Data flow analysis:\ntheory and practice. CRC Press, 2009. CRC Press.\n[52] SECBIT. 2018. bad_tokens.all.csv. https://github.com/sec-bit/awesome-buggy-e\nrc20-tokens/blob/master/bad_tokens.all.csv. (2018).\n[53] Oguz Serdar. 2018. Ethereum bug causes integer overflow in numerous ERC20\nsmart contracts [Update]. https://thenextweb.com/hardfork/2018/04/25/ethereu\nm-smart-contract-integer-overflow/. (2018).\n[54] Matthew De Silva. 2017. Ethereum Improvement Proposal 20 Finalized, Formally\nEstablishes ERC20 Standard. https://www.ethnews.com/ethereum-improveme\nnt-proposal-20-finalized-formally-establishes-erc20-standard. (2017).\n[55] Remon Sinnema. 2013. eXtensible Access Control Markup Language (XACML)\nXML Media Type. https://tools.ietf.org/html/rfc7061. (2013).\n[56] Shahar Somin, Goren Gordon, and Yaniv Altshuler. 2018. Network Analysis of\nERC20 Tokens Trading on Ethereum Blockchain. In International Conference on\nComplex Systems.\n[57] Sergei Tikhomirov, Ekaterina Voskresenskaya, Ivan Ivanitskiy, Ramil Takhaviev,\nEvgeny Marchenko, and Yaroslav Alexandrov. 2016. SmartCheck: Static Analysis\nof Ethereum Smart Contracts. In IEEE/ACM International Workshop on Emerging\nTrends in Software Engineering for Blockchain.\n[58] Christof Ferreira Torres, Julian Schütte, and Radu State. 2018. Osiris: Hunting\nfor Integer Bugs in Ethereum Smart Contracts. In Annual Computer Security\nApplications Conference.\n[59] Petar Tsankov, Andrei Dan, Dana Drachsler-Cohen, Arthur Gervais, Florian\nBünzli, and Martin Vechev. 2018. Securify: Practical Security Analysis of Smart\nContracts. In ACM SIGSAC Conference on Computer and Communications Security.\n[60] Haijun Wang, Yi Li, Shangwei Lin, Lei May, and Yang Liu. 2019. VULTRON:\nCatching Vulnerable Smart Contracts Once and for All. In International Conference\non Software Engineering – NIER.\n[61] Tielei Wang, Tao Wei, Zhiqiang Lin, and Wei Zou. 2009. IntScope: Automati-\ncally Detecting Integer Overflow Vulnerability in X86 Binary Using Symbolic\nExecution. In The Network and Distributed System Security Symposium.\n[62] WIKI. 2018. ERC20 Token Standard. https://github.com/ethereum/EIPs/blob/ma\nster/EIPS/eip-20.md. (2018).\n[63] Gavin Wood. 2018. Ethereum: A Secure Decentralised Generalised Transaction\nLedger. https://ethereum.github.io/yellowpaper/paper.pdf. (2018).\n[64] ZeusTrade. 2018. Topic: there was a coin out of my wallet that I did not even get\nwhat it is. https://bitcointalk.org/index.php?topic=5023796.0. (2018).\nSession 7B: Blockchain III\nCCS ’19, November 11–15, 2019, London, United Kingdom\n1520"}
{"title": "Towards Transparent and Stealthy Android OS Sandboxing via Customizable Container-Based Virtualization", "content": "Towards Transparent and Stealthy Android OS Sandboxing via\nCustomizable Container-Based Virtualization\nWenna Song1,2, Jiang Ming3,†, Lin Jiang4, Yi Xiang1,2, Xuanchen Pan5, Jianming Fu1,2\nGuojun Peng1,2,†\n1School of Cyber Science and Engineering, Wuhan University, China\n2Key Laboratory of Aerospace Information Security and Trusted Computing, Ministry of Education, China\n3University of Texas at Arlington, USA\n4Independent Researcher,5Wuhan Antiy Information Technology Co.,Ltd, China\nABSTRACT\nAfast-growingdemandfromsmartphoneusersismobilevirtualiza-\ntion. This technique supports running separate instances of virtual\nphoneenvironmentsonthesamedevice.Inthisway,userscanrun\nmultiple copies of the same app simultaneously, and they can also\nrun an untrusted app in an isolated virtual phone without causing\ndamages to other apps. Traditional hypervisor-based virtualiza-\ntionisimpracticaltoresource-constrainedmobiledevices.Recent\napp-levelvirtualizationeffortssufferfromtheweakisolationmech-\nanism. In contrast, container-based virtualization offers an isolated\nvirtual environment with superior performance. However, exist-\ningAndroidcontainersdonotmeettheanti-evasionrequirement\nfor security applications: their designs are inherently incapable of\nproviding transparency or stealthiness.\nIn this paper, we present VPBox, a novel Android OS-level sand-\nbox framework via container-based virtualization. We integrate\ntheprincipleofanti-virtual-machinedetectionintoVPBox’sdesign\nfromtwoaspects. First,weimprovethestate-of-the-artAndroid\ncontainerworksignificantlyfortransparency.Wearethefirstto\noffer complete device virtualization on mainstream Android ver-\nsions.TominimizethefingerprintsofVPBox’spresence,weenable\nall virtualization components (i.e., kernel-level device and user-\nleveldevicevirtualization)tobeexecutedoutsideofvirtualphones\n(VPs).Second, we offer new functionality that security analysts\ncancustomizedeviceartifacts(e.g.,phonemodel,kernelversion,\nand hardware profiles) without user-level hooking. This capabil-itypreventsthetestedappsfromdetectingtheparticularmobiledevice (e.g., Google Pixel phone) that runs an Android container.Our performance evaluation on five VPs shows that VPBox runsdifferent benchmark apps at nativ e speed. Compar ed with other\nAndroid sandboxes, VPBox is the only one that can bypass a set of\nvirtual environmentdetection heuristics.At last, wedemonstrate\nVPBox’sflexibilityintestingenvironment-sensitivemalwarethat\ntries to evade sandboxes.\n†Guojun Peng (guojpeng@whu.edu.cn) and Jiang Ming (jiang.ming@uta.edu) are the\ncorresponding authors.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n© 2021 Association for Computing Machinery.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3484544CCS CONCEPTS\n•Security and privacy →Mobile and wireless security.\nKEYWORDS\nContainer-Based Virtualization, Android OS Sandboxing, Anti-\nEvasion\nACM Reference Format:\nWenna Song, Jiang Ming, Lin Jiang, Yi Xiang, Xuanchen Pan, Jianming\nFu, Guojun Peng. 2021. Towards Transparent and Stealthy Android OS\nSandboxingviaCustomizableContainer-BasedVirtualization.In Proceedings\nof the 2021 ACM SIGSAC Conference on Computer and Communications\nSecurity(CCS’21),November15–19,2021,VirtualEvent,RepublicofKorea.\nACM,NewYork,NY,USA,17pages.https://doi.org/10.1145/3460120.3484544\n1 INTRODUCTION\nWith the proliferation of mobile systems and networks, smart-\nphones are replacing traditional personal computers to fulfill most\nusers’ daily computing needs [ 22,27]. The trend of Bring Your\nOwnDevice[ 13]haspavedthewayforanotherfast-growingde-\nmand:mobilevirtualization.Itallowsuserstorunmultiple separate\ninstances of smartphone environments on the same physical de-\nvice. Although Android’s multiple users features [ 7] can switch\namong different user accounts without leveraging virtualization,\nresearchershavefoundasignificantnumberofvulnerabilitiesfrom\nthis new feature due to its weak isolation mechanism [ 1,52]. Espe-\ncially,mobileappsarenowperformingvariouscriticaltaskssuch\nasonlinepayment[ 76],GPSnavigation[ 68],andIoTdeviceremote\ncontrol [32]. Inevitably large amounts of private data, such as user\ncredentialsandlocationdata,arestoredinthesmartphone.Therise\ninrisksofdatatheftsandfraudulentattacks[ 33,38]alsodrivesthe\ntrendofsecuremobilevirtualization,whichcanprovideanisolated\nenvironment to run untrusted apps and monitor their behaviors.\nResource-constrained mobile devices limit the adoption of tradi-\ntional hypervisor-based virtualization [ 14,21,59]. Security experts\nandresearchershavebeenanalyzingAndroidappsdynamicallyus-ingemulators[\n41,43,53,64,75]ontopofaPC.However,traditional\nAndroid emulators are often slow in performance and leave plenty\nof fingerprints regarding the runtime environment, hardware ef-\nfects,anddeviceartifacts.Astheyarefundamentallydifferentfromrealdevices,abroadspectrumofanti-emulationheuristicshasbeen\nproposed to detect emulators [ 16,30,34,45,50,55,69]. The recent\nprogress on app-level virtualization can run multiple copies of the\nsame app within a host app [ 11,12,51]. The most representative\none, Parallel Space [ 42], has been downloaded hundreds of mil-\nliontimes.However,theirweakisolationmechanismviolatesthe\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2858\nleast-privilege principle, leading to possible permission escalation\nattacks to guest apps [20, 56, 57, 77, 78].\nIncontrast,container-basedvirtualizationcanpotentiallyover-\ncome the limitations that exist on both hypervisor-based and app-\nlevel virtualization. It is lightweight OS-level virtualization that\nallows several isolated guest virtual machines to run on top ofthe Operating System (OS) kernel [\n28,61]. Because a container\nis managed by the OS kernel and executes directly on the hard-\nware, it is able to provide a close-to-native virtual environmentwith high performance. Moreover, as a container does not have\nsoftware-emulated hardware, the fingerprint of its presence is also\nminimized [18, 36, 37].\nCells [10] is the first Android container architecture to run mul-\ntiplevirtualphones(VPs)onasingle Androidinstance.H owever,\nthe design of Cells does not meet the anti-evasion requirement.\nIts user-level virtualization method introduces non-system compo-\nnents into the VP. The VP’s apps, running at the same privilege\nlevelasthesevirtualizationcomponents,canfindsuspiciousfiles\nand processes via interface scanning. Besides, Cells’s virtualization\nof many devices has been obsolete (e.g., Binder, Network, Display,\nand Power), and it also lacks support for some essential devices,\nsuchasBluetoothandGPS.Furthermore,Cellsisinherentlyinca-\npable of customizing the VP’s device attributes stealthily. All ofthese limitations (i.e., the deficiency in stealthiness, incomplete\ndevicevirtualization,andalackofdeviceattributecustomization)\ncanbeexploitedbyadversariestofingerprintthepresenceofthe\nVP. Otherfollow-up container frameworks[ 17,71,73] sharesimi-\nlar limitations of lacking transparency and stealthiness, restricting\ntheir applications to security-related tasks.\nThis project seeks to integrate the principle of anti-evasion into\nthe development of a new Android OS-level sandbox, called VP-\nBox.1Weachievethisgoalthroughtwocontributions:1)improving\nthe state-of-the-art Android container work significantly so that\ntransparent virtualization works on mainstream Android versions;\n2) customizing the virtual phone’s device attributes stealthily to\nbypass the ad-hoc fingerprinting for a specific phone model.\nIn particular, we improve Cells [ 10] significantly to achieve the\ngoalof“out-of-the-box ”virtualization:havingnoin-guestvirtual-\nizationcomponent.VPBoxconsistsofkernel-levelanduser-level\ndevicevirtualizationmethods.Thekernel-levelmechanismenables\ntransparencyandperformance,anditalsopavesthewayforour\nnovel user-leveldevice virtualization.For theproprietarydevices\nthat are entirely closed source (e.g., Bluetooth) and the devices\nwhoseconfigurationshappenatuserspace(e.g.,WiFi),wepropose\na stealthy user-level device virtualization mechanism without com-\npromising transparency. In addition, we take a set of optimization\ntechniquestominimizememoryconsumption.Toenforceafine-\ngrainedaccesscontrolpolicyandrecordsystemcallsinvoked,we\nalso virtualize SELinux to enable SELinux settings for each VP.\nAlthough apps are difficult to recognize the difference between\nVPBox and the underlying physical device, they can still finger-\nprint the particular smartphone (e.g., Google Pixel phone) that\nrunsVPBox.Weaddressthislimitationbyallowinguserstoconfig-\nure the VP with various device attributes (e.g., phone model and\nhardwareprofiles).Unlikeexistingworkthatreliesonuser-level\n1“VPBox” means running VirtualPhones as an OS-level SandBox.hooking [ 54], our customization methods are more stealthy be-\ncausetheyrunoutsideoftheVP.VPBoxleveragesthenew device\nnamespace mechanism to isolate the VP’s requests from the host’s,\nand it returns the custom parameters to the VP’s inquiries. Our\nisolation design ensures that an app in the VP is unaware of the\ncustom device artifacts. This new feature also enables security ap-\nplicationsthatrequirediversifiedvirtualphones,suchasanalyzing\nlogic bombs [29] that are triggered by particular device artifacts.\nVPBox has been tested to support Android versions from 6.0\nto 10.0. Our performance experiments, running a set of bench-\nmark apps in up to five VPs on Google Nexus 6P and Pixel 3a\nXL phones, demonstrate that VPBox introduces negligible runtime\noverheadandonlymodestmemoryconsumption.Unlikeemulators,\nVPBox’s native performance indicates measuring execution time’s\nvariabilitywillfailtodetectit.Next,wetestAndroidemulators,app-virtualizationsandboxes,andAndroidcontainersusingmainstream\nvirtual environment detection heuristics [ 16,34,50,55,56,69,78],\nsuch as detecting Android system properties, sensor events, video\nframe rate, and instruction-level profiles. VPBox is the only one to\nexhibit the same hardware effects and device artifacts as the under-\nlying physical device. Besides, VPBox is immune to two advanced\nunsafeenvironmentdetectionAPIs:GoogleSafetyNet’s“basicIn-\ntegrity” [5] and ishumei [ 60]. They can recognize the environment\nofAndroidemulators,app-levelvirtualization,APIhooking,and\nrooted device, but they fail to detect VPBox. At last, we evaluate\nVPBox’sresilienceagainst1 ,961environment-sensitivemalware,\nincluding samples that try to detect Google phones.\nThreat Model. We assume the apps running in the VP are\nunprivileged user-mode programs. This assumption is also held\nby bare-metal malware analysis frameworks such as BareBox [ 39]\nand BareDroid [ 48]. That being said, a skilled attacker may exploit\naLinuxkernelzero-dayvulnerabilitytocompromiseVPBox.For\nthis reason, we disable the loading of arbitrary kernel modules\nand prevent user-level apps from accessing kernel memory. §9 will\ndiscusswhetherVPBoxintroducesthenewartifacts(ifany)that\ncan be exploited by adversaries. In a nutshell, our research makes\nthe following contributions.\n•ATransparentAndroidContainerFramework. VPBox\nrepresents the latest progress in mobile container-based vir-\ntualization.Our“out-of-the-box”designadvancesstateofthe\nartintransparentdevicevirtualization.Ouruser-levelvir-\ntualization solution offers a flexible and stealthy alternative\ntovirtualizenewhardwaredeviceswithoutcompromising\ntransparency.\n•Device Attribute Customization. In VPBox, each VP’s\nartifactsarehighlycustomizablewithoutuser-levelhooking.\nThisnewfeatureoffersacost-effectivewaytosimulatemore\ndiversified VPs on a single device. To the best of our know-\nledge,VPBoxoffersthemostcomprehensivedevice-attribute\nediting options so far.\n•Open-source Implementation. VPBox reveals a strong\nresilienceagainstvirtual-machinedetectionheuristicsand\ndevice-consistency checks, as well as native performance.\nVPBox’s demo video is available at https://youtu.be/TpGD_\njjxSqc.TofostermoreresearchontheVPBoxplatform,we\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2859release VPBox’s source code at (https://github.com/VPBox/\nDev).\n2 BACKGROUND AND RELATED WORK\nWefirstsummarizetwocommonAndroidvirtualizationtechniques\nthat do not rely on new hardware features (e.g., TrustZone [ 35]):\nAndroid emulators and app-level virtualization. Their deficiencies\ninlackingtransparencyandstealthinesshavebeenutilizedaseffec-\ntiveevasionmethods.Next,wediscussthestatusquoofAndroid\ncontainer-based virtualization. It is a new style, lightweight vir-\ntualization technique, but the weaknesses of existing containers\nseverely limittheir adoptions in securityapplications. Our project\nunleashes the power of container-based virtualization to foster\nstrengths and circumvent weaknesses of the current work. At last,\nwe introduce the background about Binder. Our Binder virtual-\nization enables having no in-guest virtualization component at\nuser-level.\n2.1 Android Emulators\nAndroid sandboxes based on full-system emulation provide an iso-\nlatedenvironmenttocollectappbehaviors[ 41,43,53,64,75].Upon\nanalysiscompletion,thevirtualenvironmentcanberestoredtoa\ncleansnapshotinamatterofseconds.Securityanalyststypically\nrunAndroidmalwareinanemulatortoobservemaliciousbehaviors.\nHowever, a long-standing challenge of emulators is to virtualize\nvarious hardware device effects realistically. It is fundamentally\ninfeasible to make hardware emulation and native hardware in-\ndistinguishable [ 31]. Researchers haveproposed a set ofdetection\nheuristicstofindthehardware-relateddiscrepanciescausedbynon-transparentsystememulationtechniques[\n16,30,34,45,50,55,69],\nandmanyofthemhavebeenadoptedbymalware[ 3].Forexample,\nduetotheperformanceslowdowningraphicsrenderingemulation,\nAndroid emulators typically exhibit a low video frame rate [ 69].\nPetsas et al. detect QEMU-based emulators by checking the vir-\ntual program counter update and cache consistency [ 50]. Bordoni\netal.findthatsensor-relatedAPIs’returnvaluesaredifferentbe-\ntweenmobileemulatorsandrealdevices[ 16].Sahinetal.uncovered\ninstruction-leveldiscrepancies betweensoftware-based emulators\nand real ARM CPUs [55].\nIncontrast,VPBox’scontainer-basedvirtualizationhasaunique\nadvantage in the transparent virtualization effect: VPBox does not\nhavesoftware-emulatedhardware,andtheforegroundVPcanal-\nways access hardware devices and run apps at nativ espeed.\n2.2 App-Level Virtualization\nTherecentapp-virtualizationdevelopment(e.g.,VirtualApp[ 11],\nDroidPlugin [ 51], and Parallel Space [ 42]) provides a more light-\nweight option to run multiple copies of the same app on a single\ndevice, such as accessing Facebook simultaneously with two dif-\nferentaccounts.Thekeyideaisthatahostappprovidesavirtual\nenvironment ontop of theAndroid framework,and it createssys-\ntem service proxies to launch arbitrary guest apps from their APK\nfileswithoutinstallation.Duetothedynamicproxyhooking,the\nactions from a guest app will be treated by the Android system as\nthe host app’s actions. In this way, two copies of the same app are\nable to bypass the UID restriction and execute at the same time.Despitethegrowingpopularityofapp-virtualization-basedapps\nin the Android market, researchers have realized the security prob-\nlemscausedbythisnewtechnicalprogress[ 20,56,57,77,78].Asall\nguestappssharethesameUIDwiththehostapp,thecurrentdesign\nintroduces a serious “shared-everything” threat to guest apps [ 56],\nwhich has made malicious attacks such as permission escalation\nand privacy leakage tremendously easier. Although guest apps can\nalsodirectlyaccesstheAndroiddevicethatinstallsthehostapp,the\nhostapphastohookAPIinvocationsoftheguestappsothatthe\nAndroidsystemthinksthatallAPIrequestsandcomponentsare\nfrom the host app. However, the hooking mechanism leaves many\nhost app’s signatures in the guest app’s call stack and memory;\nDiPrint[56]utilizesthesesignaturestodetectthepresenceofan\napp-virtualization environment.\nBy contrast, VPBox can achieve the same goal of running multi-\npleinstancesofthesameappsimultaneously,butwithastronger\nisolation mechanism among virtual phones and the host device.Furthermore, VPBox’s virtualization and customization do notadopt user-level API hooking and thus have better stealthiness\nthan app-level virtualization.\n2.3 Android Container-Based Virtualization\nThe container-based virtualization reveals distinct benefits in per-\nformance and transparent hardware virtualization effects. Initial\ninvestigationsonLinuxContainers[ 18,36]andDocker[ 37]have\nshown that container-based virtualization is very promising to de-\nfeatemulator-awaremalware.However,theseworks[ 18,36,37]did\nnotdeliverafunctionalmobilevirtualizationplatform,andmany\nimportant topics,such as how tohide new artifactsintroduced by\ncontainersandanextensiveevaluationwithexistinganti-virtual-\nmachine heuristics, are still missing. Our research bridges this gap.\nChallenges. Comparedwith theriseof container-basedvirtu-\nalizationinPCandserverplatforms[ 2,26,72],Androidcontainer’s\ndevelopment has to overcome the challenge of hardware resource\nmultiplexing.Especially,manymobiledevicesarephysicallynotdesigned for multiplexing (e.g., WiFi and Bluetooth). For the An-droid OS, at least the devices and pseudo-device drivers listed in\nTable 1 must be fully supported. However, none of the existing\nAndroid containers can meet this goal. Besides, to facilitate a rapid\ntransplantationandupgradeoftheAndroidsystem,Android8.0re-architectedthevendorinterfaceintheAndroidOSframework[\n46].\nThis new update invalidates existing virtualization methods on\nmultiple devices, such as Telephony, Display, Network, and Binder.\nAnother take-away message from Table 1 is that none of the\nexisting work can meet the “out-of-the-box” design; that is, all\nof them have in-guest virtualization components that run at the\nsame privilege level as the VP’s apps. As a result, it is trivial to\ndetectwhetheranappisrunninginthesecontainersbyscanning\nsuspicious non-system files and processes. Furthermore, as shown\ninTable1’sgraycolorrow,noexistingworkcancustomizetheVP’s\ndevice attributes. As we will present in §7, stealthy customization\nis impossible without the “out-of-the-box” virtualization design.\nCells [10]. Cells is the pioneering work of mobile container-\nbased virtualization. Limited by the small-scale touchscreen, Cells\nintroducesausagemodelofhavingoneforegroundVPandother\nVPs running in the background. The VP running in the foreground\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2860Table 1: The comparison of devices, pseudo-device drivers, and services among five Android container-based virtualization\nsolutions.Cellrox[17]isCells’scommercialversion.Thelabels /Circle//CIRCLEindicatethevirtualizationismissing(/Circle)orenabled(/CIRCLE). /LEFTCIRCLE /Circle\nmeansthevirtualizationhasbeenoutdatedinmainstreamAndroidversions.Themarks \u0013/\u0017indicatethedevicevirtualization\nmeets the “out-of-the-box” design (\u0013) or not (\u0017).\nDescription Cells [10] Cellrox [17] Condroid [73] VMOS [71] VPBox\nDevice/Pseudo Device1\nDisplay Display screen graphics /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nFilesystem SD card partition virtualization /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /CIRCLE,\u0013\nPower Power management /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nBinder Inter-process communication /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nInput Touchscreen and input buttons /CIRCLE,\u0013 /CIRCLE,\u0013 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nNetwork Core network resources /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nWiFi Wireless connection configuration /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /Circle/CIRCLE ,\u0013\nTelephony Incoming/outgoing calls /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /Circle/Circle /CIRCLE ,\u0013\nGPU Graphics processing unit /LEFTCIRCLE /Circle,\u0013 /LEFTCIRCLE /Circle,\u0013 /Circle/LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nSensors Light sensor and accelerometer /CIRCLE,\u0013 /CIRCLE,\u0013 /Circle/LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nCamera Video and still-frame input /Circle/Circle /LEFTCIRCLE /Circle,\u0017 /LEFTCIRCLE /Circle,\u0017 /CIRCLE,\u0013\nAudio Speakers, microphone /Circle/Circle /LEFTCIRCLE /Circle,\u0017 /Circle/CIRCLE ,\u0013\nGPS Global positioning system /Circle/Circle /Circle /Circle /CIRCLE ,\u0013\nBluetooth Short-range wireless communication /Circle/Circle /Circle /Circle /CIRCLE ,\u0013\nADB Command-line utility for debugging /Circle/Circle /Circle /Circle /CIRCLE ,\u0013\nService\nMultiple virtual phones /CIRCLE/CIRCLE /CIRCLE /Circle /CIRCLE\nReduce memory consumption /LEFTCIRCLE/Circle/LEFTCIRCLE /Circle/LEFTCIRCLE /Circle/Circle /CIRCLE\nSecurity-Enhanced Linux in Android /Circle/Circle /Circle /Circle /CIRCLE\nDevice attribute customization /Circle /Circle /Circle /Circle /CIRCLE\nThe latest Android version supported 4.0.3 5.1 4.4.2 5.1 10.0\n1Pseudo-device drivers (e.g., Binder) are parts of the kernel that act like device drivers but do not correspond to any actual hardware.\nisdisplayedatanytimeandisalwaysgivendirectaccesstohard-\nwaredevices.Cellsinventsanew devicenamespacemechanism\ntosupportefficienthardwareresourcemultiplexing,andeachVPis\nassociatedwithaunique devicenamespacefordeviceinteractions.\nInadditiontothekernel-levelvirtualization,Cellsalsointegrates\nuser-leveldevicevirtualizationmethodstohandleproprietaryde-\nviceswithclosedsoftwarestacks.Unfortunately,manyofCells’s\ndevice virtualization methods are either incompatible with new\nAndroid versions or leave in-guest components. Furthermore, it\nalso lacks some essential device virtualization solutions that are\nindispensabletoamalwaresandbox.Forexample,asnoexisting\nworkcanvirtualizeBluetoothbecauseofitscomplexity,malware\ncaneasilycheckBluetoothprofiles(e.g.,BluetoothMACAddress)\nto differentiate a sandbox from a real machine [4, 69].\nCondroid[73]&VMOS[71]. CondroidandVMOS,twofollow-\nupAndroidcontainers,sharesimilarlimitationswithCellsintrans-\nparencyandcustomization.CondroidtransplantstheLinuxCon-\ntainertools[ 44]toAndroidandmakesthemostofthemodifications\nat the Android framework layer; it ensures the isolation of contain-\ners by leveraging namespaces and cgroups. VMOS runs another\nAndroid OS as the guest operating system by mounting the virtual\nroot file system and virtualizing the JAVA runtime. VMOS’s virtual\nsystemandthehostphonesharethehost’snativelibrariestoaccess\nhardware devices. Compared with Cells, VMOS’s implementation\nis simpler, but at the cost of a weaker container isolation mecha-\nnism.Exceptforthemountnamespace,VMOS’svirtualsystemand\nthe host device have the same namespaces, which cannot isolate\noperating system resources.Summary. TheexistingAndroidcontainersarenotqualifiedto\nbe an OS-level sandbox for security applications. Their limitations\non outdated/incomplete device virtualization, having in-guest com-\nponents, and a lack of device customization, can all be exploited\nby attackers as new fingerprints to detect the presence of Android\ncontainers. Our work delivers a novel Android container platform\nwith strong anti-evasion capability, even to a dedicated adversary.\n2.4 Binder\nBinderistheAndroid-specificinter-processcommunication(IPC)\nmechanism and the remote method invocation system. Binder con-\nsistsofBinderdriver,ServiceManager,server,andclient.TheBinder\ndriver is a pseudo device in the kernel and does not correspond to\nthephysicaldevice.UserspaceprocessessupportingtheBindercom-\nmunicationwillcreatecorrespondingBinderdatastructures(e.g.,\nbinder_proc ,binder_node ) in the kernel to maintain the process\nstate. The server is the Binder service. ServiceManager is a special\nBinderservice.TheAndroidkernelcreatesaglobal binder_node\nobjectbinder_context_mgr_node in the Binder driver to indicate\nthatitistheBinderservicemanagerandset handler=0 forother\nclient processes to call. When the client (e.g., App) requests the\nBinder service, it will obtain the ServiceManager service by calling\nthehandlerwithavalueof0.ServiceManagerfinallyqueriesthe\nbinder_node from the server according to the list of services it\nmaintainsandbindsitto binder_node fromtheclienttoimplement\nthe client-to-server binder interface call.\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2861Host Root Namespace\nBluetoot\nhTelephon\ny\nKernel-Level Device VirtualizationBinder Service Sharing\nWiFi\nConfigurationDisplay GPUAudio &\nCameraDevice Namespace\nProxy\nTelephony BluetoothCellD\nNamespace(pid, uts, mnt, net, user, ipc, device )\ncgroups chroot\nLinux KernelCellc\nVirtual Phone\n(Foreground)\nVirtual\nPhones\n(Background)\nNetwork Binder Power Input Sensors GPS\nFigure 1: Overview of VPBox’s architecture. The names in\nred represent Cells’s modules reused by VPBox.\n3 VPBOX SYSTEM OVERVIEW\nVPBox is a transparent and stealthy Android OS-level sandbox via\na novel, customizable container-based virtualization technique. To\nenabletheapplicationtosecurityrelatedtasks,VPBox’sdesignis\ncapable of meeting the following two progressive requirements:\n(1)Transparency. Thisrequirementinvolvestwoaspects:a)\nthe virtualized device exhibits the same hardware effects as\nthe underlying physical device; b) complete virtualization\nsupport for all devices and services listed in Table 1.\n(2)Stealthiness. On top of the transparency, this requirement\nensures a dedicated adversary in the VP is difficult to finger-printthepresenceofthecontainer,includingthepresenceof\nvirtualization components and the particular mobile device\nthat runs the container.\nExisting Android containers partially meet the transparency re-\nquirementduetotheirincompletedevicevirtualization,butnoone\nsatisfiesthestealthinessrequirement.ThelastcolumnofTable1\nshowsVPBox’sadvantages.Allofthedevicesandserviceslistedin\nTable 1 are fully supported by VPBox, including hardware devices,\npseudo-device drivers,and necessary servicesto the Androidsys-\ntem (e.g., Bluetooth, ADB, and SELinux). Security analysts are free\nto configuredifferent deviceartifacts andthen bootup diversified\nvirtualenvironments.Toachievethegoalofstealthiness,weenable\nourdevice virtualization andthecustomizationof device-specific\nattributes to be executed outside of VPs.\nFigure 1 provides an overview of VPBox’s device virtualiza-\ntion. VPBox retains the foreground-background VP usage model of\nCells[10].EachisolatedVPrunsastockAndroiduserspaceenvi-\nronment.TheVPrunningintheforegroundcanalwayshavedirect\naccesstohardwaredevices.VPBox utilizesLinuxnamespacesand\nthedevicenamespaceintroducedbyCellstoremapOSresource\nidentifierstoVPs.EachVPhasitsprivatenamespacesothatitdoes\nnot interfere with the other VPs and the host. The names in redinFigure1representCells’smodulesreusedbyVPBox.Wereuse\nCells’s kernel-level virtualization methods that still work in the\nlatestAndroidversion,includingInput(e.g.,touchscreenandinput\nbuttons) and Sensors (e.g., accelerometer and light sensors). The\nvirtualization of Input and Sensors is to modify a device subsystem\nto be aware of the devicenamespace. We also keep two custom\nprocesses, “Cellc” and “CellD,” in the host device’s root namespace;\nthey manage the service of booting up a VP and switching VPs be-\ntween the foreground and background. CellD also coordinates our\nADBvirtualization.WeaddacontrolcenterappforVPBoxusersto\nstartandswitchVPsswiftly.Moreimportantly,weimproveCells\nin four significant ways to meet our requirements on transparency\nand stealthiness.\n(1)Wedesignkernel-leveldevicevirtualizationtobecompati-\nble with device changes in the new Android systems. Our\nmethod makes it possible to have no in-guest virtualization\ncomponent for our user-level device virtualization(§4).\n(2)We propose a novel user-level virtualization mechanism,\nwhichoffersaflexibleandstealthysolutiontovirtualizenew\nhardware devices without compromising transparency ( §5).\n(3)We take new measures to reduce memory consumption and\nenable SELinux settings for each VP (§6).\n(4)We provide a broad spectrum of options to customize the\nVP’s device attributes stealthily. This enables us to simulate\nmore diversified VPs on a single device (§7).\n4 KERNEL-LEVEL DEVICE VIRTUALIZATION\nKernel-level device virtualization provides efficient hardware re-\nsourcemultiplexing,anditisalsotransparenttouser-modeapps\nrunninginVPs.Ourkernel-levelmechanismenablesthevirtualiza-tionofBinder,powermanagement,corenetworkresource,andGPSon mainstream Android versions. Our key method is to rewrite thesourcecodeofkerneldriverstobeawareofthe\ndevicenamespace.\nNext,weuseBinderandGPSasexamplestopresentthestrategyof\nourkernel-leveldevicevirtualization.Weputcorenetworkresource\nand power management virtualization in Appendix A.\nBinder. Binder allows high-level framework APIs to cross pro-\ncess boundaries and interact with Android system services. The\nBinderdriverconsistsofthreepseudo-devicedrivers.Inaddition\nto the traditional “/dev/binder” driver, the Android system adds\nanothertwoBinderdriverssinceAndroid8.0:“/dev/hwbinder”and\n“/dev/vndbinder”;theyareusedforIPCbetweenframework/vendor\nprocessesandIPC betweenvendor/vendorprocesses[ 8].Without\nBinder virtualization, Binder’s IPC feature can be abused by dif-\nferent container processes, violating the system isolation between\ncontainers. In VPBox, we have modified all Binder drivers’ data\nstructurestoenableIPCbetweentwoprocessesthatsharethesame\ndevicenamespace.Binderdrivervirtualizationisthefoundationof\nour new user-level device virtualization technique (see §5), which\nallowsa serviceprocess intheVP toshare thecorrespondingser-\nviceinthehostsystemandleavesnovirtualizationcomponentin\nthe VP’s userspace.\nGPS.GPS provides a more accurate positioning service than\nnetworkpositioning,butexistingAndroidcontainersdonotsup-\nport GPS virtualization. GPS relies on a physical chip for loca-tiontracking. Inthe Androidframework layer,the GPSprovider,\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2862GpsLocationProvider ,callsthehardwareabstractionlayer(HAL)\ninterfaceviaJavaNativeInterfacemethods.TheHALinterfaceinter-\nactswiththeGPSchipthrough“/dev/gss”driver.TheGPSchipisanactivetrackingdevice.Afterauser’sfirstrequest,theGPSchipwill\ncontinuetoreportthelocationinformationto\nGpsLocationProvider\nwithout interruption. However, the GPS chip only supports one\nconnection.OurvirtualizationofGPSistorewrite“/dev/gss”dri-\nver to support multiple connections. We modify “gss_open” and\n“gss_event_output”functionssothatthelocationinformationre-\nceivedfromthechipisforwardedtomultipleclientssimultaneously.\nThelocationinformationgoesthroughHALandeventuallyreaches\nGpsLocationProvider intheAndroidframeworklayerofthehost\nand virtual phones, respectively.\n5 USER-LEVEL DEVICE VIRTUALIZATION\nUser-leveldevicevirtualizationisnecessarybecausesomehardware\nvendors provide proprietary software stacks that are completely\nclosed source. Without hardware vendor’s support, it would be\ndifficult,ifnotimpossible,tovirtualizetheminthekernel.VPBox’s\nuser-level virtualization achieves the goal of having no in-guest\nvirtualizationcomponent bydevelopingtwo newmethods,which\nenable the VP space to retain native-like system components.\n1. Binder Service Sharing For the system services registered\nin ServiceManager (e.g., WifiService & SurfaceFlinger), we pro-\npose a new, general virtualization technique via Binder servicesharing. We first modify the Binder-driver data structure (e.g.,\ncontext_mgr_node ,procs, anddead_nodes ) to ensure that each\nVP has its own Binder-driver data structure. Next, we create a\nnewspecifichandlerinBinder’sdatastructureandletitpointto\nthehost’s context_mgr_node .Ascontext_mgr_node isassociated\nwith ServiceManager, with this handler, the VP can access the host\nphone’sServiceManagernode.Therefore,thismechanismallows\na VP’S service process to share the corresponding service in the\nhostsystem.Then,weleveragetheSELinuxtechniquetoenforce\nwhichservices theVPcan shareinthe hostsystem.In VPBox,we\nuseBinderservicesharingtovirtualizeWiFiconfiguration,Display,\nGPU, Audio, and Camera.\n2. Device Namespace Proxy We cannot apply Binder service\nsharingtotheanonymousservicesnotregisteredinServiceMan-\nager, such as telephone and Bluetooth, because their binder_node\nandbinder_ref kernel structures are missing. Therefore, we de-\nvelopanewdevicenamespaceproxytovirtualizetelephoneand\nBluetooth, leaving no in-guest virtualization component. Cells’suser-level virtualization is not stealthy. It creates each VP’s own\nproxy,connectingtoCellDrunninginthehost’srootnamespace.\nCellD, in turn, communicates related hardware vendor librariesto respond to the VP’s requests. However, Cells’s proxy layer is\nlocated at the VP’s application framework layer. Like API hooking,\napps running in the VP can easily detect the presence of Cells’s\nproxylayerbecausetheysharethesameprivilegelevel.Weaddress\nthe stealthiness concernby creating a device namespaceproxyin\nthe host’s userspace only.\nNext,§5.1and§5.2explorethemethodofBinderservicesharing,\nand§5.3takesBluetoothasanexampletopresentthemethodofde-\nvicenamespaceproxy.Weputthedetailsofotheruser-leveldevices’Host Userspace\nLinux KernelHost: BinderWifiServiceNetworkAgent\nVP NetworkAgent\nwpa_supplicantWiFi Java Native\nInterface\nWPA Server &\nClient\nBinder service\nsharingVP Userspace\nConnectivityServiceWifiManagerApp\nVP: Binder\nThe VPಬs app receives network status notifications.The workflow to answer a WiFi status query from the VP ಬs app.13\n2\n5ConnectivityService4\nApp\nWiFi configuration and status notifications before virtualization.6\n7\nFigure 2: VPBox’s WiFi configuration virtualization.\nvirtualization (telephony, filesystem, and ADB) in Appendix B and\nAppendix C.\n5.1 WiFi Configuration\nWiFi configuration and status notifications occur at the userspace.\nWeuseBinderservicesharingforitsvirtualization.Comparedwith\nCells’smethod,ourapproachissimplerandleavesnovirtualization\ncomponent in the VP’s userspace. Cells’s WiFi virtualization is not\nstealthy because it adds a WiFi poxy inside each VP. In contrast,our virtualization occurs at the host’s userspace and the kernel.\nFigure2illustratesourdesign.IntheAndroidsystem,beforevir-\ntualization,WifiService( 1)callsthelibraryof“wpa_supplicant”\n(2) to detect WiFi connections. The “wpa_supplicant” library is a\nuser-level library that contains wireless network service code. The\nWiFi-connectioninformationissentthroughNetworkAgent( 3)\nto ConnectivityService ( 4), which answers app queries about the\nstateofnetworkconnectivity.TovirtualizeWiFi,weusethebinder\nservice sharing mechanism ( 5) to bridge WifiService between the\nVP and the host. The blue double arrow line in Figure 2 shows the\nworkflowtorespondtoaWiFistatusqueryfromtheVP’sapp.In\naddition, we create a new NetworkAgent in the host and bind it to\nthe VP’sdevicenamespace ( 6). As shown by the red dotted line,\nwealsouse Binderservicesharingto connectthenewNetworkA-\ngent(6)with theVP’s ConnectivityService ( 7).The purposeof\ndoingsoistoautomaticallyforwardnetworkstatusnotifications\n(e.g., WiFi signal strength) to the VP.\n5.2 Display, GPU, Audio, and Camera\nDisplay, GPU, Audio, and Camera are all virtualized via the Binder\nservicesharingmechanismwhileensuringtheisolationbetween\nVPs.WeuseDisplayand GPU asexamplestodescribethe design.\nThe virtualization methods of Audio and Camera are similar by\nsharing the Binder service of AudioFlinger and CameraService.\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2863APP\nAndroid\nBluetooth APIs\nBluetooth Stack\nBluetooth\nController\nDriversAPP\nAndroid\nBluetooth APIs\nBinder IPC\nBluetooth Stack\nBluetooth\nControllerAPP\nAndroid\nBluetooth APIs\nBinder IPC\nJava Native\nInterface\n(JNI)\nHIDL\nLinux KernelHIDL\nLinux KernelDriversJava Native\nInterface (JNI)JAVA Modulecom.android.bluetooth\nJNI ModuleJAVA Modulecom.android.bluetooth\nJNI Modulepackages/apps/BluetoothBinder ServiceJAVA Modulecom.android.bluetooth\nYesBluetooth JNI ProxyForeground VP ?Host Userspace\n(a) Android Bluetooth\nArchitecture(b) VPBox Bluetooth Architecture5 5\n2\n38\nVP Userspace1\n6\n7Binder IPC Binder IPC\n4Binder Service\nSharing\nFigure 3: VPBox’s Bluetooth virtualization.\nThe Display is an essential device in smartphones, and the GPU\nprovides hardware display acceleration. Before Android 6.0, the\nAndroid system takes Linux framebuffer (FB) as an abstraction\nto a physical display and screen memory. Cells virtualizes FB by\nmultiplexing FB’s device driver. However, Android 6.0 and later\nversions have switched to the ION driver for managing the screen\nmemory. Modifying the IONdriver to virtualize FB is error-prone\nand complicated.\nTosolvethisissue,wetakeadvantageoftheBinderserviceshar-\ningtoenableeachVPtomultiplexanessentialgraphicsservice—\nSurfaceFlinger of the host system. SurfaceFlinger is responsible for\ncompositingalloftheapplicationandsystemsurfacesintoasingle\nframebuffer for a final display. Also, we adapt related data struc-\ntures, graphics rendering APIs, and interfaces for virtualization. 1)\nWe add the system tag field in the Layer data structure to detect\nto which system (VP or host) the Layer belongs. 2) With the added\nsystem tag, we identify the foreground system layer from Surface-\nFlinger’sAPIs,such aslayercroppingandcompositing, todisplay\nthe final image on the screen. 3) To switch the screen between the\nVP and host, we add new interfaces for clearing and redrawing im-\nages in SurfaceFlinger. Our design is two-birds-one-stone because\nnoadditionalmeasuresareneededforGPUvirtualization.Sincethe\nVP multiplexes the host system’s screen memory buffer, the host’s\nGPU can directly work on it for display acceleration. Additionally,\ntoproperlysupporttheforeground-backgroundusagemodel,we\nlimittheSurfaceFlingerservicetoonlyrespondtotherequestfrom\nthe foreground VP, ignoring the requests from background VPs.5.3 Bluetooth\nNone of the existing Android emulators or containers can virtu-\nalizeBluetooth.Eachsmartphonemanufacturerprovidesitsown\nproprietary Bluetooth vendor code that is entirely closed source.\nWithout the hardware vendor’s support, the kernel-level virtual-\nization of Bluetooth would be very challenging. Figure 3(a) shows\ntheAndroidBluetootharchitecturesinceAndroid8.0.Tousethe\nBluetoothservice,anappfirstcallsAndroidBluetoothAPIs( 1),\nwhich further sends the request to the Bluetooth service process\n(2)viaBinderIPC.Next,theBluetoothserviceprocessconnectsto\nthe Bluetooth stack ( 3) via Java Native Interface (JNI). Then, the\nBluetooth stack interacts with the Bluetooth controller ( 4) using\nHardware Interface Design Language (HIDL).\nBluetooth service process ( 2) only provides the anonymous\nBinder service externally, which does not submit the registeredBinder to the ServiceManager. This means we cannot apply the\nbinderservicesharingmechanismto 2.Instead,weimplementa\nnew service proxy to virtualize Bluetooth. Figure 3(b) illustrates\nour workflow. We modify the Bluetooth app (“packages/apps/Blue-\ntooth”)andembedaBluetoothJNIproxy.Afterourmodification,\nthe Bluetooth service process now only contains the JAVA module\n(5), and the original JNI module is put into the newly added Blue-\ntoothJNIproxy( 8)inthehost.Now,itisourBluetoothJNIproxy\nto interact with the Bluetooth stack and the Bluetooth controller.\nFurthermore, to enable our proxy to communicate with new\nBluetoothserviceprocesses( 5)inthehostandeachVP,wealso\nbuildabinderserviceintheBluetoothJNIprocess( 6).Inthisway,\neachVPcanfinallyaccesstheBluetoothdriverinthehostdevice.\nPleasenotethattheBluetoothdriverdoesnotsupportmultiplexing.\nAnexceptionwillhappenifmultipleconnectionsareestablished\nwith the Bluetooth driver at the same time. Therefore, we add a\nnamespacecheckinourproxy( 7):weonlyforwardtheforeground\nVP’s Bluetooth service request. Our SELinux policy specifies user-\nlevelappsineachVPhavenoprivilegetoaccessthenewBluetooth\nservice process ( 5) to detect our change.\n6 SCALABILITY AND SELINUX\nWhen running multiple VPs on VPBox, memory usage becomes\nthe scalability bottleneck. We modify related kernel functions and\ndata structuresto supportthree memory optimization techniques:\nadvancedmulti-layeredunificationfilesystem(AUFS)[ 49],Linux\nkernelsame-pagemerging(KSM)[ 65],andAndroidlowmemory\nkiller [6]. We use the AUFS mechanism to mount the read-only\npartition of the VP system to reduce the load storage of the de-\nvice. However, there is no AUFS module in the Android system.\nWe first transplant the AUFS module from its gitrepository to\nthe “/fs” directory of the Android kernel source code. Then, wemodify the file operation interface of the kernel, such as\nd_walk,\nsetfl,sync_filesystem , and related data structures, to complete\nthe adaption. KSM is a module in the Android kernel, but weneed to activate it to support multiple container instances. KSMis a memory-saving de-duplication feature. The major modifica-\ntions we made include enabling “/sys/kernel/mm/ksm/run=1” and\n“CONFIG_KSM=y”, configuring the values of sleep_millisecs ,\npages_to_scan , and other parameters in “kernel/mm/ksm.c” mod-\nule based on the terminal hardware configuration and the number\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2864EXLOG\u001193%R[\u0011SURS\n6KDUHG\u00030HPRU\\\u000393\u001d\u0003,QLW+RVW\u001d\u0003,QLW 6\\VWHP\u00033URSHUWLHV\u0003\"\n<HV\u0003\n,3&\u0003\n1DPHVSDFH12\n31R\n$QGURLG\u00036\\VWHP\u0003\n3URSHUWLHV93\u00030HPRU\\\n6HOI\u0010PDGH\u00036\\VFDOO+RVW\u00030HPRU\\\n9LUWXDOL]HG\u0003'HLYLFH\u0003\n3URSHUWLHV5\n9LUWXDOL]DWLRQ\n+RVW\u00038VHU\u0010OHYHO\u00033UR[\\\n\u000b%OXHWRRWK\u0003_\u00037HOHSKRQ\\\u0003_\u0003'LVSOD\\\u0003_\u0003*38\u0011\u0011\u0011\f+RVW\u0003.HUQHO\u0003'ULYHU\n\u000b&38\u0003_\u00033RZHU\u0003_\u0003*36\u0003_\u00030HPRU\\\u0011\u0011\u0011\u0003\f9LUWXDOL]DWLRQ\n80\nSURSHUW\\BJHW\n5HDO\u0003'HYLFH\u0003\n'DWD&XVWRP\u0003'HYLFH\u0003'DWD\n&XVWRPL]DWLRQ\u0003)XQFWLRQ &XVWRPL]DWLRQ\u0003)XQFWLRQ&XVWRP\u0003'HYLFH\u0003'DWD\n5HDO\u0003'HYLFH\u0003\n'DWD'HYLFH\n$FFHVV'HYLFH\n$FFHVV9\n'HYLFH\u0003$WWULEXWH\u0003\n4XHU\\'HYLFH\u0003$WWULEXWH\u0003\n4XHU\\6\n7 4%UDQG\u001d\u0003*RRJOH\u00033L[HO\n$QGURLG\u0003,' \u001d\u0003GEF;;;\n6HULDO\u00031XPEHU \u001d\u0003\u001b\u0019\u0018\u0014\u001b[[[[[[[\u0017\u001b\n66,'\u001d\u00033L[HO\u0010;;;\u0010\u0018*\n0$&\u0003$GGUHVV \u001d\u0003D\u0017\u001dFD\u001dD\u0013\u001d\u0017\u0013\u001d[[\u001d\u0019\u001c\n3KRQH\u00031XPEHU \u001d\u0003\u001b\u0014\u0017\u0010\u001a\u001a\u001a\u0010[[[[\n\u0011\u0011\u0011\nVP\nFigure 4: VPBox’s workflow of customizing the VP’s device attributes.\nofcontainerinstances.WevirtualizethekerneldriverofLowMem-\noryKillersothateachVPcanindependentlyusethismechanism\nto manage the process memory of its namespace. We mainly mod-\nified the process task_struct data structure to bind the device\nnamespace to identify the VP that different processes belong to. In\nparticular, we modified “kernel/drivers/staging/android/lowmemo-\nrykiller.c”module,registereda lowmem_shrinker memorycallback\nforeachVP,andconfiguredtheschedulingstrategysothattheback-\nground VP’s lowmem_shrinker has moreexecution opportunities\nthan the foreground VP’s lowmem_shrinker.\nMoreover, we also provide an optional, “screen off” function for\nbackground VPs to further improve scalability. In this way, when a\nVPisswitchedtothebackground,itspowermodelwillbecomethe\nsameaspressingthepowerbuttonofthenativeAndroidsystem.\nTurning off the screen causes each component to stop unnecessary\nservices, processes, and threads, which further reduces memory\nconsumption.\nTo isolate all VPs from the host machine and one another, we\nutilize three kinds of namespaces (UID, device, and mount) to\nenforce the access control on user credentials, data, device state,and filesystem. Also, we disable the capability of creating device\nnodes inside a VP. Furthermore, we add a fine-grained permission\nstrategy that monitors a VP’s internal processes in real time. We\nmodifythehost’sSELinuxpolicytotakedifferentVP’snamespaces\nas new labels and create new SELinux access control strategies for\neachVP’sinternalprocesses.Inthisway,wecanpreventuntrusted\napps from abusing the VP’s device access permissions.\nInspiredbyBareDroid[ 48],wealsotakeadvantageofSELinux\ntorecordthesystemcallsinvokedduringappexecution.Bydefault,\nonlydenied operationsarerecorded bySELinux.We modifiedthe\nSELinuxpolicybyaddingan auditallow tagtoeachauthorizedop-\neration. In this way, we can collect complete operations performed\nby a user app.\n7 DEVICE ATTRIBUTE CUSTOMIZATION\nOurvirtualizationtechniquesattempttoprovideVPBoxuserswith\nthe same experiencesas usinga physicalsmartphone. However,a\ndedicatedadversarycanstilldetecttheparticulardevicerunningVPBox, such asthe Google phoneswe used. Even bare-metalmal-\nwareanalysisframeworks,suchasBareBox[ 39]andBareDroid[ 48],\nare still susceptible to ad-hoc fingerprinting techniques by examin-\ningspecificsoftware/hardwareenvironmentfeatures.Toaddress\nthis issue, we go one step further to enable customizing VP’s de-\nvice attributes. Our “out-of-the-box” virtualization design enables\nthe device attribute customization to preserve stealthiness. Thisnew feature offers a cost-effective way to simulate more diversi-fiedvirtualenvironments(e.g.,XiaomiRedmiseriesandHuawei\nHonorseries)onasingledevice.Figure4showstheworkflowof\nour proposed device-attribute customization. VPBox users provide\na configuration file “build.VPBox.prop” in advance ( 0in Figure 4),\nwhich stores device-specific attributes in the form of key-value\npairs.Weclassifythesekey-valuepairsintothreecategories:An-\ndroid system properties, user-level-virtualized device properties,\nandkernel-level-virtualizeddeviceproperties.Eachcategoryhas\na different customization method. The strategy and advantages ofour customization are explored next.\n7.1 Android System Property Customization\nAndroidsystempropertiesareconstvaluesthatdescribethemobile\ndevice’s configuration information, such as brand, model, serialnumber, IMEI, and manufacturer. These properties are stored inthe init process’s shared memory, but they are independent of\nour device virtualization. This shared memory is typically used to\nstoresomesystemandhardwareinformationwhenthesystemis\nbeing initialized. Other processes enquire about Android systemproperties at runtime by calling “property_get” (\n5in Figure 4),\nan API for other processes to read the data stored in the shared\nmemory space. Therefore, during the process of booting up the VP,\nits init process will call “load_system_props” to load the custom\nAndroid systemproperties from “build.VPBox.prop” intothe VP’s\nsharedmemoryspace( 1).Then,thecustomsystempropertiesare\nready for apps running in the VP to access and inquire.\n7.2 User-level Customization\nThe second category of “build.VPBox.prop” contains the device\nattributesthatwecustomizeforuser-level-virtualizeddevices,such\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2865as Bluetooth, WiFi, and telephony. The customized data in the\nsecondcategorywillbeloadedintothehostinitprocess’sshared\nmemory( 2).WeenforcetheIPCnamespacetoisolatethehost’s\nandVP’ssharedmemory( 3).Weembedacustomizationfunction\nintheplacewhereweperformuser-leveldevicevirtualization,such\nasBluetoothJNIproxyandTelephonyRilDproxy.Inparticular,thecustomizationfunctiontakeseffectafterthevirtualizationfunction\nhas responded to the app’s device attribute query request ( 4).\nThecustomizationfunctionfirstdetermineswhetherthecurrent\nquery request is from the VP by checking the associated device\nnamespace.IfthequeryisfromtheVP’sapp,itcalls“property_get”\n(5) to get the custom data from the shared memory that maps\n“build.VPBox.prop”,andthenitreturnsthecustomdevicedatato\nthe VP (6).\n7.3 Kernel-level Customization\nThe third category contains key-value pairs used to customize\nkernel-level-virtualizeddevices,suchasPowerandGPS.Besides,\ncertainkerneldriverscontainbasicdeviceattributes(e.g.,kernel\nversionandmemory/processorinformation),whichareincluded\nin the third category of our customized data as well. These kernel-\nrelated configuration data are also stored in the host init process’s\nshared memory.\nInthekerneldriver,weembedacustomizationfunctionatthe\nplace where our kernel-level virtualization function has responded\ntotheapp’sdeviceaccessrequest( 7).Thecustomizationfunctions\nneed to interact with the shared memory of the host’s init process.\nHowever, the customized data in the init process have no privilege\nto enter the kernel space. To overcome this obstacle, we create a\nnewsystemcalltocopydatafromtheuserspacetothekernelspace\n(8). All of our customization functions in the kernel drivers work\nsimilarly. For example, we customize the battery-related profiles\n(e.g.,batterylevel)inthekernelpowerdriverandusethe device\nnamespace to determine whether the query request is from the VP\northehost.IftherequestisfromtheVP,thePower’scustomizationfunctionwillcallourcreatedsyscalltoextractthecustomdataand\nthen return them to the VP ( 9).\nHowever, we have to take special measures to customize kernel\nversioninformation,ofwhichtwoattributesaredefinedintheUTS\nnamespace data structure (“UTS_RELEASE” and “UTS_VERSION”).\nWe need to modify the UTS namespace data structure to embed\nourcustomization function.Interestedreaders arereferredto Ap-\npendix D for more details.\n7.4 Advantages of VPBox’s Customization\nVPBox now provides 150 device configuration options, which span\nabroadspectrumofdeviceattributes.AppendixTable6listscus-\ntomizable device-attribute options. We collect them from 1) the\nrelated work on Android sandbox detection, and 2) existing device-\nattribute editing tools. To the best of our knowledge, VPBox’sdevice-attribute customization options are the largest and most\ncomprehensive so far.\nExisting Android device-attribute editing tools [ 15,74] are built\nonXposed[ 54]byhookingAPIs.Comparedtothem,VPBoxreveals\ntwodistinctadvantages. First,ourcustomizationmethodsaremore\nstealthy, because they occur at internal data structures or internalExit the original VP\nStart a new VPReplace\nbuild.VPBox.propCompile image files\nInstall image\nInitialize a VPControl\ncenter\nPC\nUSB\nHOST\nControl center\nConfigure\nbuild.VPBox.prop\nCreate a VP\n(a) Create and initialize a VP (b) Start a new customized VPadb remount\nVPBox VPBox\nUSB\nFigure 5: The workflow of starting a custom virtual phone.\ninterfacesthatareinaccessibletothevirtualphone.Besides,theydonotrelyonuser-levelAPI-hooking,whichmeansourcustomization\ndoes not leave footprints in the VP’s runtime environment.\nSecond, our VP’s customization does not interfere with nor-\nmaloperationsonthehostdevice.Systemmodificationswithout\nleveragingcontainervirtualizationlackflexibilityandcompatibility,\nbecause only changing return values of APIs or syscalls is likely to\nresultinsystemcrashesorexceptions.Forexample,blindlyediting\nBluetoothattributeswouldcausetheBluetoothsystemserviceto\nkeep restarting, affecting the app that is using the Bluetooth ser-\nvice.InVPBox’scustomizationfunctions,wedonotusethecustom\ndevice data to respond to all device access requests. Instead, we\nanalyzethedataflowoftheVPinterfacethataccessesthedevice.\nOnlyifthedevicedataobtainedbytheVPinterfacefinallyflows\nintotheVP’sprocess,andtheprocessUIDisauserapp,wesend\nthecustomdevicedatatotheVPinterface.Poweredbyour“out-\nof-the-box”virtualizationdesign,VPBoxcangracefullydecouple\ndevice-attribute editing operations from normal operations on the\nhost device and solve incompatibility issues.\n8 EVALUATION\nVPBox Usage The VP images are created and configured on a PC\nanddownloadedtothehostdeviceviaUSB.Weprovideacontrol\ncenter app for VPBox users to switch between the host system\nand VPs swiftly. To start a new custom VP, a user takes the follow-\ning three steps: 1) exit the original VP; 2) update and replacing a\nnew “build.VPBox.prop” configuration file; 3) stat a new VP via the\ncontrol center app. Figure 5 shows how to start a new custom VP.\nWe evaluate VPBox from three dimensions. First, we provide\nperformance measurements to show that VPBox reveals nativeperformance. Second, we compare existing Android sandboxesinevadingvariousvirtualenvironmentdetectionheuristics.Thethird experiment evaluates VPBox’s device customization using\nenvironment-sensitive malware. Please note that we are unable to\ncompare VPBox with other peer Android containers in the perfor-\nmance test. The complete source code download links of Cells [ 10],\nCellrox [17], and Condroid [ 73] have been out of work for a while,\nso we cannot compile and run their virtual phones. We can only\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n286600.20.40.60.811.2\nLinpack\u00033Dmark\u0003Quadrant \u0003WiFi\u0003\u0003BluetoothNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n'W^\u0003\ndĞƐƚ\n(a) Normalized Nexus 6P results00.20.40.60.811.2\nLinpack\u00033Dmark\u0003Quadrant \u0003WiFi\u0003BluetoothNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n'W^\u0003\ndĞƐƚ\n(b) Normalized Pixel results00.20.40.60.811.2\nLinpack\u00033Dmark\u0003Quadrant \u0003WiFi\u0003BluetoothNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n'W^\u0003\ndĞƐƚ\n(c) Normalized Nexus 6P + music results\n00.20.40.60.811.2\nLinpack\u00033Dmark\u0003Quadrant \u0003WiFi\u0003BluetoothNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n'W^\u0003\ndĞƐƚ\n(d) Normalized Pixel + music results02565127681,0241,2801,5361,792\nNo APPs Browser Browser\n+EmailBrowser\n+Email\n+\u0012alendĂrNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n(e) Nexus 6P memory usage in MB02565127681024128015361792\nNo APPs Browser Browser\n+EmailBrowser\n+Email\n+\u0012alendĂrNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n(f) Pixel memory usage in MB\n02565127681,0241,2801,5361,792\nNo APPs Browser Browser\n+EmailBrowser\n+Email\n+\u0012alendĂrNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n(g) Nexus 6P memory usage after optimization02565127681024128015361792\nNo APPs Browser Browser\n+EmailBrowser\n+Email\n+\u0012alendĂrNative Phone 1-VP 2-VP 3-VP 4-VP 5-VP\n(h) Pixel memory usage after optimization0.20.40.60.811.2\nNexus6p\n(4h+Music)Nexus6p\n(12Ś+Idle)Pixel\n(4h+Music)Pixel\n(12h+Idle)Native phone 1-VP 2-VP 3-VP 4-VP 5-VP\n(i) Normalized battery consumption\nFigure 6: VPBox’s performance measurements on Google Nexus 6P and Pixel 3a XL phones.\nrunoneVPusingVMOS[ 71]onAndroid5.1,butVMOS’s1-VPand\nVPBox’s performance data on multi-VPs are not comparable.\n8.1 Performance Measurements\nWe measure runtime overhead, memory usage, and power con-\nsumption using two different Google Phones: Nexus 6P (1.55 GHz\nCortex-A53,Adreno430GPU,3GRAM,and32GROM)andPixel3a\nXL (2.15 GHz Kryo, Adreno 530 GPU, 4G RAM, and 32G ROM). We\nfollowsimilarexperimentalsettingsasCells’spaperinSOSP’11[ 10].\nWe measured the performance of VPBox when running 1VP, 2VPs,\n3VPs,4VPs,and5VPs,eachwithafullybootedAndroidenviron-\nment. Our runtime overhead measurement contains two scenarios.\nThefirstoneisrunningasetofbenchmarkappsonVPBox’sVPs\nand a native phone, respectively. The second one is running the\nsame benchmark apps on VPs and the native phone, but simultane-\nouslywithanadditionalbackgroundmusicplayerworkload.The\nbenchmarkapplicationisalwaysrunintheforegroundVP;ifthe\nbackground workload is used, it runs in a single background VP\nwhenmultipleVPsarestarted.Theresultsofruntimeoverheadare\nnormalized against the performance of running the same bench-\nmarkappsonthelatestmanufacturerstockimageavailablefortwo\nGoogle phones, but without the background workload.BenchmarkApps. Eachbenchmarkappisdesignedtostress\nsome aspect of the system performance: Linpack (v1.1) for CPU;\n3DMark (v2.0.4646) for 3D graphics; Quadrant advanced edition\n(v2.1.1) for 2D graphics and file I/O; WiFi using BusyBox wget\n(v1.21.1)todownloada409MvideofilethroughaPC’sWiFihotspot;\nBluetoothmeasurementisthetimethattheBluetoothmoduletakes\nto transfer a 1M file between two paired Bluetooth devices; andGPS performance is measured by the time that the GPS Test app\n(v1.6.3) takes to acquire the GPS location.\nRuntime Overhead. Figure 6(a) & 6(b) show the normalized\nruntimeoverheadontwoGooglephoneswithnobackgroundwork-\nloadrunning.Thedeviationsbetween“n-VP”and“NativePhone”\nrepresent the additional overhead caused by VPBox’s device vir-tualization. The negligible deviations in most cases indicate no\nuser-noticeable performance difference between running in VPBox\nand running natively on a real phone, even with up to five VPsrunning simultaneously. The WiFi benchmark shows the largestoverhead—it introduces about 3%\n∼6% additional slowdowns on\ntwo phones. In addition to VPBox’s virtualization, we argue that\nWiFivariabilitylevelscouldalsoaffectnetworkperformance.Fig-\nure6(c)&6(d)showthenormalizedruntimeoverheadwhenrun-\nning the background music player. As would be expected, running\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2867thebackgroundworkloadcausesadditionaloverheadsrelativeto\nour baseline. Among all of our benchmarks, 3DMark shows the\nleastoverhead becauseplayingmusic doesnotinvolve 3Drender-\ning. Compared to Cells’s performance data [ 10], VPBox reveals the\nsame level of variability in runtime overhead.\nMemoryUsage. Figure6(e)&6(f)showthedefaultmemoryus-\nage(withoutmemoryoptimization)ontwophones.The“NoApps”\nmeasures the memory usage after booting each VP but running\nno apps. Then, we measure the memory usage after starting an\ninstance of Chrome browser, Gmail client, and Google Calendar in\neach running VP. Apparently, after starting multiple VPs, memory\nusagebecomesthescalabilitybottleneck.NotethatVPBoxrequires\nincrementally less memory when starting more VPs. The reason\nis Android low memory killer; even without specific memory opti-\nmization methods, it automatically takes effect to kill background\nprocessesandfreememoryfornewapplications.Figure6(g)&6(h)\nshow results after we apply kernel same-page merging, file system\nunioning,and“screenoff”forbackgroundVPs.Withthesemem-\nory optimization methods enabled, we can further reduce memory\nconsumption by 100MB to 600MB.\nPowerConsumption. Figure6(i)showsthenormalizedpower\nconsumption on two Google phones; the larger value means more\npower consumption. The “4h + Music” measures the power con-sumption after playing the music repeatedly for 4 hours. When\nmultiple VPsexist, werun the musicplayer inthe foreground VP.\nComparedwiththenativephone,thepowerconsumptionresults\nfrom 1-VP to 3-VP increase by less than 5%, and the power con-\nsumption results from 4-VP to 5-VP increase by less than 10%. The\nPixel3aXLphone’spowermeasurementisbetterthantheNexus6p\nphone,becausePixel3aXLphone’spowermanagementhasbeen\nimproved. The “12h + Idle” measures the power consumption after\n12hoursinanidlestate.Comparedtothenativephone,VPBox’s\nnumbers in “12h + Idle” show no measurable increase.\nConclusion. VPBox’s superior performance data indicate that\nit is immune to the evasions that measure the performance gap\nbetween virtual machines and real devices.\n8.2 Security Analysis\nOur second experiment evaluates the resilience against virtual en-\nvironment detection heuristics proposed by the previous work [ 16,\n34,50,55,56,69,78]. The superset of them covers the mainstream\nAndroid virtual environment detection heuristics. Table 3 presents\nthe results under Android emulators, app-level virtualization, and\nAndroid container environments. Row 2 to 10 are nine types of\nAndroidvirtualenvironmentdetectionheuristics,andtheirdescrip-\ntionsarepresentedinTable2.Wefirstrunthesedetectionheuristics\nin a physical device and save their results as Output 1. Then, weinstall seven different virtualization environments listed in Row\n1onthisdeviceandthenrerunthesedetectionmethodsinseven\nvirtual environments, respectively. After that, we compare their\noutputswithOutput1.Atransparentvirtualenvironmentshould\nshow no appreciable difference with its underlying device.\nVPBox meets thisgoal from two aspects: 1) thevirtualized de-\nvice exhibits the same hardware effects as the underlying physical\ndevice;2)VPBox’svirtualizationsupportsalldevicesandservices\nlisted in Table 1. Besides, to achieve the goal of stealthiness, weTable 2: Android virtual environment detection heuristic\ntypes and their descriptions.\nType Description\nEmulated Network [69]The emulated network environment is typically\ndifferent from that of physical devices, such as\nIP address, virtual router, and host loopback.\nCPU & Graphical 1) Calculate 1 ,048 ,576 digits of Pi;\nPerformance [69] 2) measure video frame rate\nHardware Components [69] E.g., Bluetooth, Radio, and Power management.\nSensor Events [16] Detect accelerometer API return values.\nHypervisor Heuristics [50]1) Virtual program counter update;\n2) cache consistency\nInstruction-level Software-based emulators reveal different\nProfiles [55] instruction-level behaviors from real ARM\nCPUs when processing undefined instructions.\nAndroid APIs [34, 69] Many APIs return unique device identifiers.\nSystem Properties [34] Android system configurations and status.\nShared UID & In app-level virtualization, the host app shares\nHooking [56, 78] the same UID with all guest apps and relies\non hooking to hide guest apps’ API requests.\nenable our device virtualization and the customization of device\nspecificattributes tobe executedoutsideof VPs.Itensures adedi-\ncatedadversaryintheVPisdiffculttofingerprintthepresenceof\nVPBox, including the presence of virtualization components.\nHardware-related Discrepancies. Row 2 to Row 7 focus on\ndetecting the hardware-related discrepancies caused by virtualiza-\ntion.Androidemulatorsareeasytobedetectedbecauseofsoftware-\nemulatedhardwareandslowperformance.VirtualAppandParallelSpacerevealthesamehardwareeffectsbecauseguestappscanstill\ndirectlyaccesstheunderlyingAndroiddevice’shardware.VMOS\nfails five times in the category of “Hardware Components.” The\nreasonisVMOSlacksvirtualizationsupportforWiFi,Telephony,\nAudio, GPS, and Bluetooth. VMOS’s results imply that incomplete\ndevice virtualization can also be exploited by adversaries to finger-\nprint the presence of a virtual phone.\nDevice Artifacts. Row 8 and Row 9 represent the detection of\ndevice artifacts. Software-based emulators exhibit different values\nin some Android system properties, and many APIs return unique\ndeviceidentifiers.Forapp-levelvirtualization,torunmultiplecopies\nofthesameguestappssimultaneously,thehostapp(e.g.,Virtual-\nApp) has to intentionally reveal some different device artifacts (e.g.,\nAndroid ID) to each guest app instance. As VMOS’s device virtual-\nizationisnotcomplete,italsoreturnstendifferentAPIvaluesaboutdeviceidentifiers,suchas\nTelephonyManager.getLine1Number() .\nIn contrast, as VPBox’s foreground VP can directly access the hard-\nware, it reveals the same device artifacts as the physical device.\nApp-levelVirtualization. Row 10 detects two characteristics\nof app-level virtualization [ 56,78]: 1) Shared UID between the host\nappandguestapps;2)API-hookingmechanism.ThethreeAndroid\nemulators also adopt API-hooking as an analysis approach. By\ncontrast,onlyVPBoxsucceedsinbypassingalldetectionheuristics.\nBecause each VP has its private namespace so that it does not\ninterfere with the other VPs and the host. Besides, VPBox does not\nrely on user-level API-hooking, which means our virtualization\ndoes not leave hook footprints in the VP’s runtime environment.\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2868Table3:Theresultsofanti-virtual-environmentdetection.Fortheresultslike“X/Y”,Yisthetotalnumberofdetectionheuris-\ntics, and X is the number of effective ones. For the results of SafetyNet and ishumei, /Circlemeans a tool successfully detects this\nvirtual environment, and /CIRCLEmeans it treats this virtual environment as a genuine Android device. For each evasive malware\nfamily, the value in “()” is the number of samples, and we represent the number of file operations generated by each evasive\nmalware family as (min, max, median).\nDetection HeuristicsAndroid Emulator App-Level Virtualization Android Container\nDroidScope [75] CuckooDroid [53] DroidBox [41] VirtualApp [11] Parallel Space [42] VMOS [71] VPBox1\nEmulated Network [69] 5/5 5/5 5/5 0/5 0/5 0/5 0/5\nPerformance [69] 2/2 2/2 2/2 0/2 0/2 0/2 0/2\nHardware Components [69] 11/13 13/13 13/13 0/13 0/13 5/13 0/13\nSensor Events [16] 9/9 9/9 9/9 0/9 0/9 0/9 0/9\nHypervisor Heuristics [50] 2/2 2/2 2/2 0/2 0/2 0/2 0/2\nInstruction-level Profiles [55] 6/6 6/6 6/6 0/6 0/6 0/6 0/6\nAndroid APIs [34, 69] 38/47 47/47 40/47 22/47 16/47 10/47 0/47\nSystem Properties [34] 10/10 10/10 10/10 0/10 0/10 0/10 0/10\nUID & Hooking [56, 78] 1/4 1/4 1/4 4/4 4/4 0/4 0/4\nSafetyNet-bI [5] /Circle/Circle /Circle /Circle/Circle /Circle /CIRCLE\nishumei [60] /Circle/Circle /Circle /Circle/Circle /Circle /CIRCLE\nEvasive Malware (1,961)\nRotexy (273) [58] (9, 77, 25) (9, 73, 10) (9, 73, 16) (18, 24, 19) (0, 0, 0) (24, 113, 43) (50, 170, 74)\nAshas (152) [63] (0, 27, 0) (0, 20, 0) (0, 23, 0) (0, 46, 29) (0, 0, 0) (51, 92, 63) (65, 99, 75)\nHeHe (145) [23] (0, 0, 0) (0, 0, 0) (0, 0, 0) (0, 6, 0) (0, 0, 0) (0, 31, 17) (26, 44, 30)Ztorg (143) [67] (0, 37, 25) (0, 30, 20) (0, 30, 20) (0, 31, 26) (0, 0, 0) (0, 59, 3) (40, 63, 45)Andr RuSms-AT (217) [62] (0, 29, 0) (0, 20, 0) (0, 25, 0) (4, 41, 10) (0, 0, 0) (17, 79, 36) (48, 157, 74)\nOBAD (290) [66] (26, 52, 40) (20, 40, 30) (25, 49, 35) (16, 50, 26) (0, 6, 0) (38, 87, 70) (78, 101, 94)\nAndroid.BankBot (290) [40] (0, 176, 50) (0, 118, 30) (0, 149, 24) (1, 224, 71) (0, 0, 0) (6, 211, 93) (64, 250, 101)GhostClicker (442) [25] (24, 94, 41) (12, 47, 23) (24, 65, 35) (56, 192, 92) (0, 59, 35) (85, 273, 97) (108, 392, 125)\nG-Ware\n2(9) [9] (0, 10, 8) (0, 5, 3) (0, 9, 7) (0, 24, 3) (0, 0, 0) (5, 31, 7) (127, 160, 150)\n1All VPBox’s anti-virtual-machine detection experiments are performed in the foreground virtual phone.\n2In addition to detecting virtual environments, G-Ware family also detects Google phones.\nCommercialDetectionTools. GoogleSafetyNet[ 5]andishumei[ 60]\naretworepresentativeanti-abuse/anti-fraudAPIs.Theyhelpdevel-\noperstodeterminewhethertheirappsarerunningonagenuine\nAndroiddevice.The“SafetyNet-bI”inTable3representsSafetyNet’s\n“basicIntegrity”verdict.SafetyNet’s“basicIntegrity”andishumei\ncanidentifythesignsofarooteddevice,emulator,andAPIhook-\ning. Our results show that both of them are able to recognize all\nof the tested Android emulators, VirtualApp, Parallel Space, and\nVMOS, but they fail to detect VPBox. Please note that SafetyNet\nalsoprovidesanothermorestringentAndroidcompatibilitytesting,\ncalled “ctsProfileMatch.” It detects genuine but uncertified devices,\ncertified devices with an unlocked bootloader, and devices with\ncustom ROM. VPBox does not pass the verdict of “ctsProfileMatch,”\nbecause we have to unlock the bootloader to flash VPBox’s image.\nWe argue that this is not a specific limitation caused by our virtual-\nizationsystem.WedownloadthecompleteAndroid6.0-10.0system\nsource code, compile them in Ubuntu, and then flash them on mo-\nbiledevices—allofthemcannotpassthecheckof“ctsProfileMatch”\neither. Also, many top phone manufacturers run a custom ROM in\ntheir products, such as the MIUI system in Xiaomi smartphones.\nEvasiveMalware. Wecollect1 ,961environment-sensitivemal-\nwaresamples(9families)fromourindustrycollaborator.Security\nanalystshaveconfirmed thatallofthesesamples trytodetectvir-\ntual machines. For example, HeHe [ 23] variants detect whether\nthey are being run in an emulator by checking the IMEI, phone\nnumber, operator,andphone model.LikeBareDroid [ 48],we alsouse the number of file operations as a quantitative measurement\nfor the amount of malicious behaviors. Under each virtual environ-\nment,wefollowCopperDroid’stargetedstimulationstrategy[ 64]\ntostimulatearunningmalwaresamplefor1minuteandmonitor\nits behaviors. The last nine rows of Table 3 show the number of\nfile operations generated by each evasive malware family—they\narestrikinglydifferentbetweenVPBoxandtheothers.Thenum-\nber“0”indicatesthatthesamplecrasheduponstart;weattribute\nthis to the successful detection of virtual environment. Apparently,\nevasive malware samples either crashed upon start or performed a\nverysmallnumberoffileoperationsunderemulatorsandapp-levelvirtualizationtools.Incontrast,noevasivemalwaresamplecrashed\nunder VPBox, and malware exhibits much more behaviors thanother sandboxes. For example, we find most malware crashed inParallelSpace[\n42],andthevariantsofHeHe[ 23]andZtorg[ 67]\ncan detect all virtual environments except for VPBox.\n8.3 VP Customization Evaluation\nWe conduct a separate experiment to compare evasive malware\nbehaviorsinVPBoxandphysicalGooglephones.Althoughmost\nmalware samples reveal the same behaviors in VPBox and physical\nGoogle phones, we do find an exception for G-Ware [ 9]. Upon\nfurther investigation, we find that, in addition to evading virtualmachines, G-Ware family also avoids running in Google phones.\nG-Waresamplesfirstretrievethedevice’ssystemproperty.Ifthe\nstring of “http.agent” or “Manufacturer” contains “Pixel,” “Nexus,”\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2869Table 4: Number of file operations generated by G-Ware in\nGoogle phones (Pixel 3a XL and Nexus 6p) and four differ-\nent custom VPs. We customize the four VPs as Xiaomi Red-miNote4(VP1),XiaomiRedmiNote4x(VP2),HuaweiHonor6x (VP3), and Huawei Honor 8 (VP4).\nSamples Real Devices VP1 VP2 VP3 VP4\nG-Ware1 11 147 143 139 141G-Ware2 10 157 152 142 157G-Ware3 8 139 134 141 149G-Ware4 8 153 149 150 151G-Ware5 7 133 127 132 131G-Ware6 26 152 146 147 153G-Ware7 9 146 147 141 157G-Ware8 23 160 159 147 151G-Ware9 12 141 157 150 146\nor “google,” G-Ware’s malicious activities will not be triggered.\nWe construe this behavior as a way to evade Android’s built-in\nApplication Sandbox or bare-metal analysis framework, because\nAndroid’s built-in sandboxing environments are usually named as\n“NexusXXX”or“PixelYYY,”andthebare-metalanalysisframework\nlike BareDroid [ 48] is also built on a specific Google Nexus phone.\nWe list G-Ware samples’ MD5 values in Appendix Table 7.\nOurdeviceattributecustomizationfunctionalitypreventsmal-\nwarefromfingerprintingtheunderlyingmobiledevicethatruns\nVPBox. We configure our VPs as four different phones: Xiaomi\nRedmiNote4(VP1),XiaomiRedmiNote4x(VP2),HuaweiHonor\n6x (VP3), and Huawei Honor 8 (VP4). In particular, we edit cus-\ntomizable device-attribute options (shown in Appendix Table 6) as\nthesamevaluesofthetargetphone.Afterthat,wererunG-Ware\nmalware in custom VPs to monitor their behaviors. As shown in\nTable4,allG-Waresamplesexhibitmuchmorefileoperationsin\nVPs than in physical Google phones. Besides, we observe the same\nbehaviors across the four VP environments, such as calling “set-\nComponentEnabledSetting” to hide the current App icon and then\nstealthily downloading new malicious packages.\n9 DISCUSSION AND FUTURE WORK\nAnaturalquestiontoVPBoxiswhetheraskilledattackercaneasily\ndetectthepresenceofthenewAndroidcontaineronceitispublicly\nknown.Wedonotassumethatevadingourapproachesisstrictly\nimpossible, butthey canprohibitivelyincrease attackers’cost. We\nacknowledgethatVPBoxintroducessomespecificartifacts,such\nasnever-changinggeographicallocationand devicenamespace.\nHowever, these artifacts can be hidden by VPBox’s unique feature\non device attribute customization and its fine-grained SELinux\npolicy. As some devices’ virtualization methods happen at the host\nuserspace, if an app in the VP has the root privilege, it can find out\nthecorrespondingserviceprocessesareincomplete.Forexample,\ntheVP’sBluetoothserviceprocessdoesnotinteractwithitsown\nBluetooth stack and Bluetooth controller. However, our design\npushes attackersfrom attemptingto fingerprint avirtual machine\noravery specificmobiledevice,to attemptingtoexploitprivilege\nescalation vulnerabilities to root devices. We believe this to be a\nnon-trivial task even for skilled attackers.VPBoxnowprovides150devicecustomizationoptions,butwe\ncannot guarantee that our list is complete. The arms race here is\nthatanattackercoulddetecttheexistenceofVPBox’sunderlying\nGoogle phone by checking the consistency of some obscure device\nproperties,butfindingallofthemisanopenproblem.Itisworth\nnoting that only the foreground VP shows the full strength in\nbypassing virtual-machine detection heuristics. Some devices (e.g.,\nBluetooth and ADB) in background VPs are disabled because they\nare physically not designed for multiplexing. Therefore, the beststrategy to run untrusted apps or evasive malware is executing\nthem in the foreground VP.\nReverseTuring Test. A new trend of evading virtual environ-\nment is the so-called “Reverse Turing Test” by detecting human\ninteractions [ 19,24,47]. For example, Miramirkhani et al. [ 47]p r o -\npose using the “wear and tear” artifacts that typically occur ondevices of real users, but not virtual devices, to detect malware\nsandboxes.Theauthors[ 47]alsodevelopedastatisticalmodelto\nhelpbuildvirtualmachineimagesthatexhibitmorerealistic“wear-\nand-tear”characteristics.Theirfindingshelpfurtherimprovethe\nfidelityofVPBoxbycustomizingtheVPwiththe“wear-and-tear”\nartifacts.\nDynamicMalwareAnalysis. VPBoxshowspromiseasasand-\nboxfordynamicmalwareanalysis.Currently,systemcallinvoca-\ntion tracking is ready via SELinux virtualization. With the device\nnamespace and our custom SELinux policy, we can capture sys-\ntem calls pertaining to the malware process. However, system calls\nalonehavebeenquestionedtodepicthigh-levelAndroid-specific\nsemantics [ 64,75]. Next, inspired by CopperDroid’s out-of-the-\nbox approach [ 64], we will reconstruct malware behaviors from\nlow-levelsystemevents,leavingnoin-guestbehavioranalysiscom-\nponents.Wealwaysperformmalwareanalysisintheforeground\nVP,andallbackgroundVPsarecustomizedinacleanstate.Upon\nanalysiscompletion,abackgroundVPisswitchedtotheforeground\nto start the next round of malware analysis.\n10 CONCLUSION\nInthispaper,wecharacterize,research,andevaluateVPBox,anew\nAndroidcontainer-basedvirtualizationframework.VPBoxprovides\natransparentvirtualphoneenvironmentandallowsuserstocus-\ntomize the virtual phone’s device attributes stealthily. Currently,\nVPBox is the only Android container framework that can work on\nmainstream Android versions. Our experiments demonstrate that\nVPBox introduces negligible runtime overhead and reveals strong\nresilience against various virtual machine detection heuristics. VP-\nBox has been deployed into a production environment to assist\nsecurity professionals in identifying evasive malware.\nACKNOWLEDGMENTS\nWe sincerely thank CCS 2021 anonymous reviewers for their in-\nsightful comments and Dr. Srdjan Capkun for helping us improvethepaperthroughouttheshepherding process.Thisresearchwas\nsupportedinpartbytheNationalNaturalScienceFoundationofChina (62172308, U1626107, 61972297, 62172144), and Jiang was\nsupportedbytheNationalScienceFoundation(NSF)undergrant\nCNS-1850434 and CNS-2128703.\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2870REFERENCES\n[1]Yousra Aafer, Jianjun Huang, Yi Sun, Xiangyu Zhang, Ninghui Li, and Chen\nTian. 2018. AceDroid: Normalizing Diverse Android Access Control Checks\nforInconsistencyDetection.In Proceedingsofthe2018NetworkandDistributed\nSystem Security Symposium (NDSS’18).\n[2]Theodora Adufu, Jieun Choi, and Yoonhee Kim. 2015. Is Container-based Tech-\nnology a Winner for High Performance Scientific Applications?. In Proceedings\nof the 17th Asia-Pacific Network Operations and Management Symposium.\n[3]Amir Afianian, Salman Niksefat, Babak Sadeghiyan, and David Baptiste. 2019.\nMalware Dynamic Analysis Evasion Techniques: A Survey. Comput. Surveys 52,\n6, Article 126 (November 2019), 28 pages.\n[4]Vitor Afonso, Anatoli Kalysch, Tilo Müller, Daniela Oliveira, André Grégio, and\nPaulo Lício de Geus. 2018. Lumus: Dynamically Uncovering Evasive Android\nApplications.In Proceedingsofthe21stInternationalConferenceonInformation\nSecurity (ISC’18).\n[5]Android Developers. [online]. SafetyNet Attestation API. https://developer.\nandroid.com/training/safetynet/attestation.\n[6]AndroidOpen SourceProject.2019. LowMemoryKillerDaemon (lmkd). https:\n//source.android.com/devices/tech/perf/lmkd.\n[7]AndroidOpenSourceProject.[online]. SupportingMultipleUsers. https://source.\nandroid.com/devices/tech/admin/multi-user/.\n[8]AndroidOpenSourceProject.[online]. UsingBinderIPC. https://source.android.\ncom/devices/architecture/hidl/binder-ipc.\n[9]androidcentrol. 2018. G-Ware Virus. https://forums.androidcentral.com/ask-\nquestion/885223-g-ware-virus-app-not-deleting.html.\n[10]Jeremy Andrus,Christoffer Dall, AlexanderVan’tHof, Oren Laadan,and Jason\nNieh.2011. Cells:A VirtualMobileSmartphoneArchitecture. In Proceedingsof\nthe 23rd ACM Symposium on Operating Systems Principles (SOSP’11).\n[11] asLody. 2015. VirtualApp. https://github.com/asLody/VirtualApp.\n[12]MichaelBackes,SvenBugiel,ChristianHammer,OliverSchranz,andPhilippvon\nStyp-Rekowsky.2015. Boxify:Full-fledgedAppSandboxingforStockAndroid.\nInProceedings of the 24th USENIX Conference on Security Symposium (USENIX\nSecurity’15).\n[13]RafaelBallagas,MichaelRohs,JenniferGSheridan,andJanBorchers.2004.BYOD:\nBring Your Own Device. In Proceedings of the 6th International Conference on\nUbiquitous Computing (UbiComp’04).\n[14]Ken Barr, Prashanth Bungale, Stephen Deasy, Viktor Gyuris, Perry Hung, Craig\nNewell,HarveyTuch,andBrunoZoppis.2010.TheVMwareMobileVirtualization\nPlatform: Is That a Hypervisor in Your Pocket? ACM SIGOPS Operating Systems\nReview44, 4 (2010).\n[15]Antonio Bianchi, Eric Gustafson, Yanick Fratantonio, Christopher Kruegel, and\nGiovanniVigna.2017. ExploitationandMitigationofAuthenticationSchemes\nBased on Device-Public Information. In Proceedings of the 33rd Annual Computer\nSecurity Applications Conference (ACSAC’17).\n[16]LorenzoBordoni,MauroConti,andRiccardoSpolaor.2017. Mirage:Towarda\nStealthierandModularMalwareAnalysisSandboxforAndroid.In Proceedings\nof the 22th European Symposium on Research in Computer Security (ESORICS’17).\n[17] Cellrox ltd. [online]. Cellrox Mobile Virtualization. https://www.cellrox.com/.[18]\nNgoc-TuChauandSouhwanJung.2018. DynamicanalysiswithAndroidCon-\ntainer: Challenges and Opportunities. Digital Investigation 27 (2018).\n[19]ValerioCostamagna,CongZheng,andHeqingHuang.2018.IdentifyingandEvad-\ning Android Sandbox Through Usage-Profile Based Fingerprints. In Proceedings\nof the First Workshop on Radical and Experiential Security.\n[20]DeshunDai,RuixuanLi,JunweiTang,AliDavanian,andHengYin.2020. Parallel\nSpace Traveling: A Security Analysis of App-Level Virtualization in Android. In\nProceedingsofthe25thACMSymposiumonAccessControlModelsandTechnologies\n(SACMAT’20).\n[21]ChristofferDallandJasonNieh.2014. KVM/ARM:TheDesignandImplemen-\ntation of the Linux ARM Hypervisor. In Proceedings of the 19th International\nConferenceonArchitecturalSupportforProgrammingLanguagesandOperating\nSystems (ASPLOS’14).\n[22]David Pierce. 2018. Your Smartphone Is the Best Computer You Own. The Wall\nStreet Journal, http://tiny.cc/cqsnpz.\n[23]HiteshDharmdasani. 2014. Android.HeHe:Malware NowDisconnects Phone\nCalls. https://www.fireeye.com/blog/threat-research/2014/01/android-hehe-\nmalware-now-disconnects-phone-calls.html.\n[24]Wenrui Diao, Xiangyu Liu, Zhou Li, and Kehuan Zhang. 2016. Evading Android\nRuntimeAnalysis ThroughDetecting ProgrammedInteractions. In Proceedings\nof the 9th ACM Conference on Security & Privacy in Wireless and Mobile Networks\n(WiSec’16).\n[25]EchoDuanandRolandSun.2017. GhostClickerAdware:aPhantomlikeAndroid\nClick Fraud. http://tiny.cc/7w5ctz.\n[26] Michael Eder. 2016. Hypervisor- vs. Container-based Virtualization. In Proceed-\nings oftheSeminars FutureInternet (FI)and InnovativeInternet Technologiesand\nMobile Communications.\n[27]Eric Enge. 2019. Mobile vs. Desktop Usage in 2019. https://www.perficient.com/\ninsights/research-hub/mobile-vs-desktop-usage-study.[28]Wes Felter, Alexandre Ferreira, Ram Rajamony, and Juan Rubio. 2015. An Up-\ndatedPerformanceComparisonofVirtualMachinesandLinuxContainers.In\nProceedings of the 2015 IEEE International Symposium on Performance Analysis of\nSystems and Software.\n[29]YanickFratantonio,AntonioBianchi,WilliamRobertson,EnginKirda,Christo-\npherKruegel,andGiovanniVigna.2016. TriggerScope:TowardsDetectingLogic\nBombsinAndroidApplications.In Proceedingsofthe37thIEEESymposiumon\nSecurity and Privacy.\n[30]Jyoti Gajrani, Jitendra Sarswat, SMeenakshi Tripathi, Vijay Laxmi, M.S. Gaur,\nandMauroConti.2015. ARobustDynamicAnalysisSystemPreventingSandBoxDetectionbyAndroidMalware.In Proceedingsofthe8thInternationalConference\non Security of Information and Networks (SIN’15).\n[31]TalGarfinkel,KeithAdams,AndrewWarfield,andJasonFranklin.2007. Compat-\nibility is Not Transparency: VMM Detection Myths and Realities. In Proceedings\nof the 11th USENIX Workshop on Hot Topics in Operating Systems (HOTOS’07).\n[32]Grant Ho, Derek Leung, Pratyush Mishra, Ashkan Hosseini, Dawn Song, and\nDavid Wagner. 2016. Smart Locks: Lessons for Securing Commodity Internet of\nThings Devices. In Proceedings of the 11th ACM on Asia Conference on Computer\nand Communications Security (ASIACCS’16).\n[33]JohnHøegh-Omdal.2020. StrandHogg2.0-The‘eviltwin’,NewAndroidVul-\nnerability Even More Dangerous, With Attacks More Difficult to Detect Than\nPredecessor. https://promon.co/strandhogg-2-0/.\n[34]Yiming Jing, Ziming Zhao, Gail-Joon Ahn, and Hongxin Hu. 2014. Morpheus:\nAutomaticallyGeneratingHeuristicstoDetectAndroidEmulators.In Proceedings\nof the 30th Annual Computer Security Applications Conference (ACSAC’14).\n[35]UriKanonovandAvishaiWool.2016.SecureContainersinAndroid:TheSamsung\nKNOX Case Study. In Proceedings of the 6th Workshop on Security and Privacy in\nSmartphones and Mobile Devices (SPSM’16).\n[36]Alexander Kedrowitsch, Danfeng (Daphne) Yao, Gang Wang, and Kirk Cameron.\n2017. A First Look: Using Linux Containers for Deceptive Honeypots. In Pro-\nceedings of the 2017 Workshop on Automated Decision Making for Active Cyber\nDefense.\n[37]Ayrat Khalimov, Sofiane Benahmed, Rasheed Hussain, S.M. Ahsan Kazmi, Alma\nOracevic, Fatima Hussain, Farhan Ahmad, and Chaker Abdelaziz Kerrache. 2019.\nContainer-BasedSandboxesforMalwareAnalysis:A CompromiseWorthCon-\nsidering. In Proceedings of the 12th IEEE/ACM International Conference on Utility\nand Cloud Computing (UCC’19).\n[38]ILukKim,YunhuiZheng,HogunPark,WeihangWang,WeiYou,YousraAafer,\nandXiangyuZhang.2020. FindingClient-sideBusinessFlowTamperingVulnera-\nbilities.In Proceedingsofthe42ndInternationalConferenceonSoftwareEngineering\n(ICSE’20).\n[39]DhilungKirat,GiovanniVigna,andChristopherKruegel.2011. BareBox:Efficient\nMalware Analysis on Bare-Metal. In Proceedings of the 27th Annual Computer\nSecurity Applications Conference (ACSAC’11).\n[40]MohitKumar.2019. NewAndroidMalwareAppsUseMotionSensortoEvadeDe-\ntection. https://thehackernews.com/2019/01/android-malware-play-store.html.\n[41]Patrik Lantz. 2015. Dynamic Analysis of Android Apps. https://github.com/\npjlantz/droidbox.\n[42]LBETech.[online]. ParallelSpace:RunMultipleSocialandGameAccountsin\nYour Phone Simultaneously. http://parallel-app.com/.\n[43]Martina Lindorfer, Matthias Neugschwandtner, Lukas Weichselbaum, Yanick\nFratantonio, Victor van der Veen, and Christian Platzer. 2014. ANDRUBIS –\n1,000,000AppsLater:AViewonCurrentAndroidMalwareBehaviors.In Proceed-\ningsofthe3rdInternationalWorkshoponBuildingAnalysisDatasetsandGathering\nExperience Returns for Security.\n[44]Linux Containers. [online]. Infrastructure for Container Projects. https:\n//linuxcontainers.org/.\n[45]DominikMaierandMykolaProtsenko.2014. Divide-and-Conquer:WhyAndroid\nMalwareCannotBeStopped.In Proceedingsofthe9thInternationalConference\non Availability, Reliability and Security (ARES’14).\n[46]Iliyan Malchev. 2017. Here comes Treble: A modular base for An-\ndroid. https://android-developers.googleblog.com/2017/05/here-comes-treble-\nmodular-base-for.html.\n[47]Najmeh Miramirkhani, Mahathi Priya Appini, Nick Nikiforakis, and Michalis\nPolychronakis.2017. SpotlessSandboxes:EvadingMalwareAnalysisSystemsUsing Wear-and-Tear Artifacts. In Proceedings of the 38th IEEE Symposium on\nSecurity and Privacy (S&P’17).\n[48]Simone Mutti, Yanick Fratantonio, Antonio Bianchi, Luca Invernizzi, Jacopo Cor-betta, Dhilung Kirat, Christopher Kruegel, and Giovanni Vigna. 2015. BareDroid:\nLarge-Scale Analysis of Android Apps on Real Devices. In Proceedings of the 31st\nAnnual Computer Security Applications Conference (ACSAC’15).\n[49]Junjiro R. Okajima. [online]. Advanced Multi Layered Unification Filesystem.\nhttp://aufs.sourceforge.net/.\n[50]ThanasisPetsas,GiannisVoyatzis,EliasAthanasopoulos,MichalisPolychronakis,\nand Sotiris Ioannidis. 2014. Rage Against the Virtual Machine: Hindering Dy-\nnamicAnalysisofAndroidMalware.In Proceedingsofthe7thEuropeanWorkshop\non System Security (EuroSec’14).\n[51]Qihoo360.2015.DroidPlugin.https://github.com/DroidPluginTeam/DroidPlugin.\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2871[52]PaulRatazzi,YousraAafer,AmitAhlawat,HaoHao,YifeiWang,andWenliang\nDu. 2014. A Systematic Security Evaluation of Android’s Multi-User Framework.\nInProceedings of the Mobile Security Technologies (MOST’14).\n[53]Idan Revivo and Ofer Caspi. 2016. CuckooDroid - Automated Android Malware\nAnalysis. https://github.com/idanr1986/cuckoo-droid.\n[54] rovo89. [online]. Xposed Module Repository. https://repo.xposed.info/.\n[55]Onur Sahin, Ayse K. Coskun, and Manuel Egele. 2018. PROTEUS: Detecting\nAndroidEmulatorsfromInstruction-levelProfiles.In Proceedingsofthe21stInter-\nnational Symposium on Research in Attacks, Intrusions, and Defenses (RAID’18).\n[56]LumanShi,JianmingFu,ZhengweiGuo,andJiangMing.2019. “JekyllandHyde”\nisRisky:Shared-EverythingThreatMitigationinDual-InstanceApps.In Proceed-\nings of the 17th ACM International Conference on Mobile Systems, Applications,\nand Services (MobiSys’19).\n[57]Luman Shi, Jiang Ming, Jianming Fu, Guojun Peng, Dongpeng Xu, Kun Gao, and\nXuanchen Pan. 2020. VAHunt: Warding Off New Repackaged Android Malware\ninApp-Virtualization’sClothing.In Proceedingsofthe27thACMConferenceon\nComputer and Communications Security (CCS’20).\n[58]Tatyana Shishkova and Lev Pikman. 2018. The Rotexy Mobile Trojan —- Banker\nandRansomware. https://securelist.com/the-rotexy-mobile-trojan-banker-and-\nransomware/88893/.\n[59]JunaidShuja,AbdullahGani,KashifBilal,AttaUrRehmanKhan,SajjadA.Madani,\nSamee U. Khan, and Albert Y. Zomaya. 2016. A Survey of Mobile Device Virtual-\nization: Taxonomy and State of the Art. Comput. Surveys 49, 1 (April 2016).\n[60]shumei. [online]. ishumei Android Device Security Threat Detection SDK. https:\n//www.ishumei.com/product/bs-post-sdk.html.\n[61]Stephen Soltesz, Herbert Pötzl, Marc E. Fiuczynski, Andy Bavier, and LarryPeterson.2007. Container-BasedOperatingSystem Virtualization:AScalable,High-Performance Alternative to Hypervisors. In Proceedings of the 2nd ACM\nSIGOPS/EuroSys European Conference on Computer Systems (EuroSys’07).\n[62]SophosLabs. 2017. Android Malware Anti-emulation Techniques. http://tiny.cc/\ns416tz.\n[63]Lukas Stefanko. 2019. Tracking down the developer of Android adware affecting\nmillionsof users. https://www.welivesecurity.com/2019/10/24/tracking-down-\ndeveloper-android-adware/.\n[64]Kimberly Tam, Salahuddin J. Khan, Aristide Fattoriy, and Lorenzo Cavallaro.\n2015. CopperDroid:AutomaticReconstructionofAndroidMalwareBehaviors.\nInProceedingsofthe2015NetworkandDistributedSystemSecuritySymposium\n(NDSS’15).\n[65]The kernel development community. [online]. Kernel Samepage Merging. https:\n//www.kernel.org/doc/html/latest/admin-guide/mm/ksm.html.\n[66]RomanUnuchek.2013. ThemostsophisticatedAndroidTrojan. https://securelist.\ncom/the-most-sophisticated-android-trojan/35929/.\n[67]Roman Unuchek. 2017. Ztorg: money for infecting your smartphone. https:\n//securelist.com/ztorg-money-for-infecting-your-smartphone/78325/.\n[68]StevenJ.Vaughan-Nichols.2009. WillMobileComputing’sFutureBeLocation,\nLocation, Location? Computer 42, 2 (2009).\n[69]TimothyVidasandNicolasChristin.2014. EvadingAndroidRuntimeAnalysis\nvia Sandbox Detection. In Proceedings of the 9th ACM Symposium on Information,\nComputer and Communications Security (ASIACCS’14).\n[70]TimothyVidas,DanielVotipka,andNicolasChristin.2011. AllYourDroidAre\nBelong to Us: A Survey of Current Android Attacks. In Proceedings of the 5th\nUSENIX Conference on Offensive Technologies (WOOT’11) .\n[71] VMOS Inc. [online]. Virtual Android on Android . http://www.vmos.com/.[72]\nMiguelG.Xavier,MarceloV.Neves,FabioD.Rossi,TiagoC.Ferreto,Timoteo\nLange,andCesarA.F.DeRose.2013. PerformanceEvaluationofContainer-Based\nVirtualization for High Performance Computing Environments. In Proceedings of\nthe 21st Euromicro International Conference on Parallel, Distributed, and Network-\nBased Processing.\n[73]Lei Xu, Guoxi Li, Chuan Li, Weijie Sun, Wenzhi Chen, and Zonghui Wang. 2015.\nCondroid:AContainer-BasedVirtualizationSolutionAdaptedforAndroidDe-\nvices. InProceedings of the 3rd IEEE International Conference on Mobile Cloud\nComputing, Services, and Engineering (MobileCloud’15).\n[74]XxsqManage. 2019. The Best Tool to Change Android Phone’s Configuration.\nhttp://www.javaer.xyz/XxsqManager/html/index.html.\n[75]Lok Kwong Yan and Heng Yin. 2012. DroidScope: Seamlessly Reconstructing\ntheOSandDalvikSemanticViewsforDynamicAndroidMalwareAnalysis.In\nProceedings of the 21st USENIX Conference on Security Symposium.\n[76]Wenbo Yang, Yuanyuan Zhang, Juanru Li, Hui Liu, Qing Wang, Yueheng Zhang,\nandDawuGu.2017. ShowMetheMoney!FindingFlawedImplementationsof\nThird-partyIn-appPaymentin Android Apps.In Proceedingsof the2017Network\nand Distributed System Security Symposium (NDSS’17).\n[77]Lei Zhang, Zhemin Yang, Yuyu He, Mingqi Li, Sen Yang, Min Yang, Yuan Zhang,\nandZhiyunQian.2019. AppintheMiddle:DemystifyApplicationVirtualization\nin Android and its Security Threats. In Proceedings of the 45th International\nConferenceonMeasurementandModelingofComputerSystems(SIGMETRICS’19).\n[78]CongZheng,WenjunHu,andZhiXu.2018. AndroidPluginBecomesaCatas-\ntrophe to Android Ecosystem. In Proceedings of the 1st Workshop on Radical and\nExperiential Security (RESEC’18).APPENDIX\nA CORE NETWORK RESOURCE AND POWER\nMANAGEMENT\nWereusemostofCells’skernel-levelworktovirtualizecorenet-\nwork resources such as network adapters, IP addresses, and port\nnumbers.However,theAndroidsystemhasbeenupdatedsignifi-\ncantlysinceAndroid6.0.Itadoptedtheso-called“policyrouting”to\nwork with multiple routing tables and rules. Policy routing defines\nwhichtrafficaspecificroutingtableisusedfor.Therefore,weneed\nto come up with a new virtualization method. We extend Cells\nby configuring ndcandiptables commands to add new rules for\npolicy routing. As WiFi configuration management happens in the\nuserspace,weadoptthebinderservicesharingtovirtualizeWiFi\nconfiguration (see §5.1).\nIn power management virtualization, VPBox reuses Cells’s solu-\ntioninwake-locks virtualizationbutmanages earlysuspend com-\npletely differently. Since Android 6.0, the early suspend subsystem\nhasbeenreplacedbySurfaceFlinger’s setPowerMode interfaceto\nmanagedisplay’son/off-screen,whichinvalidatesCells’svirtualiza-\ntion that modifies the early suspend subsystem to recognize device\nnamespaces. By contrast, we virtualize SurfaceFlinger service at\nthe user level (see §5.2). We only need to prevent background VPs\nfrom putting the foreground VP into a low power mode via the\nsetPowerMode interface.\nRIL Java\nVendor RILRilDAndroid Java\nLibraries\nDrivers/PPP\nBaseband\nGSM/CDMALinux Kernel\nDrivers/ PPPLinux Kernel\nGSM/CDMABasebandHost Userspace VP Userspace\nCellDRIL Java\nVendor RIL\n(a) Android\nRadio Interface Layer(b) Cells\nRadio Interface LayerRilD\nRIL Proxy\nFigure 7: Cells’s Radio Interface Layer (RIL). Cells’s RIL\nproxy is visible to apps running in the VP.\nB TELEPHONY VIRTUALIZATION VIA RILD\nPROXY\nAs smartphone vendors customize their own proprietary radio\nstack,weadoptauser-leveldevicenamespaceproxytovirtualize\nthetelephonyintheVP.TheprevioussolutionproposedbyCellsis\nnot stealthy, because its proxy is located in the VP’s userspace and\nvisible to apps running in the VP. We show Cells’s Radio Interface\nLayerin Figure7.Bycontrast, wedesignasocket-interface-based\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2872proxythatonlypresentsatthehostuserspace.AsshowninFigure8,\ninthehost’sRadioInterfaceLayer,wecreateaRadioInterfaceLayerDaemon (RilD)proxy betweenthe communication flowof Android\ntelephonyJavalibraries(RILJava)andRilD.Then,wecreatetwo\nstandardUnixDomainsocketsintheproxy.Onesocketconnects\nto the RIL Java of each VP; the other connects to the RIL Java of\nthehostsystem.TheRILJavaineachVPcommunicateswiththe\nproxy of the host system, and the proxy passes the communication\ndata (e.g., dial request and SIM) to the host system’s RilD. TheRilD proxy also passes the VP-related arguments (e.g., call ringand signal strength) to the VP’s RIL Java over a socket. In this\nway, we provide a separate telephony functionality for each VP. In\naddition, we customize the SELinux-based device access controlstrategy to ensure that private call data (e.g., incoming/outgoing\ncall information and voice data) pertaining to a specific VP cannot\nbe accessed by other VPs.\nRIL Java\nVendor RILRilDAndroid Java\nLibraries\nDrivers/PPP\nBaseband\nGSM/CDMALinux Kernel\nDrivers/ PPPLinux Kernel\nGSM/CDMABasebandRIL JavaHost Userspace VP Userspace\nRilDRilD ProxyRIL Java\nVendor RIL\n(a) Android\nRadio Interface Layer(b) VPBox\nRadio Interface Layer\nFigure 8: VPBox’s Radio Interface Layer (RIL).\nTable 5: Common Radio Interface Layer(RIL) commands.\nType Commands\nSoliciteddial request, get current calls, SIM I/O,\nset screen state, set radio state\nUnsolicitedsignal strength, call ring\ncall state changed\nOnceaVP’sphonefunctionisenabled,theVPcanmake/receive\ncallsandaccessphonehardwareinformation,suchasinternational\nmobilesubscriberidentity(IMSI)andmobileequipmentidentifier\n(MEID). VPBox disables the telephony functionality for VPs that\nhave no telephony access. In addition, when the foreground VP is\nmakingorreceivingcalls, otherbackgroundVPscannotmake/re-\nceivecallseveniftheyhavethetelephonyfunctionality.Toproperly\nsupporttheforeground-backgroundusagemodel,RILcommands\nshown in Table 5 require filtering from background VPs or special\nhandling. We take the same special handling with Cells.C FILESYSTEM AND ANDROID DEBUG\nBRIDGE\nExisting Android containers’ SD card partition virtualization does\nnotcomplywiththenewSDcardaccessmanagementstartingfrom\nAndroid6.0,whichintroducesFilesysteminUserspace(FUSE)tech-\nnology to managethe SD card partition. Recent Androidversions\ndirectly fork a process in the Volume Daemon (Vold) subsystem\nandstartthesdcardprocesstomounttheFUSEfilesystem.Because\ntheFUSEmodulesupportsfilesystemcreationinuserspace,and\ntheVPinVPBoxrunscompleteuserspace,wetakethefollowing\ntwo steps to virtualize SD card partition: 1) open a “dev/fuse” node\nin the VP’s Vold process and fork a sdcard process; 2) mount FUSE\nfilesystem to the “dev/fuse” node.\nADB is a command-line utility that can debug apps, transfer\nfiles back and forth with a PC, and run shellcommands. Enabling\nADB for a VP facilitates app security testing [ 70]. ADB includes\nthree components: a client, a server, and a daemon ( adbd). Usually,\nthe ADB server and ADB client are located in one device, and they\ncommunicatewith adbdprocessinanotherdevice.Thecross-device\ncommunicationperformedbyADBcomplicatesitsvirtualization.\nIfthehostandtheVParerunningADBcommandatthesametime,\nwe must virtualize the two ends of ADB protocol to avoid conflict.\nWebuildamutualexclusionmechanismintheAndroidframe-\nwork layer. When switching a system to the foreground, we ter-\nminate the adbdprocess in the other ones. In this way, only the\nforeground VP can use ADB exclusively. This mechanism is simple\ntoimplement,butthesideeffectisthatthehostandbackground\nVPs’ADBdonotwork.Wearguethatthistrade-offisacceptable,\nastheVPisalwaysactivatedwhenusingADB.Besides,astheADB\nprotocol partition can only be mounted for one time, we also solve\nthe difficulty of sharing the ADB protocol partition with the VP. In\ntheCellDprocess,weintentionallymount“/dev/usb-ffs/adb”,the\nADBprotocolpartition’smountpoint,totheVP’ssystemdirectory.\nAs a result, the ADB protocol partition is visible to the VP.\nD KERNEL VERSION CUSTOMIZATION\n1const char linux_banner[] =\n2\"Linux version \" UTS_RELEASE \"( \"LINUX_COMPILE_BY \"@\"\n3LINUX_COMPILE_HOST \") (\"LINUX_COMPILER \") \"UTS_VERSION \"\\n\";\nListing 1: Kernel version information.\n1const char linux_proc_banner[] =\n2\"%s version %s\"\n3\"( \"LINUX_COMPILE_BY \"@\"LINUX_COMPILE_HOST \")\"\n4\"( \"LINUX_COMPILER \") %s\\n\";\nListing 2: linux_proc_banner.\nCustomizingkernelversioninformationisalittlebittricky.List-\ning1showsthekernelversioninformation.Itconsistsoftwoob-\njectsdefinedintheUTSnamespacedatastructure(“UTS_RELEASE”\nand“UTS_VERSION”),aswellaslinux_proc_bannerinformation\n(asshowninListing2).Thecustomizationoflinux_proc_banner\ninformation(Listing2)issimilartootherkernel-relatedprofilecus-tomizations,butweneedtotakespecialmeasuresfor“UTS_RELEASE”\nand “UTS_VERSION.” These two objects are bound to the UTS\nnamespace, and the only place that we can edit them is in the func-\ntion “clone_uts_ns”, which creates a new UTS namespace when\nbootingtheVP.Therefore,weembedacustomizationfunctionin\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2873Table 6: VPBox’s customizable device-attribute options (total number: 150).\nType Customizable Device-Attribute Options Number\nSystem PropertySECURITY_PATCH, RESOURCES_SDK_INT, BASE_OS, Gsm.version.baseband, Product Name, Useragent,\n36PREVIEW_SDK_INT, CODE NAME, Description, Secure, USER, Brand, Specific Version Number,\nHardware Serial Number, Device Fingerprint, Device Version Number, Product Local region,\nDevice Model, Device TAGs, Manufacturer, Device Version Type, Version ID, Product Device,\nHttpagent, Device Bootloader, Product Board, Product Locale Language, User Key, RADIO,Compile machine name, Compiler, SDK, SDK_INT, Version increment, Compile time, Compile type\nKernel VersionUTS_RELEASE, UTS_VERSION, LINUX_COMPILE_BY, UTS_VERSION,6LINUX_COMPILE_HOST, UTS_MACHINE\nMemory Heapsize, Heapgrowthlimit, AvailROMSize, TotalROMSize, AvailRAMSize, TotalRAMSize 6\nCPUCPUFreq, CPUHardware, CPU Cores, CPU Model, CPU Hardware, CPU Architecture, CPU Version,14CPUTemp, CPUABI, CPU Variant, CPU Part, Feature, CPU Serial Number, CPU Vendor\nNetworkMAC address, SSID, BSSID, RSSI, IP Address, DNS1, DNS2, Gateway, Available Networks, NetRate,18Netmask, WiFiState, NetworkInerfaces, TypeName, NetworkId, NetworkType, Network Capabilities, Throttling\nPowerBattery Scale, Battery Plugged, Battery Temperature, Battery health, Battery Voltage,9Battery Level, Battery Status, Battery Technology, Battery Type\nBluetoothBluetooth Name, Bluetooth MAC Address, Connected Devices, ProfileConnectionState,\n14 Available Devices, Bluetooth Scanmode, Bluetooth Version, Bluetooth State, Bonding State,Device Alias, Profiles (e.g., Contact Sharing), Rssi, ScanResultType, ManufacturerData\nLocationAccuracy,Speed , GPS Status, Location Type, Best Providers, Base Station Signal Strength, NetworkId,15Longitude, Latitude, Bearing, Altitude, Location Area Code, Cell Identity, SystemId, BaseStationId\nTelephonySubId, ImsRegistrationState, MMS_USER_ANENT, MMS_UA_PROF_URL, Mobile Network Cod,\n20 IMEI1, IMEI2, MEID, IMSI, IMEISV, ESN, ICCID, Phone Number, SIMState, SIMCountryIso,Carrier_name, Mobile Country Code, SIMOperatorName, Phone Type, SIMOperator\nDisplay & GPUGPU Version, Vendor, Density, Renderer, Resolution, ScaledDensity, Extensions,12Touch Screen Type, Brightness, x_px/y_px, x_dpi/y_dpi, GPU Extension\nTable 7: G-Ware samples’ MD5 values.\nSample MD5\nG-Ware1 B7494A6879FD107FC0910D9F6B7F49B2\nG-Ware2 AE2437BC6B21D83A9262A752CD56E678\nG-Ware3 BB878E32E75D1136CC10D89619C64E37\nG-Ware4 6F46F37EFACE7E6ED38306DA9536A9E5\nG-Ware5 5B6614A0E3A824DE836B5D86919F37DA\nG-Ware6 8FDFD410B35B356EE2D67828A6A2F05C\nG-Ware7 5F62A64CCA5E5CA87C36D3FC6D2FC986\nG-Ware8 F9265AA20E6D53C680B9A76E4CFC9F28\nG-Ware9 1F66A7A83A331C4DA8FF9EB55C7B317C“clone_uts_ns”to1)accessourcustomized“UTS_RELEASE”and\n“UTS_VERSION”viaourcreatedsyscall;2)updatethedatastructure\n“new_utsname” that defines these two objects.\n,\nSession 11A: Attestation and Firmware Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n2874"}
{"title": "TrustOre: Side-Channel Resistant Storage for SGX using Intel Hybrid CPU-FPGA", "content": "TrustOre: Side-Channel Resistant Storage for SGX\nusing Intel Hybrid CPU-FPGA\nHyunyoung Oh\nECE&ISRC,SeoulNationalUniversityAdil Ahmad\nPurdue UniversitySeonghyun Park\nECE, Seoul National University\nByoungyoung Lee∗\nECE, Seoul National UniversityYunheung Paek∗\nECE&ISRC,SeoulNationalUniversity\nABSTRACT\nIntelSGXisasecuritysolutionpromisingstrongandpracticalse-\ncurity guarantees for trusted computing. However, recent reports\ndemonstrated that such security guarantees of SGX are broken\ndue to access pattern based side-channel attacks, including page\nfault, cache, branch prediction, and speculative execution. In order\nto stopthese side-channel attackers, ObliviousRAM (ORAM) has\ngainedstrongattentionfromthesecuritycommunityasitprovides\ncryptographicallyprovenprotectionagainstaccesspatternbased\nside-channels.Whileseveralproposedsystemshavesuccessfully\nappliedORAMtothwartside-channels,thoseareseverelylimitedin\nperformanceanditsscalabilityduetonotoriousperformanceissues\nof ORAM. This paper presents TrustOre , addressing these issues\nthat arise when using ORAM with Intel SGX. TrustOre leverages\nanexternaldevice,FPGA,toimplementatrustedstorageservice\nwithin a completed isolated environment secure from side-channel\nattacks.TrustOre tacklesseveralchallengesinachievingsucha\ngoal:extendingtrustfromSGXtoFPGAwithoutimposingarchi-\ntecturalchanges,providingaverifiably-secureconnectionbetween\nSGX applications and FPGA, and seamlessly supporting various\naccessoperationsfromSGXapplicationstoFPGA.Weimplemented\nTrustOre onthecommodityIntelHybridCPU-FPGAarchitecture.\nThenweevaluatedwiththreestate-of-the-artORAM-basedSGX\napplications,ZeroTrace,Obliviate,andObfuscuro,aswellasanend-\nto-end key-value store application. According to our evaluation,\nTrustOre -basedapplicationsoutperformsORAM-basedoriginal\napplicationsrangingfrom 10×to43×,whilealsoshowingfarbet-\nter scalability than ORAM-based ones. We emphasize that since\nTrustOre canbedeployedasasimpleplug-intoSGXmachine’s\nPCIeslot, itis readilyused tothwart side-channelattacks inSGX,\narguably one of the most cryptic and critical security holes today.\nCCS CONCEPTS\n·Securityandprivacy →Side-channelanalysisandcounter-\nmeasures; Security services ; Security protocols.\n∗co-corresponding author\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,\ntopostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’20, November 9ś13, 2020, Virtual Event, USA\n© 2020 Association for Computing Machinery.\nACM ISBN 978-1-4503-7089-9/20/11...$15.00\nhttps://doi.org/10.1145/3372297.3417265KEYWORDS\naccess pattern based side-channel; secure storage; hybrid CPU-\nFPGA; Intel SGX\nACM Reference Format:\nHyunyoungOh,AdilAhmad,SeonghyunPark,ByoungyoungLee,andYun-\nheung Paek. 2020. TrustOre : Side-Channel Resistant Storage for SGX\nusing Intel Hybrid CPU-FPGA. In Proceedings of the 2020 ACM SIGSAC\nConference on Computer and Communications Security (CCS ’20), Novem-\nber 9ś13, 2020, Virtual Event, USA. ACM, New York, NY, USA, 16 pages.\nhttps://doi.org/10.1145/3372297.3417265\n1 INTRODUCTION\nIntelSoftwareGuardeXtension(SGX)isaprocessorextensionthat\noffersstrongandpracticalsecurityguaranteesbyexcludingprivi-\nleged system software and other unprivileged software from the\ntrustedcomputingbase(TCB).Thisprocessorextensionprovides\nsoftwareapplicationswithshieldedexecutionenvironments,called\nanenclave,wheresecurity-sensitivecodeanddatacansafelyrunin\nan environment isolated from the rest of systems. Using SGX, even\nprivileged software components such as OSes and hypervisors are\nnot allowed to directly access the enclave’s memory.\nHowever, recent reports have demonstrated that Intel SGX is\nvulnerabletovariousmemory-basedside-channelattacks(e.g.page-\nfault-based attacks [ 82], cache-based attacks [ 11], branch predic-\ntion[42],ForeShadow[ 73],RIDL[74],andFallout[ 49]).Wenote\nthese side-channel attacks pose real threats as demonstrated by\nrecent studies Ð using these attacks, it has been shown that adver-\nsaries can completely nullify the confidentiality guarantee of Intel\nSGX through leaking sensitive information from enclaves.\nInordertopreventtheseside-channelattacksagainstSGX,re-\ncentstudies[ 3,4,60]haveproposedusingObliviousRAM(ORAM)\ntoprotectaccesspatternsleakedwhileaccessingmemory.Underthe\nconceptofORAM[ 23],whichprovidescryptographicallyproven\nsecurity resistant against access pattern based attacks, each data\nobject is appended with multiple dummy objects and continuously\nshuffledaftereachaccess.UsingORAM,severalprotectionsystems\nhavebeenproposed.ZeroTrace[ 60]ensuressecureaccessestodata\nstructures, Obliviate [ 3] provides secure file systems, and Obfus-\ncuro [4] guarantees black-box based secure program execution.\nWhile these applications have further security benefits and protec-\ntion scopes, the key common feature is that they are all relying on\nORAM protocols to thwart side-channels within enclaves.\nHowever,ORAMisnotoriousforitsslowperformanceandscala-\nbilityissues,severelyhinderingitsadoptioninreal-worldscenarios.\nThe ORAM protocol requires orders of magnitude larger memory\nbandwidth than a normal memory access, as it has to access an\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1903entiretreepathforeachmemoryaccessÐitapproximatelyrequires\nO(LoдN)memory accessesper access, where Nis proportionalto\nthesizeofprotecteddata.Basedontheexperimentalevaluations\nin above-mentioned papers, the overhead of ORAM is at minimum\ntwodegreesovernativeenclaveexecution.Moreimportantly,all\nthesepaperspointtoscalabilityissuesofORAMÐasthesizeofpro-\ntecteddatabecomeslarger,theperformanceexponentiallyslows\ndown, a fact we experimentally verify in our evaluation as well.\nThis paper proposes TrustOre , a system that addresses perfor-\nmanceandscalabilityissuesthatarisewhileusingORAMwithIntel\nSGX. The main idea behind TrustOre is to leverage an external\ndevice, i.e., an FPGA, to implement a trusted storage service for\nenclaves. This is based on the observation that the root cause of\nmemory-based side-channel issues in enclaves is because memory-\nrelated units (such as caches, page tables and branch prediction\nunits)aredesignedtobesharedwithuntrustedsoftware.Therefore,\nwe design the trusted storage on an isolated FPGA environment,\nhavingitsownmemory-relatedunitsisolatedfromotherentities\nand as a result avoiding memory-based side-channels by design.\nInordertoadoptFPGAswithIntelSGX, TrustOre hastotackle\nfollowing challenges: (a) extending trust from enclaves to FPGA\nwithoutimposingarchitecturalchangestoinvolvedcomponents;\n(b)providingaverifiably-secureconnectionfromenclavestoFPGA\nwithoutimposingmassiveoverheads;and(c)seamlesslysupport-\ning various accessoperations from enclaves to the FPGAwithout\ninvolving huge porting efforts. To elaborate, TrustOre relies on\nan external FPGA device, but the FPGA is not a trusted component\nintheIntelSGXarchitectureandthereforeweneedanadditional\nmechanismtoextendtrusttoit.Moreover,anFPGAarchitecture\nitself does not provide a mechanism to affirm its authenticity to\nothers. To address this challenge, TrustOre designs a new attesta-\ntion mechanism for the CPU-FPGA architecture such that enclaves\ncan safely verify the authenticity of FPGA instance.\nWe highlight that TrustOre ’s attestation does not impose any\nhardware/architectural change, and thus it can be used with\ncommodity-off-the-shelf Intel SGX hardware and FPGA devices.\nThis is a notable difference from previous solutions, which require\nhardware/architectural changes,renderingtheir solutionslimited\ntocustomarchitecturesandthusincurringfabricationchallengesor\nhigh manufacturing costs. For example, hardware-assisted ORAM\ndesigns[21,22,43,45]requireaddingspecialhardwareorsignifi-\ncant extra protections (for ORAM controllers in particular) within\nthe hostCPU,as shown byrecent report[ 4]. Asanother example,\npreviousworksencryptingthecommunicationchannelbetween\nCPU and memory [ 2,8,63,76] either require special hardware\ncomponents in memory (i.e., processing-in-memory) or design a\ncustommemoryboard.Onthecontrary, TrustOre isbuiltonan\nIntel hybrid CPU-FPGA architecture for which its practical aspect\nis already evidenced in several places Ð for instance, Amazon EC2\nalreadyprovidesFPGA-builtinserversinAmazonWebServices[ 5].\nFurthermore, TrustOre has to efficiently connect an enclave to\ntheFPGAwithsecurityassurance.Since TrustOre outsourcesa\nmemory access to the external FPGA device, the performance of\nan SGX application can be blocked by the extra communication\ndelaybetweenCPUandFPGA.Moreimportantly, TrustOre hasto assume that an attacker would be able to eavesdrop this com-\nmunicationwhichinvolvesuntrustedsystemcomponentsaswell\nas untrusted memory. As such, in consideration of the man-in-the-\nmiddleattackmodel, TrustOre carefullydesignsitscommunica-\ntion channel while ensuring following features: (a) all MMIO/DMA\naddressesremainconstantand(b)alldatawrittentotheseaddresses\nis encrypted using a shared key established between the enclave\nand the FPGA module.\nLastly,TrustOre has to seamlessly support various memory\nallocation/deallocation as well as access operations from enclaves\nwithout involving huge porting efforts. To this end, TrustOre\ntakes akey-value store model in designing its FPGA on-chip mem-\nory storage, and provides minimal and simple interfaces for en-\nclavestoutilize TrustOre ’skey-valuestore.Sincethekey-value\nstore model can be easily used to represent many different data\nresources and objects, TrustOre ’s storage model can easily fit the\nneedsofdifferentenclaveapplications.Asaconcretecase-study,we\nfirstimplemented TrustOre basedonacommodityhybridCPU-\nFPGA architecture. Then, we develop extra APIs to fairly evaluate\nexisting schemes such as ZeroTrace, Obliviate, Obfuscuro, while\nreplacingtheirORAMoperationswith TrustOre ’strustedstorage\nservice. We also applied TrustOre for an end-to-end key-value\nstore, ShieldStore [39].\nAccordingtoourevaluation, TrustOre -basedapplications(which\nreplacedORAMwith TrustOre )significantlyoutperformsORAM-\nbasedoriginalapplicationsforallcases. TrustOre -basedZeroTrace\naccesses data structures with various block sizes 49×faster than\nORAM-based ZeroTrace (i.e., an original ZeroTrace) on average.\nTrustOre -based Obliviate accesses the files of size 1GB about 10×\nfastercomparedtoORAM-basedObliviate. TrustOre -basedObfus-\ncuroisfasterthanORAM-basedObfuscuro,rangingfrom 2×to43×.\nTrustOre -based ShieldStore is faster than ORAM-based Shield-\nStore about 188×. Particularly focusing on scalability , TrustOre -\nbased applications showed far better scalability compared to its\noriginal ORAM version. While ORAM-based applications expo-\nnentiallyslowdownasincreasingthedatasize, TrustOre -based\napplicationsslowdownsmoothlyormaintaintheconstantthrough-\nput irrespective to the data size (more details are in ğ7).\nGiven the trusted memory storage provided TrustOre , vari-\nousinterestingapplicationsforanenclavecanbebuiltwithside-\nchannelsecurityassurance.Webelieve TrustOre isanattractive\nsolution particularly because it is ready-to-deploy and easy-to-\ndeploy Ð by simply plugging-in the FPGA card to the available\nPCI-Eslot, TrustOre canstartservingthetrustedmemorystorage\natthegigabytesscale1withoutanyhardware/architecturechanges.\nIn summary, this paper makes the following main contributions:\n•Design:ExtendingTrusttoFPGA. Tothebestofourknowl-\nedge,TrustOre is the first system extending the trust of In-\ntel SGX to FPGA. Unlike other related work [ 75] extending\ntrust to an external device, TrustOre does not impose archi-\ntectural/hardware changes, and is therefore readily deployable\noncommodity-off-the-shelf Intel SGX machines.\n•Design: Trusted Storage on FPGA. TrustOre designs its\ntrusted storage on FPGA, which tackles unique design require-\nments.TrustOre providesthe secureconnectionbetweenan\n1IntelcurrentlyprovidesFPGAwith16GBpackedDRAMinIntelStratix10MXand\nXilinx does 8GB in Virtex UltraScale+ HBM VCU128-ES1.\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1904SGX application and the FPGA, and seamlessly supports the\nrequirements of various enclave applications by maintaining a\nkey-valuestoremodelontheFPGAmemory,achievingefficient\nand scalable performance.\n•CaseStudy:PracticalEnd-to-EndSystem. Weimplemented\nTrustOre on a commodity Intel hybrid CPU-FPGA architec-\nture.Then,inordertostakeourclaimasafaster,andmorescal-\nablestoragesystemthanORAMforSGXenvironments,weused\nTrustOre to re-implementthree ORAM-based protection sys-\ntems,includingZeroTrace[ 60],Obliviate[ 3]andObfuscuro[ 4],\nand compared performance aspects between ORAM-based and\nTrustOre -based ones. Our results indicate that TrustOre -\nbasedschemesoutperformsORAM-basedschemesbyalmost\ntwo degrees, demonstrating its scalability for real-world work-\nloads.\n2 BACKGROUND\n2.1 Intel SGX\nIntelSGX[ 48]isanextensiontothex86InstructionSetArchitecture\n(ISA)availabletoprocessorsstartingfromtheSkylakearchitecture.\nTheseinstructionsallowauser-levelprocesstoallocateatrusted\nmemoryregioncalledanenclave,whichisonlyaccessibletothe\nenclave itself, and not to other user or system components, e.g.,\notherprocesses,OS,hypervisorandBIOS.Thismemoryregionis\nallocatedfromareservedmemoryontheDRAMcalledtheEnclave\nPageCache(EPC),whichisinitializedatthebootingtime.TheEPC\niscurrentlylimitedto128MB,butthismemorylimitationcanbe\nalleviated by using page swap-in/out mechanism.\nSide-channel Issues. Reports [72,82] have shown that attackers\ncanobservepage-granularmemoryinteractionsbeingperformed\nby SGX application using page faults or stealthily observing the\naccess/dirty bit within enclave page tables. Using this information,\nresearchers have demonstrated how to leak various information\nsuchasinferringrenderedJPEGimagesandspell-checkedwords\nfromenclaves.Furthermore,researchers[ 11,61]haveshownhowto\nleakentirecryptographickeysfromenclavesrunningmbedTLS[ 44]\nthrough prime+probe attacks [ 52] on various caches (from L1 to\nLLC)whicharesharedbyenclaveandnon-enclaveentities.Finally,\nbranch prediction [ 19,42] allows privileged entities to observe\nthebranchinghistoryoftheenclavetherebyprovidingthemfine-\ngrained insightsinto thecontrol-flowallowing forsimilar attacks\nto the ones mentioned above. More recently, various speculative\nexecution attacks [ 13,73] have been shown to affect SGX enclaves.\n2.2 FPGA\nAField-ProgrammableGateArray(FPGA)isaspeciallydesigned\nre-configurableintegratedcircuit.Atahigh-level,FPGAsconsist\noftwo components,the infraprimitive andfabric.The infraprim-\nitive is a set of non-configurable hardware circuits. The fabric is\na configurable circuit which is initialized by the infra primitive\ntorealizealogicdesignedbythedeveloper.Withthistwo-staged\ncircuitdesign,FPGAsofferdevelopersadesignflexibilityaswellas\nvarioussecurityguarantees,asexplainedinthecomingparagraphs.\nBitstream Preparation. The core of an FPGA module is a bit-\nstream,whichisthelogicintendedbythedeveloper.Thisbitstream\niscompiledusingtheFPGAmanufacturer’scompiler-toolsandis\nappendedwithamanufacturer-specificbootloadertoformarawFPGA\nFPGA fabric\nFPGA infra primitive\nBoot ROMAES \ndecryptor\neFUSE \u0001\u0002\u0003\u0004\u0004\u0005\u0006\u0007\u0006\b \u0001\t\n\u000b\u0004\u0005\u0006\u0007\u0006\b\nFPGA ManufacturerBoot image\nBootloader\n\u0001\u0002\b\u0005\f\u0004\u0005\u0006\u0007\u0006\b\u0001\t\n\u000b\u0004\u0005\u0006\u0007\u0006\bBitstream\nBoot loader❹\n❶❺ ❸ FPGA\nVendor\nTool\n❷Boot imageS\nBootloaderSBitstreamS\nSignatureConfigurable\nNon-configurable\nFPGA Developer\nFigure 1: A generic secure boot architecture of FPGA\nboot image. To protect the the FPGA design from copying or re-\nverse engineering, the boot image is encrypted. Authentication\nadditionally provides assurance that the boot image is genuine\nand created by an authorized developer, i.e., authentication verifies\nboth data integrity and authenticity of the boot image. For such\nencryptionandsigning,itisrequiredtogenerateandsecurelyman-\nage two kinds of keys: an RSA public/private keys for signing (i.e.,\nkbitstr\nPubandkbitstr\nPriv)andanAESencryptionkey(i.e., kbitstr\nAES).Tobemore\nspecific, each component of the boot image (i.e., boot loader and\nbitstream) is encrypted using kbitstr\nAESand then signed using kbitstr\nPriv, in\nturn (bootloaderSand bitstreamS). So,kbitstr\nAESandkbitstr\nPrivshould be\nprotected from any others except an authorized user. Since FPGAs\nhave one-time programmable and tamper-resistant storage for the\nkeys as will be explained later, we assume the FPGA manufacturer\nbakesthekeyduringmanufacturing.Oncealloftheabovestepsare\ncomplete,bootloaderSandbitstreamSarenowreadytobereleased.\nBitstream Loading. The on-chip FPGA infra primitive loads\nsignedbootimageusinga securebootprocess.Theimplementation\ndetails of this process depend on FPGA manufacturers, such as\nSecure Device Manager (SDM) [ 69] of Intel and Processing System\n(PS)ofXilinx[ 59].Figure1providesageneraloutlookonthesecure\nboot process in a hardware-agnostic manner. The boot ROM in the\ninfraprimitiveloadsthesignedbootimagefromthehostsystem.\nThen, it authenticates each component of the image using the RSA\npublickey(i.e., kbitstr\nPub)(1),anddecryptscorrectlyauthenticatedones\nusing the AES key (i.e., kbitstr\nAES) (2,3). After this, the bootloader is\nlaunchedintheinfraprimitive( 4).Lastly,thebootloaderloadsthe\nbitstream to the FPGA fabric ( 5), and hands over the execution to\nthe loaded bitstream.\nSecure Boot Assumptions. FPGA manufacturers support a se-\ncurebootprocessofbitstreamstoensureauthenticityandconfiden-\ntiality.Thissecurityfeatureisdesignedtoholdunderthefollowing\nassumption on key management and FPGA configuration. First,\nFPGAmanufacturers(suchasIntelandXilinx)areassumedtobe\ntrusted and responsible to securely generate cryptographic keys\n(i.e.,kbitstr\nPubandkbitstr\nPrivforRSAauthenticationand kbitstr\nAESforAESen-\ncryption)suchthatanadversarycannotobtainsecuritysensitive\nkeys including kbitstr\nPrivandkbitstr\nAES.kbitstr\nPubandkbitstr\nAEScan be programmed\nto either one-time programmable eFUSE or multiple re-writable\nbattery-backedRAM,whichcanflexiblyfacilitatethesecurekey\nsetup.Second, allsecuritysensitive code anddata(including boot\nROM,AESdecryptor,and kbitstr\nPubandkbitstr\nAES)areassumedtobetamper-\nresistant by their design. The boot ROM functions as a root-of-trust\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1905forensuringconfidentialityandauthenticityofbitstreamandthere-\nfore should not be tampered-with by system components.\nItisworthtonotethatwhereasIntelSGXsupportsremoteattes-\ntationofanenclaveapplication,currentFPGAarchitecturesdonot\nemploysuchremoteattestationfeature.FPGA’ssecurebootonly\nguarantees the authenticity and confidentiality of the bitstream\nduringboottime.ThereasonwhyFPGAsdonothavetheremote\nattestation feature is arguably related to the fact that FPGAs are\ndesignedasageneralpurposehardwarecomponents,e.g.,proto-\ntyping new hardware logics or facilitating highly parallelizable\ncomputation.ThisisdifferentfromIntelSGX,whichisdesignedas\na security enhancing feature for trusted remote computation.\nConnectionwithHostCPU. Afterthebooting,theFPGAbegins\noperation as programmed in the bitstream. When the bitstream\nis running, the FPGA is connected to the host CPU through the\nIObus(QPI[ 31]orPCIe[ 80],whichareoftenusedinCPU-FPGA\nhybrid architectures). The FPGA device driver provided by the\nmanufacturer extends host CPU memory space to include FPGA\nmemoryusing memorymappedIO, suchthatthe CPU canaccess\nFPGA address space in the same way as regular memory. Inside\nthe FPGA, the IO bus signals from the host CPU are converted\nto its internal bus and transmitted to the programmed hardware\nmodulesoron-chipFPGAmemorydirectly.Thesenderwaitsfor\nan acknowledgment before initiating the next transmission.\n3 THREAT MODEL\nEnclave Assumptions. We assume that a user wants to run an\napplicationsafelyusingatrustedSGXenclaveonaremotemachine.\nTheapplicationitselfispublicandknowntotheattackerandthere-\nfore,thecodesectionsoftheapplicationarenotsecurity-critical.\nHowever, the data provided to the enclave by the user (e.g., a cryp-\ntographic key) is critical and has to be protected from side-channel\nleakage prevalent in Intel SGX. In the context of our work, we\nassume a single party, i.e., the enclave developer is the same entity\nwhowillbootstrapourserviceontotheFPGAdevice.However,the\ndevelopercanrunmultipleenclaveswhichcanconcurrentlyaccess\nthe FPGA device for some service.\nHardware Assumptions. Our hardware trusted base consists of\nthe CPU chip and FPGA chip, which we assume are tamper-proof\nand correctly implemented. We assume that the attacker cannot\ndirectly extract secrets or corrupt state within the packages, as\nreverse engineering these packages is highly challenging. We note\nthat,similartocommodity-off-the-shelfCPUs,currentFPGAshave\na3D-stackedlayer with14nanometerfabricationnodes2,thereby\nintroducing similar reverse-engineering challenges. Power [ 40],\nthermal[55]side-channelsforFPGAandCPUpackagesareoutside\nthe scope of this paper.\nAttacker’sCapabilities. Theattackercontrolsallprivilegedsoft-\nware components including BIOS, OS, VMM, and device drivers.\nFurthermore,theycontrolallotherexternaldevices(e.g.,storage,\nnetworking etc.) on the system except for the FPGA device. There-\nfore,whiletheattackercannotdirectlyaccessmemoryownedby\nthe target application, they can still launch side-channel attacks\nsuch as page tables and cache attacks. Furthermore, all non-EPC\n2Inteli7-9700CPUhas14nanometerfabricationnodes,whileXilinxUltraScale+FPGA\nhas 16 and Intel Hyperflex FPGA has 14 nanometer.CPU\nEnclave\nUser\nCodeTRUST LIBrequest\nresponse\nUntrusted Memory           DMA Buffer\nencrypted data (DMA mode)\nplain dataFPGA\nTRUST MODIO BUS\nID Address\nDMA\nControllerAttester,\nKeyExchanger\nAES\nOn-chip Memory\nencrypted data (MMIO mode)On-chip Memory\nAllocation Table\nID\nAddress Lookup\ndata block\nMemory ManagerMMIO Region\nFigure 2: Design overview of TrustOre.\nhost memory (such as DMA/MMIO buffers) is assumed to be com-\npletely controlled by the attacker. Although the attacker cannot\ndirectlyextractthedatafromtheFPGAdevicememoryprotected\nbyTrustOre’saccesscontrolmechanism(seeğ4.2,ğ4.3),weassume\nthat the attacker can launch side-channel attacks against the FPGA\ndevice memory (similar to DRAM-based side-channel attacks [ 54]).\nWe further assume that the attacker has physical access to all hard-\nware components such as FPGAs. Thus, the attacker can launch\nphysical side-channel attacks, which snoop various buses on hostÐ\nthe host memory bus, the PCIe bus, and other exposed IO buses.\nWenotethat TrustOre doesnotmitigatetransientexecution\nattacks(suchasForeShadow,RIDLandFallout)whichtargetthe\nenclaveprogramrunningontheCPU.Instead, TrustOre prevents\nside-channelattacksoftheenclave’ssensitivedatabyoffloadingthe\ndatatotheFPGA.Attackerscanstilllaunchside-channelattacks\nagainsttheenclaveprogram,butthedataisprotectedandtheaccess\npattern is also protected by TrustOre . Specifically, we design the\nFPGAmodulesandinterfaceswhicharesecurefromvariousside-\nchannel attacks (as will be shown in Table 1) and provide the side-\nchannelresistantstorageforsensitivedataevacuatedfromtheCPU.\nInFPGA,attackslikeForeShadowcannotbelaunchedbecauseno\ncaches and prediction logics are inside the FPGA (see ğ4.2).\n4 DESIGN\nTrustOre isa trustedstoragesystem forenclaveapplications im-\nplemented on an authenticated and attested external FPGA de-\nvice.Figure2depictsadesignoverviewof TrustOre .Ingeneral,\nTrustOre consists of two major components Ð TrustLib and\nTrustMod.\nTrustLib is an in-enclave library required for establishing and\nmaintaining the communication channel between the enclave pro-\ngram and the trusted storage service.\nTrustMod is the core component implementing the trusted stor-\nage, which is a module loaded to the FPGA device.\nInthecomingsubsections,webeginbydescribinghow TrustOre\nextends trust from an SGX enclave (containing TrustLib ) to\nTrustMod (ğ4.1). Since TrustMod is an external component (i.e.,\nnot locatedinside theenclave), wedesign anew remote attestation\nmechanismforFPGAalongwithacryptographicschemeforsecur-\ning communication between these entities. Next, we describe how\nTrustOre implementsthetrustedstoragewithin TrustMod (ğ4.2).\nIngeneral, TrustMod constructsakey-valuestoreusingtheFPGA\non-chip memory, providing a storage service capable of servic-\ning multiple enclaves while enforcing access control ensuring the\nsecurityofenclavedatastoredontheFPGAdevice.Lastly,wede-\nscribe the two communication mechanisms (i.e., MMIO and DMA)\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1906TRUST MODFPGA Chip\nManufacturerTRUST ORE\nDeveloper\n①KeyGen()\n→  , ②-a TRUST MODbitstream\n②-b Encrypted and signed \nTRUSTM ODbitstream ⓪-a\nPrepareKey() \n→ ,\nFPGA\n⓪-b Write keys to FPGA at manufacturing stage\n③-a Encrypted and signed \nTRUSTM ODbitstream\n③-b Verify and decrypt \nbitstream to load T RUST MOD\nEnclave \nCode\n④Remote attestation and key exchange\nTRUST MOD\nTRUST MOD\nTRUST LIB\nTRUST MOD\nFigure 3: Key management for secure loading TrustMod\nsupported by TrustOre in order to efficiently connect the afore-\nmentioned components (ğ4.3).\n4.1 Loading and Attesting TrustMod\nOneofthekeycomponentsof TrustOre ,i.e.,TrustMod isimple-\nmentedonanexternalFPGAdevice.However, TrustMod hasto\nbeloadedbytheuntrustedOS(usingthedevicedriver)andisthere-\nforesusceptibletotheattacker’smaliciousbehavior.Sinceexternal\ndevicesarenotpartoftheprotectionscopeofSGX,conventional\nremoteattestationprovidedbyIntel[ 48]isinsufficienttoattestthe\ncorrect loading of TrustMod . Furthermore, state-of-the-art FPGA\narchitectures(suchasthoseprovidedbyIntelandXilinx)lackan\nattestation feature as mentioned in ğ2.2. As a result, we develop\nnewtechniquesforextendingtrustto TrustMod inordertoverify\nthe correctness of loaded instance.\nLoading using Device Driver. TrustOre provisions anexisting\nsecurity feature of the FPGA platform to securely load TrustMod\nto the FPGA. More specifically, TrustOre leverages an FPGA’s\nsecure boot process (see ğ2.2) to ensure the confidentiality and\nauthenticityof TrustMod (i.e.,abitstreamlayoutof TrustMod )\nto be loaded to the FPGA fabric. The confidentiality of TrustMod\nis important since it contains a pre-installed private key, which\nis used to attest TrustMod itself (as we explain shortly). On the\notherhand,authenticationisimportantbecauseanunauthenticated\nmodule can directly leak the trusted data of an enclave and should\ntherefore not be utilized.\nHowever,consideranaivesecurebootof TrustMod ,natively\nsupported by existing FPGAs and mentioned in ğ2.2. In particu-\nlar, a bitstream layout of TrustMod is initially prepared by the\nTrustOre developer (let the TrustOre developer be us in this\npaper). Then, this bitstream is delivered to the FPGA manufacturer,\nwhoreturnsanencryptedandsignedbitstreampairwhichisloaded\nontotheFPGAdevice.EventhoughtheFPGAchipmanufacturercorrectly signs and encrypts the bitstreams, this step only guar-\nantees the confidentiality of TrustMod . The reason is that the\nattackercanjustaseasilyprocuresignedbitstreamsfromtheFPGA\nmanufacturer and overwrite TrustMod at runtime. As a result,\nthereisaneedforafurtherauthenticationorattestationscheme\nto augment the protections of secure boot.\nAttestation through TrustLib. TrustLib is responsible for at-\ntesting that the correct module of TrustMod is loaded onto the\nFPGA device that the enclave is copying its private data to. To\nachievethis, TrustOre placesanRSAprivatekeywithinthebit-\nstreamof TrustMod andusesitasasecurityanchorforruntime\nattestation of the FPGA.\nTobemorespecific,wegenerateauniqueattestationkeypair\n(i.e.,kattest\nPubandkattest\nPriv)beforehand.Thesepairsaregeneratedfrom\nscratch each time a module is compiled ensuring that different de-\nvices have different attestation key pairs. Afterwards, TrustOre\nappendstheattestationprivatekey( kattest\nPriv)toTrustMod (2-a)and\nthe attestation public key ( kattest\nPub) is provided to TrustLib (4) as\nshowninFigure3.As TrustMod ’scompiledbitstreamishanded\nover to the FPGA manufacturer for signing, kattest\nPrivis stored en-\ncrypted withinthe bitstream( 2-b,2-c). Oneshortcoming ofthis\nschemeisthattheFPGAchipmanufacturermayperformcircuit-\nlevelreversingtodeciphertheattestationkeystoredin TrustMod .\nHowever,inourthreatmodel,thechipmanufactureristrustedand\ntherefore this problem is out-of-scope. It can be solved by applying\nobfuscation techniques proposed previously [37, 46, 79].\nAs soon as TrustMod ’s bitstream is loaded to the FPGA ( 3),\nTrustLib attests it using its attestation private key ( 4), similar to\nother known attestation schemes [ 6,16]. One notable difference is\nthatTrustMod does not need to provide a runtime measurement,\nsincetheFPGA’ssecurebootalreadyensurestheintegrityofthe\nloaded bitstream. Moreover, in order to ensure the freshness of the\nattestation message, TrustLib generates a random nonce for each\nattestationandsendsitto TrustMod asillustratedinFigure4( 1).\nThenTrustMod creates a signature of the received nonce with\nkattest\nPriv,andreturnsthesignaturebacktotheenclavewhichcanbe\nverified by an enclave using kattest\nPub(2). This prevents malicious\nentities from intercepting and/or replaying communication. There-\nfore,ifanadversaryrewritestheFPGAbitstreamtoimpersonate\nTrustMod , this would be detected by our runtime attestation as\nlong askattest\nPrivfrom the encrypted bitstream is secure.\nInsummary,theattestationprocessworksasfollowsÐ TrustLib\nwrites a random nonce to the fixed MMIO address assigned to the\nattestationtransmissionchannel. TrustMod receivestherequest\nof the nonce and starts thesigning operation. After signingusing\nkattest\nPriv,TrustMod transmitstheresultantbacktothe enclave.The\nenclaveatteststhatitbelongstoacorrectmoduleusing kattest\nPubwhich\nshould only work as long as the module has the correct kattest\nPriv.\n4.2 Bootstrapping a Storage Model\nAfterTrustMod has been loaded onto the FPGA, it begins the\nprocess of building a trusted storage within the internal device\nmemory. In order to accommodate various enclave applications,\nTrustOre designs a flexible storage model which is compatible\nwith various use-cases Ð including the general data structures\n(similar to ZeroTrace [ 60]), various files (similar to Obliviate [ 3])\nandgeneralmemoryblocks(similartoObfuscuro[ 4]).Furthermore,\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1907wesupportanaccesscontrolmechanismwithrespecttoanenclave\napplicationsothataninstanceof TrustMod canbeconcurrently\nused by multiple different enclave applications.\n4.2.1 Memory Addressing &Tracking. TrustOre needs a scheme\nto address the device memory for further storage semantics and\nneeds to track the device memory which will be allocated to differ-\nent enclaves.\nDevice Memory Addressing. TrustMod accesses the underly-\ningFPGAmemorydirectlyÐitdoesnotcache/fetchthememory\ncontent and does not utilize virtual addresses either. This is the\nnotable difference from enclave applications, where its page tables,\ncacheunits,andbranchprediction-units(BPUs)areaccessibleto\nuntrusted components and therefore vulnerable to side-channels.\nOn-Chip Memory Allocation Table (OCMAT). TrustMod\ntracks all memory allocated to various enclaves using the On-Chip\nMemory Allocation Table (OCMAT). Using OCMAT, all storage op-\nerations (requested by TrustLib as we will describe later in ğ4.3.3)\narecarriedoutbasedon ID(i.e.,akeyinakey-valuestore).Each\nrowof OCMAT recordsfollowinginformation: 1) ID,an identifier\nspecifyingadataobject. IDisinternallymaintainedandassigned\nbyTrustMod ; 2) EID, an identifier specifying the owning enclave.\nTrustMod ensuresanenclavecannotaccessdataobjectsownedby\notherenclaves;3)On-chipaddress,aphysicalFPGAon-chipaddress\nstoringthedataobjectcorrespondingto ID;SinceTrustMod ’sstor-\nageisbuiltuponFPGAon-chipmemory(whichhaslinearphysical\nmemoryspace),thisaddressassists TrustMod tolocatethedata\nusingID; and 4) Size, the memory size allocated for each ID.\n4.2.2 RequestServicing. Eachenclaveis assignedauniqueidenti-\nfierduringinitializationandtheir subsequentrequestsareplaced\nin an internal FIFO queue by TrustMod , for servicing on a first-\ncome-first-servebasis.IncasetheinternalFIFOqueuebecomesfull,\nTrustMod stallsthebusfromacceptingmorerequestsbydelaying\nthe acknowledgment signals.\nAccess Control. TrustMod assigns a unique Enclave-ID (EID)\ntoeachconnectedenclave.EIDisderivedfromthecryptographic\nshared key linked to the enclave and TrustMod stores this in-\nformation internally. Afterwards, each subsequent request from\nthe enclave (identified by encrypted communication on a fixed\nMMIO/DMA region), is attributed to this EID. The EID ensures\nthat an enclave can only access its own memory and a request\nto a memory region it does not own will be promptly caught by\nTrustMod and dropped.\nServicingMemoryAllocation/DeallocationRequests. When\nallocating a new data object, TrustMod first searches for an avail-\nableID,whichwillbededicatedforthisobject.Then, TrustMod\nsearchesforanavailableFPGAon-chipmemorylargeenoughto\nhold the requested object size. Finally, all this information is stored\nasanewrowinOCMAT,whilealsoappendingtheEIDofthere-\nquestingenclave.Whendeallocatingtheobject(specifiedbyits ID),\nTrustMod removesthematchedrowinOCMATonlyif TrustLib\nistheowner oftheobject.Thiseffectively makestheobjectcorre-\nspondingFPGAon-chipmemoryspaceavailable.Itisworthnoting\nthatTrustMod denies all requests to map, unmap or access FPGA\nmemory from all entities except the enclave which has established\nsecure channel with TrustMod (see ğ4.3).ServicingRead/WriteRequests. Toperform write/read request\nforanobject, TrustMod firstassertswhethertherequesthasbeen\ninitiated by the owner of the enclave (using the allocated enclave-\nID)andthenlocatestheFPGAon-chipmemoryaddressstoredin\nOCMAT. Next, for a write operation, TrustMod writes the pro-\nvided data to the FPGA on-chip memory sequentially. For a read\nTrustMod transfers data sequentially starting from the FPGA on-\nchipmemoryto TrustLib .Wenotethat TrustMod doesnothave\nhardware cache units in accessing on-chip memory within the\nFPGA,so TrustOre issecureagainstcacheside-channelattacks\nplaguing in the traditional computing architectures.\nTo mitigate any potential side-channel issues in accessing FPGA\non-chip memory (e.g., DRAM-based side-channel attacks utiliz-\ning the time difference between row hits and row conflicts [ 54]),\nTrustMod ensures that the access time of FPGA on-chip memory\nisalwaysthesamefromoutside.Tobespecific, TrustMod ensures\nthat the access time always takes the worst-case cycle (which is\nobtained through empirical experiments) by stalling the response.\nAlthough this worst-case based mitigation may not sound the best\ndesign choice from the performance aspect, this in fact only incurs\n0.7%overhead according to our evaluation Ð the 64-Byte array\naccesstakes 9639.6ns,67ns(0.7%)morethantheonebeforethemit-\nigation. This is because performance bottlenecks of TrustOre are\nmostlyineitherpacketconstructionorIOdatatransmission,and\nthus always-worst DRAM access time does not contribute much\non the overall performance overhead. In the next section (ğ4.3), we\nwill explain how the above mentioned data is actually transmitted\nbetweenTrustLib andTrustMod.\n4.2.3 Memory Resource Management. TrustMod has to handle\nfragmentationofdevicememorywhichcanoccursincedifferent\nenclaves will have different memory demands which have to be\naccommodated altogether.\nOn-ChipMemoryCompaction. Inordertoavoidmemoryfrag-\nmentation and subsequent failure of memory allocation request,\nTrustMod runsamemorycompactionalgorithm[ 27]atregularin-\ntervals, which moves fragmented data objects to available space so\nastoclusterdataobjectsintheon-chipmemoryspace.Morespecif-\nically,TrustMod compactstheon-chipmemoryifithasprocessed\na specific number of deallocation requests (a configurable parame-\nter),andaccordinglyupdatesOCMAT.Althoughtheattackercould\nfigureoutthroughtimingchannelswhetheramemorycompaction\nevent is taking place or not, the event itself leaks no meaningful\ninformation to the attacker. It only shows the device does not have\na physically contiguous chunk of memory as requested.\nIn the unlikely case that a new allocation fails even after per-\nforming memory compaction, TrustMod can swap-out data ob-\njectstosecondarystorage(i.e.,systemmemoryordisk).Inorder\nto avoid leaking information, TrustMod would require Oblivious\nRAM (ORAM) primitives to ensure secure loading/unloading of\ndata.However, recentFPGA on-chipmemoryhas reachedseveral\nGBs and we believe that this will not occur frequently. The design\nof such a scheme is out-of-scope of this paper.\n4.3 Connecting TrustLib andTrustMod\nThis subsection first describes how TrustOre creates a secure\nchannel between its two major components (ğ4.3.1). Then, we elab-\norateofthe I/Ocommunicationtechniquessupported (ğ4.3.2)and\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1908lastly,weexplaintheprogramminginterfacessupportedforsuch\ncommunication (ğ4.3.3).\n4.3.1 SecureChannelEstablishment. Tofacilitatesecurecommu-\nnication between TrustLib andTrustMod , we use the Diffie-\nHellman [ 58] key exchange. This allows TrustLib andTrustMod\nto share a secret key, which can be used to encrypt and decrypt\nall later communication. We use rdseedinstruction [ 32] within\nTrustLib toobtaintruerandomnumbersfromCPUandinclude\nFPGA-basedtruerandomnumbergeneratorproposedin[ 53]within\nTrustMod , to make extremely hard for the adversary to influence\nor guess random numbers on both CPU and FPGA. Alongwith the\nDiffie-Hellman, TrustMod also sends an attestation nonce (using\nkattest\nPriv, as per the scheme described in Figure 4) which is used by\nTrustLib toensurethatitiscommunicatingwithacorrectinstance\nofTrustMod.\nWhilegeneratingthesecretvaluesrequiredforDH, TrustLib\nandTrustMod utilizes constant-time implementations to avoid\nleakinginformation.Morespecifically, TrustLib andTrustMod\nalways run a multiplier by a fixed number of times, which may\ninclude dummy runs (i.e., multiplying with 1). To make even the\nexecution time by adding dummies is a widely used concept in the\nworkmitigatingtimingside-channelattack[ 2].Wenotethatthe\ncomputationcyclesof TrustOre ’smultiplieranddividerdepend\non the width of data (not the value of it), and the width is constant.\nAfter the above setup, only TrustLib andTrustMod can de-\nrive the shared randomkey, дabmod p, based ontheir own secret\nvalue,aandb, respectively. This shared random key is used to\nencryptanddecryptallfollowingcommunication.Similartothe\nattestationprocess,thekeyexchangingprocedurecanbestarted\nasneededduringprogramexecutionthroughthefixedMMIOad-\ndressassignedtothekeyexchangingtransmissionchannel.Weuse\nAES-128 (with Galois/Counter Mode) as the authenticated encryp-\ntionalgorithmbecauseitsside-channelresistantimplementationis\neasily accessible with the SGX library using AES-NI.\nFreshness and Integrity. InAES-GCM,a96-bitcounter, Initial-\nizationVector (IV)is initiallysetthrough ourkey exchangemech-\nanism and synchronized between the enclave and TrustMod by\nmonotonically increasing for every AES operation. AES-GCM also\nprovides an authentication tag that is calculated by combining the\nhashes of the messages and the counter value. Since the counter\nvalue acts as a timestamp, data freshness as well as the integrity\nis guaranteed, which can prevent an adversary to corrupting or\nreplaying captured data. Therefore, TrustOre avoids the need for\nMerkleTreetypicallydemandingconsiderableoverheadtomanage.\n4.3.2 SupportedI/OCommunicationMethods. TrustOre supports\ntwocommunicationchannelsbetween TrustLib andTrustMod ,\nMemory Mapped IO (MMIO) and Direct Memory Access (DMA).\nMemory Mapped IO (MMIO). An MMIO channel is established\nusingthedevicedriver.Weassumethisdriverhasbeeninstalled\non the untrusted operating system, and it registers the FPGA to\nthe Linux device file system ( devfs) such that the access to the\nFPGAdevicememorycanbeperformedthroughMMIO.Sinceall\ncommunicationthroughthischannelisencrypted,thedevicedriver\ncanatmostinitiatea denial-of-service attack(suchasunmapping\nor modifying the PCIe configuration during runtime) which is also\nbeyond the scope of SGX. To setup MMIO access for an enclaveCPU FPGA\n❺-a Encrypted request\n❺-b Encrypted response❶Random nonce\n❷-a Signed nonce by \n❷-b Verify the signature with Challenger\nKey\nExchangerAttester\nKey\nExchanger\nOn-chip\nMemoryInterfaces❸{p, g, (gamod p)}\n❹ Signed (gbmod p) by \nSession key (gabmod p) shared\n❹-b Verify the signature with \nFigure 4: Secure channel establishment between CPU and FPGA\napplication, TrustLib asksthedevicedrivertomap TrustMod ’s\nmemoryto TrustLib ’snon-EPCmemoryregionwhichcandirectly\nbe accessed without an enclave exit.\nDirectMemoryAccess(DMA). InadditiontoMMIO, TrustOre\nalso supports efficient transfer of large data using Direct Memory\nAccess(DMA).TheDMAmodeofmemorytransferinvolvestwo\nmaincomponentsÐ(a)aMMIOregionforpassingrequests,and\n(b)aDMAbuffertotransmitactualmemoryrelatedtotherequests,\nbothsetupby thedevicedriver. Requests,throughMMIOrequest\nbuffer, are passed in plaintext but are only used by the device to\nfetchtheactualencryptedcommandssentby TrustLib ontheDMA\nbuffer. Although there are setup costs in sending commands to the\nDMAcontrollerandprocessingDMAinterrupts,theDMAmode\nallowsburst transmissions ontheIObus, supportingsignificantly\nimproved throughput for a big chunk data packets (as we show\nin Figure 5a and Figure 5b).\nPreventingSide-channelsonMMIO/DMARegions. Although\neach request/response transmitted through MMIO/DMA is en-\ncrypted,TrustOre couldstillsufferfromside-channelinferenceas\nmessagesarepassed.Toprotectfromtheseside-channels, TrustOre\nensures that all data accesses Ð attestation, key exchange, data\npacket transfer and DMA request are performed through the\ndedicated and fixed MMIO addresses. Furthermore, TrustOre\nreads/writes a data packet within an MMIO region at the gran-\nularity of 16 bytes that is synchronized to the block size of AES. To\naccessapacketlargerthan16bytes, TrustOre repeatedlywrites\norreadsthe16bytesregionwhilerepeatedlyconcatenatingeach\npacket. Therefore, the enclave accesses the same MMIO location\nregardless of execution context and in the exact same way, thereby\nmitigating other side-channels. The concrete empirical analysis\nis provided in the Appendix C. TrustOre also restricts that the\ndata block size is always the same at runtime (e.g., ORAM-based\napplicationsoftenusedthestaticdatablocksizebydefault,suchas\n4KB[3,67]).Asaresult, TrustOre alwaysreadsorwritesthesame\nsize of data irrespective of the request, and that size is determined\nduring the initialization.\n4.3.3 SupportedProgrammingInterfaces. Aftersettingupthecom-\nmunicationchannelsbetween TrustLib andTrustMod ,TrustOre\nisnowreadytoacceptcommandsfromtheenclaveprogram.Inthe\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1909followingwefirstexplainthesingularinterfacefunction TrustLib\ncan invoke on TrustMod to perform variousdifferent operations.\nThen wedescribehow TrustOre definesthe communicationfor-\nmat of the interface function.\nStorageInterfaces. TrustMod supportsthefollowinginterfaces\nthatTrustLib canrequesttousevariousstorageoperations.The\ninterfaces are labeled as: alloc,deallocandaccess.\nOUT ID alloc();\nOUT STATUS dealloc(IN ID id);\nOUT STATUS access(IN type, IN id, IN SIZE_T offset,\nIN void* dat_in, OUT void* dat_out, IN SIZE_T size)\nIn the above prototype of the interface functions, INandOUTare\natypequalifier: INdenotesanargumentthat TrustLib isrespon-\nsibletoprovideavalue;and OUTdenotesareturnoranargument\nthatTrustMod is responsible to return or fill up in response to\nthe request. IDdenotes an identifier of a data object, and STATUS\nindicates whether the invocation was successful or not.\nallocallocatesa dataobject within TrustMod’son-chip mem-\nory, and returns an IDwhich uniquely identifies the corresponding\ndata object. deallocmakes the previously allocated data object\navailablewithin TrustMod ’son-chipmemory.Itisworthnoting\nherethat allocanddeallocfunctionsaremeanttobeonlycalled\nat the start and end of the program’s execution respectively. There-\nfore, callstothese functionsare notsensitive anddonot need to\nbe protected as such.\nInaccess,TrustMod takes the offset as a parameter to deter-\nmine the offset within the data object specified by ID. Then, de-\npendingon type(i.e.,thefirstparameterwhich canbeeither read\norwrite),TrustMod performs the followings. In the case of read,\nTrustMod copiesthe sourcedataina rangestartingfrom (base+\noffset) to (base + offset + size) to the destination buffer specified by\nthe data argument, where base is the FPGA on-chip memory ad-\ndressspecifiedinOCMAT.Inthecaseof write,TrustMod updates\ntheFPGA’sinternalmemory withthedata providedby TrustLib .\nIt is worth noting here that accessequalizes the lengths of data\npacketsineithercaseof writeorreadbyappendingdummies.A\nsingle interface is utilized to serve both readandwriterequests to\nensurethatattackerscannotdistinguishbetweentheserequests,in\norder to provide protections at-par with Oblivious RAM (ORAM).\nCommunication Packet Format. Foreachinterfacecommand\ninvoked by TrustLib , arequestpacket is first sent from TrustLib\ntoTrustMod , and then a responsepacket is returned. TrustOre\nillustratestheformatofthispacketinFigure8(intheAppendixA).\nFollowing the illustrated format, TrustOre constructs a packet\naccording to INandOUTtype qualifiers Ð the request packet sets\nfields with INwhile the response packet does with OUT.\nWealsotriedtoreducethepacketheaderinformationtosupport\nmultiple enclaves. To be more specific, we do not include an ID\nofeachenclaveinthetransactionheadersincethiswouldrequire\nmore bits in the header. Instead, as we assign a unique MMIO\naddressforeach TrustLib instance(i.e.,eachenclaveinstance),itis\npossible to easily support multiple TrustLib through transporting\ntransactions to different address value.\n5 SECURITY ANALYSIS\nWesummarizethesecuritypropertiesachievedby TrustOre inTa-\nble 1. In the following paragraphs, we provide details about criticalside-channel attacks against our system and discuss the remaining\nattacks(mentionedinthetableandpreviouslytackledinthedesign\nsection) in Appendix B.\nSide-channel attacks against Enclave (TrustLib). Since en-\nclave memory is prone to side-channel information leakages,\nTrustOre carefullyprovisions TrustLib tomitigateinformation\nleakage through all known memory channels including page table,\ncacheandbranch-prediction.Inparticular, TrustLib craftsall read\nandwriterequests in the same branch-free manner (using oblivi-\nouswrapper [ 56]) to ensure that the attacker cannot distinguish\nbetween a read and write request. It is worth mentioning here that\nallocanddeallocaredistinguishablebutsincetheyaremeantto\nbecalledatthestartandendofenclaveexecutionrespectively,they\ndo not possess or leak sensitive information.\nSide-channelattacksagainstFPGA(TrustMod). Aspreviously\nmentioned,ourstorage model (on TrustMod )hasno pagetables\norcaches.Also, TrustMod guaranteesthateachread/writerequest\nreturnsthesameamountofdata(fixedduringinitialization)irre-\nspectiveofwhattheprogramhasrequested.Therefore, TrustMod\nis free from memory-based side-channel attacks.\nFurthermore, each request to TrustMod could leak some tim-\ning information (i.e., the processing time of a request is depen-\ndent to the processing time of previous requests). As we illustrated\nin ğ4.2,TrustOre ensures that regardless of TrustOre ’s opera-\ntional contexts, an allocation request takes the worst-case time\nandread/writerequestsareconstanttime.Therefore,theonlyin-\nformation leaked is the number of previous read/write operations\nperformed by TrustMod. It is worth noting that this information\nis not secured by other schemes (e.g., ORAM-based storage) either\nand is out-of-scope of our work.\nLastly,TrustOre does not allow any other logic to run con-\ncurrently onthe FPGArunning TrustMod and thereforethis isa\nnon-viable attack channel.\n6 IMPLEMENTATION\nIn the following, we explain how TrustOre implements its two\nmain components, TrustMod andTrustLib.\nTrustMod. We implemented all components of TrustMod in\nVerilog-HDL,andconvertedthosetothebitstreambyXilinx’sVi-\nvado 2015.1 tool. Then we generated and managed secret keys\nfor the secure loading and the attestation as explained in ğ4.1.\nTrustMod isloadedintotheXC7Z045FFG900-2XilinxZynq-7000\nseriesFPGA[ 81]whichisconnectedtothehostCPUviaPCIe,and\nrunsat150MHz.FPGAchipXC7Z045contains2.2 MBon-chipblock\nRAM and two 1 GBon-board DRAMs. We implemented TrustOre\nto utilize on-board DRAMs if the data size is over 2.2 MB. Our logic\nforTrustMod has 3,846 lines of code.\nOur current implementation of TrustMod supports the follow-\ning storage structures:\n(1)Trusted Data Array. We implement a trusted data array\n(similartoZeroTrace[ 60])whichisallocatedusingour alloc\n(mentionedinğ4.3.3).Thetrusteddataarrayhasfunction-\nality of read/write on indices using our accesscalls and\ndeallocation is performed using dealloccall.\n(2)Trusted File System. We also develop a trusted file sys-\ntem(similartoObliviate[ 3]).WeextendourAPIs(namely\ntrus_open ,trus_close ,trus_read ,trus_write ,trus_fsync )\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1910Table 1: Security analysis of TrustOre. Mor e details are provided in Appendix B.\nTrustOre Event/Comp onent Potential attacks Defenses\nLoading TrustMod to the FPGAReverse-engineering the bitstream;\nUnloading/exchanging\nthe moduleSecure boot and remote attestation (ğ4.1)\nCommunication between TrustLib and\nTrustModEavesdropping/tampering; Side-channels for\nMMIO/DMA regionCryptographic schemes (ğ4.3.1); Oblivious manner accesses\n(ğ4.2.2, ğ4.3.2)\nTrustLib Side-channels on EPC memory [41]No input-specific data access; Branch-free implementation\n(ğ4.3.3)\nTrustModSide-channelsonFPGAmemory;Concurrent\nattack logic on FPGA [84]Novirtualmemoryorcaches;Constant-timeaccess(ğ4.2.2);No\nother logic runs with TrustMod (ğ4.1)\nFPGA device driver Eavesdropping/tampering Cryptographically-secured protocols (ğ4.3.1)\nin order to support POSIX file system APIs. While some\nof these calls are trivial to understand, we mention a few\nthat pose some trick to them.\ntrus_open(). Since we need to allocate a new region within\ntheFPGAon-chipmemory, allociscalledaspartof trus_open .\nWhenO_WRONLY orO_RDWRisspecifiedasanargument,weal-\nlocateapre-definedsize,similartowhatObliviatedoes.Ifthe\nprogram attempts to write over the boundary of the file, we\nre-run the function with the O_APPEND flag andTrustMod\ndoubles the current file size in the trusted storage.\ntrus_close(). The process of closing a file involves dealloc\nreleasing the FPGA on-chip memory resources and writing-\nback all the stored data to the original file. This does not\nleak any information since it is a sequential write-back of\nthe entire contents onto the main memory. Also, TrustOre\nuses a library for data sealing provided by SGX to ensure\nconfidentiality of files.\nTrustLib. WeimplementedthiscomponentusingtheIntelSGX\nSDK. Each API listed above is implemented as a wrapper function\ncalling the primitive interfaces (i.e., alloc,dealloc,access) as sub-\nroutines. Two software modules, Challenger andKey Exchanger\nillustrated in Figure 4 for attesting TrustMod and exchanging the\nsession key are also implemented together in TrustLib . The open\nsourceFPGAdriver[ 10]wasloadedintoLinuxkerneltoregister\nthe FPGA through MMIO and enable the DMA transfer. We do not\nneedtomodifythedriverbutonlyadds66linesofcodetothenon-\nenclave code for delivering each pointer of MMIO and DMA buffer\nto the application enclave. In an enclave, TrustLib consists of 212\nlines of code where the primitive interfaces introduce 155 lines\nofcodeamongthem.Asapartof TrustMod ,hardwaremodules\nrelatingtocryptographicoperations(i.e., Attester,KeyExchanger\nandAES) consists of 1,412 lines of code.\n7 PERFORMANCE EVALUATION\nIn order to show the superior performance achieved by TrustOre\nagainst existing ORAM-based schemes employed to defend against\nside-channel leakage, we perform a case-study comparing each of\nObliviate [3], ZeroTrace [60] and Obfuscuro [4].\nExperimental Setup. All our experiments were performed on\nIntel (R) Core (TM) i7-6700 CPU @ 3.40GHz (Skylake with 8 MB\ncache) with 32GB of RAM (128 MBfor EPC) and running Ubuntu\n16.04 with Linux 4.4.0.31 (64-bit). We used the official Intel SGX\nSDK and Intel SGX drivers for Linux for all experiments. To obtain\nexperimentalvalues,eachofthesameexperimentswasrepeated\natleast100times.Inaddition,powersavingmodewasturnedoff\nand CPU frequency was set to the maximum value in Linux in\norder to minimize variation between experiments. For all the time\nmeasurements, clock() function was used in common.7.1 Experimental Results\nInthissubsection,weshowtheperformanceachievedbyindividual\nstorage structures supported by TrustOre.\nPerformanceofDataArray. Wecomparethelatencyandthrough-\nput achieved by TrustOre while accessing a data array as com-\npared to ZeroTrace. Figure 5b shows the latency when accessing\nan index within an oblivious array of various sizes using Zero-\nTrace’sORAM-basedaccessand TrustOre ’sFPGA-basedaccess.\nFurthermore, we provide results by varying the size of N, i.e., 5000,\n10000, and 50000. The value of Ncorresponds to the size of the\nobliviousarrayforZeroTrace.SinceZeroTraceusesORAMoper-\nations, it has to create a fixed size tree (and a fixed size array as\na result). TrustOre does not have such a restriction as long as\nthesizedoesnotexceedthetotalmemoryavailableontheFPGA\ndevice. Based on the results, TrustOre accesses data 49×faster\nthan ZeroTrace on average across different block sizes. In the case\nof64Bblock,whichisageneralcache-linesizeandthusreferenced\nas a default configuration when evaluating ORAM-based systems’\nperformance[ 21,22,57],TrustOre shows37×fasteraccessspeed.\nHowever, as the block size grows (greater than 103), the amount of\nmemory accessed for an ORAM operation exponentially increases,\nandasaresulttheperformancedegradesconsiderably.Forexam-\nple, for block size of 105, the difference between ZeroTrace and\nTrustOre is almost 75×.\nTo better compare the scalability difference between TrustOre\nandZeroTrace,wemeasurethethroughputwithrespecttothenum-\nberofblocks( N)asshowninFigure5c.Inthefigure,thethroughput\nofZeroTracedecreasesas Nincreases,while TrustOre showscon-\nstantthroughput.ThisisduetothattheORAMtreethatZeroTrace\nhas to access increases considerably as the value of Nincreases.\nIt is worth recalling that ORAM trees grow exponentially as the\nblocks are increased in order to maintain the security properties.\nFor further details on this matter, we refer to the original works\nrelated to ORAM [68, 78].\nTomeasuretheperformanceof TrustOre comparedtothestate-\nof-the-arthardware-basedORAMs[ 21,22],wecomparedtheaccess\ntimefor64Bblockwith TrustOre ’soneandtheperformancenum-\nber reported in [ 21,22]. Compared to the native access time for\n64B block (i.e., without any protection mechanism), TrustOre de-\ncreasesthethroughputby 102×while[21]and[22]decrease 22×\nand4×, respectively. While this performance result may not be\nin favor of TrustOre , we note that TrustOre does not require\nanyhardware/architecturalchangeswhichwouldbechallenging\ntodeployforpracticaluse-cases.WefurthernotethatZeroTrace\ndecreases by 3774×, so we argue that TrustOre provides the com-\nparableperformanceleveragingthereadilyavailablehybridCPU-\nFPGA architecture.\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1911020406080100\n0 200 400 600 800 1000Access time (in μs)\nBlock size (in bytes)TrustOre (MMIO)\nTrustOre (DMA)\n(a) Performance of MMIO and DMA mode00.511.522.533.54\n1.E+00 1.E+01 1.E+02 1.E+03 1.E+04Access time (in ms)\nBlock size (in bytes)ZeroTrace (N=50000)\nZeroTrace (N=10000)\nZeroTrace (N=5000)\nTrustOre\n(b) Performance on various block sizes00.20.40.60.811.2\n1.E+03 1.E+04 1.E+05 1.E+06 1.E+07Normalized Throughput\nNumber of Blocks (N)TrustOre\nZeroTrace\n(c)Throughputonvariousblocknumbers( N)\nFigure\n5: Performance comparison of oblivious data array access\nNative Obliviate TrustOre\n11111Throughput (KB/s)1.E+031.\nE+041.E+051.E+061.E+07\n2M 128M 512M 1G\nFile Size (byte)\n(a) Sequential reads1.E+031.\nE+041.E+051.E+061.E+07\n2M 128M 512M 1G\nFile Size (byte)\n(b) Sequential writes1.E+031.\nE+041.E+051.E+061.E+07\n2M 128M 512M 1G\nFile Size (byte)\n(c) Random reads1.E+031.\nE+041.E+051.E+061.E+07\n2M 128M 512M 1G\nFile Size (byte)\n(d) Random writes\nFigure\n6: Performance comparison of oblivious file access\n1122334Execution time (in sec)050100150200250300350400\n0 20000 40000 60000\nInput array size (n )\n(a) findmax050100150200\n0 20000 40000 60000\nInput array size (n )\n(b) sum050100150200250\n5 15 25 35 45\nInput matrix dimension (n )Obfuscuro\nTrustOre\n(c) matmul\nFigure\n7: Performance comparison of oblivious execution with various input data size\nPerformance of File System. We evaluate the performance of\nTrustOre ’sfilesystemascomparedtothenativefilesystem(ac-\ncessing the disk) and Obliviate [ 3]. Figure 6 shows the results of\nsequential and random read/write (not including open/close) com-\nparingthethreefilesystemsusingIozone[ 51],awidelyusedfile\nsystembenchmark. TrustOre performs 102×sloweronaverage\nthanthenativefilesystem,whileObliviate 221×slowerthanthe\nnativeone.Whenthetestfilesizeis2 MB,theperformanceofOblivi-\nate andTrustOre is comparable.This is because the TrustOre ’s\nIOtransmissionoverheadthroughPCIeisstillhigherthantheoper-\nation of the Obliviate’s ORAM controller which deals with the 2 MB\ndataset.However, TrustOre maintainstheconstantthroughput,\n44MB/son average, regardless of the file size, while Obliviate ex-\nhibits severethroughput degradation asthe filesize increased. As\nthe size of the data set grows, the memory accessed by Obliviate’s\nORAMcontrollerincreasessignificantlyduetotheincreasedsize\nof the ORAM tree. On the other hand, TrustOre performs only\na number of operations depending on the requested data size. In\nthe test for a 1GB file, TrustOre is approximately 10×faster than\nObliviate. We expect this trend to explode further as the file size\nincreasesbutduetoimplementationlimitations,wewereunable\nto get results from larger than 1GB files for Obliviate.\nOtherSystems(Obfuscuro). Ourstoragestructures(e.g.,trusted\ndata array) can also be indirectly applied to other systems. For\nexample,Obfuscuro[ 4]proposesanobfuscationschemeforIntel\nSGX while relying on trusted in-enclave storage using ORAM. We\ncompared our trusted storage against Obfuscuro’s ORAM-based\nstorage by reusing their framework but changing all ORAM accessTable 2: Execution time comparison of nbench between ZeroTrace\nandTrustOre\nnbenchNative\nSGX (u\ns)ZeroTrace\n-based\n(sec)TrustOre\n-based\n(sec)Speed\n-up\nNum sort 548.186 229.947 1.777129.38\nString sort 18670.301 17526.434 140.267 124.95\nBit op\neration 0.001 2434.542 12.666 192.21\nFp.\nemulation 1556.493 6.795 0.091 74.30\nFourier 7.543 0.065 0.002 31.43\nAssignment 297.796 121.658 1.071113.59\nIdea 56.430 800.842 4.501177.94\nHuffman 149.011 109.081 0.568191.92\nNeural net 7954.184 10839.355 94.621 114.56\nLu de\ncomp. 280.143 430.785 2.215194.53\nGeoMean 120.16\noperations in their source code (publicly available [ 1]), with our\ntrusted data array implementation.\nWe tested three programs which perform matrix multiplication\n(matmul),integersummation(sum),andfindingthemaxinanarray\n(findmax). These programs were provided to us with the source\ncode of Obfuscuro. To test the scalability of TrustOre , we vary\ntheinputdatasize nforeachoftheaforementionedprogram.As\nshowninFigure7,theexecutiontimeofObfuscuroexponentially\nincreaseswhilethatof TrustOre increasessmoothly.Forexample,\nTrustOre executesfindmax 2.88×fasterwhentheinputsizeis2K\nand43×fasterwhentheinputsizeisincreasedto64K.Itdemon-\nstrates that TrustOre solves the scalability problem of Obfuscuro\nwhich has to rely on costly ORAM operations.\n7.2 Other Benchmarks\nNbench. Weevaluatetheperformanceof TrustOre forrealworld\nworkloadbyusingnbench[ 47].TorunnbenchtoSGX,eachtest\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1912programofnbenchismanuallymodifiedandsplitintotwoparts:\nnon-enclave and enclave part. Non-enclave part generates input\ndataarrays,copiesthemtoenclavearraysandthenenclaveruns\ntheprogramwithoutanotherentry/exituntilfinishingtheprogram.\nEach memory store/load operation in enclave is modified to per-\nform oblivious access using ZeroTrace’s API calls and TrustOre ’s\naccessAPI. This modification is straightforward and is intended\ntoseehowslowtheperformanceofobliviousaccesswouldbeon\nnbench.Forthefaircomparison,weset N(numberofblocks)for\nZeroTrace to the exact number of blocks required by each individ-\nualbenchmarkwithinthetest-suite. Nvariesfrom 3000to20000\nin our experiment. And the block size is set to the same as the size\nof each data object (mostly integers and floats). As shown in Ta-\nble2,although TrustOre -basedshowsordersofmagnitudeslower\nthanthenativeexecutionbecauseofIOdelaytoaccessFPGAper\nevery memory accessing operation, TrustOre is120×faster on\naverage than ZeroTrace. As expected, TrustOre shows better per-\nformance in programs where data access occurs heavily ( Huffman,\nLu decomp.) rather than compute-intensive ones (Fourier).\nMMIO Versus DMA. TrustOre supports both communication\nstandards for CPU-FPGA communication, i.e., MMIO and DMA. In\nordertogaugetheperformancedifferencebetweenthesestandards,\nwe measure the latency when transferring data packets of various\nsizes using each of the aforementioned channels. As shown in Fig-\nure5a,TrustOre transfersdataofsizegreaterthan128-bytesfaster\nusing DMA than MMIO. There are two main reasons why DMA is\nslowerwhenthedatasizesaresmaller:(a)requiringtotransferthe\ncontrolcommandtotheDMAcontrollerwithin TrustMod inorder\ntoinitiateDMAtransferexceedstheperformancegainand(b)wait-\ning the DMA interrupt passed back from OS also takes some time.\nSo, to maximize the performance of TrustOre ,TrustLib seam-\nlesslychoosesDMAtransfermodefordatabiggerthan128-bytes\nand MMIO otherwise.\nEnd-to-EndKey-ValueStore. Toevaluate TrustOre onthereal\nsystemrequringtheside-channelprotection,weused TrustOre for\nan end-to-end key-value store application, ShieldStore [39]. Shield-\nStore is astate-of-the-art in-memory key-valuestore designed for\nSGX. ShieldStore addresses the performance issues due to the SGX\nmemorylimitationthroughstoringthedatainunprotectedmemory,\nwhere each key-value pair is individually encrypted and integrity-\nprotected using its secure component running inside an enclave.\nHowever,ShieldStoreisvulnerabletoside-channelattacks,since\nShieldStore does not hide the address being accessed. Thus, its key-\nvalue store is insecure against access pattern based side-channel\nattacks.TrustOre offersaside-channelresistantstorageforShield-\nStore to address those attacks.\nWe implemented TrustOre -based ShieldStore, which modified\nShieldStore to store the table (the hash and its corresponding data)\non our trusted data array (see ğ6). To better understand the per-\nformance impact of TrustOre -based ShieldStore, we also imple-\nmented ZeroTrace-based ShieldStore, which provides side-channel\nresistant storage with an ORAM mechanism. We compare the\nthroughput of key-value store operations (i.e., SET/GET) between\nZeroTrace-basedShieldStoreand TrustOre -basedShieldStore.500\nrandom operations were tested when both the sizes of key andTable3:ThroughputcomparisonofShieldStorebetweenZeroTrace\nandTrustOre\nShieldStore ZeroTrace-based TrustOre-based\nThroughput (Ops/s) 35465.484 1.702 320.054\nSlow-down - 20.8K× 111×\nvalue are 16-byte. As shown in Table 3, TrustOre -based Shield-\nStore shows 188×higher throughput against ZeroTrace-based one\nonaverage.ComparedtothebaselineShieldStore, TrustOre -based\nShieldStoreshowed 111×lowerthroughput,whileZeroTrace-based\none showed 20.8K×lower throughput. We believe such an out-\nstanding performance improvement of TrustOre -based Shield-\nStore (compared to ZeroTrace-based one) is due to the fact that\nTrustOre only requires the same number of memory accesses\ncomparing to the native ShieldStore, while ZeroTrace needs much\nmore accesses to perform an ORAM mechanism.\n8 DISCUSSION\nThissubsectiondiscussesmoresubtle,sophisticatedattacks(which\nare not part of our threat model) against TrustOre : cold-boot\nattacks and part of side-channel attacks. We also discuss the secu-\nrity concerns about involving the FPGA manufacturer as our new\ntrusted party.\nCold-Boot Attacks. Cold-boot attacks attempt to read the un-\nencrypteddatastoredinmemorybyphysicallydetachingitfrom\ntheboard.Similarattacksmaybelaunchedon TrustOre aswellÐ\ndesoldering the FPGA chip at runtime and dumping the data from\nthe on-chip memory. However, compared to the previously known\ncold-bootattacks [ 28,83], it wouldbe much more challengingto\ndump FPGA on-chip memory. FPGA on-chip DRAM is 3D stacked\nwith the FPGA fabric, and IO port for accessing the stacked DRAM\nis not directly exposed unlike a traditional DRAM [35].\nNevertheless, in order to completely thwart cold-boot attacks,\nTrustOre can beextended witha memory encryption mechanism\nsimilartoIntelSGX’sMemoryEncryptionEngine[ 26].Wenotethat\nasTrustOre ’s encryption logic would be written in bitstream and\neventually run at the hardware level and therefore, it should incur\nless overhead compared to the purely software-based ones [ 14,29].\nSide-Channel Attacks TrustMod introduces new operational\nsemantics to the system, including allocation, read, write, and deal-\nlocation requests, each of which can be a source of side-channel\nattacks.First,theserequestsmayleverageresourcessharedwith\notherbitstreaminstances,asanOSmayinstructtheFPGAtorun\notherbitstreamthan TrustMod .Tomitigatetheseside-channels,\nTrustOre always wipes out all data and resources before being\nunloaded. Moreover, since the OS has the full control over the\nFPGAandthuscansuddenlyreprogramtheFPGAbeforewiping\nall data and resources, TrustOre disables the processor’s connec-\ntion to the configuration ports of the FPGA during the secure boot\nas illustrated in [ 17]. Second, each request may share resources\nwith other requests (i.e., the processing time of a request is depen-\ndent to the processing time of previous requests). As we illustrated\nin ğ4.2,TrustOre ensures that regardless of TrustOre ’s opera-\ntional contexts, an allocation request takes the worst-case time\nandread/writerequeststaketheconstanttime,effectivelyavoiding\npotential side-channel attacks.\nThe Trusted FPGA Manufacturer We acknowledge that impos-\ninganadditionaltrustedparty(i.e.,anFPGAmanufacturer)may\nweaken the original threat model of SGX. We argue that, however,\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1913if the FPGA manufacturer and the CPU manufacturer are the same\n(i.e., Intel), this would not raise much trustworthy issues. In fact,\ngiventhemarketdominanceonCPUandFPGA,webelieveboth\nwould be (or already are) manufactured by the same party, Intel.\nIntelis aggressivelypushing towardsan CPU-FPGAhybrid archi-\ntecture in response to the data-intensive computing trends (e.g.,\nXeon-FPGA chip [ 33], FPGA acceleration card [ 34]). In this case,\nIntel would be manufacturing both CPU and FPGA, so the key\ncan be installed in the FPGA by Intel (just as the SGX key in the\nCPU)inordertoutilizetheFPGAasasecurityextensionofSGX.\nInthisdeploymentscenario,itcanbeassumedthattheserverfor\nbitstreamencryption/signingisalsosecurelyintegratedwiththe\nserver for the SGX attestation.\n9 RELATED WORK\nSystems based on SGX. Haven[9]is thepioneeringSGX work\nwhich developed a windows-based library operating system (Li-\nbOS)toenableeasyportingoflegacyapplicationsonIntelSGX.Its\ncounterpart,Graphene[ 70,71]proposedaLinux-compatibleLibOS.\nOpenSGX [ 36] provides an opensource framework for SGX devel-\nopment.Ryoan[ 30]implementsadistributedsandbox,Scone[ 7]\nproposes secure containers, and SGX-Shield [ 62] enables ASLR on\nSGX enclave. Graviton [ 75] proposes hardware modifications to\nenable trusted execution on GPUs in tandem with Intel SGX. All\naforementioned systems are not concerned with side-channel limi-\ntationsofIntelSGXandwouldgreatlybenefitfromtheside-channel\nprotections afforded by TrustOre.\nSide-channel Attacks on SGX. There are four main types of\nside-channel attacks discovered against Intel SGX, i.e., IAGO [ 12],\nPagetable[ 72,82],cache[11,24,61]andbranchprediction[ 19,42].\nLeaky Cauldron [ 77] provides anoverview of memory-based side-\nchannel attacks possible within Intel SGX. TrustOre involves a\ntrusted FPGA in order to protect trusted data from all aforemen-\ntioned side-channels.\nSide-channel Mitigations for SGX. The existing side-channel\ndefenses for Intel SGX can be divided into cryptographic [ 3,4,60]\nand non-cryptographic [ 25,62,64,65] defenses. The existing cryp-\ntographic defense schemes utilize ORAM to protect the application\nfromaccesspattern-basedattacks.AlthoughORAMofferscrypto-\ngraphicsecurity,itisprohibitivelyslow(asweexperimentallyshow\ninğ7)sinceitinvolvesadegreeofhighermemoryinteractionsthan\nnativeexecution.Ontheotherhand,existingnon-cryptographic\ndefensesoffercomparativelyloweroverheadsbutprotectagainstin-\ndividualside-channelsandcannotbeleveragedtoprotectagainstall\nside-channels which leak access patterns. For example, T-SGX [ 64]\nprotects against page-fault attacks but cannot protect against page\ntable and cache attacks. Similarly, Cloak [ 25] can protect against\npage-fault and cache attacks but cannot protect against page table\nattacks. SGX-Shield [ 62] can only provide probabilistic defense of\nside-channels through memory randomization. Compared to all\nexistingsolutions, TrustOre offerssuperiorperformanceaswell\nas proven protection against all access pattern leakage.\nOther Side-channel Mitigation Schemes. There are various\nothersoftware[ 15,38,56,66,85]andhardware[ 20,43,45]schemes\ntomitigateside-channelsinnon-SGXenvironments.Someofthe\nsoftwareschemes[ 15,38,85]arenotapplicablewithinIntelSGXsincetheyrequireOSsupport.Fromamongsttheapplicableschemes,\nRaccoon [ 56] is the most notable since it provides protections\nagainst all digital side-channels. However, Raccoon only secures\nannotated part of a program’s data and uses oblivious copy (and\nORAM)tosecurelyaccessthedataatahighcosttoperformance(i.e.,\n21×).Hardwaretechniques,suchasHOP[ 50]andPhantom[ 45],\nalsoutilizeORAMtoprotectthedatawhichasmentionedbefore\nis very slow as compared to TrustOre . Also, these schemes are\nprototypedusingcustom(RISC-V)processorsandarethereforeless\ndeployment-friendly than TrustOre.\nSecure Memory Architectures. Themostrelatedworksare[ 2,\n8], which leverage computation capabilities (i.e. encryption and\ndecryption)of3D-stackedmemorytoachieveORAM-equivalent\nsecurityguarantees.Inparticular,itencryptsallmemorybustraffic\nand thus adversaries launching man-in-the-middle attacks cannot\nsee the intention behind memory bus uses. However, these ap-\nproaches are limited for the following reasons: essentially built\nbasedonnewmemoryarchitecture,smartmemory,whichcomes\nathighcostandprovidesthelimitedcapacity.SecureDIMM[ 63]\nemploysanASICbufferchiptooffloadORAMfunctionalitysuch\nthatmemorybandwidthcanbereduced.Comparedto TrustOre ,\nall of these works rely either on new memory structure or a cus-\ntom hardware, limiting their use-cases in real-world. TrustOre\nisimplementedon hybridCPU-FPGA architectureandIntelSGX,\nreadily available to use today.\n10 CONCLUSION\nThis paper proposed TrustOre , a system built for stopping side-\nchannel attacks against Intel SGX. It utilizes an external device, an\nFPGA, to implement a trusted storage service for SGX applications.\nSincetheFPGAisrunninginanisolatedenvironmenthavingits\nowndedicatedmemory-relatedunits, TrustOre avoidsmemory-\nbasedside-channelsbydesign.Moreover,unlikeORAM-basedside-\nchannel protection solutions, TrustOre scales well as the data\nsize increases, demonstrating its strong practical prospects for real-\nworldworkloads.Weemphasizethatas TrustOre doesnotimpose\nanyarchitecturalchangebutcanbedeployedasasimpleplug-into\nSGXmachine’sPCIeslot,itisreadilyusedtothwartside-channel\nattacksinIntelSGX,arguablyoneofthemostcrypticandcritical\nsecurity holes today.\nACKNOWLEDGMENTS\nThisworkwaspartlysupportedbytheBK21Plusprogramofthe\nCreativeResearchEngineerDevelopmentforIT,SeoulNationalUni-\nversityin2020andtheEDAtoolfromtheICDesignEducationCen-\nterandtheNationalResearchFoundationofKoreagrantfundedby\ntheKoreagovernment(MSIT)(NRF-2017R1A2A1A17069478,NRF-\n2019R1C1C1006095) and Institute of Information & communica-\ntions Technology Planning & Evaluation grant funded by MSIT\n(No.2018-0-00230, Development on Autonomous Trust Enhance-\nmentTechnologyofIoTDeviceandStudyonAdaptiveIoTSecurity\nOpenArchitecturebasedonGlobalStandardization[TrusThingz\nProject]andNo.2017-0-00213,DevelopmentofCyberSelfMutation\nTechnologies for Proactive Cyber Defense and No.2020-0-00325,\nTraceabilityAssuaranceTechnologyDevelopmentforFullLifecycle\nData Safety of Cloud Edge).\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1914REFERENCES\n[1]Github - adilahmad17/obfuscuro: Commodity obfuscation for intel sgx, 2019.\nURL https://github.com/adilahmad17/Obfuscuro.\n[2]S.AgaandS.Narayanasamy. Invisimem:Smartmemorydefensesformemory\nbus side channel. In Proceedings of the 44th ACM/IEEE International Symposium\non Computer Architecture (ISCA), New York, NY, June 2017.\n[3]A. Ahmad, K. Kim, M. I. Sarfaraz, and B. Lee. Obliviate: A data oblivious file\nsystemforintelsgx. In Proceedingsofthe2018AnnualNetworkandDistributed\nSystem Security Symposium (NDSS), San Diego, CA, Feb. 2018.\n[4]A.Ahmad,B.Joe,Y.Xiao,Y.Zhang,I.Shin,andB.Lee. OBFUSCURO:ACom-\nmodity Obfuscation Engine on Intel SGX. In Proceedings of the 2019 Annual\nNetwork and Distributed System Security Symposium (NDSS), San Diego, CA, Feb.\n2019.\n[5]Amazon. Aws ec2 fpga development kit. https://github.com/aws/aws-fpga.\n[Online; Accessed 22. August 2019], 2018.\n[6]I. Anati, S. Gueron, S. P. Johnson, and V. R. Scarlata. Innovative technology\nfor cpu based attestation and sealing. In Proceedings of the 14th Hardware and\nArchitectural Support for Security and Privacy (HASP), Tel-Aviv, Israel, June 2013.\n[7]S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe, J. Lind,\nD. Muthukumaran, D. O’Keeffe, M. Stillwell, et al. Scone: Secure linux con-\ntainerswithintelsgx. In Proceedingsofthe12thUSENIXSymposiumonOperating\nSystems Design and Implementation (OSDI), Savannah, GA, Nov. 2016.\n[8]A. Awad, Y. Wang, D. Shands, and Y. Solihin. Obfusmem: A low-overhead\naccess obfuscation for trusted memories. In Proceedings of the 44th ACM/IEEE\nInternationalSymposiumonComputerArchitecture(ISCA),NewYork,NY,June\n2017.\n[9]A. Baumann, M. Peinado, and G. Hunt. Shielding applications from an untrusted\ncloud with haven. In Proceedings of the 11th USENIX Symposium on Operating\nSystems Design and Implementation (OSDI), Broomfield, Colorado, Oct. 2014.\n[10]K.Bhimani. Zc706pciedriver. https://github.com/codelec/zc706_pcie.[Online;\nAccessed 22. August 2019], 2017.\n[11]F. Brasser, U. Müller, A. Dmitrienko, K. Kostiainen, S. Capkun, and A.-R. Sadeghi.\nSoftware grand exposure: SGX cache attacks are practical. In 11th USENIX\nWorkshop on Offensive Technologies (WOOT 17), Vancouver, BC, 2017.\n[12]S.CheckowayandH.Shacham. Iagoattacks:Whythesystemcallapiisabad\nuntrusted rpc interface. In Proceedings of the 18th ACM International Conference\non Architectural Support for Programming Languages and Operating Systems\n(ASPLOS), Houston, TX, Mar. 2013.\n[13]G. Chen, S. Chen, Y. Xiao, Y. Zhang, Z. Lin, and T. H. Lai. Sgxpectre attacks:\nLeakingenclavesecretsviaspeculativeexecution. CoRR,abs/1802.09085,2018.\nURL http://arxiv.org/abs/1802.09085.\n[14]X.Chen,T.Garfinkel,E.C.Lewis,P.Subrahmanyam,C.A.Waldspurger,D.Boneh,\nJ. Dwoskin, and D. R. Ports. Overshadow: a virtualization-based approach to\nretrofitting protection in commodity operating systems. In Proceedings of the\n13th ACM International Conference on Architectural Support for Programming\nLanguages and Operating Systems (ASPLOS), Seattle, WA, Mar. 2008.\n[15]B. Coppens, I. Verbauwhede, K. De Bosschere, and B. De Sutter. Practical mit-\nigations for timing-based side-channel attacks on modern x86 processors. In\nProceedings of the 30th IEEE Symposium on Security and Privacy (Oakland), Oak-\nland, CA, May 2009.\n[16]V.CostanandS.Devadas. Intelsgxexplained. IACRCryptologyePrintArchive,\n2016:86, 2016.\n[17]M.Coughlin,A.Ismail,andE.Keller. Appswithhardware:Enablingrun-time\narchitectural customization in smart phones. In Proceedings of the 2016 USENIX\nAnnual Technical Conference (ATC), Denver, CO, June 2016.\n[18]M. Dworkin. Recommendation for block cipher modes of operation: Ga-\nlois/counter mode(gcm) andgmac. In Federal InformationProcessing Standards\n(FIPS) Special Publications (SP), Nov 2007.\n[19]D.Evtyushkin,R.Riley,N.C.Abu-Ghazaleh,ECE,andD.Ponomarev. Branch-\nscope: A new side-channel attack on directional branch predictor. In Proceedings\nofthe23rdACMInternationalConferenceonArchitecturalSupportforProgramming\nLanguages and Operating Systems (ASPLOS), Williamsburg, VA, Mar. 2018.\n[20]C.W.Fletcher,M.v.Dijk,andS.Devadas. Asecureprocessorarchitecturefor\nencrypted computation on untrusted programs. In Proceedings of the Seventh\nACM Workshop on Scalable Trusted Computing, STC ’12, 2012.\n[21]C.W.Fletcher,L.Ren,A.Kwon,M.v.Dijk,E.Stefanov,D.Serpanos,andS.De-\nvadas. A low-latency, low-area hardware oblivious ram controller. In 2015 IEEE\n23rd Annual International Symposium on Field-Programmable Custom Computing\nMachines, pages 215ś222, May 2015. doi: 10.1109/FCCM.2015.58.\n[22]C. W. Fletcher, L. Ren, A. Kwon, M. van Dijk, and S. Devadas. Freecursive oram:\n[nearly] free recursion and integrity verification for position-based oblivious\nram. InProceedings of the 20th ACM International Conference on Architectural\nSupportforProgrammingLanguagesandOperatingSystems(ASPLOS),Istanbul,\nTurkey, Mar. 2015.\n[23]O. Goldreich and R. Ostrovsky. Software protection and simulation on oblivious\nrams.Journal of the ACM (JACM), 43(3):431ś473, 1996.\n[24]J. Götzfried, M. Eckert, S. Schinzel, and T. Müller. Cache attacks on intel sgx. In\nEUROSEC, pages 2ś1, 2017.[25]D.Gruss,J.Lettner,F.Schuster,O.Ohrimenko,I.Haller,andM.Costa. Strongand\nefficientcacheside-channelprotectionusinghardwaretransactionalmemory. In\nProceedings of the 26th USENIX Security Symposium (Security), Vancouver, BC,\nAug. 2017.\n[26]S.Gueron. Amemoryencryptionenginesuitableforgeneralpurposeprocessors.\nIACR Cryptology ePrint Archive, 2016:204, 2016.\n[27]B. K. Haddon and W. M. Waite. A Compaction Procedure for Variable-Length\nStorageElements. TheComputerJournal,10(2):162ś165,081967. ISSN0010-4620.\ndoi: 10.1093/comjnl/10.2.162. URL https://doi.org/10.1093/comjnl/10.2.162.\n[28]J.A.Halderman,S.D.Schoen,N.Heninger,W.Clarkson,W.Paul,J.A.Calandrino,\nA. J. Feldman, J. Appelbaum, and E. W. Felten. Lest we remember: Cold-boot\nattacksonencryptionkeys. Commun.ACM,52(5):91ś98,May2009. ISSN0001-\n0782. doi: 10.1145/1506409.1506429. URL http://doi.acm.org/10.1145/1506409.\n1506429.\n[29]O. S. Hofmann, S. Kim, A. M. Dunn, M. Z. Lee, and E. Witchel. Inktag: Secure\napplicationson anuntrustedoperatingsystem. In Proceedingsof the18thACM\nInternationalConferenceonArchitecturalSupportforProgrammingLanguagesand\nOperating Systems (ASPLOS), Houston, TX, Mar. 2013.\n[30]T.Hunt, Z.Zhu,Y.Xu,S. Peter,andE.Witchel. Ryoan: Adistributedsandbox\nfor untrusted computation on secret data. In Proceedings of the 12th USENIX\nSymposiumonOperatingSystemsDesignandImplementation(OSDI),Savannah,\nGA, Nov. 2016.\n[31]Intel. An introduction to the intel(r) quickpath interconnect. https:\n//www.intel.com/content/www/us/en/io/quickpath-technology/quick-path-\ninterconnect-introduction-paper.html. [Online; Accessed 22. August 2019], 2009.\n[32]Intel. Intel 64 and ia-32 architectures software developer’s manual.\nhttps://www.intel.co.kr/content/www/kr/ko/architecture-and-technology/64-\nia-32-architectures-software-developer-vol-1-manual.html. [Online; Accessed\n18. August 2020], 2016.\n[33]Intel. Intel(r) xeon(r) gold 6138 processor, 2018. URL https://en.wikichip.org/\nwiki/intel/xeon_gold/6138p.\n[34]Intel.Intel(r)programmableaccelerationcard(pac)withintel(r)arria(r)10gxfpga\ndatasheet, 2018. URL https://www.intel.com/content/dam/www/programmable/\nus/en/pdfs/literature/ds/ds-pac-a10.pdf.\n[35]Intel. Intel stratix 10 mx (dram system-in-package) device overview.\nhttps://www.intel.com/content/dam/www/programmable/us/en/pdfs/\nliterature/hb/stratix-10/s10-mx-overview.pdf. [Online; Accessed 22. Au-\ngust 2019], 2019.\n[36]P.Jain,S.Desai,S.Kim,M.-W.Shih,J.Lee,C.Choi,Y.Shin,T.Kim,B.B.Kang,\nandD.Han. OpenSGX:AnOpenPlatformforSGXResearch. In Proceedingsof\nthe2016 AnnualNetworkand DistributedSystem SecuritySymposium(NDSS),San\nDiego, CA, Feb. 2016.\n[37]R. Karam, T. Hoque, S. Ray, M. Tehranipoor, and S. Bhunia. Robust bitstream\nprotection in fpga-based systems through low-overhead obfuscation. In 2016\nInternational Conference on ReConFigurable Computing and FPGAs (ReConFig),\npages 1ś8, Nov 2016. doi: 10.1109/ReConFig.2016.7857187.\n[38]T.Kim,M.Peinado,andG.Mainar-Ruiz. Stealthmem:System-levelprotection\nagainstcache-basedsidechannelattacksinthecloud. In Proceedingsofthe21st\nUSENIX Security Symposium (Security), Bellevue, WA, Aug. 2012.\n[39]T. Kim, J. Park, J. Woo, S. Jeon, and J. Huh. Shieldstore: Shielded in-memory\nkey-valuestorage withsgx. In Proceedingsof theFourteenth EuroSysConference\n2019, EuroSys ’19, pages 14:1ś14:15, New York, NY, USA, 2019. ACM. ISBN\n978-1-4503-6281-8. doi: 10.1145/3302424.3303951. URL http://doi.acm.org/10.\n1145/3302424.3303951.\n[40]P. Kocher, J. Jaffe, B. Jun, and P. Rohatgi. Introduction to differential power\nanalysis. JournalofCryptographicEngineering,1(1):5ś27,Apr2011. ISSN2190-\n8516. doi:10.1007/s13389-011-0006-y. URLhttps://doi.org/10.1007/s13389-011-\n0006-y.\n[41]D. Lee, D. Jung, I. T. Fang, C.-C. Tsai, and R. A. Popa. An off-chip attack on\nhardware enclaves via the memory bus. In Proceedings of the 29th USENIX\nSecurity Symposium (Security), Boston, MA, Aug. 2020.\n[42]S. Lee, M.Shih, P. Gera, T. Kim,H. Kim, and M. Peinado. Inferring fine-grained\ncontrolflowinsideSGXenclaveswithbranchshadowing. In Proceedingsofthe\n26th USENIX Security Symposium (Security), Vancouver, BC, Aug. 2017.\n[43]C. Liu, A. Harris, M. Maas, M. Hicks, M. Tiwari, and E. Shi. Ghostrider: A\nhardware-software system for memory trace oblivious computation. ACM\nSIGARCH Computer Architecture News, 43(1):87ś101, 2015.\n[44]A. Ltd. mbed tls. https://tls.mbed.org. [Online; Accessed 22. August 2019], 2015.\n[45]M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic, J. Kubiatowicz,\nand D. Song. Phantom: Practical oblivious computation in a secure processor.\nInProceedings of the 20th ACM Conference on Computer and Communications\nSecurity (CCS), Berlin, Germany, Oct. 2013.\n[46]H. Mardani Kamali, K. Zamiri Azar, K. Gaj, H. Homayoun, and A. Sasan. Lut-\nlock:Anovellut-based logicobfuscationforfpga-bitstreamandasic-hardware\nprotection. In 2018IEEEComputerSocietyAnnualSymposiumonVLSI(ISVLSI),\npages 405ś410, July 2018. doi: 10.1109/ISVLSI.2018.00080.\n[47]U. F. Mayer. Linux/unix nbench. https://www.math.utah.edu/~mayer/linux/\nbmark.html. [Online; Accessed 22. August 2019], 2011.\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1915[48]F.McKeen, I.Alexandrovich, A.Berenzon, C.V. Rozas,H. Shafi,V.Shanbhogue,\nand U. R. Savagaonkar. Innovative instructions and software model for isolated\nexecution. In Proceedings of the 14th Hardware and Architectural Support for\nSecurity and Privacy (HASP), Tel-Aviv, Israel, June 2013.\n[49]M. Minkin, D. Moghimi, M. Lipp, M. Schwarz, J. Van Bulck, D. Genkin, D. Gruss,\nB. Sunar, F. Piessens, and Y. Yarom. Fallout: Reading kernel writes from user\nspace.CoRR, abs/1905.12701, 2019. URL http://arxiv.org/abs/1905.12701.\n[50]K. Nayak, C. Fletcher, L. Ren, N. Chandran, S. Lokam, E. Shi, and V. Goyal. Hop:\nHardwaremakesobfuscationpractical. In Proceedingsofthe2017AnnualNetwork\nand Distributed System Security Symposium (NDSS), San Diego, CA, Feb. 2017.\n[51]W.D.NorcottandD.Capps.Iozonefilesystembenchmark.http://www.iozone.org.\n[Online; Accessed 22. August 2019], 2003.\n[52]D. A. Osvik, A. Shamir, and E. Tromer. Cache attacks and countermeasures:\nthecaseofaes. In CryptographersâĂŹTrackattheRSAConference,pages1ś20.\nSpringer, 2006.\n[53]A. Peetermans, V. Rozic, and I. Verbauwhede. A highly-portable true random\nnumbergeneratorbasedoncoherentsampling. In 201929thInternationalCon-\nference on Field Programmable Logic and Applications (FPL), pages 218ś224, 2019.\nURL https://github.com/KULeuven-COSIC/COSO-TRNG.\n[54]P.Pessl,D.Gruss,C.Maurice,M.Schwarz,andS.Mangard. Drama:Exploiting\ndramaddressingforcross-cpuattacks. In Proceedingsofthe25thUSENIXSecurity\nSymposium (Security), Austin, TX, Aug. 2016.\n[55]J.-J. Quisquater and D. Samyde. Side Channel Cryptanalysis. In Invited talk\nin SEcuritÃľ de la Communication sur Internet (SECI 02). Tunis, Tunisia, 9 2002.\nInvited talk.\n[56]A.Rane,C.Lin,andM.Tiwari. Raccoon:closingdigitalside-channelsthrough\nobfuscated execution. In Proceedings of the 24th USENIX Security Symposium\n(Security), Washington, DC, Aug. 2015.\n[57]L. Ren, C. Fletcher, A. Kwon, E. Stefanov, E. Shi, M. Van Dijk, and S. Devadas.\nConstants count: Practical improvements to oblivious ram. In Proceedings of the\n24th USENIX Security Symposium (Security), Washington, DC, Aug. 2015.\n[58]E.Rescorla. Diffie-hellmankeyagreementmethod. https://tools.ietf.org/html/\nrfc2631. [Online; Accessed 22. August 2019], 1999.\n[59]L. Sanders. Secure boot of zynq-7000 all programmable soc. https:\n//www.xilinx.com/support/documentation/application_notes/xapp1175_\nzynq_secure_boot.pdf. [Online; Accessed 22. August 2019], 2015.\n[60]S.Sasy,S.Gorbunov,andC.W.Fletcher. Zerotrace:Obliviousmemoryprimitives\nfrom intel sgx. In Proceedings of the 2018 Annual Network and Distributed System\nSecurity Symposium (NDSS), San Diego, CA, Feb. 2018.\n[61]M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and S. Mangard. Malware guard\nextension: Using sgx to conceal cache attacks. In International Conference on\nDetection of Intrusions and Malware, and Vulnerability Assessment, pages 3ś24.\nSpringer, 2017.\n[62]J.Seo,B.Lee,S.Kim,M.-W.Shih,I.Shin,D.Han,andT.Kim. Sgx-shield:Enabling\naddress space layout randomization for sgx programs. In Proceedings of the 2017\nAnnual Network and Distributed System Security Symposium (NDSS), San Diego,\nCA, Feb. 2017.\n[63]A.Shafiee,R.Balasubramonian,M.Tiwari,andF.Li. Securedimm:Movingoram\nprimitives closer to memory. In Proceedings of the 24th IEEE Symposium on High\nPerformance Computer Architecture (HPCA), Vienna, Austria, Feb. 2018.\n[64]M.-W. Shih, S. Lee, T. Kim, and M. Peinado. T-SGX: Eradicating Controlled-\nChannelAttacksAgainstEnclavePrograms. In Proceedingsofthe2017Annual\nNetwork and Distributed System Security Symposium (NDSS), San Diego, CA, Feb.\n2017.\n[65]S. Shinde, Z. Chua, V. Narayanan, and P. Saxena. Preventing your faults from\ntellingyoursecrets. In Proceedingsofthe11thACMSymposiumonInformation,\nComputerandCommunicationsSecurity(ASIACCS),Xi’an,China,MayśJune2016.\n[66]R. Sinha, S. Rajamani, and S. A. Seshia. A compiler and verifier for page ac-\ncess oblivious computation. In Proceedings of the 2017 11th Joint Meeting on\nFoundations of Software Engineering, ESEC/FSE 2017. ACM, 2017.\n[67]E.StefanovandE.Shi. Oblivistore:Highperformanceobliviouscloudstorage.\nInProceedingsofthe34thIEEESymposiumonSecurityandPrivacy(Oakland),San\nFrancisco, CA, May 2013.[68]E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and S. Devadas. Path\noram:Anextremelysimpleobliviousramprotocol. In Proceedingsofthe20thACM\nConferenceonComputerandCommunicationsSecurity(CCS),Berlin,Germany,\nOct. 2013.\n[69]R. K. S. A. Ting Lu. Secure device manager for intel(r) stratix(r) 10 devices\nprovides fpga and soc security. https://www.intel.com/content/dam/www/\nprogrammable/us/en/pdfs/literature/wp/wp-01252-secure-device-manager-\nfor-fpga-soc-security.pdf. [Online; Accessed 22. August 2019], 2018.\n[70]C.-C. Tsai, K. S. Arora, N. Bandi, B. Jain, W. Jannen, J. John, H. A. Kalodner,\nV.Kulkarni, D.Oliveira,andD.E.Porter. Cooperationand securityisolationof\nlibrary oses for multi-process applications. In Proceedings of the 9th European\nConferenceonComputerSystems(EuroSys),Amsterdam,TheNetherlands,Apr.\n2014.\n[71]C.-C. Tsai, D. E. Porter, and M. Vij. Graphene-sgx: A practical library os for\nunmodified applications on sgx. In 2017 USENIX Annual Technical Conference\n(USENIX ATC), 2017.\n[72]J. Van Bulck, N. Weichbrodt, R. Kapitza, F. Piessens, and R. Strackx. Telling\nyour secrets without pagefaults: Stealthy page table-based attacks onenclaved\nexecution. In Proceedings of the 26th USENIX Security Symposium (Security),\nVancouver, BC, Aug. 2017.\n[73]J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens, M. Silber-\nstein,T.F.Wenisch,Y.Yarom,andR.Strackx. Foreshadow:Extractingthekeys\nto the Intel SGX kingdom with transient out-of-order execution. In Proceedings\nof the 27th USENIX Security Symposium (Security), Baltimore, MD, Aug. 2018.\n[74]S. van Schaik, A. Milburn, S. ÃŰsterlund, P. Frigo, G. Maisuradze, K. Razavi,\nH.Bos,andC.Giuffrida. RIDL:Roguein-flightdataload. In Proceedingsofthe\n40th IEEE Symposium on Security and Privacy (Oakland), San Francisco, CA, May\n2019.\n[75]S.Volos,K.Vaswani,andR.Bruno. Graviton:Trustedexecutionenvironments\non gpus. In Proceedings of the 13th USENIX Symposium on Operating Systems\nDesign and Implementation (OSDI), Carlsbad, CA, Nov. 2016.\n[76]R.Wang,Y.Zhang,andJ.Yang. D-oram:Path-oramdelegationforlowexecution\ninterference on cloud servers with untrusted memory. In Proceedings of the 24th\nIEEE Symposium on High Performance Computer Architecture (HPCA), Vienna,\nAustria, Feb. 2018.\n[77]W.Wang,G.Chen,X.Pan,Y.Zhang,X.Wang,V.Bindschaedler,H.Tang,and\nC. A. Gunter. Leaky cauldron on the dark land: Understanding memory side-\nchannel hazards in sgx. In Proceedings of the 24th ACM Conference on Computer\nand Communications Security (CCS), Dallas, TX, Oct. 2016.\n[78]X. Wang, H. Chan, and E. Shi. Circuit oram: On tightness of the goldreich-\nostrovsky lower bound. In Proceedings of the 22nd ACM Conference on Computer\nand Communications Security (CCS), Denver, Colorado, Oct. 2015.\n[79]J.B.WendtandM.Potkonjak. Hardwareobfuscationusingpuf-basedlogic. In\nProceedings of the 33rd IEEE/ACM International Conference on Computer-Aided\nDesign (ICCAD), San Jose, CA, USA, Nov. 2014.\n[80]J. Winkles. Pci express(r) basics. http://www.cs.uml.edu/~bill/cs520/slides_15B_\nPCI_Express.pdf. [Online; Accessed 22. August 2019], 2006.\n[81]Xilinx. Zc706 evaluation board for the zynq-7000 xc7z045 soc user\nguide. https://www.xilinx.com/support/documentation/boards_and_kits/zc706/\nug954-zc706-eval-board-xc7z045-ap-soc.pdf.[Online;Accessed22.August2019],\n2018.\n[82]Y.Xu,W.Cui,andM.Peinado. Controlled-channelattacks:Deterministicside\nchannelsforuntrustedoperatingsystems. In Proceedingsofthe36thIEEESympo-\nsium on Security and Privacy (Oakland), San Jose, CA, May 2015.\n[83]S. F. Yitbarek, M. T. Aga, R. Das, and T. Austin. Cold boot attacks are still hot:\nSecurity analysis of memory scramblers in modern processors. In Proceedings of\nthe 23rd IEEE Symposium on High Performance Computer Architecture (HPCA),\nAustin, TX, Feb. 2017.\n[84]M. Zhao and G. E. Suh. Fpga-based remote power side-channel attacks. In\nProceedingsofthe39thIEEESymposiumonSecurityandPrivacy(Oakland),San\nFrancisco, CA, May 2018.\n[85]Z. Zhou, M. K. Reiter, and Y. Zhang. A software approach to defeating side\nchannels in last-level caches. In Proceedings of the 23rd ACM Conference on\nComputer and Communications Security (CCS), Vienna, Austria, Oct. 2016.\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1916Table 4: Pearson correlation of the accessed memory addresses\nNative SGX\n(1st input)Native SGX\n(2nd input)TrustOre\n(1st input)TrustOre\n(2nd input)\nNative SGX\n(1st input)10.383801 0.035149 0.035149\nNative SGX\n(2nd input)0.383801 10.034864 0.034864\nTrustOre\n(1st input)0.035149 0.034864 1 1\nTrustOre\n(2nd input)0.035149 0.034864 1 1\nTable5:Memoryreadandwritecountcomparisonofnbench(Num\nsort) b\netween native SGX and TrustOre\nRead\nCountWrite\nCountTotal\nCount\nNative SGX (1st input) 616,106 212,446 828,552\nNative\nSGX (2nd input) 616,564 212,626 829,190\nTrustOre (1st input) 1,697,664 1,697,664 3,395,328\nTrustOre (2nd input) 1,698,940 1,698,940 3,397,880\nAppendix A DATA FORMAT OF\nTRANSACTION\nPACKET\nOnenotablefeatureof TrustOre ’spacketformatisthatitprovides\ntwo format options for the request packet, ReqTand ReqG. ReqT\nis fortime efficient communication by decreasing the header over-\nhead,particularlywhen N≤8(Nisthesizeofdata).ReqGisfor\nsupportingother generalcaseswhere Nislarger.Figure8illustrates\ntwopacketformats,ReqTandReqGsupportedby TrustOre .Since\neveryencryption/decryptionisexecutedinaunitofAESblock,the\nnumber of the blocks directly impacts the performance. ReqTis for\nreducing the number of the AES blocks when the data size Nis\nrelatively small.\nIn particular, if Nis 8B, the total request packet size is to be\n128-bit in the ReqTformat, which is the same as an AES block size\nand thus an entire packet can be sent within a single AES block.\nHowever,ifdataof8-bytesizeistransmittedinReqGformat,the\ntotalpacketsizebecomes208-bitandtwoAESblocks(theremaining\n48-bitsarefilledwithdummy)havetobetransmitted.Therefore,\nthe access latency is increased each time as compared with ReqT.\nAppendix B FURTHER SECURITY ANALYSIS\nWediscussthesecuritypropertiesof TrustMod components/events\nnot thoroughly discussed previously.\nLoading TrustMod As mentioned in ğ4.1, TrustOre uses ex-\nisting hardware-based security features implanted in commod-\nity FPGA platforms in order to guarantee the correct loading of\nTrustMod . To reiterate, FPGAs support a secure boot mechanism\nwhich ensures confidentiality and verifiability. Using the secure\nbootmechanism, TrustOre canloadanencryptedmoduleontothe\nFPGA. Furthermore, it can verify the module’s correctness through\na returned bitstream from the FPGA corresponding to the memory\nlayout of the module. The bitstream layout of TrustMod remains\nconsistent regardless of the underlying FPGA and can therefore\nbe easily verified by the enclave. If the verification is successful,\nthe enclave knows that the correct module was securely loaded\non the FPGA via the untrusted system. In case the verification\nfails, the enclave finds out that some entity on the system is behav-\ning maliciously and aborts. If the adversary behaves maliciously,\nTrustOre hasnootherchoicebuttostopexecutingsinceitconsti-\ntutes adenial-of-service violation, neither guaranteed by Intel SGX\norTrustOre.Communication channel. TrustOre creates a secure channel\nbetweenTrustMod (loadedontotheFPGA)and TrustLib (located\ninsidetheenclave)usingDiffie-Hellmansecretkeyexchangeproto-\ncol[58].TrustOre establishesasecretkeybetweenthetwotrusted\npartieswhichisbolstered usingside-channelobliviousAES-GCM\nprotocol [ 18] provided by Intel SGX SDK. All ensuing communi-\ncation (i.e., allocating/deallocating or reading/writing memory) is\nencrypted using the shared key as it passes through the untrusted\nmemory. All requests passed from TrustLib toTrustMod are en-\ncryptedandwrittendirectlybytheenclaveontotheMMIOregions\nor DMA buffers. At this point, OS can launch only a denial-of-\nserviceattackbyremappingMMIOandDMAregions.Furthermore,\neach request is carefully crafted to be indistinguishable from each\nother (as mentioned in ğ4.3). To elaborate, TrustOre ensures that\nthe size of each transaction is set at the start of the program and\nnever changes at runtime. In the same way, all responses have a\nconsistent format and size and are encrypted. Finally, all MMIO or\nDMA regions are established during initialization and remain con-\nsistent throughout the program’s execution. Therefore, an attacker\ncan only figure out the number and time of requests/responses\nwhich are not the protection scope of TrustOre.\nFPGA Device Driver. The device driver is responsible for the\nsetup of the MMIO/DMA channelbetween an application and the\nFPGA device. We conceive that the untrusted device driver can\nact maliciously in the following ways: (a) Choose not to setup\nMMIO/DMA regions, (b) Stop handling device and CPU interrupts,\nor (c) Modify messages as they are being transmitted. Amongst the\nfollowing, (a) and (b) are denial-of-service violations which are out\nof the scope of this paper. Furthermore, (c) will easily be caught by\nTrustLib andTrustMod since all messages are encrypted with a\nsharedsecretkeyunknowntotheattacker.Therefore, TrustOre\nis secure from tampering by the FPGA device driver.\nAppendix C MEMORY ACCESS PATTERN\nANALYSIS\nWe provide the results of our empirical study on how TrustOre\nprotectsmemoryaccesspatterns.Topresenttherealisticcompar-\nison, we chose one of the nbench program, Num sort. Num sort\nperforms the heap sort algorithm for the given data array. We run\nNum sort on the different two input data sets which are gener-\natedfromthedifferentrandomseed.Tocomparememorytraces\nbetween the native SGX and TrustOre , we capture all the write\nand read accesses for the data array stored in the enclave. We also\ngather the traces of TrustLib including the mapped MMIO region\nto communicate with the FPGA.\nFigure9 showsthecomparisonof thecapturedmemorytraces\nbetween the tests. Using the accumulated data, we calculate the\nPearsoncorrelationvalue(Table4)betweeneachtesttoquantify\nhow similar (close to 1) and different (close to 0) the traces are.\nAsshowninFigure9aandFigure9b,aparticulartracepatternis\nobserved in the memory trace gathered from the program running\ninthenativeSGX.Furthermore,thetracesbetweenwheninputting\nthedifferentdataisdistinguishable,giventhatthePearsoncorre-\nlationvalueis0.383801calculatedinTable4.Thechangeintrace\npattern according to the input data is likely to result in the leak-\nage of data information (e.g., ordering) by differential attack. On\ntheotherhand,thememorytraceshowninthe TrustOre -based\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1917ReqTReqG\nOP_TYPEIndicating the requested operation type\n0x0: write request\n0x1: read request\n0x2: allocation request\n0x3: deallocation request\nIDIndicating the ID of the data that is targeted of the request\n(supporting range: 0~1023)\n[12:26] [12:64] SIZEIndicating the requested data size in bytes (= N )\n26-bit for the option ReqT (up to 64MB)\n64-bit for the option ReqG (up to 264 bytes)\n[38:26] [76:64] OFFSETIndicating the byte offset within the object to write or read\n26-bit for the option ReqT, 64-bit for the option ReqG\n- [140:4] - For byte-wise alignment for data\n[64:8N ] [144:8N ] DATA_TO_WRITEData to write\nIf OP_TYPE is not write request, dummies are filled.\nN here means the byte size of data, SIZE\nSTATUSIndicating the status of the request\n0x0: request success\n0x1: request fail\nIDIndicating the allocated ID of the data\n(supporting range: 0~1023)\n- For byte-wise alignment for data\nDATA_TO_READRead data\nIf OP_TYPE was not read request, dummies are filled.\nN here means the byte size of data that is received via SIZE[1:10]Direction\nEnclave to\nFPGABit position [start:size]\nFPGA to\nEnclave\n[16:8N ][11:5]Field name Description\n[0:2]\n[2:10]\n[0]\nFigure 8: The data format of transaction packet between TrustLib andTrustMod.\n(a) Native SGX (1st input)\n (b) Native SGX (2nd input)\n (c)TrustOre (1st input)\n (d)TrustOre (2nd input)\nFigur\ne 9: Memory Access Pattern Comparison for nbench (Num sort)\nprogram (Figure 9c and Figure 9d) is constant during executing\nthe heap sort function. TrustOre -based program shows the same\ntrace even if the input data is changed as shown in Table 4. The\nonly non-constant trace pattern that an attacker can observe are\nwhat is observed at the beginning and end of the program but it\nleaks no meaningful information to the attacker. The ascending\ntracepatternsatthebeginningandendareformovingdataarray\nfrom the enclave to the FPGA memory and vice versa, respectively.\nWe also count the number of write and read to show TrustOre\nprotectstheaccesstype,too.Recall, TrustLib executesthesamenumberofwriteandreadateachrequestregardlessoftheactual\naccess type by inserting dummy write or read as explained in ğ4.3.\nAsaresult, TrustOre -basedprogrambalancesthetotalnumberof\nwriteandreadasshowninTable5,whilethenativeSGXshowsthe\nunbalanced write/read ratio. More specifically, TrustLib executes\nfourmemoryaccesses,i.e.,twowritesandtworeadssequentially\nat each write or read request for the data block. Therefore, total\nmemory access count of TrustOre is about four times larger than\nthat of the native SGX. The reason why TrustOre needs a little\nmorethanthefourtimeslargernumberis theadditionalmemory\noperations at the beginning and end as mentioned earlier.\nSession 6C: Side Channels\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1918"}
{"title": "Watch Out for Race Condition Attacks When Using Android External Storage", "content": "Watch Out for Race Condition Attacks When Using Android\nExternal Storage\nShaoyong Du\nState Key Laboratory of Mathematical Engineering and\nAdvanced Computing\nZhengzhou, Henan, China\nshaoyong.du.cs@gmail.comXin Liu\nState Key Laboratory of Mathematical Engineering and\nAdvanced Computing\nZhengzhou, Henan, China\nlx_ieu@163.com\nGuoqing Lai\nState Key Laboratory of Mathematical Engineering and\nAdvanced Computing\nZhengzhou, Henan, China\nguoqinglai_ieu@163.comXiangyang Luo∗\nState Key Laboratory of Mathematical Engineering and\nAdvanced Computing\nZhengzhou, Henan, China\nluoxy_ieu@sina.com\nABSTRACT\nCurrently, in Android, applications (apps for short) rely heavily\nonexternalstoragetoprovidetheirservices.Raceconditionsare\nintroducedbytheinappropriatefileoperations.Throughracecondi-\ntions,themaliciousappcanmanipulatethefilecontentandinduce\nthevictimapptoperformunexpectedactions,whichwecall race\nconditionattack .Raceconditionattackcancauseaseriesofsecurity\nproblemsandpriorworkhasalreadyimplementedsomeofthem.\nFrom Android 10, Google has introduced scoped storage to defend\nagainst attacks based on external storage. However, considering\ncurrentmarketsharesofdifferentAndroidversions,itisstillalong\nway to have scoped storage deployed on each device. To protect\ncurrent users from this kind of attack, it is essential to raise app\ndevelopers’securityawareness.Therefore,weconductacompre-\nhensive survey on race condition attack to learn about its current\nstatusoverAndroidapps.Weproposeananalysisengine,named\nRECAST,whichgathersfileoperationeventsonexternalstorage\nandinferstheassociatedfileoperationprocesses.WithRECAST,\nwecollect5,359,339fileoperationeventsover105,963files.From\nthe analysis result, we find that, with the limited kinds of events, a\ntremendous number of unique file operating patterns (1,977) are\nconstituted. Over these file operating patterns, the time window is\nmuchcommonandavailabletolaunchaseriesofattacks(94.26%\nof the tested files are vulnerable to this problem). Consequently,race condition attack has become a non-negligible issue for app\ndevelopers when using Android external storage.\nCCS CONCEPTS\n•Security and privacy →Software and application security.\n∗Corresponding author of this paper.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9450-5/22/11...$15.00\nhttps://doi.org/10.1145/3548606.3560666KEYWORDS\nAndroid external storage; race condition attack; file operation\nACM Reference Format:\nShaoyong Du, Xin Liu, Guoqing Lai, and Xiangyang Luo. 2022. Watch\nOut for Race ConditionAttacks When Using Android External Storage. In\nProceedingsofthe2022ACMSIGSACConferenceonComputerandCommuni-\ncationsSecurity(CCS’22),November7–11,2022,LosAngeles,CA,USA. ACM,\nNew York, NY, USA, 14 pages. https://doi.org/10.1145/3548606.3560666\n1 INTRODUCTION\nNowadays, the smartphone’s storage capacity increases rapidly to\nfulfill different apps’ storage requirements. In Android, the storage\nislogicallysplitintotwoparts: internalstorage andexternalstorage.\nDifferent from the internal storage used to keep sensitive data, the\nexternal storage can be used for different purposes. As a result, the\nexternal storage becomes an essential medium for apps to store\nandsharedata.However,thelimitedprotectiononexternalstorage\nmakes external storage suffer from a series of security problems.\nPrior work [ 2,4,11,27] already found that plenty of stored files\nleakedtheuser’ssensitiveinformationtotheattacker,indicating\nthe severity of security problems on external storage.\nTo solve the security problems caused by external stor-\nage, Google proposed a new defense, scoped storage [ 10], in\nAndroid 10. Since Android 11 (targetSdkVersion =30), scoped\nstorage has been strongly enforced. Even though, the MAN-\nAGE_EXTERNAL_STORAGE permission still leaves a way to fully\naccess the whole shared storage. Up to March 2022, the market\nshares of Android 11 and 10 are 34.7%, 24.7%, separately1. The\nprior versions of Android still have a considerable part of mar-\nketshare(40.6%intotal).Androidfragmentationmakesitalong\nwaytohavealltheAndroiddevicesupdatedtothelatestversion.\nMoreover, censorship policies make Google Play Store unavailable\nin some countries and areas, which results in a large number ofthird-party app stores. These third-party app stores may not vet\ntheappsasseriouslyasGooglePlayStoredoes.Accordingtoour\nsurveyononeofthemostpopularappstoresinChina,Wandoujia2,\nwe find that with targetSdkVersion ≥30 (i.e.,the target platform is\n1AndroidOSversionmarketshareovertime:www.appbrain.com/stats/top-android-\nsdk-versions\n2Wandoujia app store: https://www.wandoujia.com\n \n891\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\nAndroid 11 or newer), there are 11.17% (129) apps declaring the\nMANAGE_EXTERNAL_STORAGE permission in their manifest\nfiles. Therefore, even with scoped storage, the security problemcaused by external storage is still a big challenge faced by app\ndevelopers.\nUnfortunately, compared with the security problem of external\nstorage,appdevelopersprefertofocusmoreattentiononthenovel\nfunctions of their apps so as to attract more users. Hence, evenapp developers propose some methods to deal with the security\nproblems on external storage, the solutions may be not as effective\nas they expect. It is because that the file operations are not well-\norganized whichcan introduce somerace conditions.A malicious\napp can utilize the race condition to manipulate the file contentjust before the real app uses it. Consequently, the real app is in-\nducedtoperformsomeunexpectedactionswhichleaktheuser’s\nprivacy, cause the property loss, or even put the user in danger.\nRace condition attack on external storageis not a new problem. It\nhas been mentioned in prior work [ 2,9]. However, its universality\nandseverityovercurrentAndroidappsintherealworldarestill\nunknown. As a result, only a small number of app developers take\nthis problem seriously. Considering the potential risks of this prob-\nlem, it is urgent to have a clear picture about current status of this\nproblem,whichmotivatesustoconductacomprehensivesurvey.\nIn this paper, we attempt to answer the following questions:\nQ1:Doesraceconditionwidelyexistwhenappsusethefileson\nexternal storage?\nQ2:Isiteasytoexploitraceconditiononexternalstoragetolaunch\nattacks?\nQ3:Is there any uniform workflow to exploit race condition on\nexternal storage?\nChallenges. Tolearnabouttheraceconditionattackonexternal\nstorage,wehavetocollectdetailedinformationaboutfileoperations\non external storage, and then conduct a comprehensive investiga-\ntion. This idea sounds easy, but there are still some challenges that\nwe need to solve:\nC1:How to collect file operation information? The code analysis\nmethod can tell us how an app works. Howev er, it cannot\nprovideuswithenoughinformationtostudytheracecondi-\ntion attack on external storage: 1) it is hard for us to precisely\nidentifythefileoperationsonexternalstorage;2)wecannot\nobtain any timeinformation of the file operations; 3)we can-\nnot identify the app’s critical components (usually used by\nusers).Therefore,itisurgentforustofindaneffectivemethod\nto collect the file operation information.\nC2:How to organize the file operation information? The file op-\neration information comes from a huge number of files onexternal storage, and most files are named according to the\ndynamicrandomizedfilenamingrules.Whenweorganizethe\nobtained file operation information to study the race condi-\ntionsoverthesefiles,wehavetodealwiththechallengeraised\nby the dynamic randomized file naming rules.\nC3:How to extract the file operating patterns? To understand how\nan app uses a file each time, we have to extract the associ-ated operating patterns from the hundreds or thousands of\ncollected file operation events. It is common that some file op-\neration events are lost occasionally while some others appearrepeatedly. Both of these two cases make the extracted fileoperating patterns vary. Therefore, it is not an easy task to\nobtain the uniform operating patterns.\nC4:How to verify and exploit the potential race conditions? Once\nwe identify the race conditions in the obtained file operating\npatterns, we want to verify and exploit these race conditions.\nHowever, different files are processed under different work-\nflowsandtheircontentsaremuchdifferent,ifwedesignthe\nverification process case by case, it will be a tremendous task.\nHence,wehavetobuildupauniformframeworktoverifythe\ndiscovered race conditions.\nSolutions. To conquer the above challenges, we propose the fol-\nlowing solutions. First, instead of the code analysis method, weutilizeandroid.os.FileObserver to build a powerful file operation\nmonitorthatcaptureseachfileoperationonexternalstorageand\nrecords detailed information about these file operations (e.g., file\noperationtype,happeningtime, etal.).Todealwiththeproblem\nraisedbythedynamicrandomizedfilenamingrules,weattempttojudgeandlearnabouttherandomizednamingrulesbasedonsome\nstatistics metrics. To solve the third challenge, we take the relation\nfeatures (e.g., once a file is opened, it must be closed later) and\nthe time features(e.g., the time intervalfrom the prior file closing\noperation to the next file opening operation) as clues to extract the\nfile operating patterns and analyze the potential race conditions.\nLast but not least, as the race condition happens just before the file\ncontentisaccessed,toverifythepotentialraceconditionattack,we\nfocusourattentiononthetimewindowbeforethefileisopened.\nMeanwhile, considering that, for an app, each of the file process\nfunctions can handle a series of files, we utilize one of the existing\nfiles as a template so that we do not have to be deeply involved in\nanalyzing the filestructure and content. Wecan use this template\nfile to check each time window where the race condition can exist.\nFindings. Inthispaper,wetrackthefileoperationson10volun-\nteers’smartphonesover10days.Withtheobtained5,359,339file\noperation events, we find that the limited types of file operation\nevents constitute a huge number of file operating patterns (i.e.,\n1,977 unique patterns in our obtained dataset). The time windows\n(betweentwoadjacent OPENevents)aremuchcommoninthesefile\noperatingpatterns, whichindicatesthatthe raceconditionattack\nexistswithahighprobability.Overthesefileoperatingpatterns,the\ntop100fileoperatingpatternscover66.43%obtainedfiles,which\nfully proves that app developer uses the same workflow to process\na kind of files. In this situation, once we find a vulnerability caused\nby race condition, we can further validate this vulnerability on the\nother files which are processed by the same workflow. With our\nmanualverification,we findthat94.26%randomlyselectedtested\nfilesarevulnerabletotheraceconditionattacks.Meanwhile,the\nmanual verification result also proves that with the help of the\nobservedfileoperatingpatterns,wecaneasilyexploitthepotential\nrace conditions through a uniform workflow.\nContributions. Insummary,wemakethefollowingcontributions:\n•We design and implement a powerful analysis engine, RECAST,\nthat collects file operation information from different smart-\nphones and recasts the associated file operations.\n \n892Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n•We propose a series of solutions to organize and process the\nobtained file operation events. We conduct a deep investigation\nontheobservedfilesonexternalstorageaswellastheassociated\nfileoperationstolearnaboutthepotentialraceconditionattacks\non external storage.\n•We propose a uniform workflow to verify and exploit the po-\ntential race conditions over different file operations on different\nfiles.Accordingtotheverificationresult,wefindthattheraceconditions can be easily employed to impact the victim apps’\nnormal functions and perform a series of attacks.\nRoadmap. Therestofthispaperisorganizedasfollows.In §2,we\nintroduce some background information. §3 presents the design of\nthe analysis engine, RECAST. The evaluation result is shown in §4.\n§5 presents a uniform workflow to verify and exploit the potential\nraceconditionsaswellasthemanualverificationresult. §6talks\nabout some related work. We conclude our work in §7.\n2 BACKGROUND\n2.1 Android Storage Management\nInAndroid,storageisacriticalcomponentthatismadeupofthe\nbuilt-in storage and external storage devices, shown in Figure 1. In\nfact, Android provides the apps with two kinds of storage (internal\nstorageandexternal storage ) to save data. The internal storage is\nusedtokeepthesystem’scoredataandapps’privatedata,while\nthe external storage (“/sdcard/” or “/storage/emulated/0/”) is used\nto store the public data. Considering the sensitivity of the data\nstored on internal storage, Android sets the strict access policy\non internal storage. However, external storage is much different\nfrom internal storage. With Android’s evolution from 1.0 to 13, the\nstorage management policies have been updated multiple times.\n•Starting from Android 1.0, when an app writes data on exter-\nnalstorage,theWRITE_EXTERNAL_STORAGEpermissionis\nrequired.\n•From Android 4.1, the READ_EXTERNAL_STORAGE per-mission is introduced to deal with reading a file on exter-nal storage. Meanwhile, when an app is granted with the\nWRITE_EXTERNAL_STORAGE permission, it is also implicitly\ngranted with the READ_EXTERNAL_STORAGE permission.\n•From Android 4.4, when an app reads the file on external stor-\nage, it must be granted with the READ_EXTERNAL_STORAGE\npermission3. However, an app can freely visit its application-\nspecific directory on external storage (“/storage/emulated/0/ An-\ndroid/data/<package_name>/”), in Figure 1, without any permis-\nsion required.\n•Android 10 introduces a new kind of protection policy onexternal storage, scoped storage, to restrict the access to ex-\nternal storage. In this way, if an app wants to visit the\nwhole external storage, it must make a clear declaration\n“\nrequestLegacyExternalStorage=true ”4in its manifest file\nand require the associated permissions5.\n3Android 4.4 API: https://developer.android.google.cn/about/versions/android-4.4\n4R.attr:https://developer.android.google.cn/reference/android/R.attr#requestLegacyEx\nternalStorage\n5Access media files from shared storage: https://developer.android.google.cn/training\n/data-storage/shared/media?#direct-file-paths\n,QWHUQDO\u0003\n6WRUDJH\n([WHUQDO\u0003\n6WRUDJH\n6KDUHG\u0003\n6WRUDJH$SSOLFDWLRQ\u0010VSHFLILF\u0003\n'LUHFWRULHV\n6PDUWSKRQH¶V\u0003\n%XLOW\u0010LQ\u00036WRUDJH\n([WHUQDO\u00036WRUDJH\u0003\n'HYLFHV\nFigure 1: Android Storage Management\n•The scoped storage is fully deployed in Android 11 and strongly\nenforced in Android 12. As a result, instead of the whole ex-ternal storage, the app can only visit a limited number of di-rectories. Prior work [\n10] gives a detailed introduction to the\nscoped storage. However, there is an exception that with the\nMANAGE_EXTERNAL_STORAGEpermission6granted,theas-\nsociated app can still visit all the files on shared storage. Even\nGooglePlay Store vetseach app requiringaccess to thewhole\nshared storage before it is published, it cannot guarantee all the\napps in the world completely follow the rules of Google. Note\nthatusers’limitedsecurityawarenessmakesthemhardlyiden-\ntify the differences between MANAGE_EXTERNAL_STORAGE\nand WRITE_EXTERNAL_STORAGE permissions. They can eas-\nilygrantthesepermissions,and,asaresult,operatingexternal\nstorage is almost the same whether in scoped storage or not.\nTherefore, in this paper, when we use the item “external storage ”,\nwe do not distinguish whether it is scoped storage or not.\n2.2 File Operations\nIn Android, when an app operates a file on external storage,\nit will trigger a series of operation events (e.g., CREATE,OPEN,\nACCESS,MODIFY,etc., in Figure 2). Based on Linux’s basic func-\ntioninotify7, Android provides app developers with a class an-\ndroid.os.FileObserver8tocapturethesefileoperationevents.With\nthis class, app developers can be noticed in time when a target\noperationevent happenson thetarget file.From nowon, without\na specific explanation, we use the item “file ” to refer to both di-\nrectories and files. Android external storage can be accessed by\nany app granted with the associated permissions. In this case, with\nandroid.os.FileObserver,anappcanmonitornotonlyitsownfiles\nbut also other files saved by different apps on external storage.\nJustasFigure2shows,someinternalrelationsexistamongthese\nfileoperationevents.Comparedwiththesingleoperationevent,the\noperation sequences made up of different operation events can tell\nusmoreinformation.Whenanappimplementsafunctionwhich\nis based on external storage, once it runs, the associated operation\nevents can tellus how the appprocess the file on external storage.\nIntuitively,anapp’sfunctionwillbecompletedinashorttimeso\nas to provide the excellent user experience. Sometimes, the files on\n6Manageallfilesonastoragedevice:https://developer.android.google.cn/training/data-\nstorage/manage-all-files\n7linux-3.0.1/include/linux/inotify.h: http://rswiki.csie.org/lxr/http/source/include/linu\nx/inotify.h\n8FileObserver: https://developer.android.google.cn/reference/android/os/FileObserver\n \n893CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\n&5($7(\n029(B7223(1 $&&(66 &/26(B12:5,7(\n&/26(B:5,7('(/(7(\u0012\n'(/(7(B6(/)\u0012\n029(B6(/)\n029(B)52002',)<\u0012\n$&&(6602',)< 23(1\nFigure 2: Temporal Relationships of File Operation Events\n&5($7(\n23(1\n$&&(66 &/26(B12:5,7(&/26(B:5,7( 02',)<\n23(1\n23(1\n$&&(66 &/26(B12:5,7(&/26(B:5,7( 02',)<\n23(102',)<02',)<:ULWH\u0003GDWD\u0003\nLQWR\u0003WKH\u0003ILOH\n:ULWH\u0003GDWD\u0003\nLQWR\u0003WKH\u0003ILOH\n5HDG\u0003GDWD\u0003\nIURP\u0003WKH\u0003ILOH5HDG\u0003GDWD\u0003\nIURP\u0003WKH\u0003ILOH5RXQG\u0003\u0014\n5RXQG\u00031\u0011\u0011\u0011\nFigure 3: An Example of File Operation Events on a File\n23(1029(\u0003\n)520\n2SHUDWLRQV\u0003%DVHG\u0003RQ\u0003\nWKH\u0003)LUVW\u000323(1\u0003(YHQW029(\u0003\n)520029(\u0003\n)520\n)XUWKHU\u00032SHUDWLRQV0RUH\u0003\n2SHUDWLRQV3UHSDUHG\u0003)DNH\u0003)LOH\n7DUJHW\u0003)LOH\n5HQDPHG\u0003)LOH\n7LPH\u0003:LQGRZ6WHS\u0003\u0015\n6WHS\u0003\u0014\n6WHS\u0003\u0016029(\u0003\n72\n029(\u0003\n72029(\u0003\n72\nFigure 4: Workflow of Race Condition Attack\nexternal storage are accessed frequently over a long time. Figure 3\npresents a simple example that just one process operates the file.\nTherealsituationcanbemorecomplexwhenmultipleprocesses\nareinvolved.Therefore,justaswhatwehavetalkedaboutin §1,in\nthis paper, a great challenge is how we deal with the file operation\nevents.\n2.3 Race Condition Attack\nInthispart,wegiveabriefintroductiontoraceconditionattack.\nNormally, when an app operates a file, its file operation process is\nseldom influenced by other apps. However, since Android supports\nmultipleappstomanipulateafilesimultaneously,whenamalicious\napp exists, the file operation process can be interrupted by a ma-\nliciousapp,justasFigure4shows.Themaliciousapputilizesthe\ntime window, marked in Figure 4, to conduct additional file opera-\ntions (e.g., replacing the file). Once the original file is replaced with\nthe prepared fake file (i.e., Step 1 and Step 2 are done successfully),\nthevictimapp’sfollowingoperationsareconductedonthefakefile.Inthisway,thevictimapp’sassociatedfunctionscanbeinfluenced\nby the malicious app through the content of fake file. To make the\nattackgounnoticedbytheuser,themaliciousappmayrecoverthe\noriginalfile(i.e., Step3inFigure4)whenitspurposeisachieved.\nIt is worth noting that the file replacement can be completed in(YHQW\u0003*DWKHULQJ\u0003\n0RGXOH(YHQW\u0003)LOWHULQJ\n0RGXOH(YHQW\u0003/LQNLQJ\n0RGXOH\n(YHQW\u00035HVRUWLQJ\n\t\u0003&DWHJRUL]LQJ\n0RGXOH(YHQW\u0003$QDO\\]LQJ\n0RGXOH(YHQW\u00030RQLWRULQJ\u0003\n0RGXOH\n&OLHQW 6HUYHU\nFigure 5: Overview of RECAST\n)LOH\u00032SHUDWLRQ\u0003(YHQW\u00037\\SH\u0003DQG\u0003$VVRFLDWHG\u0003&RGH\n)LOH\u0003$EVROXWH\u00033DWK +DSSHQLQJ\u00037LPH\u0003\u000bPV\f\nFigure 6: A Fragment of File Operation Event Log\nashorttime(aconstantinmostcases),whichenablesthisattack\nwithin the small time window.\nConsidering that the apps use external storage for different pur-\nposes, the race condition attack can be employed by the malicious\napptolaunchaseriesofattacks.Weleavethedetaileddiscussion\nabout these attacks in §5. In this part, we use two common scenes\nto show the impact of race condition attack.\n•Scene #1. When a user receives a QR code picture shared by\nher friend through a social app, the QR code picture is saved on\nexternal storage by the social app. This QR code picture may be\nreplacedbytheattackerwithafakeonethatcontainsamalicious\nwebsite’s URL. Once the user scans it, she is misguided to the\nmalicious website.\n•Scene#2. Whenauserdownloadsanappthroughathird-party\napp store. The attacker can replace the original apk file, savedon external storage, with the one that contains the malicious\ncode.Asaresult,Whenthefakeoneisinstalled,itwillrunon\nthe victim’s smartphone to launch further attacks.\n2.4 Threat Model\nIn this paper, we take the following situation into account. A mali-\nciousapphasalreadybeeninstalledonthevictim’ssmartphoneand\ngranted with the associated permissions to access external storage\nandInternet.Thisapptakesadvantageof android.os.FileObserver\nto continuously monitor the files on external storage, and receives\ntasks from the remote server through the Internet. With the as-sociatedfileoperationeventscollected,justasFigure4shows,it\nidentifiesachance(thetimewindow)tomanipulatethefilesoas\nto performa series ofattacks such asthe scenes presented in §2.3.\nIn the next section, we present our analysis engine, RECAST, first.\n3 DESIGN OF RECAST\nTo fully understand the potential race conditions over external\nstorage,weimplementananalysisengineRECASTthatcollectsa\nlarge number of file operation event logs first, and then performs a\nseries of processes to gain the insights. Before talking about any\ntechnique details, we present an overview of RECAST first.\n \n894Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nTable 1: Collected Data Items and Their Usage\nItem Usage\nTarget File Pathxlocate the operated target,\nystudy file organization rules,\nzclassify the associated file operation events.\nEvent Type xstudy the relationship among different file operations.\nHappening Timexresort the file operation events,\nystudy the potential time windows over file operations.\n3.1 Overview\nJustasFigure5shows,RECASTismadeupoftwoparts:clientand\nserver.Theclientrunsonthesmartphone,monitorsandrecordsthe\nfileoperations.Onceafileoperationeventoccurs,theassociated\ninformation (including target file path, operation event type and\nhappening time) will be recorded just as Figure 6 shows. All the in-\nformationwillbeuploadedtotheserverlaterforfurtherprocessing.\nThe usage of the collected information is listed in Table 1.\nThe server is responsible for conducting a series of processes on\nthe uploaded data. The server receives and saves all the data from\ndifferent clients.And then, theserver filters outthe noise data( e.g.,\nthe file that just has a single file operation event on it). The filtered\noperation events are linked based on the target file path and sorted\nbytheirhappeningtime.Next,theserverresortsandcategorizes\nthe data so as to learn about the file organizing patterns as well as\nfile operating patterns.\nIn the following parts, we will describe some details that deal\nwiththechallengespresentedin §1.Notethatinthissection,we\nengageindealingwiththefirstthreechallenges(i.e., C1,C2,and\nC3). We leave the challenge C4 to be resolved in §5. In§3.2, we\ndealwiththechallengesC1andC3,separately.ThechallengeC2is\nsolved in §3.3.\n3.2 Obtaining File Operating Patterns\nAcquirementofFileOperationInformation. Thoughthecode\nanalysis method has been utilized in prior work to find out the\nvulnerabilities in Android systems, we find it is not capable to\nsolve current problem in this paper due to some reasons whichhave been talked about in\n§1. However, just as Figure 6 shows,\nandroid.os.FileObserver can directly tell us where, when and how a\nfileisoperated,whichprovidesuswithabigcluetounderstandtheraceconditionsonexternalstorage.Inthispaper,wetakeadvantage\nofandroid.os.FileObserver to monitor when and how the files on\nexternal storage are operated. Beginning with the root directory\n(i.e.,“/sdcard/” in Figure 7), we recursively build the file operation\nmonitoroneachofthedirectories.Insteadofthewholefiles,wejust\nbuild the file operation monitors on the directories. It is because\nthat when a file operation monitor runs on a directory, besides\nthe file operations happening on this directory, the file operations\nhappeningonthecontainedfilesalsowillbecaptured.Whenthe\nclient runs, the monitors are adjusted dynamically to deal with\nchangesoffileorganizationonexternalstorage.Ifadirectory(such\nas “Dir_A2/” in Figure 7) is deleted, the associated monitor will\nbe removed. When a new directory (such as “Dir_A3/” in Figure\n7) is constructed, a new monitor will be built. In this way, we\ncancollectdetailedinformationaboutfileoperationsonexternal\nstorage.Thefrequentlyoperatedfilesareincloserelationshipwith\ntheapp’sfrequentlyusedcomponents.Therefore,withtheobtained\u0012VGFDUG\u0012\n$QGURLG\u0012\nGDWD\u0012 PHGLD\u0012 REE\u0012'&,0\u0012 'RZQORDG\u0012\n\u001fSDFNDJH\u0003QDPH!\u0012'LUB$\u0012\n'LUB$\u0014\u0012 'LUB$\u0015\u0012 'LUB$\u0016\u0012\n)LOHBD )LOHBE\nFigure 7: File Organization of Android External Storage\nTable 2: File Operations and the Associated Events\nAction File Exists File Operation Events1\nCreate a file ×CREATE→ATTRIB2→OPEN\n→CLOSE_WRITE\nWrite a file×CREATE→ATTRIB2→OPEN\n→MODIFY*3→CLOSE_WRITE\n/checkMODIFY→OPEN→MODIFY*\n→CLOSE_WRITE\nRead a file /checkOPEN→ACCESS* →\nCLOSE_NOWRITE\nDelete a file /check DELETE\nMove a file in × MOVE_TO\nMove a file out /check MOVE_FROM\n1These file operation events are obtained from Android 9. Different\nAndroid versions have small differences on the file operation events.\n2Fileoperationevent ATTRIBdoesnotappearinsomeAndroidversions.\n3The mark “*” indicates that the associated events can appear more\nthan one time.\n2ULJLQDO\u0003)LOH\u00032SHUDWLRQ\u0003(YHQWV\n)LOH\u0003& )LOH\u0003% )LOH\u0003' )LOH\u0003$\n)LOH\u0003$ )LOH\u0003% )LOH\u0003& )LOH\u0003'&ODVVLI\\LQJ\u0003)LOH\u00032SHUDWLRQ\u0003(YHQWV\n/LQNLQJ\u0003)LOH\u00032SHUDWLRQ\u0003(YHQWV\nFigure 8: Preprocessing on Original File Operation Events\ninformation, we can discover an app’s critical components that are\nfrequentlyusedbyusers.Theraceconditionattacksonthesecritical\ncomponentsmaycauseseveresecurityproblems.Uptonow,the\nchallenge C1 has been solved. Next, we process these obtained file\noperation events and start to deal with the challenge C3.\nPretreatment on Whole Files’ Operation Events. A single file\noperation event ecannot tell us enough information about the\npotential race condition. When an app reads or writes a file, it will\ntriggeraseriesofoperationevents sraw={ei|i∈{1,n}},shown\nin Table 2. In reverse, once we build up the file operation event\nsequence sraw,wecaninferwhattheappwantstodowiththefile.\nSincethedatasetgatheredfromdifferentparticipantsismadeup\noffileoperationeventsoverdifferentfiles,thefirststepwehaveto\ndo is to classify these file operation events based on the target file\npaths,showninFigure8.Andthen,weusethetimeinformationto\nrecover the file operation event sequence srawon each file.\nTreatmentonEachFile’sOperationEvents. Itismuchcommon\nto see that an app can operate a file multiple times (e.g., each time\nthe app is activated), which results in a long file operation event\n \n895CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\nAlgorithm1: Treatmentoneachfile’soperationsequence.\nInput:A file operation sequence sraw\nOutput:A list of short operation sequences\nS={si|i∈{1,m}}\n1stackopen={},sfiltered={},stemp={},S={},\nδ=10minutes;\n2for∀ej∈srawdo\n3ifejis neither OPEN nor CLOSE event then\n4 ifthe type of ejis not the same as the one of ej−1\nthen\n5 sfiltered.add(ej);\n6else\n7 sfiltered.add(ej);\n8for∀ej∈sfiltereddo\n9tj−1 ,jis the time interval between ej−1andej;\n10iftj−1 ,j>δthen\n11 setstempnot able to be appended with any\nfollowing events;\n12 S.add(stemp)and reset stemp;\n13 stackopen.clear();\n14stemp.add(ej);\n15ifejis OPEN event then\n16 stackopen.push(ej);\n17else ifejis CLOSE event then\n18 ifstackopen.isEmpty()==falsethen\n19 stackopen.pop();\n20 ifstackopen.isEmpty()==truethen\n21 S.add(stemp)and reset stemp;\n22 else\n23 ifthe last short sequence slast∈Scan be\nappended with more events then\n24 slast.addAll(stemp)and reset stemp;\n25 else\n26 S.add(stemp)and reset stemp;\n27S.add(stemp)and reset stemp;\nsequence sraw.Tohaveabetterunderstandingofeachactionon\nthisfile,wehavetodealwiththisfileoperationeventsequence sraw.\nIn this part, we mainly conduct two steps: 1) merge continuously\nrepeating file operation events, and 2) split file operation sequence.\nAlgorithm 1 shows the details.\nMergecontinuouslyrepeatingfileoperationevents. Amongtheob-\ntained file operation events, we find that when an app reads/writes\nfiles, a number of ACCESSorMODIFYevents occur. Though these\nevents can tell us the app’s intent, the continuously appearing\nACCESSorMODIFYeventswillresultinaseriesofvariancesofthe\nreal fileoperating pattern.These variances complicateour further\nanalyses. In most cases, the number of ACCESSorMODIFYevents\ndepends on not only the associated app but also the operating sys-\ntem.Takingthe MODIFYeventasanexample,nomatterhowanappwrites a file, the MODIFYevent happens only when data is really\nwrittentothephysicalstoragemedium.Infact,the OPEN,CLOSE(in-\ncluding CLOSE_NOWRITE andCLOSE_WRITE )eventscanprovideus\nwith some clues about the potential race conditions. Hence, except\nforOPEN,CLOSE_NOWRITE andCLOSE_WRITE events,whenthefile\noperation events of the same type appear continuously, we merge\nthem into only one, just as what is done from Line 2 to Line 7 in\nAlgorithm 1.\nSplit file operation sequence. As shown in Figure 3, when an app\noperatesafile,the OPENandCLOSEeventsappearinsequence.In\nthispart,wefullytakeadvantageofthisrelationbetween OPENand\nCLOSEevents to split the file operation sequence (from Line 8 to\nLine 27 in Algorithm 1). Ho wever, there i s still a case that we need\ntotakeintoaccount—RECASTclientmaybestoppedoccasionally\nanditwill misssomefileoperationevents. Themissing OPENand\nCLOSEevents raise a challenge to couple the obtained OPENand\nCLOSEevents,whichwouldresultintheincompletesequences.This\nproblem is fully considered from Line 18 to Line 27 in Algorithm 1.\nIf the prior obtained sequence slastcan be appended with more\nfile operation events, we append the incomplete sequence to the\npriorone slast.Otherwise,wejustputitin S.WheneitherRECAST\nclient or the file owner app is stopped for a period of time (e.g.,\nδ=10minutes),thetimeinterval tj−1 ,jbetweentwoevents ej−1\nandejwill be longer than δ. In this case, ej−1andejdo not belong\ntoafileoperatingpattern.wedealwiththiscaseinadvance,just\nas shown from Line 9 to Line 13 in Algorithm 1.\nExtractionofFileOperatingPatterns. Withtheabovestage,we\nspliteachfile’slongfileoperationsequence srawintoshortones\n{si|i∈{1,m}}.However,theseshortsequencesarestillincapable\ntosupportourfurtheranalyses,asthetimeinformationisrarely\nconsidered.JustasFigure3shows,whenafunctionisactivated,the\nassociated file will be operated continuously within a short period\nand the time intervals among the file operation events are not too\nlong.Thetimeinformationplaysanimportantroleinextracting\nthefileoperatingpatterns.Therefore,wehavetofullyutilizethe\ntime information to extract the file operating patterns. The details\narepresentedinAlgorithm2.Oncethetimeinterval ti,i+1between\ntwo file operation sequences siandsi+1is shorter than the time\nthreshold ( η= 5 seconds), siandsi+1need to be put in one file\noperating pattern, from Line 8 to Line 13. Otherwise, siandsi+1\nbelong to different operating patterns, from Line 14 to Line 17.\nMoreover, considering the missing file operation events mentioned\nabove,wefilterouttheincompletefileoperatingpatterns,fromLine\n18 to Line 20. In this way, the incomplete file operating patterns’\ninfluences on our subsequent analysis and verification are reduced.\nMeanwhile, we take advantage of the long-term data collectionon participants’ smartphones to remedy the impact of filteringout these incomplete patterns. Now, the challenge C3 is settled.\nMoreinformationabouttheextractedfileoperatingpatternswill\nbedescribedin §4.3.Inthe followingpart,wepresenthowto solve\nthe challenge C2.\n3.3 Learning About File Naming Patterns\nWecanseethatthefileoperationeventshappentoavarietyoffiles.\nItisahugeworkloadtoanalyzeeachfile.Todealwiththischallenge,\nweclassifythesefilesinadvance.Wefindthat,inadirectory,the\n \n896Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nAlgorithm 2: Extract the valid file operating patterns.\nInput:A list of short operation sequences\nS={si|i∈{1,m}}\nOutput:A list of file operating patterns P={pj|j∈{1,n}}\n1P={},η=5seconds;\n2for∀si∈Sdo\n3ifP.isEmpty() == true then\n4 copysitopcurrent;\n5 P.add(pcurrent);\n6else\n7 get the last added pattern plastfromP;\n8 ifthe time interval between siandplastis shorter\nthanηthen\n9 ifplastis able to be appended with more events\nthen\n10 plast.addAll(si); //Link these two parts\n11 else\n12 copysitopcurrent;\n13 P.add(pcurrent);\n14 else\n15 setplastunabletobeappendedwithanyevents;\n16 copysitopcurrent;\n17 P.add(pcurrent);\n18for∀pj∈Pdo\n19ifinpj,thenumberofOPENeventsisnotequaltotheone\nof CLOSE events then\n20 P.remove(pj);\n)LOH\u00031DPH\u001d\n2EWDLQHG\u00031DPLQJ\u00033DWWHUQ\u001d \r>5\u001b@B\r>5\u001b@\u0010\r>5\u0014\u0019@6ZLWFK\u00033RLQW\n\u0015\u0018\u0019GI\u001a\u0014\u0013B\u0019\u0019\u0013\u0015FI\u0013\u0013\u0010\u0017D\u0014\u001c\u001a\u0013\u0013\u001c\u001b\u0016\u0017\u001b GGFF\n/DQGPDUN\u00033RLQW 6KDUS\u00033RLQW\nFigure 9: An Example of the Randomized File Name\nfiles having similar naming patterns share similar file processes.\nMeanwhile, for some directories, the app gives different names\nbased on different devices and different users. Considering that the\noperation event logs come from different devices, it is urgent for\nus to learn about each file’s naming pattern, based on which we\ncanperformthefurtherclassificationtask.Withaninvestigation\non the collected file names, we find that the file names can be\nclassifiedintotwokinds:(1)namedwithmeaningfulwords,such\nas “login”, “wallet”, “purchase”, etc.; (2) named with strings that are\ndynamicallygeneratedbysomealgorithms( e.g.,MD5algorithm)\nbased on some clues, such as user IDs or device IDs. The first case\niseasyforusaswecanfullyutilizethefeaturesofthesamestrings\nand the same locations in file systems. However, the second one\nis much challenging for us. In this part, we mainly deal with the\nsecond case.Algorithm 3: Judging whether a file name string is ran-\ndomly constructed.\nInput:A file name string nameStr\nOutput:A boolean value indicating whether nameStr is\nrandomly constructed\n1Cnamecontains all the characters that can appear in a file\nname;\n2Cletter={ a∼z, A∼Z},Cnumber={ 0∼9};\n3countswitch=0 ;\n4countsharp=0 ;\n5iflength(nameStr) ≤2then\n6returntrue;\n7if∀ci∈nameStr,ci∈Cnumberthen\n8returntrue;\n9for∀ci∈nameStr do\n10ifci∈Cletterandci+1∈Cnumberthen\n11 countswitch++;\n12 ifci−1∈Cnumberthen\n13 countsharp++;\n14ifci∈Cnumberandci+1∈Cletterthen\n15 countswitch++;\n16 ifci−1∈Cletterthen\n17 countsharp++;\n18ifcount switch\nlenдth(nameStr )≥1\n6then\n19returntrue;\n20ifcountsharp≥3then\n21returntrue;\n22returnfalse;\nWefindthatthefilenameinthesecondcaseismadeupofnum-\nbersCnumber,lettersCletteraswellassomespecialmarks Cmark\n(e.g.,“*”,“_”,“-”, etc.),andnumbersandlettersappearrandomly.Itis\ndifficult for us to predict where a letter appears or where a numberappears.Weattempttousesomestatisticsmetricstojudgewhether\na file name is randomized. Before we introduce Algorithm 3, we\ndefine some items first, shown in Figure 9:\n•Switch Point. It iswhere the characterschange from theletter\nto the number (or in reverse), such as “f7” and “6d”. Note that\ntheletters andnumbersappearrandomly, whichcontributesto\na series of switch points.\n•Sharp Point. It is where the character belongs to Cletterwhile\nits neighbors belong to Cnumber(or in reverse), such as “4a1”,\n“A7D”. It is also much common in the randomized file names.\n•Landmark Point. It is where the character belongs to Cmark.\nThis kind of points can indicate the structure of filename since\nin most cases they are used to link different strings.\nFor a file name string, we divide it into short substrings accord-\ning tolandmark points first, and then judge each substring with\nAlgorithm 3. From Line 9 to Line 17 in Algorithm 3, we conduct\n \n897CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\nsomestatisticswiththeaboveitems.Withthesestatistics,wede-\ncide whether a substring is randomized from Line 18 to Line 23\nin Algorithm 3. Obviously, for a long string, even if it is not ran-domized, there still can be a number of switch points. Therefore,\nin Algorithm 3, we usecount switch\nlenдth(nameStr )as an indicator at Line 19,\ninsteadofdirectlyusing countswitch.However,therearealsosome\nspecialcasesweneedtotakeintoaccount:1)thelengthoffilename\nis too short to be meaningful; 2) the file name does not have anyletters (i.e., characters in it all belong to\nCnumber∪Cmark). We\nconsider the file names in these two cases as the randomized ones.\nAlgorithm 3 identifies these two cases first, from Line 5 to Line 8.\nIfasubstringisrandomlygenerated,weshortenitwiththemark\n“*[n]”where nindicatesthenumberofcharacters.Otherwise,we\nkeep the original content. The landmark points remain during this\nprocess.Inthisway,webuildupanamingpatternaboutaname,\njustasFigure9shows.Notethatafilepathcontainsthedirectories’namesandthefile’sname,wecanobtainthefileorganizingpattern\nby building up the naming pattern for each part of the file path.\nThroughtheabove process,thechallengeC2is conquered.We\nare able to learn about how app developers organize the files on\nexternal storage and we can further organize the obtained data.\n3.4 Data Collection & Ethics Concerns\nJust as Figure 5 shows, to study the race conditions on external\nstorage, the first step is to collect enough data. In this part, we just\npresent how we collect the data.\nParticipants. 10volunteersparticipateinourexperimentsucces-\nsively. They are recruited from our team members’ family and\nfriends who are interested in our study. Among these participants,\nthere are 5 undergraduates, 1 PhD student and 4 teachers. All of\nthem are much familiar with smartphones and rely heavily on\nsmartphones to conduct different daily activities, such as chatting\nwith friends, shopping online, playing games, reading news, and\nsoon. Theaveragenumber ofappsobserved ineachparticipant’s\nsmartphone is 162. For each participant, the average time spent on\nsmartphone each day is at least 4 hours. The participants use their\nown smartphones to run the clients and conduct the associatedexperiment. Except for keeping the clients running continually\nduring the experiment, we do not have any other requirements on\nhow the participants use their smartphones daily.\nDataset. Wecontinuallytrackthefileoperationsonthese10volun-\nteers’smartphonesover10days.Theinformationofthevolunteers’\nsmartphonesislistedinTable3.Wecanseethat6smartphonesare\nequippedwithAndroid 10whichalreadyhasthe scoped storage.\nOnce the volunteer installs and activates RECAST client, the client\nruns in the background to monitor the whole Android external\nstorage without further interrupting the volunteer’s normal smart-\nphoneuse.Wetotallycollect5,359,339fileoperationeventsover\n105,963 files. A brief profile of the obtained dataset is presented in\nTable 4. Obtained file operations are related to 247 apps, including\nnot only the popular apps from famous Internet companies (e.g.,\nTencent, NetEase, Baidu, Jingdong), but also some pre-installed\napps from different vendors (e.g., Google, Huawei, Xiaomi, OPPO).\nThefiletypesalsovary.Weleavethesecuritysensitivityanalysis\non these files to §4.2.Table 3: Information of the Involved Smartphones\n#Manufacturer Model Android Version\n1Huawei CDY-TN90 10\n2Huawei JSN-AL00 10\n3Huawei PCT-AL10 10\n4Huawei CLT-AL01 10\n5 Xiaomi Redmi Note 8 Pro 10\n6 Xiaomi Redmi Note 8 9\n7 Xiaomi MI PAD 4 8.1.0\n8OnePlus A5010 10\n9 VIVO V1932A 9\n10 OPPO PACM00 8.1.0\nTable 4: Details of the File Operation Event Dataset\nFile Location1Operated\nFilesFile\nOperation\nEvents“OPEN”\nEvents2“CLOSE_NO-\nWRITE”\nEvents3\nIn application-specific\ndirectories78,619\n(74.2%)3,662,968\n(68.3%)423,335\n(72.8%)401,023\n(75.9%)\nIn public directories27,344\n(25.8%)1,696,371\n(31.7%)157,832\n(27.2%)127,472\n(24.1%)\nIn total 105,963 5,359,339 581,167 528,495\n1Both of application-specific directories and public directories are on external storage.\n2“OPEN” events indicate that the files are to be read or written.\n3“CLOSE_NOWRITE” events indicate that the files are only read.\nEthicsConcerns. Inourexperiment,wedonotcollectanyperson-\nallyidentifiableinformation(PII).Wejustcollecttheinformation\nrelevant to the problem that we study, shown in Table 1. We userandom IDs to differentiate the devices. The random ID is gener-\nated by the time when RECAST client first runs on the volunteer’s\nsmartphone without obtaining any hardware information of thesmartphone. We provide a well-prepared user manual to the vol-\nunteerssothattheycanhaveacomprehensiveunderstandingof\nhowwecollectandusethedata.Wealsoprovideamechanismthat\nallowsthevolunteerstofreelystartandstoptheclientwhenever\nthey want. When we utilize the file names to classify the associ-ated file operation events, we do not attempt to collect and use\nany filecontent on the volunteers’smartphones. The datasetthat\nwe collect is only used to study the race condition attack in this\npaper. Considering that the dataset may contain the volunteers’\nsensitive information, we will not make this dataset public unless\nwithallthevolunteers’agreement.Inthispaper,wejustpresent\nsome statistics information, and we will not provide any furtherinformation about the victim apps as well as the files. When we\nattemptedtoverifyandexploitthepotentialraceconditions,the\nexperiments were all conducted on our test smartphones. Based on\nour manual verification result, we already informed the associated\napp developers about the discovered vulnerabilities caused by race\nconditions. Note that before we started our research, we have con-\nsulted our university about the issue of obtaining an IRB approval,\nand their response was that it was not necessary.\n4 FILE OPERATION BEHAVIOR ANALYSIS\nNow, we conduct some analyses on the obtained dataset to gain\ndeep insights. Considering that the dataset includes operations on\nfilesaswellasdirectories,andonlythemanipulatedfilesmaycausesomesecurityproblems,therefore,inthissection,wejustfocusour\nattention on the operation events occurring on files.\n \n898Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n40%\n28%11%10%7%2%3%MODIFY\nACCESS\nOPEN\nCLOSE_NOWRITE\nCLOSE_WRITE\nDELETE\nOther Event Types\nFigure 10: Proportions of Different File Operation Events\n4.1 Study on File Operation Events\nEventTypes. Thecollecteddatasetcontainsalargenumberoffile\noperation events, therefore we take a glance at these file operation\nevents first. Just as Figure 10 shows, when apps use the external\nstorage,avarietyoffileoperationeventsareintroduced.Among\nthese file operation events, the top 5 kinds of file operation events\nareMODIFY(40%), ACCESS(28%), OPEN(11%), CLOSE_NOWRITE (10%)\nandCLOSE_WRITE (7%).Thesekindsoffileoperationeventsaccount\nfor95%ofthewholecollectedevents.Obviously,boththenumbers\nofMODIFYandACCESSeventsaremuchhigherthantheothers.Itis\nbecause of the limited user-spacebuffer that makes an app repeat\nthesameactions(e.g., MODIFYorACCESS)todealwiththewholefile\ncontent.Meanwhile,anapp’schoiceonwhethertowritedatato\ntheharddiskimmediatelyalsoaffectsthenumberof MODIFYevents.\nItisagreatsurprisethatthenumberof OPENeventsismuchless\nthanthetotalnumberof CLOSE_NOWRITE andCLOSE_WRITE events.\nIntuitively, the number of OPENevents should be equal to the total\nnumber of CLOSE_NOWRITE andCLOSE_WRITE events. Just as what\nwe have mentioned in §3.2, when the RECAST client runs in the\nbackground,thesmartphonemaystopittosaveenergy.Inthiscase,\nthe client will miss some file operation events before it is restarted\nmanually. We reduce the impact of this case in Algorithm 2.\nOccurringPositions. ItisworthnotingthatnowadaysAndroidin-\ntroducestwokindsofdirectoriesonexternalstorage:public(shared)\ndirectories(e.g., “/Picture/”)andapplication-specificdirectories(e.g.,\n“/Android/data/<package_name>/”).Thelatteroneishighlyrecom-\nmended by Google since Google has made a special access control\non it and the installed apps can visit their own directories without\nany permission requested. However, in current major Android ver-\nsions,oncethepermissionsaregranted,appscanvisitbothofthem,\nwhich indicates that the race conditions on external storage can\nstillexist.Inourmeasurement,wefindthat74.2%(78,619)accessed\nfilesareintheapplication-specificdirectoriesandtherearestilla\nconsiderablenumberoffiles(25.8%,27,344)inthepublicdirectories,justasTable4shows.Fromthenumberoffileoperationevents,wefindthatoperationsonthefilesinpublicdirectoriesareasfrequent\nas the ones on the files in application-specific directories. Just as\nwhat we have mentioned above, when a file is processed, it will\nintroduce a number of MODIFYorACCESSevents. To learn about\nhow frequently a file is used, we make statistics on OPENevents in\nTable4.Aswearemoreinterestedinhowoftenafileisread,wealso\nconductstatisticson CLOSE_NOWRITE eventswhichcantellusthe\nleastnumberoffilereadingactions.Frombothofthesestatistics,0 5 10 15 20\nNumber of \"CLOSE_NOWRITE\" Events050001000015000Number of FilesIn application-specific directories\nIn public directories\nFigure 11: The Number of Files over Different Numbers of\n“CLOSE_NOWRITE” Events (The last column includes the\nfiles with no less than 20 “CLOSE_NOWRITE” events)\nwe can see that the files in public directories are used as frequently\nas the ones in application-specific directories which indicates that\nthepublicdirectoriesarestillamostcommonchoiceoftheapps.\nNote that an app with the permissions granted can still manipulate\nanyfilesonexternalstorage,inthefollowingparts,unlesswiththe\ndetailed specification, we do not make a clear distinction between\nthepublicdirectoriesandtheapplication-specificdirectories,and\ncall both of them “external storage”.\nUptonow,wehavealreadyconductedapreliminarystudyon\nthe collected file operation events. However, before we go on with\nthe further analyses on these file operation events, we still need to\nfully consider the operated files.\n4.2 Study on Operated Files\nIn this part, we attempt to learn some useful information from the\nobtainedfilepaths.Wefindthatalthoughthedatasetismadeup\nofdatafromdifferentsmartphones,thereareasmallpartoffiles\n(8,411, 7.94%) that have the same paths over different smartphones.\nThemajorityofthefiles(97,552,92.06%)arewithdifferentpaths,\nwhichindicatesthatwhenappdevelopersnameandorganizethe\nfiles,theyhavetheirownstandards.Asweareinterestedintheraceconditionsonexternalstorage,weconducttheanalysisondifferent\nfiles’ CLOSE_NOWRITE events, which can tell us the file content is\njustaccessedwithoutanymodifications.JustasFigure11shows,\nfor most of the files, the number of operations on each file is much\nlimited. To deal with this problem, we have to fully utilize each\nobtained file path.\nFile Naming Rules. Just as what we have presented above, there\nare so many files operated by apps that it is impossible for app\ndevelopers to manually name each of these files. Considering that\napp developers follow their own naming rules to name files and\ndirectories, we conduct an analysis on the names of both files and\ndirectoriesinthispart.TheresultispresentedinTable5.Wefind\nthat most of these names (96.28%) are made of letters (i.e., a-z and\nA-Z), numbers (i.e., 0-9 ) as well as other specific symbols, and only\na small number of names are just made up of single one kind of\ncharacters, e.g.,Case 1 (0.89%), Case 2 (2.81%) and Case 4 (0.02%).\nAmong these cases, Case 4 surprises us very much. However, ac-\ncordingtoourinvestigation,namesinCase4actuallyconsistofthe\ncharacters in other languages (such as Chinese), instead of English.\nObviously,itismuchchallengingforustogetthedetailsofeach\n \n899CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\nTable 5: Different Kinds of File Names\nCase\nIndexComposition of File Name1\nNumber (%) Has Specific\nSymbolsHas\nNumbersHas\nLetters\n1 F F T 819 (0.89%)\n2 F T F 2,587 (2.81%)\n3 F T T18,643 (20.24%)\n4 T F F 16 (0.02%)\n5 T F T 2,403 (2.61%)\n6 T T F 1,420 (1.54%)\n7 T T T66,216 (71.89%)\n1“T” represents true, and “F” represents false.\napp’s naming rules. Anyhow, we can still use some observations to\nobtain naming patterns so as to go on with our clustering work.\nFile Organizing Patterns. Note that the dynamic randomized\nnaming rules raise a great challenge to understand the relations\noftheobtainedfiles.Therefore,tounderstandhowthesefilesare\norganized,wehave todealwiththe dynamicrandomizednaming\nrulesfirst. Consideringthat afile’s absolutepath containsthedi-\nrectories’namesandthefile’sname,weconstructtheassociated\norganizingpatternbybuildingupthenamingpatternforeachpart\nofthisfilepath.Anapphasauniformstandardtoorganizethefiles\nover different smartphones, therefore, when different files share\nthesameorganizingpattern,theymainlybelongtoonecategory.\nOverthe97,552files,eachofwhichhasauniquefilepath,weob-\ntain 10,395 organizing patterns. From Figure 12, we can see that\neachorganizingpatterninthetop200coversatleast64files,and\nintotal72,200(74.01%)filesarecoveredbythesetop200organiz-\ning patterns, fully illustrating the effectiveness of these obtained\norganizingpatterns.Accordingtotheseorganizingpatterns,wecat-\negorize the files. However, due to some abnormal naming patterns,\nthere are still 7,974 (8.17%) organizing patterns, each of which can\nonly cover one file. Files in this case require more effort to analyze\nthe associated operations.\nFile Security Sensitivity Analysis. Through the obtained file\npath,wecanalsogetthefileextensionwhichcanbefurtherutilized\ntoinfertheassociatedfiletype.Wefindthatamongthesefiles,mostaremultimediafiles(e.g.,\njpg,mp4,mp3,gif,silk,amr,etc.).These\nfiles are frequently used by the apps to enrich the user’s visual and\nauditory feelings. They could be manipulated by the malicious app\nso as to lure the user into some traps, such as the fake QR code\npicture,fakeadpicture,fakecommunicationcontent, etc.Thereare\nalsosomecompressedfiles,suchas zip,gz,7z,zip,etc.Thesefiles\ncontain avariety offiles inside.Hence, besidesmanipulating the\nfiles contained inside, the malicious app can also insert some extra\nfilesintothesecompressedfiles.Moreover,someexecutablefiles\n(e.g., js,html,apk, and jar) are also included. These files can be\ndirectly used to inject and run the malicious code so as to access\nuser’s sensitive data. Meanwhile, there are also some kinds of files\nused for organizing and storing data (e.g., json,html,db,xml, and\nsqlite). These files can contain the associated apps’ configuration\ndata so that it is also possible for the malicious app to affect the\ntargetapp’sactionsthroughthesefiles.Insummary,considering\nthe security sensitivity of the involved files, the race condition\nattack may cause a series of security problems.\nInthefollowingpart,weconductaninvestigationonfileoperat-\ning patterns to study the race condition attack.0 50 100 150 200\nIndex of File Or ganizin g Patterns05001000150020002500300035004000Number of Files(150, 98)(100, 178)(50, 324)\n(200, 64)(1, 3774)\nFigure 12: Statistics of the Top 200 File Organizing Patterns\n0 5 10 15 20\nNumber of File O peration Patterns Over Different Files020406080100Percentage of Files (%)(1, 78.29%)(2, 94.24%)(5, 99.45%) (20, 99.99%)\nFigure 13: File Operating Patterns Over Different Files\n4.3 Investigation on File Operating Patterns\nJust as what we have mentioned in §4.1, through separated file\noperationevents,wecanlearnaboutsomeinformation.Inthispart,\nwe present further insights about the potential race conditions\nthroughthefileoperatingpatterns.FromFigure13,wecanseethat\nin most cases, a file is just processed with an operating pattern,\nwhichindicatesthatthisfilecouldbeonlyusedbyasinglefunction.\nSometimes, different functions (or apps) may operate the same file.\nAsaresult,therearealsoanumberoffilesthatarewithmultiple\n(2∼103) operating patterns.\nAmongthe obtainedfileoperating patterns,weare moreinter-\nestedintheonesthatmayintroducesomeraceconditionattacks.\nTherefore,inthispart,weconcentrateontheoperatingpatterns\nincluding ACCESSeventswhichindicatefilereadingoperations,just\nas Table 6 shows. From Table 6, we can see that it is most common\nthat filesare openedand thenread directly, i.e.,Case 1.Obviously,\nthereisjustone OPENeventinCase1.However,consideringthat\nwhenweextractfileoperatingpatterns,thefileoperationevents\naresplitbythetimethreshold η,henceatimewindowstillexists\nbefore OPENeventinCase 1.Justas priorwork[ 2]states thatthere\nis a high probability that the file integrity verification process is\nmissing, the race condition attacks can be launched successfully\nwith a high probability. So are the other cases that have just an\nOPENevent. Except for the cases with the single OPENevent, in the\nrest cases, the files are read more than twice. In these cases, the\ntimeintervals(orwindows)between OPENeventsmarkedinTable6\nhighlyindicatethepotentialracecondition.Withafurtherstudy\non the time windows in these cases, we find that a considerable\nnumberoftimewindowsarelongenoughtomanipulatethefiles,\nshowninFigure14,amongthesecases.21.41%timewindowsare\n \n900Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\nTable 6: Top 30 Filtered File Operating Patterns\n#File Operating Pattern Number (%)\n1OPEN→ACCESS→CLOSE_NOWRITE 97,188 (34.11%)\n2OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE 18,392 (6.45%)\n3[OPEN→ACCESS→CLOSE_NOWRITE]*114,486 (5.08%)\n4CREATE→ATTRIB→OPEN→CLOSE_WRITE →MODIFY→OPEN→MODIFY→OPEN→ACCESS→DELETE→CLOSE_WRITE →CLOSE_NOWRITE 2,765 (0.97%)\n5OPEN→ACCESS→CLOSE_NOWRITE →DELETE 1,862 (0.65%)\n6OPEN→ACCESS→CLOSE_NOWRITE →ATTRIB 1,244 (0.44%)\n7OPEN→ACCESS→CLOSE_NOWRITE →MODIFY→OPEN→MODIFY→CLOSE_WRITE 1,075 (0.38%)\n8CREATE→ATTRIB→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE 853 (0.3%)\n9MOVED_TO →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE 627 (0.22%)\n10[CREATE →ATTRIB→OPEN→CLOSE_WRITE →MODIFY→OPEN→MODIFY→OPEN→ACCESS→DELETE→CLOSE_WRITE →CLOSE_NOWRITE]* 585 (0.21%)\n11MOVED_TO →OPEN→ACCESS→CLOSE_NOWRITE 567 (0.2%)\n12OPEN→ACCESS→CLOSE_NOWRITE →DELETE→CREATE→ATTRIB→OPEN→MODIFY→CLOSE_WRITE 546 (0.19%)\n13OPEN→ACCESS→CLOSE_NOWRITE →MOVED_FROM →CREATE→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE 531 (0.19%)\n14CREATE→ATTRIB→OPEN→CLOSE_WRITE →MODIFY→OPEN→MODIFY→OPEN→ACCESS→DELETE→CLOSE_WRITE →CLOSE_NOWRITE →\nCREATE→ATTRIB→OPEN→CLOSE_WRITE →MODIFY→OPEN→MODIFY→OPEN→ACCESS→DELETE→CLOSE_WRITE →CLOSE_NOWRITE489 (0.17%)\n15OPEN→ACCESS→MODIFY→CLOSE_WRITE 467 (0.16%)\n16ATTRIB→OPEN→ACCESS→CLOSE_NOWRITE 460 (0.16%)\n17CREATE→ATTRIB→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE →DELETE 425 (0.15%)\n18OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→OPEN→ACCESS→CLOSE_NOWRITE →CLOSE_NOWRITE 381 (0.13%)\n19OPEN→ACCESS→CLOSE_WRITE 311 (0.11%)\n20CREATE→ATTRIB→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE 308 (0.11%)\n21CREATE→ATTRIB→OPEN→CLOSE_WRITE →OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→\nCLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN\n→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →OPEN→ACCESS→CLOSE_NOWRITE →\nDELETE293 (0.1%)\n22OPEN→OPEN→ACCESS→CLOSE_NOWRITE →ACCESS→CLOSE_NOWRITE 287 (0.1%)\n23CREATE→ATTRIB→OPEN→MODIFY→CLOSE_WRITE →ATTRIB→OPEN→ACCESS→CLOSE_NOWRITE 261 (0.09%)\n24OPEN→ACCESS→MODIFY→OPEN→CLOSE_NOWRITE →MODIFY→CLOSE_WRITE 248 (0.09%)\n25OPEN→ACCESS→CLOSE_NOWRITE →DELETE→CREATE→OPEN→MODIFY→CLOSE_WRITE 223 (0.08%)\n26OPEN→OPEN→ACCESS→CLOSE_NOWRITE →ACCESS→CLOSE_NOWRITE →[OPEN→ACCESS→CLOSE_NOWRITE]* 210 (0.07%)\n27OPEN→ACCESS→OPEN→ACCESS→CLOSE_NOWRITE →ACCESS→CLOSE_NOWRITE 202 (0.07%)\n28OPEN→ACCESS→CLOSE_NOWRITE →MODIFY→OPEN→MODIFY→CLOSE_WRITE →MODIFY→OPEN→MODIFY→CLOSE_WRITE 182 (0.06%)\n29OPEN→ACCESS→CLOSE_NOWRITE →MOVED_FROM →CREATE→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE →\nOPEN→ACCESS→CLOSE_NOWRITE →MOVED_FROM →CREATE→OPEN→MODIFY→CLOSE_WRITE →OPEN→ACCESS→CLOSE_NOWRITE178 (0.06%)\n30MOVED_TO →OPEN→ACCESS→CLOSE_NOWRITE →DELETE 174 (0.06%)\n1“[XXX→XXX]*” indicates that the included operating pattern XXX →XXX repeats more than twice.\n0 500 1000 1500 2000\nTime Window (ms)020406080100Percentage (%)(500, 78.59%)\nFigure 14: Statistics of Time Windows\nlongerthan500ms,andtheaveragesizeofthewholetimewindows\nis 1,593 ms.\nMultiple Threads’ Impact. In most cases, when an app operates\nafile, tokeep thefilecontent’s integrity,the currentactionneeds\nto be finished at first, and then the following actions can go on.\nHowever, it still cannot be avoided that the file content is accessed\nbymultiplepartiessimultaneously,suchasCase22,24,26and27in\nTable6.Whenmultiplepartiesoperateafilesimultaneously,dueto\nthelackofsynchronization,itwillresultinaseriesoffileoperating\npatterns,insteadofthestableoperationpatterns.Sinceitisdifficult\nto identify each operation event’s owner, it is much challenging to\ncheck the potential race conditions.\nIn the next section, we will present a uniform workflow to iden-\ntifythe criticaltimepoint tolaunchthe raceconditionattack (i.e.,\ndealing with the challenge C4 in §1) and present the manual verifi-\ncation result based on this workflow.5 VERIFICATION & EXPLOITATION\nJustaswhatwehavementionedatthechallengeC4in §1,different\nfilesareprocessedunderdifferentworkflowsandtheircontentsaremuchdifferent.However,throughtheprocessesdescribedin\n§3,we\ncanclassifytheoperatedfilesandtheassociatedworkflowsintofile\norganizingpatternsandfileoperatingpatterns,separately.Inthis\npart, we fully utilize these two kinds of patterns to prepare the file\ncontentandverifythepotentialraceconditionattacks.Fromthe\nobtainedfileoperatingpatterns,wecanseethatthetimewindow\nismuchcommonbeforethe OPENevents.Anyhow,aswehavelittle\nknowledge about how an app processes a file, what we can do is to\ncheck each time window so as to decide whether it will result in\npotential race conditions.\nVerificationWorkflow. Whenwemanuallychooseafileorganiz-\ningpatternandoneofitsassociatedfileoperatingpatterns,wealso\nhavetoinvestigatehowtotriggerthetargetworkflow.Andthen,\nthe verification framework works as follows:\n(1)Prepare the fake file. Each function can have different require-\nments on the operated file, which is hard for us to know in\nadvance.Todealwiththisproblem,wefullytakeadvantage\noftheexistingfilesthatsharethesamefileorganizingpattern.\nOnceafileorganizingpatternischosen,thewholeAndroid\nexternalstorage issearchedto findout thefileswith thesamefile organizing pattern. And then, we choose one of these files\nas the fake file to conduct the following steps.\n(2)Replace the original file. Once the fake file is ready, we start to\nmonitor the files on Android external storage that have the\n \n901CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\nsamefile organizingpattern.Basedon theobtainedfileoper-\nationeventsandtheselectedfileoperatingpattern,thetime\nwindows are automatically tested, one by one, by replacing\nthe original file. We adopt the file operations MOVE_TO and\nMOVE_FROM to reduce the time cost on replacing the file.\n(3)Check theassociated app’s followingworkflow. When theorig-\ninal file is replaced, we check whether the associated app is\nimpacted by the manipulated file. Once the app accepts the\nmanipulatedfilecontent,itsfunctionwillbeinfluenced.There-\nfore,wecanfollowthisideatodecidewhetherthemanipulated\nfilecanaffecttheapp’snormalfunction.Ifthisattemptfails,\nwewillcheckthenexttimewindowintheselectedfileoper-\natingpattern.Whentheattemptsonallthetimewindowsfail,\nwe think that the race condition attack does not exist.\nThefirsttwosteps, preparingthefakefile andreplacingtheorigi-\nnal file, can be implemented automatically to fully satisfy the time\nrequirementoflaunching raceconditionattacks.However,before\nand during the verification, a considerable part of manual effort is\nstillrequiredtoidentifyhowtotriggerthetargetworkflowofan\napp,andcheckwhethertheapp’sfollowingworkflowisinfluenced.\nThis means that the final verification result is checked manually so\nas to keep its correctness.\nManual Verification Result. With the above verification work-\nflow,weconductsomeexperimentsonthefilesonexternalstorage.\nNotethatdifferentfileshavedifferenteffectsontheassociatedapps,\nand some of these effects are observable while others are not. Itis a much tremendous work to get the whole details about howapps process and use each kind of files. Therefore, according to\nRECAST’sanalysisresult,werandomlychoose122kindsoffiles\n(withdifferentfileorganizingpatterns),whoseeffectsareobserv-\nable, to validate the potential race condition attacks. In this part,\nwedonotusethefileextensiontoclassifythefiles,mainlybecause\nthatsomefilesdonothaveanyfileextensionsorarenamedwith\nthe self-defined file extensions by the developers. These selected\nfilesareusedbydifferentfunctionsfromdifferentapps( i.e.,with\ndifferentfileoperatingpatterns).Accordingtotheverificationre-\nsult,wefindthat115kindsoffiles(94.26%)arevulnerabletorace\ncondition attacks. An app can open a file multiple times and for\ndifferent purposeseach time( e.g.,checking thefile format,check-\ning the file integrity, using the file content). As a result, the race\nconditions existamong these OPENevents. Whatis more, therace\ncondition is much common when the files are shared among differ-\nent apps. Besides, there are also some important findings during\nour verification.\nImpact of Continuous OPEN Events. When we observe the file\noperatingpatternslistedinTable6,inmostcases( e.g.,Case2,3and\n4), some types of file operation events always appear between two\nOPENevents.Thisleavesusenoughtimetomanipulatethetarget\nfiles. However, the continuous OPENevents (e.g., in Case 22 and 26)\ngreatly compress the time window, resulting in the failures during\nour verification.\nImpact of Multiple Files’ Combination. When we verify the po-\ntential race condition attacks, we mainly focus on the single file.\nHowever, an app may use multiple files to realize its function. For\nexample,whenavideoplayerappplaysvideo,itusesmultiplefiles\ntostoretheaudio,videoaswellasconfigurationdata,separately.Thesefilesarekeptinadirectory.Whenwejustmanipulateone\nof these files, it is hard to launch the attack. To make the attack\nsuccessful,wehavetoreplaceallthefilesinthisdirectory.Mean-\nwhile, an app can split a large file (e.g., a video file) into a series of\nsmallfiles.Inthissituation,wealsohavetomanipulateallthefiles,\ninstead of a single file.\nFileDirectorySharedwithDifferentApps. Wefindthatsomeapps\n(e.g.,browser apps including Edge, Firefox, Opera) use the same\ndirectory (“/storage/emulated/0/Download/”) to store the down-loaded files. When users download the target apk files through\nthesebrowserapps,thedownloadedapkfilesaresavedinthisdi-\nrectory and processed under the similar workflows. Besides theabove case, some apps may be integrated with the same third-\npartylibraryandthislibraryusesaspecificdirectory(e.g., “/stor-\nage/emulated/0/ByteDownload/” found in our experiment) to save\nthe downloaded apk files. In both of these two cases, the race con-\ndition attacks can influence a considerable number of apps.\nCase Study. According to our manual verification result, in this\npart, we talk about some cases, which are much common when we\nuse smartphones but vulnerable to the race condition attacks.\n#1:Email Attachment Download. E-mail apps greatly facilitate the\nusers to send and receive e-mails. When a user reads a new\nincoming e-mail, besides the text in the message body, the\nattachment is also a critical component. When the user clicks\nthe associated attachment to download and read it, the file\ncontent can be manipulated before it is fully shown to the\nuser. Since it is difficult for the user to check the attachment’s\nintegrity,themaliciousappcantakeadvantageofthedifferent\nkindsofattachmentstotrap theuserintoaseriesofsecurity\nproblems such as the phishing attack.\n#2:Multimedia File Sharing Through Social Apps. Nowadays, most\nsocialappssupportmultimediafilesharing.Thesemultimediafilesincludeimagefiles(\njpg,png),audiofiles( amr),videofiles\n(mp4),etc.When users receive these files through social apps,\nitisdifficultforthemtoverifytheintegrityofthesefiles.Asa\nresult,whenthesefilesareopenedbytheappsorusers,the\nfile content may be manipulated in advance.\n#3:App Promotion Through Embedded Ads. To attract more users,\napp developers promote their apps through various distrib-utors(e.g., third-partyappstores,mobileads, etc.).Through\nmobileads,theappdistributorsoftensavethedownloadedapk\nfilesonexternalstorage.Someoftheappdistributorsverify\ntheintegrityofthedownloadedapkfilebeforeitisinstalled.\nHowever,sincetheappdownloadingserviceandappinstalling\nserviceareprovidedbydifferentpartiesseparately,thetime\nwindow is much common between these two services. Taking\nadvantageofthetimewindow,themaliciousappcanmisguide\nthe user to install other malware, just as prior work [2] did.\nNow,wecananswerthequestionspresentedin §1:1)therace\ncondition is much common when apps operate the files on external\nstorage;2)theraceconditioncanbeeasilyexploitedbytheattacker\ntolaunchattacks ;3)fordifferentkindsoffiles,eventhefilecontent\nand file operating patterns are much different, a uniform workflow to\nexploit the vulnerability of race conditions still exists.\n \n902Watch Out for Race Condition Attacks When Using Android External Storage CCS ’22, November 7–11, 2022, Los Angeles, CA, USA\n6 RELATED WORK\nUp to now, we have conducted a comprehensive survey about\ncurrent status of race condition attack on external storage. In this\nsection, we talk about some related work.\n6.1 Race Condition\nRacecondition[ 13]isamuchcommonprobleminparallelprograms\nexecution.Besidesrunningexceptionsanderrors,itcanalsolead\ntosomeseveresecurityproblems.Sinceitwidelyexistsindifferent\naspects of current computer systems, it attracts many researchers’\nattention.Currently,raceconditiononmemoryisahotspotincyber\nsecurityfield.Topinpointmemory-basedvulnerabilities,Chen et\nal.[1]proposedanapproachnamedRavel.Meanwhile,work[ 16,21,\n26] studied thedouble-fetch bugs in kernels from differentpoints.\nTofindtheracebugsinkernel,Jeong etal.[6]proposedatoolRazzer.\nXuet al.[25] proposed Krace to deal with race condition in kernel\nfilesystems.Forthefilesystems,especiallyUNIX-stylefilesystems,\nthe TOCTTOU vulnerabilities were also fully studied in work [ 24].\nWhat is more, web applications also suffer from race condition\nandaseriesof techniques areproposedtodealwiththisproblem,\nsuch as ARROW [ 22], RClassify [ 29] and Raccoon [ 8]. Besides\nthe above work, race condition on device drivers was studied by\nVojdaniet al.[20], and Wang et al.[23] studied the race conditions\nin interrupt-driven embedded software. Race condition also exists\nin the network protocol such as Ethernet POWERLINK. Yung et\nal.[28]justconductedastudyonthisproblem.Lu etal.[12]studied\nthe race condition in SDN.\nPrior work [ 19] has studied the race conditions in Linux, which\nmainly focuses on the system level. However, much different from\nLinux,Android’sopennessattractsahugenumberofthird-party\ndevelopers. The third-party developers’ understanding of the race\nconditionbecomesveryimportant.Meanwhile,fromthepointof\nappdesign,theraceconditioncausedbyexternalstoragehasnot\nbeenfullystudiedbefore.Hence, inthispaper,weconductadeep\nsurveyaboutthisproblemintermsofapps.Weattempttowakeup\nthethird-partyappdeveloperstowatchoutforthepotentialrace\ncondition attacks when using Android external storage.\n6.2 Security of Android External Storage\nJust as what we have presented in the above part, race condi-\ntion widely exists in current computer systems, and we just study\nthe race condition attack on Android external storage. In fact,\nnowadays,whenanappusesAndroidexternalstorage,itwillbe\nfacedwithaseriesofsecurityproblems[ 2,4,11,27].Meanwhile,\nusers’sensitiveinformationcanbeleakedthroughthemalicious\nadvertisements [ 17] or the residue of deleted apps [ 30]. What is\nworse,throughexternalstorage,attackerscaninjectsomemalicious\ncode [7]. Meanwhile, the vulnerabilities caused by code dynami-\ncally loading [ 14] also make it possible to inject the malicious code.\nExternal storage also can serve as one of the convert channels [ 15].\nThe scoped storage [ 10], as a new defense, would restrict these\nsecurity problems on external storage.\n6.3 Work on Class FileObserver\nNotethat wetakeadvantageof theclass FileObserver tostudythe\nrace condition attack on external storage. In fact, this class has\nalready been studied or utilized in prior work [ 2,3,5,9,18]. WhenFriedmanandSainz[ 3]studiedthefileusagepatternsinAndroid,\nthey employed this class to access file operation events. Our work\nseems similar to this work, but we study a much different problem.\nInotherwords,thoughbothofthemusethesameclasstocollectthe\ndata,differentprocessesareconductedontheobtaineddatasets.We\ntrytobuildmoredetaileddescriptionsaboutdifferentfiles’usage\npatterns so that we can obtain deep insights into race condition\non external storage. When Huang et al.[5] studied the unexpected\nhazards in current Android antivirus software, they found that\nsome antivirus software’s monitoring functions were just based on\ntheclassFileObserver.Meanwhile,whenTang etal.[18]designed\nUpDroid to monitor apps’ sensitive actions, they utilized the class\nFileObserver tomonitorthechangesoffilesystem.However,neither\nwork [5,18] paid attention to the race condition. When Lee et\nal.[9]studiedthesecurityproblemsduringappinstallation,they\nemployed this class to catch the time window. They just showed\nthat the race condition could be used to hijack app installation, but\nthe universality of race condition did not catch their attention. Du\netal.[2]studied theusage ofexternal storagethrough staticcode\nanalysis, and they also took advantage of the class FileObserver to\nimplementsomepotentialattacks.Anyhow,theyreliedonthestatic\ncodeanalysistounderstandtheapps’behaviorsonexternalstorage,ratherthanawidestudyonthefileoperationeventscollectedfrom\nthe real world, which is much different from our work.\n7 CONCLUSION\nIn this paper, we attempt to draw a clear picture about current\nstatusoftheraceconditionattackonexternalstorage.Wedesign\nand implement an analysis engine RECAST and collect a large\nnumberoffileoperationeventstogainsomedeepinsights.With\nthese file operation events, we investigate the file operating ac-\ntions of different apps (the pre-installed apps and the popular apps\ninstalled by users), and discover these apps’ critical components\nfrequently used by users. Based on the analysis result, we find that\nrace condition is much common when an app uses the external\nstorageanditcanbeeasilyexploitedtolaunchaseriesofattacks.\nTo deal with this problem, app developers should be cautious of\nthe security problems on external storage even within the latest\nAndroidversion,andremovethepotentialraceconditionswhen\nthey use the files. In the future, we will conduct further studies on\nthe security problems related to external storage.\nACKNOWLEDGMENTS\nWe would like to thank the anonymous reviewers for their in-\nsightful comments and the volunteers for their active participation.\nThis work was partially supported by the National Natural Sci-\nence Foundation of China (No. 62002386, U1804263, 62172435), the\nState Key Laboratory of Information Security (No. 2021-ZD-05),theZhongyuanScienceandTechnologyInnovationLeadingTal-\nentProject(No.214200510019),andtheHenanKeyLaboratoryof\nCyberspace Situation Awareness.\nREFERENCES\n[1]Yue Chen, Mustakimur Khandaker, and Zhi Wang. 2017. Pinpointing Vulner-\nabilities. In Proceedings of the 12th ACM on Asia Conference on Computer and\nCommunications Security (AsiaCCS ’17) . ACM, 334–345. https://doi.org/10.1145/\n3052973.3053033\n \n903CCS ’22, November 7–11, 2022, Los Angeles, CA, USA Shaoyong Du, Xin Liu, Guoqing Lai, & Xiangyang Luo\n[2]ShaoyongDu,PengxiongZhu,JingyuHua,ZhiyunQian,ZhaoZhang,Xiaoyu\nChen, and Sheng Zhong. 2021. An Empirical Analysis of Hazardous Uses of\nAndroid Shared Storage. IEEE Transactions on Dependable and Secure Computing\n18, 1 (2021), 340–355. https://doi.org/10.1109/TDSC.2018.2889486\n[3]Roy Friedman and David Sainz. 2016. File System Usage in Android Mobile\nPhones. In Proceedings of the 9th ACM International on Systems and Storage\nConference (SYSTOR ’16) . ACM, 16:1–16:11. https://doi.org/10.1145/2928275.2928\n280\n[4]Stylianos Gisdakis, Thanassis Giannetsos, and Panos Papadimitratos. 2016. An-\ndroid Privacy C(R)ache: Reading your External Storageand Sensors for Fun and\nProfit.InProceedingsofthe1stACMWorkshoponPrivacy-AwareMobileComputing\n(PAMCO ’16). ACM, 1–10. https://doi.org/10.1145/2940343.2940346\n[5]Heqing Huang, Kai Chen, Chuangang Ren, Peng Liu, Sencun Zhu, and Ding-hao Wu. 2015. Towards Discovering and Understanding Unexpected Hazardsin Tailoring Antivirus Software for Android. In Proceedings of the 10th ACM\nSymposium on Information, Computer and Communications Security (AsiaCCS\n’15). ACM, 7–18. https://doi.org/10.1145/2714576.2714589\n[6]DaeR.Jeong,KyungtaeKim,BasaveshShivakumar,ByoungyoungLee,andInsik\nShin. 2019. Razzer: Finding Kernel Race Bugs through Fuzzing. In Proceedings\nof the 40th IEEE Symposium on Security and Privacy (S&P ’19). IEEE, 754–768.\nhttps://doi.org/10.1109/SP.2019.00017\n[7]XingJin,XuchaoHu,KailiangYing,WenliangDu,HengYin,andGautamNagesh\nPeri. 2014. Code Injection Attacks on HTML5-based Mobile Apps: Charac-terization, Detection and Mitigation. In Proceedings of the 21st ACM SIGSAC\nConference on Computer and Communications Security (CCS ’14). ACM, 66–77.\nhttps://doi.org/10.1145/2660267.2660275\n[8]Simon Koch, Tim Sauer, Martin Johns, and Giancarlo Pellegrino. 2020. Raccoon:\nautomatedverificationofguardedraceconditionsinwebapplications.In Pro-\nceedings of the 35th ACM/SIGAPP Symposium on Applied Computing (SAC ’20).\nACM, 1678–1687. https://doi.org/10.1145/3341105.3373855\n[9]Yeonjoon Lee, Tongxin Li, Nan Zhang, Soteris Demetriou, Mingming Zha, Xi-\naoFeng Wang, Kai Chen, Xiao-yong Zhou, Xinhui Han, and Michael Grace. 2017.\nGhost Installer in the Shadow: Security Analysis of App Installation on An-\ndroid. In Proceedings of the 47th Annual IEEE/IFIP International Conference on\nDependableSystemsandNetworks (DSN’17) .IEEEComputerSociety,403–414.\nhttps://doi.org/10.1109/DSN.2017.33\n[10]YuTsungLee,HainingChen,andTrentJaeger.2021. DemystifyingAndroid’s\nScoped Storage Defense. IEEE Security & Privacy 19, 5 (2021), 16–25. https:\n//doi.org/10.1109/MSEC.2021.3090564\n[11]Xiangyu Liu, Zhe Zhou, Wenrui Diao, Zhou Li, and Kehuan Zhang. 2015. An\nEmpiricalStudyonAndroidforSavingNon-sharedDataonPublicStorage.In\nProceedingsofthe30thIFIPTC11InternationalConferenceonICTSystemsSecurityandPrivacyProtection,SEC’15 (IFIPAdvancesinInformationandCommunication\nTechnology,Vol.455) .Springer,542–556. https://doi.org/10.1007/978-3-319-18467-\n8_36\n[12]GongzhengLu,LeiXu,YibiaoYang,andBaowenXu.2019. Predictiveanalysisforracedetectioninsoftware-definednetworks. ScienceChina-InformationSciences\n62, 6 (2019), 62101:1–62101:20. https://doi.org/10.1007/s11432-018-9826-x\n[13]RobertH.B.NetzerandBartonP.Miller.1992. WhatAreRaceConditions?Some\nIssues and Formalizations. ACM Letters on Programming Languages and Systems\n1, 1 (1992), 74–88. https://doi.org/10.1145/130616.130623\n[14]SebastianPoeplau,YanickFratantonio,AntonioBianchi,ChristopherKruegel,\nandGiovanniVigna.2014. ExecuteThis!AnalyzingUnsafeandMaliciousDy-\nnamic Code Loadingin Android Applications. In Proceedings of the21st Annual\nNetwork and Distributed System Security Symposium (NDSS ’14) . The Internet\nSociety, 1–16. https://www.ndss-symposium.org/ndss2014/execute-analyzing-\nunsafe-and-malicious-dynamic-code-loading-android-applications\n[15]JoelReardon,ÁlvaroFeal,PrimalWijesekera,AmitElazariBarOn,NarseoVallina-Rodriguez,andSergeEgelman.2019. 50WaystoLeakYourData:AnExplorationofApps’CircumventionoftheAndroidPermissionsSystem.In Proceedingsofthe\n28thUSENIXSecuritySymposium(USENIXSecurity’19) .USENIXAssociation,603–\n620. https://www.usenix.org/conference/usenixsecurity19/presentation/reardon\n[16]MichaelSchwarz,DanielGruss,MoritzLipp,ClémentineMaurice,ThomasSchus-\nter, Anders Fogh, and Stefan Mangard. 2018. Automated Detection, Exploitation,andEliminationofDouble-FetchBugsusingModernCPUFeatures.In Proceedings\nof the 13th Asia Conference on Computer and Communications Security (AsiaCCS\n’18). ACM, 587–600. https://doi.org/10.1145/3196494.3196508\n[17]Sooel Son, Daehyeok Kim, and Vitaly Shmatikov. 2016. What Mobile AdsKnow About Mobile Users. In Proceedings of the 23rd Annual Network and\nDistributed System Security Symposium (NDSS ’16). The Internet Society, 1–\n15. http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09\n/what-mobile-ads-know-about-mobile-users.pdf\n[18]XiaoxiaoTang,YanLin,DaoyuanWu,andDebinGao.2018.TowardsDynamically\nMonitoring Android Applications on Non-rooted Devices in the Wild. In Pro-\nceedings of the 11th ACM Conference on Security & Privacy in Wireless and Mobile\nNetworks (WiSec ’18) . ACM, 212–223. https://doi.org/10.1145/3212480.3212504\n[19]Hayawardh Vijayakumar, Joshua Schiffman, and Trent Jaeger. 2012. STING:\nFinding Name Resolution Vulnerabilities in Programs. In Proceedings of the 21th\nUSENIX Security Symposium (USENIX Security ’12). USENIX Association, 585–\n599. https://www.usenix.org/conference/usenixsecurity12/technical-sessions/p\nresentation/vijayakumar\n[20]VesalVojdani,KalmerApinis,VooteleRõtov,HelmutSeidl,VarmoVene,andRalf\nVogler. 2016. Static race detection for device drivers: the Goblint approach. In\nProceedingsofthe31stIEEE/ACMInternationalConferenceonAutomatedSoftware\nEngineering (ASE ’16). ACM, 391–402. https://doi.org/10.1145/2970276.2970337\n[21]Pengfei Wang, Kai Lu, Gen Li, and Xu Zhou. 2018. A survey of the double-fetch\nvulnerabilities. Concurrency and Computation - Practice and Experience 30, 6\n(2018), 1–16. https://doi.org/10.1002/cpe.4345\n[22]WeihangWang,YunhuiZheng,PengLiu,LeiXu,XiangyuZhang,andPatrick\nEugster.2016. ARROW:automatedrepairofracesonclient-sidewebpages.In\nProceedings of the 25th International Symposium on Software Testing and Analysis\n(ISSTA ’16). ACM, 201–212. https://doi.org/10.1145/2931037.2931052\n[23]YuWang,LinzhangWang,TingtingYu,JianhuaZhao,andXuandongLi.2017.\nAutomatic detection and validation of race conditions in interrupt-driven em-\nbedded software. In Proceedings of the 26th ACM SIGSOFT International Sym-\nposium on Software Testing and Analysis (ISSTA ’17). ACM, 113–124. https:\n//doi.org/10.1145/3092703.3092724\n[24]Jinpeng Wei and Calton Pu. 2005. TOCTTOU Vulnerabilities in UNIX-Style File\nSystems:An AnatomicalStudy.In Proceedingsof the4th USENIXConference on\nFile and Storage Technologies (FAST ’05) . USENIX Association, 155–167. http:\n//www.usenix.org/events/fast05/tech/wei.html\n[25]Meng Xu, Sanidhya Kashyap, Hanqing Zhao, and Taesoo Kim. 2020. Krace: Data\nRace Fuzzing for Kernel File Systems. In Proceedings of the 41st IEEE Symposium\non Security and Privacy (S&P ’20). IEEE, 1643–1660. https://doi.org/10.1109/SP40\n000.2020.00078\n[26]MengXu,ChenxiongQian,KangjieLu,MichaelBackes,andTaesooKim.2018.\nPreciseandScalableDetectionofDouble-FetchBugsinOSKernels.In Proceedings\nof the 39th IEEE Symposium on Security and Privacy (S&P ’18). IEEE Computer\nSociety, 661–678. https://doi.org/10.1109/SP.2018.00017\n[27]Yuanzhong Xu and Emmett Witchel. 2015. Maxoid: transparently confining\nmobileapplicationswithcustomviewsofstate.In Proceedingsofthe10thEuropean\nConference on Computer Systems (EuroSys ’15). ACM, 26:1–26:16. https://doi.org/\n10.1145/2741948.2741966\n[28]JonathanYung,HervéDebar,andLouisGranboulan.2016. SecurityIssuesand\nMitigation in Ethernet POWERLINK. In Proceedings of the 2nd International\nWorkshoponSecurityofIndustrialControlSystemsandCyber-PhysicalSystems,\nCyberICPS’16 (LectureNotesinComputerScience,Vol.10166) .Springer,87–102.\nhttps://doi.org/10.1007/978-3-319-61437-3_6\n[29]LuZhangandChaoWang.2017. RClassify:classifyingraceconditionsinweb\napplications via deterministic replay. In Proceedings of the 39th International\nConference on Software Engineering (ICSE ’17). IEEE / ACM, 278–288. https:\n//doi.org/10.1109/ICSE.2017.33\n[30]Xiao Zhang, Kailiang Ying, Yousra Aafer, Zhenshen Qiu, and Wenliang Du.\n2016. Life after App Uninstallation: Are the Data Still Alive? Data Residue\nAttacks on Android. In Proceedings of the 23rd Annual Network and Dis-\ntributed System Security Symposium (NDSS ’16) . The Internet Society, 1–\n15. http://wp.internetsociety.org/ndss/wp-content/uploads/sites/25/2017/09/life-\nafter-app-installation-data-still-alive-data-residue-attacks-android.pdf\n \n904"}
{"title": "When Good Becomes Evil: Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure", "content": "When Good Becomes Evil: Tracking Bluetooth Low Energy\nDevices via Allowlist-based Side Channel and Its Countermeasure\nYue Zhang\nTheOhio State University\nzhang.12047@osu.eduZhiqiang Lin\nTheOhio State University\nzlin@cse.ohio-state.edu\nABSTRACT\nBluetooth Low Energy (BLE) is ubiquitous today. To prevent a\nBLE device (e.g., asmartphone) frombeing connected byunknown\ndevices,itusesallowlistingtoallowtheconnectivityfromonlyrec-\nognized devices. Unfortunately, we show that this allowlist feature\nactuallyintroducesasidechannelfordevicetracking,sinceadevice\nwiththeallowedlistbehavesdifferentlyeventhoughithasusedran-\ndomized MAC addresses. Worse even we also find that the current\nMACaddressrandomizationschemespecifiedinBluetoothprotocolisflawed,sufferingfromareplayattackwithwhichanattackercan\nreplayasniffedMACaddresstoprobewhetheratargeteddevice\nwill respond or not based on its allowlist. We have validated our\nallowlist-basedsidechannelattackswith43BLEperipheraldevices,\n11centrals,and4developmentboards,andfoundnoneofthemonce\nconfiguredwithallowlistingisimmunetotheproposedattacks.We\nadvocatetheuseofanintervalunpredictable,centralandperiph-\neral synchronized random MAC address randomization scheme to\ndefeat passive device tracking (introducing 1% power consumption\noverheadforcentralsand6.75%forperipherals,and88.49 𝜇sperfor-\nmance overhead for centrals and 94.46 𝜇s for peripherals), and the\nuseof timestampsto deriverandomized MACaddressessuch that\nattackerscannolongerbeabletoreplaythemtodefeatactivedevice\ntracking (introducing 3.04% overhead for peripherals, and 63.58 𝜇s\nand20.54 𝜇sperformanceoverheadforcentralsandperipherals).We\nhavedisclosedourfindingstoBluetoothSIGandmanyotherstake-holdersinOctober2020.BluetoothSIGassignedCVE-2020-35473to\ntrack this logical-level protocol flaw. Google assigned our findings\nas a high severity design flaw and awarded us with a bug bounty.\nCCSCONCEPTS\n•Securityandprivacy →Securityprotocols; Mobileandwire-\nless security .\nKEYWORDS\nBluetoothSecurity,WirelessSecurity;BluetoothPrivacy;Identity\nResolutionKey (IRK); Side Channel Attacks; Replay Attacks\nACM Reference Format:\nYue Zhang and Zhiqiang Lin. 2022. When Good Becomes Evil: Tracking\nBluetooth Low Energy Devices via Allowlist-based Side Channel and Its\nPermissionto make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACM\nmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\n© 2022 Association for Computing Machinery.\nACM ISBN 978-1-4503-9450-5/22/11...$15.00\nhttps://doi.org/10.1145/3548606.3559372Countermeasure. In Proceedings of the 2022 ACM SIGSAC Conference on\nComputer and Communications Security (CCS ’22), November 7–11, 2022, Los\nAngeles, CA,USA. ACM, NewYork,NY, USA, 14pages.https://doi.org/10.\n1145/3548606.3559372\n1 INTRODUCTION\nBeingashort-rangewirelesscommunicationtechnology,Bluetooth\nLow Energy (BLE) is ubiquitous and has been used in numerous\napplicationstodaysuchashomeentertainment,healthcare,sports,\nretail,andeven recentlydigitalcontacttracing.However, BLEde-\nvices are subject to MAC address tracking since any nearby at-\ntackers can sniff the Bluetooth packets and associate them with\nparticular devices or even users [ 1–5]. This is because, when using\nBLE for communication, a peripheral without being connected will\nperiodically(e.g.,every20milliseconds[ 6,7])advertiseitspresence\nto nearby centrals with an Advertising Indication (i.e., ADV_IND)\npacket [8] along with its MAC address; a nearby central (e.g., a\nsmartphone)willtypicallyrespondtothe ADV_INDpacketwitha\nscanrequest(i.e., SCAN_REQ )containingtheMACaddressesofboth\nthe central and the peripheral [ 2], to see whether the peripheral\nis a known device or not. Consequently, an attacker with a sniffer\ncanobserveMACaddressesbeingexchangedbetweenBluetooth\ndevices for MAC address tracking attacks [1–5].\nBluetoothSpecialInterestGroup(SIG)iscertainlyawareofMAC\naddress tracking threats, and have specified the use of MAC ad-\ndress randomization using such as Resolvable Private Address (RPA)\ntoprotecttheBluetoothprivacy.Inparticular,RPAallowspaired\ndevices (i.e., two devices have exchanged cryptographic keys) to\nresolveandrecognizethepeerdevice’sMACaddressusingits Iden-\ntityResolutionKey (IRK)[6].WithRPA,a BluetoothMACaddress\nwillberandomizedperiodically(e.g.,every15minutes[ 6]),thereby\nhindering MAC address tracking attacks from nearby attackers.\nUnfortunately,inthispaperweshowthatMACaddresstracking\nisstillpossibleeventhoughitisrandomized,particularlywhenthe\nBLE device enables the “filter accept list” [ 6] defined by Bluetooth\nSIG (and we call it allowlist for brevity in this paper), an access\ncontrolfeatureusedbyavastmajorityofBLEdevices(e.g.,Android\nphones, or iPhones). More specifically, when a Bluetooth device is\nconfiguredwiththeallowlist,itbehavesdifferently.Forinstance,\naperipheralwouldignore SCAN_REQ fromunknowndevices,and\nonly respond to SCAN_RSP for its allowed device; a central may\ndirectly connect its allowed peripherals (much like a magnet) once\nreceivinganadvertisementpacketwithoutany SCAN_REQ .There-\nfore,anattackercantrackthesniffedMACaddressesandassociate\nthemwithspecificonesbyusingasniffertopassivelycollectand\nanalyzewhetherthedevicerespondedornot.Althoughboththe\ntwo communicating devices can enforce address randomization,\nthere could exist an interval, where one device changes its address\nbut the other one remains the same, which consequently leaves\n3181\nCCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\nsignificant footprints for attackers to track the devices based on\ntheoldandnotsimultaneouslychangedaddress.Thisallowsthe\nattacker to identify both devices across the randomization time\ninterval (e.g., more than 15 minutes).\nWhiletheabovepassiveattacksrequireanattackertokeepmon-\nitoring the advertising packets, which would be quite costly for\nattackers, we also find attackers do not have to do so if they can\nreplayasniffedMACaddresstoactivelyprobewhetheraperipheral\noracentralwillrespondornot,byexploitingtheflawwediscov-\nered in the current RPA randomization algorithm in the Bluetooth\nspecification. In particular, although a randomized address in RPA\nis generated from a random number and a pre-shared IRK betweentwopaireddevices,thecurrentBluetoothprotocoldoesnotspecify\nhow the random number should be chosen (other than mentioning\nthat the random number should neither be all 0s nor all 1s at page\n2,861 in [9]), and no mechanisms are placed to prevent the reuse\nof an existing random number. Therefore, while an attacker can-\nnotobtaintheIRK,heorshecanstilltrackthedevicesacrossthe\nrandomizationtimeinterval bysimplycollectingthe sniffedMAC\naddressesandreplayingthemtoobservewhetherthedevicesare\nin the allowlist or not.\nTodemonstrateconcretelythisnewMACaddresstrackingthreat,\nwepresentanovelallowlistbasedsidechannelattackdubbedBlue-\ntooth Address Tracking (BAT). Similar to other MAC address track-\ningattacks(e.g.,[ 1–5]),ourattacksworkagainstdevicesduringthe\nadvertising stage. Particularly, we show that an attacker can either\npassivelysniff (§4)theBluetoothpacketstoidentifytheperipherals\nandthe centrals,or activelyreplay (§5)the sniffedMAC addresses\nofcentralstoidentifytheirassociation,or activelyreplay thesniffed\nMACaddressesofperipheralstoattractknowncentrals.Iftheat-\ntacker knows the user who is using the identified centrals or the\nperipherals,anattackercanevenuse BATattackstomonitorthe\nuser’sbehaviors,andtracktheuser’spasttrajectory(e.g.,wherethe\nuserhasbeen tothepast)or eventhereal-timelocation. Wehave\nimplemented BATusing a BLE sniffer, a customized smartphone\nand a Bluetooth development board, and tested our passiveand\nactive BATattackswith54ofourowndevicesandalso4develop-\nment boards, and identified 39 devices (11 centrals, 24 peripherals,\n4developmentboards)thatusetheallowlist,noneofwhichdefeats\nourBATattackscurrently.\nWe advocate the use of an interval unpredictable, central and\nperipheral synchronized RPA generation scheme to counter our\npassiveBATattacks(§6.1).Todefendagainstouractive BATattacks,\nwe propose adding a sequence number (which could be a times-\ntamp) when generating the RPA to ensure that each MAC address\ncan only be used once to prevent the replay attack (§6.2). We have\ndeveloped a prototype of our defense named Securing Address for\nBLE(SABLE)atopAndroidOpenSourceProject(AOSP)[ 10]and\nthe SDK of Nordic [ 11] by modifying the Bluetooth protocol stack.\nWe have tested SABLE, and our experiment result shows that (1)\nour passive-attack defense will have about 1% power consumption\noverheadforcentralsand6.75%forperipherals,and88.49 𝜇sper-\nformanceoverheadforcentralsand94.46 𝜇sforperipherals;and(2)\nour active-attack defense will not impose any power consumption\nfor centrals but will have 3.04% power overhead for peripherals,and63.58\n𝜇sand20.54 𝜇sperformanceoverheadforcentralsand\nperipherals, respectively.\n❷ Scan request (i.e., SCAN_REQ)❶Broadcast (e.g., ADV_IND)(I) Advertising\n(II) Pairing (optional)\n(IV) (Encrypted) Communication\n❺ Pairing feature exchange\n❻ Encryption key generation\n❼ Key distribution (e.g.,IRK)\n❾ Write/Read valueCentral Peripheral\n_\n❸Scan response (i.e., SCAN_RSP)\n❹ Connection request (i.e., CONNECT_REQ )\n❽ Allowlist configuration×\n(III) Allowlisting initialization (optional)×advertising \nfilter policy scanning filter \npolicy \ninitiator \nfilter policy××\n❷\n_\nIRK c2MAC c1\nIRK cm...\nAllow list\n×\nIRK p2MAC p1\nIRK pn...\nAllow list\nFigure1:BLEworkflowwithcorrespondingallowlistpolicies.\n2 BACKGROUND\nWhen using BLE for communications between a central (e.g., a\nsmartphone) and a peripheral (e.g., a keyboard), it usually involves\nanumberofsteps.Asillustratedin Figure1,itcouldhaveuptonine\nsteps, and these steps can be categorized into four stages [ 6]: (I)\nAdvertising stage, (II) Pairing stage, (III) Allowlisting initialization\nstage, and (IV) Data exchange stage. The details of these stages are\ndescribed as follows:\n(I) Advertising Stage. In this stage, the central and the peripheral\nestablish the connection by first broadcasting the presence from\ntheperipheral, followed by a scan request from the central, then a\nscanresponsefromtheperipheral,andfinallyaconnectionrequest\nfrom the central.\n•StepBroadcast. In Bluetooth communication, the presence\nof a peripheral must be known to the nearby centrals. This is\nachieved bybroadcasting the packet thatincludes the MACad-\ndress of the peripheral, the PDU type of the advertisement (e.g.,\nADV_INDwhichindicatesthatthisdevice can be connected and\nscanned, or ADV_DIRECT_IND which indicates this device can\nonly be connected by devices with the expected MAC address\nspecifiedinthe ADD_Rfieldinthebroadcastpacket),andother\noptional information such as service UUIDs and manufacture\ndata.NotethatthereisaspecialtypeofBluetoothdevice,namely\nbeacons, which only broadcast ADV_NONCONN_IND packets.\n•StepScan Request .Whenacentralreceivesan ADV_INDpacket,\ntypically it will respond with a Scan Request (i.e., PDU type\nSCAN_REQ )[12].However,sinceBluetooth4.0(a.k.a.,Bluetooth\nLow Energy), a new allowlist feature called scanning filter policy\nis introduced, with which a device such as a central can con-figure to only respond its\nSCAN_REQ to the allowlisted devices.\nThisallowlistfeaturenotonly savesenergyfor thecentral,but\nalso makes the communication more secure by only allowing\nconnections with the listed devices. However, in practice, smart-\nphonestypicallydonotconfigurethispolicyasitwillprevent\nthe smartphonesfrom discovering new peripherals.\n3182Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\n•StepScan Response. When receiving a SCAN_REQ from a\ncentral, the peripheral typically will respond with a Scan Re-\nsponse[8] (i.e., PDU type SCAN_RSP ). However, similar to the\ncentral, which can have a scanning filter policy, a peripheral can\nhave anadvertising filter policy, allowing the peripheral to only\nrespond its SCAN_REQ to its allowlisted device. In addition to all\ntheadvantagesofusingallowlistincentrals,usingallowlistin\nperipherals also enables security and privacy protection. In par-\nticular,Bluetoothprotocolspecificationrecommendsadvertising\nsensitivedata(e.g.,staticdatasuchasmanufacturerinformation,device type such as keyboard) in\nSCAN_RSP (not in ADV_IND)[9]\nto only trusted devices (i.e., the ones in its allowlist).\n•StepConnection Request .Whenthecentralreceivesa SCAN_RSP ,\nitthendeterminesiftheperipheralisofitsinterest(e.g.,akey-\nboard that is of interest to its OS, or a blood pressure that isof interest to its corresponding app). By default, the OS of the\ncentralwillnotautomaticallyinitiatea Connection Request (i.e.,\nPDU type CONNECT_REQ ) to the peripherals, a user or an app\nhas to be involved to initiate the connection. However, afterthe central has paired with the peripheral, it can maintain the\npairedperipheralintoitsallowlistwithan initiatorfilterpolicy\ntodecidewhethertoautomatically(muchlikeamagnet)initiate\ntheconnectionwheneveritseesthecorrespondingperipheral.\nThe use of this allowlist policy can significantly improve the\nuserexperience,sinceitdoesnotrequiretheusertomanually\nopen the settings app of the OS or other 3rd-party apps to\ninitiate the connection. For the peripheral, when receiving a\nCONNECT_REQ , it can also use the advertising filter policy as in\nStepto decide whether to accept this CONNECT_REQ in case\nthatacentraldirectlyconnectstoitwithoutusing SCAN_REQ [9].\n(II) PairingStage. Pairing,whichis optional, is used to negotiate\ncryptographic keys for communication security and privacy and\ncanbebrokenintothreesteps(fromStep to).Inparticular,Step\nPairing Feature Exchange:thetwodevicesexchangetheirpairing\nfeatures(e.g.,havingadisplay,orakeypad),whichareneededto\ndecidetheappropriatepairingmethodsuchas Just Works, Passkey\nEntry, Out of Band, and Numeric Comparison (since Bluetooth\n4.2).Step Encryption Key Generation:thetwodevicesdetermine\nthe type of pairing method based on the features exchanged and\nnegotiate an encryption key. Step Key Distribution: two devices\nexchange keys, and these include the encryption key and also the\nIdentity Resolving Key (IRK), which is used for a BLE device to\nresolve its peer’s randomized MAC address.\nMAC address randomizationis crucial for BLE securityand pri-\nvacy [13][14]. A Bluetooth MAC address is a 48-bit value uniquely\nassociated with the device. There are four types of MAC addresses:\nPublic Address (PA), Static Random Address (SRA), Resolvable Pri-\nvateAddress(RPA),andNon-ResolvablePrivateAddress(NRPA).\nTheseaddresstypes can be identified byparsing both TxAddand\nthetwomostsignificant( MSB)bitsoftherandomizedMACaddress.\n•PublicAddress(PA) (TxAdd=0):aPAisagloballystaticaddress\nassigned by the manufacturer. It never gets changed (serving as\nanidentityforthedevice),obviouslyvulnerabletoMACaddress\ntrackingattacks.•StaticRandomAddress(SRA) (TxAdd=1,MSB=11):anSRAis\nrandomlygeneratedbythedevicewhenitisrebootedorreset[ 6].\nSRA is also vulnerable to MAC address tracking if the device\nnever reboots or resets.\n•ResolvablePrivateAddress(RPA) (TxAdd=1,MSB=01):anRPA\nisgeneratedusinganIRKanditchangesperiodically.Onlythe\npaired device with a valid IRK can resolve the corresponding\nRPA to identify the known devices.\n•Non-ResolvablePrivateAddress(NRPA) (TxAdd=1,MSB= 00):\nan NRPA is randomly generated and changes periodically de-\npendingontheimplementation.NRPAisintendedtoneverbe\nresolvable by any device.\nIt can be noticed that only RPA can still be resolved by the peer\ndevices if they know the corresponding IRK. This is particularly\nuseful for a peripheral to remember the recognized centrals or vice\nversa.Next,weexplaintheformatofRPAanditsgenerationand\nresolution process. In particular, according to the Bluetooth proto-\ncol specification [ 9], an RPA consists of prandandhash. The MSB\nofprandfor RPA is fixed (i.e., MSB=01), and the rest of the prand\nare the random bits.\n•RPA Generation. To generate an RPA (48-bits), the central,\ndenoted with symbol 𝑐, first selects a 24-bits prand(i.e.,prand24\nwhose first two bits are predefined), and then it feeds its IRK,\nassume𝑖𝑟𝑘𝑐, along with the selected prandinto a pre-defined\nhashfunction 𝐻togeta24-bitshashvalue 𝐻24(prand24||𝑖𝑟𝑘𝑐).\nFinally,theRPAof 𝑐,assume𝑟𝑝𝑎𝑐,isgeneratedbyconcatenating\nprandand the hash value:\n𝑟𝑝𝑎𝑐=prand24||𝐻24(prand24||𝑖𝑟𝑘𝑐)\n•RPAResolution.Whenreceivingan 𝑟𝑝𝑎𝑐fromacentral,the\nperipheral can determine whether this RPA is from its “known”\ndevice.ThisisachievedthroughtheRPAresolution.Atahigh\nlevel,the peripheralwill firstsplit 𝑟𝑝𝑎𝑐into twoparts: prand24\nandhash24. Next, it iterates its known IRK list (each element of\nthis listis added during the pairing), assume 𝑖𝑟𝑘𝑖, to compute\nhash/prime\n24=𝐻24(prand24||𝑖𝑟𝑘𝑖)\nIfhash/prime\n24matches the received hash24split from the 𝑟𝑝𝑎𝑐, then\nthe device is resolved with the corresponding 𝑖𝑟𝑘𝑖.\n(III)AllowlistingInitialization(Step ).Thisisalsoanoptional\nstage depending on the configurations, and it is used to configure\nthe allowlist used by early Steps (e.g., ,) for device filtering. To\nuniquelyidentifyadevice,theallowlistfeaturereliesontheIRKs\ntransmittedatStep ,andStep justaddstheIRKstothelistwith\nother information, such as the address type. However, if the added\ndevicedoesnotenabletheaddressrandomization,thentheMAC\naddressofthedeviceinsteadofitsIRKwillbeaddedtotheallowlist.\nRecall that there are three allowlist-based filtering polices: ( 𝑖)\nscanningfilterpolicy ,(𝑖𝑖)advertisingfilterpolicy,and( 𝑖𝑖𝑖)initiator\nfilterpolicy.Amongthem,the advertisingfilterpolicy isdeployed\nattheperipheralside,andtheothertwoaredeployedatthecentral\nside. Although the Bluetooth protocol does not specify how many\ndevices can be added to an allowlist, we find that different policies\nmayaffectthenumberofdevicesthatcanbeaddedtotheallowlist.\nIn the following, we summarize their practical impacts when used:\n3183CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\nUnknown Central\n Allowlisted Central\n Peripheral\nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP  (with Addr p )\nSCAN_REQ (Addr u   Æ Addr p )Addr c = MACc\nt1 \nSCAN_REQ  (Addr u  Æ Addr p )\n _\n p\n t1\nAddr p = SA Addr u = MACu\nt1  \nAdd c = MACc\nt2 \nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP  (with Addr p )\n t2\nTime\nAddr u = MACu\nt2  \nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆÆFigure 2: An example to demonstrate the key observation.\n•Scanningfilterpolicy. Whilethe scanningfilterpolicy isdefined\ninthespecification,itisnotappropriatetobedeployedonsmart-\nphones, since it will prevent smartphones from discovering new\nBLE devices. Instead, it is usually deployed in some customized\ncontrollers(e.g.,wirelesscontrollerforvideogames[ 15]),where\none controller only discovers and communicates with only one\nBLE device.\n•Initiator filter policy. This policy is widely deployed in smart-\nphonesforauto-connectionwithoutuserinvolvementifaknown\nperipheral is detected within its reach. Since it will not prevent\nsmartphonesfromdiscoveringandconnectingnewBLEdevices,\na smartphone with this policy enabled will be able to automati-\ncally connect multiple peripherals for user convenience.\n•Advertising filter policy. We find that in practice only one\nallowlistedcentralcanbeaddedwhenenabledthe advertisingfil-\nterpolicy inaperipheral.Thisisbecauseoncetheperipheralhas\npairedwithaparticularcentral,itusuallyrestrictsothercentrals\nto connect and pair with it. Without going through the pairing\nprocess,othercentralswillnotbeabletodelivertheirIRKsto\nit and the allowlist will not be able to add any new centrals. As\nsuch,thispolicyusuallyallowsaconsistentone-to-onemapping\nbetween the allowlisting peripheral and the listed central.\n(IV)DataExchangeStage(Step ).Afterthefirstthreestages,the\ntwodevicescannowexchangedatausingaclient-server(C/S)mode,eitherusingencryptioniftheyhaveexchangedcryptographickeysorplaintextifnot.Specifically, thecentralplaystheclientrole,and\nthe peripheral acts as a server providing services to the client. Aread request can be sent to the peripheral if the central needs toread data from the server, or with a write request if the central\nneeds to submit data to the server.\n3 OVERVIEW OF BATATTACKS\n3.1 Key Observation\nA key observation of our BATattacks is that once a device has\nbeenconfiguredwithallowlisting,itwillbehavedifferentlywhen\nrespondingtoitsallowlisteddevicesandnon-allowlisteddevices,asdescribedin§2.Forexample,ifaperipheralenables advertisingfilter\npolicytofilterthe\nSCAN_REQ fromthenearbycentrals,itwillalways\nrespondtoitsallowlisteddeviceswhileignoringthe SCAN_REQ sent\nfrom the non-allowlisted devices. Specifically, as illustrated in Fig-\nure 2, at time 𝑡1, assume there is a peripheral 𝑝with static address𝑆𝐴(forsimplicity,assume 𝑝usesastaticaddressatthismoment),\nwhichisbroadcasting,andtherearemultiplecentralsnearby(as-\nsumeanallowlistedcentral 𝑐andanunknowncentral 𝑢).Wecan\nobserve that 𝑝only accepts the SCAN_REQ from𝑐with𝑀𝐴𝐶𝑐\n𝑡1with\naSCAN_RSP ,butignoresthe SCAN_REQ fromthecentral 𝑢withad-\ndress𝑀𝐴𝐶𝑢\n𝑡1. As such, it is quite straightforward to identify and\ntracktheallowlistedcentral 𝑐,bysimplyassociatingtherandomized\nMACaddressestogetherfromthesniffedpackets.Thisisbecause\ntheadvertisingfilterpolicy createsaconsistentone-to-onemapping\nbetween the allowlisting peripheral 𝑝and the allowlisted central 𝑐,\nenabling the attacker to uniquely associate the central of interest.\n3.2 Objectives, Assumptions, and Attack Model\nAttack Objectives. We consider the users whose Bluetooth de-\nvicesuseRPAasourvictims,sinceaBluetoothdevicecanbeeasily\ntrackedifitsMACaddressisnotrandomized.Today,manyBlue-\ntooth devices have adopted randomized MAC addresses such asRPAs. For instance, Google has enforced the use of RPA on all\nAndroid smartphones since 2016 [\n16]. The goal of BATattack is\ntoshowthattheBluetoothdeviceswithRPAcanstillbetracked,\nallowing their users to be potentially deanoymized (e.g., when the\nMAC address can be associated to a particular user).\nWithoutlossofgenerality,wedefinetheobjectiveof BATattacks\nas follows: for a set of sniffed MAC addresses (regardless of how\nmanyBLE devices they belong to), assume that\n𝐺(𝑀𝐴𝐶)={𝑀𝐴𝐶𝑑𝑒𝑣1\n𝑡1,𝑀𝐴𝐶𝑑𝑒𝑣2\n𝑡2,...,𝑀𝐴𝐶𝑑𝑒𝑣 𝑛\n𝑡𝑛}\nwhere𝑀𝐴𝐶𝑑𝑒𝑣 𝑥\n𝑡𝑥istheMACaddressofdevice 𝑑𝑒𝑣𝑥atthetime 𝑡𝑥.\nFor any two MAC addresses, assume that\n𝑀𝐴𝐶𝑑𝑒𝑣 𝑎\n𝑡𝑎∈𝐺(𝑀𝐴𝐶),𝑀𝐴𝐶𝑑𝑒𝑣 𝑏\n𝑡𝑏∈𝐺(𝑀𝐴𝐶),|𝑡𝑎−𝑡𝑏|>𝑇\nwhere𝑇istherandomizationtimeinterval(e.g.,15minutes),the\ngoal of BATattack is to determine whether 𝑑𝑒𝑣𝑎=𝑑𝑒𝑣𝑏.I fs o ,\nthe attacker successfully associates the two MAC addresses. For\nexample, assume at time 𝑡𝑎the attacker observed a victim is at her\noffice and sniffed an address 𝑀𝐴𝐶𝑑𝑒𝑣 𝑎\n𝑡𝑎, and at time 𝑡𝑏, the attacker\nsniffedananonymousdevicewith 𝑀𝐴𝐶𝑑𝑒𝑣 𝑏\n𝑡𝑏inaStarbucks.Ifthe\nattacker identifies that 𝑀𝐴𝐶𝑑𝑒𝑣 𝑎\n𝑡𝑎and𝑀𝐴𝐶𝑑𝑒𝑣 𝑏\n𝑡𝑏are the ephemeral\naddressesofthesamedevice(e.g.,auser’ssmartphone),theattacker\nthen successfully associates these two addresses, and knows the\nuseris in or near the Starbucks.\nVictimSettings. Notallusers whoseBLE device configured with\nRPAcanbeattacked,andinsteadour BATattackshavethefollowing\ntwo requirements:\n•Werequirethevictimtohaveapairedcentralandperipheral,and\neither the central or the peripheral has configured the allowlist.\nThisistrueformostcentralsandperipheralstoday,sincecentrals\noften configure the initiator filter for automatic connection with\nknown peripherals, and many peripherals often configure the\nadvertisingfilter to respond only to known centrals.\n•We require that the central and the peripheral are not always\nconnected,whichisalsooftentrue.Forexample,asmartspeaker\nis disconnected from the mobile when the user is away, and\nearbudsaredisconnectedfromthemobilewhentheyareintheir\n3184Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nchargingcases.Iftheyareconnected,attackershavetowaituntil\neither thetwo devices beginto communicate, or oneof them is\navailableforattackerstocommunicate.Althoughtheattacker\ncan use jamming to intentionally disconnect devices, users may\nnotice that two connected devices are disconnected, which will\nbreak the stealthiness of the attacks.\nAttack Scenarios. Since the attacker is able to either ( 𝑖) passively\nsniffing the BLE traffic or ( 𝑖𝑖) actively modifying the traffic, it leads\nto two types of BATattacks:\n•Passive BATAttacks (§4), which just passively sniff the adver-\ntising packets between centrals and peripherals, to see whether\naperipheralwillselectivelyrespondto SCAN_REQ (i.e.,replywith\naSCAN_RSP ornot);ifso,attackersusethissinglebittoassociate\n(i.e., track) the corresponding centrals into unique ones based\non the observed MAC addresses.\n•Active BATAttacks(§5),whichactivelymanipulatethepack-\nets, e.g., forging new packets, or replaying the old packets, to\nobservehowaperipheraloracentralbehaves.Iftherearedis-\ntinctivebehaviorsobserved,theircorrespondingMACaddresses\nare associated too.\nAttacker’s Assumptions. When launching BATattacks, we as-\nsumethe attackersto have the following capabilities:\n•When launching passive BATattacks, we assume that attack-\ners can keep collecting the advertising packets (e.g., ADV_IND,\nSCAN_REQ ,SCAN_RSP ) sent from the victim’s devices, across the\nrandomization time interval. To this end, the attacker has to\nbe close to the victims to sniff the Bluetooth packets, and the\nvictimdeviceshavetobeturnedon(e.g.,manybattery-powered\nperipherals may enter thesleep mode when they are notin use\nfor a while and the attacker will have to wait until they have\nbeen awakened up).\n•Whenlaunchingactive BATattacks,inadditiontoassumingthat\nattackers can collect Bluetooth packets, we also assume that\ntheycanactivelyreplayandforgetheadvertisingpackets(which\nare not encrypted). This can be easily achieved using Bluetooth\ndevelopment boards or smartphones.\nWhilewehavemadetheseassumptions,webelievethatour BATat-\ntacksarestillpracticalcomparedtootherBluetoothdevicetracking\nattacks.Particularly,thefirstassumptionisanassumptionforall\ntheBluetoothtrackingattacks(e.g.,[ 3,17–19]).ThisisbecauseBlue-\ntoothisdesignedforshortrangecommunication,andtheBluetooth\npackets can always be collected by either using Bluetooth sniffers\natmultiplelocationsormovingthesnifferaroundtotrackpoten-\ntial victims. Moreover, we can also get rid of this assumption by\nconsideringsmartphonestobesniffersoncecontrolledbymalware.Inparticular,amalwarecanbeinstalledontosmartphonetoforceamobiledevicetoworkasasniffer(e.g.,asinBadBluetooth[\n20]and\nBluetooth Misbonding[ 21], which assumed that the malware can\nbeinstalledontomobiles),ourattacksthenwillnothaveanyrange\nlimitations. However, for simplicity and practicality, we do not as-\nsumethatwehaveamalware-controlledsmartphonesniffer,though\nnationstatecan have such a capability with 0-click exploits [22]).\nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆ\nUnknown Central\n Allowlisted Central\n Peripheral\nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP  (with Addr p )\nSCAN_REQ (Addr u   Æ Addr p )Addr c = MACc\nt1 \n t1\nAddr p = MACp\nt1 Addr u = MACu\nt1  \nAdd c = MACc\nt2 \n t2\nTimeAddr u = MACu\nt2 \n Addr p = MACp\nt2\n t3\nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP (with Addr p )\nSCAN_REQ  (Addr u   Æ Addr p )\nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP (with Addr p )\nSCAN_REQ  (Addr u   Æ Addr p )\nFigure 3: Workflow of our passive BATattacks.\n3.3 Scope\nVictim Scope. While our BATattacks can be launched to work\nagainstallthedevicesthatsatisfythevictim’ssettings(discussed\nin §3.2), we particularly focus on the following types of victims.\n(i)Boththecentralandperipheralhaveenforcedtherandomized\nMACaddresses.Althoughin§3.1 weusethecasewherethecentral\nuses random MAC addresses but the peripheral uses a static MAC\naddress to explain the key observation of our attacks, we do not\nconsidersuchavulnerablecasesincetheBluetoothspecification\nhasalreadyofferedthedefensesfortheseattacks—bothdevicesen-forcetheMACaddressrandomization.(ii)MultipleBLEdevicesarenearby.Thisisbecauseifthereisonlyonedevice(i.e.,thevictim)at\na specific location, and if the attacker knows such a fact, he or she\ncan easily identify the victim device without launching our attacksat all. (iii) While our attacks can track both the peripherals and the\ncentrals, we focus on tracking victim centrals for proof-of-concept\nsince many peripherals (e.g., keyboards and mouses) are stationary.\nAttack Scope. We also would like to narrow down the scope of\nour attacks. (i) We only study the BATattacks in the advertising\nstage(wheredevicesmayexchange ADV_IND,SCAN_REQ ,SCAN_RSP\nandCONNECT_REQ ), and we do not consider the tracking attacks\nintheotherthreestages,astheallowlistonlytakeseffectsatthis\nstage.Forinstance,wedonotconsiderattackssuchasBIAS[ 23],\nKNOB[24],andDowngrade[ 25](thoseattacksareusuallylaunched\ninthecommunicationstageorthepairingstage),althoughtheycan\npotentiallybeusedfordevicetracking.(ii)Whileourattackscan\nbe targeted (e.g., the attacker knows a MAC address of a specificdevice) and untargeted (e.g., the attacker does not know such a\nMAC address), we use targeted attacks to demonstrate the impacts.\nSpecifically,forproof-of-concept,weassumethatforaparticular\ntargeteduser(e.g.,Alice),weknowaninstanceoftheMACaddress\nofherBLEdevice(e.g.,hersmartphone).Therearemultipleways\nto learn such MAC addresses (e.g., physically following Alice with\nasniffer),andsimilartootherworksthatagainstBluetoothprivacy\n(e.g., [26],[27]), we consider those to be out of the scope of this\nwork. Please also note that without knowing such a MAC address,\n3185CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\ntheattackercanstilllaunchuntargetedattackstotrackarbitrary\nusers if they are in the attacker’s range.\n4 PASSIVE BATATTACKS\nOurpassive BATattacksonly sniffthebroadcasting trafficofBLE\ndevicesandrelyonthedifferentresponsesignalsfromdeviceswith\nallowlisttoassociate(i.e.,track)thesniffedMACaddresses.Note\nthat we focus on the scenario in which both centrals and periph-\nerals have used RPA-type of MAC addresses; otherwise, it is trivial\nto recognize the allowed centrals if the peripheral does not change\nits MAC address as illustrated in §3.1. Theoretically, when bothperipheral and central have used RPA perfectly, the BATattack,\nwhich relies on the different response signals, will fail. However,we notice that, although both the central and the peripheral will\nchangetheiraddresses,theaddressrandomizationusuallyoccurs\nindependently (without any synchronization), and there is often\naninterval,whereoneofthedeviceschangesitsaddressandthe\notherdoesnot,leavingfootprintsforanattackertotrackBluetooth\ndevices across randomization time interval. To be more specific,\nthe root causes of the vulnerability for such passive attacks are:\n•PredictableRandomizationTimeInterval. TheBluetoothde-\nvicesusuallyusepredictableintervals(e.g.,15minutes).Assuch,\nattackers can use timing side channel to easily link a specific de-\nvice by observing that the device changes its MAC address with\nfixedtimeintervals.Forexample,ifthereisonesmartphoneanditalwayschangesaddressesevery\n𝑇𝑟minutes,apassiveattacker\ncanobservethereisonedevicere-randomizesitsaddressesat\ntime𝑡1,𝑡1+𝑇𝑟,𝑡1+2∗𝑇𝑟, respectively. Then, it would be trivial\nfortheattackertolinkthedevicethoughithaschangeditsMAC.\n•Asynchronized Randomization. Even if both the central and\ntheperipheraluseunpredictablerandomizationtimeintervals\n(e.g.,bothdeviceschangeMACaddressrandomizationtimein-\ntervalindependently),thereisnoguaranteethatthetwodevices\nwillsimultaneouslychangetheiraddresses.Forexample,assume\nthat there are two devices, and both of them change their MAC\naddressesevery15minutes.Forthefirsttime,thecentralchanges\nits MAC address at 𝑡0, but the peripheral changes its MAC ad-\ndressat𝑡1(𝑡0≠𝑡1).Assuch,thereistheinterval 𝑡1−𝑡0,where\none device changes its address and the other remains the same.\nWe now explain the attacks in greater detail. Since broadcasting\ntrafficstartsfromperipherals,wehavetofirstidentifytheallowlist-ing peripheral from the sniffed BLE packets, and then associate the\nrandomized sniffedMAC addressesto the correspondingcentrals.\nTo be more specific:\n•AllowlistingPeripheralIdentification. Toidentifywhether\na peripheral enables allowlist or not, we can just observe howa\nSCAN_REQ gets responded (i.e., whether the peripheral only\nrespondstothe SCAN_REQ sentfromaspecificcentral).Although\nSCAN_RSP onlycontainsthesourceoftheresponse(i.e.,itcon-\ntainstheMACaddressoftheperipheralbutnottheMACaddress\nof the central) and we cannot know the destination of the re-\nsponse,wecanobservewhich SCAN_REQ (whichcontainsboth\ncentral’sMACaddressandtheperipheral’sMACaddress)trig-\ngers the SCAN_RSP . As shown in Figure 3, if we observe (i) a pe-\nripheralalwaysignoresthe SCAN_REQ containingMACaddresses\nofothercentrals(e.g., 𝑀𝐴𝐶𝑢\n𝑡1),theperipheralisanallowlistingperipheral;(ii)theallowlistingperipheralreceivesa SCAN_REQ\ncontainingtheMACaddressofaspecificcentral(e.g., 𝑀𝐴𝐶𝑐\n𝑡1),\ntheperipheralsendsa SCAN_RSP ,weknowthattheMACaddress\nbelongs to the allowlisted central.\n•Address Association. Since the central and the peripheral will\nnot change their addresses at the same time, the attacker canalwaysobserve an interval, during which one device does not\nchangeitsaddress,andsuchapatterncanbeusedtotrackitspeer.Forexample,in Figure3,assumethattheperipheralfirstchanges\nits address to 𝑀𝐴𝐶𝑝\n𝑡2, while the central MAC address remains\n𝑀𝐴𝐶𝑐\n𝑡1during the small interval 𝑇=𝑡3−𝑡2. Then, by observing\nthattheperipheralwith 𝑀𝐴𝐶𝑝\n𝑡2onlyrespondstothecentralwith\n𝑀𝐴𝐶𝑐\n𝑡1andignoresthe SCAN_REQ fromothers,weknowthatthe\nperipheral is likely to be the same peripheral (or another periph-\neral whose allowlisted central is also the same central). Later, at\n𝑡3, when the central changes its address, the peripheral remains\n𝑀𝐴𝐶𝑝\n𝑡2. Again, by observing the central to which the peripheral\nwith𝑀𝐴𝐶𝑝\n𝑡2alwaysresponds,weconcludethatthecentralisthe\nsame central (given the peripherals can only add one allowed\ncentral, as discussed in §2). Note that since the attack workflow\nforthecasewherethecentralfirstchangesitsMACaddressis\nsimilartothecasedescribedabove,weomititsdetailsforbrevity.\nAttack Example I: Monitoring a Victim’s Behavior. The\npassive BATattack is particularly useful to monitor the user’s\nbehaviorsinaspecificlocation(e.g.,user’shouse),whichmay\nbreach user’s security and privacy. Assuming victim Alice is\nusingastationaryallowlist-enabledBluetooth-keyboardinher\nhome to connect her smartphone, a passive attacker is able to\nsniff the exchanged packets (up to 2,000-ft away when using an\namplifiedantennasuchasRP-SMA-R/A[ 28])betweenthekey-\nboardandthesmartphone,sothattheattackerisabletoknow\nthe latestaddress of theAlice’ssmartphone via passiveattacks.\nThen,wheneverthesmartphonecommunicateswithanyperiph-\nerals, the attacker is able to associate the peripherals to Aliceand infer Alice’s privacy-sensitive behavior. For example, the\nattackercouldinferthatAlicemaybeplaguedbyhyperglycemia\nor other blood glucose disorders if the attacker observes that\nhersmartphonecommunicateswithaBluetoothbloodglucose\nmonitor (the blood glucose monitor can be recognized from the\nservicesUUID [19] provided by the Bluetooth device).\n5 ACTIVE BATATTACKS\nAs discussed, the passive attack requires the attacker to keep mon-\nitoring the traffic between the two devices, and it will fail whenthe central and the peripheral are far away. Therefore, we haveto look for other techniques, and this leads to the design of our\nactive BATattack,withwhichattackerscanactivelyinject(e.g.,via\nforging) traffic to BLE devices to observe how they will respond,\nand thispractice does notrequire the attackerto keep monitoring\nthetraffic.Thisispossible,sinceitisextremelyeasyforanattacker\nto program a malicious central (e.g., a smartphone) or a malicious\nperipheral (e.g., adevelopment board) to broadcast arbitrarypack-ets of interests. Therefore, the key question becomes what kind of\npacketsthe attacker has to forge.\n3186Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nPeripheral\nSCAN_REQ  (Addr c  Æ Addr p ) \nSCAN_RSP (with Addr p)\nMalicious Central\nSCAN_REQ  (Addr uÆ Addr p)\nt2 +ΔAddr c = MAC c\nt1 Addr p = MAC p\nt1 Addr u = MAC u\nt1 \nAddr c = MAC c\nt2 Addr p =MAC p\nt2 \nSCAN_REQ  (Addr uÆ Addr p)SCAN_REQ  (Addr c  Æ Addr p ) \nSCAN_RSP  (with Addr p)\nAddr m =MAC c\nt1 \nSCAN_REQ  (Addr m  Æ Addr p ) \nSCAN_RSP  (with Addr p)\nt1\nTime\nt2\nAddr u = MAC u\nt2 \nt3\nAddr m = MAC c\nt2 \nSCAN_REQ  (Addr m  Æ Addr p ) \nSCAN_RSP  (with Addr p)\nPassive \nAttack\nActive \nAttackAllowlisted Central\n Unknown Central\nÆÆ\nÆÆ\nÆ\nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆ\nÆFigure 4: Workflow of BATattacksfrom malicious centrals.\nWhen inspecting the BLE traffic of the advertising stage, as\nshownin Figure1,wecannoticethatthereisnoencryption,and\nthus the attacker can inject arbitrary packets. The only secret is\nthe randomized MAC addresses sent by centrals and peripherals.However, when devices using allowlist, they must use RPA that\nrelies on the exchanged IRKs for their randomized MAC addresses\ngeneration. Therefore, if we can replay the sniffed RPA-type MAC\naddresses to probe how a central or a peripheral would respond,\nthen the attackercan still launch the BATattack.\nSurprisingly, we find that current RPA generation algorithm\nunfortunatelyneverconsidersreplayattacks,andouractive BAT\nattack can indeed work. In particular, based on the RPA generationandresolutionprocessdescribedin§2,wefindthatthecurrentBlue-\ntooth specification only requires that a random number to be used\nintheRPAgeneration,butitdoesnotspecifyhowtochoosethis\nrandomnumber(e.g.,whetherthedevicecanchooseapreviously\nusedrandomnumber).Asaresult,arandomizedMACaddressgen-\neratedfromapreviouslyusedrandomnumberisalsoconsidered\nvalid, even though the attacker does not know the correspond-\ningIRK.Therefore,amaliciouscentralorperipheralcancreatea\nspoofedpacketwithapreviouslyusedMACaddresstoprobethe\nperipheral or central. Since the replay attack can be launched from\neitheramaliciouscentral(§ 5.1)oramaliciousperipheral(§5.2),we\ndescribe these two types of active BATattacks,respectively.\n5.1 Active BATfrom Malicious Centrals\nThegoalofamalicious centralbasedactive BATattackistousea\nmaliciouscentral tofirstidentify theallowlisting peripheral, from\nwhich to further track the allowlisted central. As illustrated in\nFigure 4, in addition to using the same approach to identify the\nallowlisting peripheral as in the passive BATattacks (described in\n§4),itonlyaddsoneadditionalstepofactivelyinjectinga SCAN_REQ\nat𝑡2+Δwith the harvested 𝑀𝐴𝐶𝑐\n𝑡1at𝑡1, where|𝑡2−𝑡1|>𝑇,t o\nprobewhethertheMACaddressrandomizedperipheralresponds\nto this injected address. If so, the peripheral is identified first, from\nwhich attackers can then track the potential centrals by actively\ninjectingthe collected the MAC addresses of these centrals.More specifically, as illustrated in Figure 4,a t 𝑡2+Δ, an attacker\ncan use a malicious central to create a SCAN_REQ with the previ-\nously used 𝑀𝐴𝐶𝑐\n𝑡1(which was sniffed somewhere), and then sends\nthis request to allallowlisting peripherals. If one of them (e.g., the\nperipheralwitha 𝑀𝐴𝐶𝑝\n𝑡2)respondswitha SCAN_RSP ,theattacker\nidentifies that this peripheral 𝑝is the one paired with the victim\ncentral (having the central’s IRK and recognizing it). At time 𝑡3,\ntheattackercanfurtherassociatetheaddressof 𝑀𝐴𝐶𝑐\n𝑡2to𝑀𝐴𝐶𝑐\n𝑡1,\nsincetheattackerknowsthattheidentified 𝑝issupposedtoonly\nrespond to this allowlisted central 𝑐. The active attacks from mali-\nciouscentralsaremorepowerfulthanpassiveattacks,andtheycan\nbeusedtotrackboththe(past)trajectoryandreal-timelocationsofavictim.Inthefollowing,weprovidetwoexamplestodemonstrate\nhow these can be achieved.\nAttack Example II: Tracking a Victim’s Past Trajectory.\nAssume that Alice is using her smartphone to communicate\nwith her stationary allowlist-configured Bluetooth keyboard\n𝑝in her workspace, and the attacker is able to collect one of\nits MAC addresses (assume 𝑀𝐴𝐶𝑝\n𝑡1). When at 𝑡2Alice is away\nfrom her workspace, the attacker aims to know where Alice has\nbeento.Tothisend,theattackerdeploysbeacon-alikesniffers\n(everywhere or just a few targeted places) that broadcast the\nADV_INDpackets with 𝑀𝐴𝐶𝑝\n𝑡1to collect the MAC addresses of\nallnearbycentralsintheir SCAN_REQ s(assume 𝑀𝐴𝐶𝑐𝑖\n𝑡2,𝑀𝐴𝐶𝑐𝑗\n𝑡2,\n𝑀𝐴𝐶𝑐𝑘\n𝑡2). Then, at 𝑡3, the attacker moves closer to Alice’s\nworkspace,andusesamaliciouscentraltoreplaythecollected\nSCAN_REQ s with𝑀𝐴𝐶𝑐𝑖\n𝑡2to Alice’s 𝑝to test whether it responds.\nIfso,theattackerknows 𝑐𝑖isAlice’sphone,andif 𝑀𝐴𝐶𝑐𝑖\n𝑡2was\ncollected from Starbucks (based on the sniffer’s location), the\nattackerknows Alice was in (or near) the Starbucks.\nAttack Example III: Tracking a Victim’s Real-time Loca-\ntionw/Tunneling. InourattackexampleII,theattackerhas\nto wait at 𝑡3to detect Alice’s past trajectory, because there is no\ndirect communication channel between the wild centrals and 𝑝.\nTherefore, if the attacker is able to build a tunnel to relay the\nsniffed SCAN_REQ s directly to 𝑝in Alices’ workspace, then he or\nshe would be able to know Alice’s location instantly. This leads\ntoour3rdattackexample,whichistoadditionallybuildatunnel\nbetween the wild sniffers and 𝑝using attacks such as the worm-\nholeattack[ 29].Detailsareomittedsincesuchatunnelingattack\nis well-known, and also the rest is similar to attack example II.\n5.2 Active BATfrom Malicious Peripherals\nUsing malicious centrals to probe true peripherals relies on the\nallowlist of the advertising filter policy in the peripherals. However,\nnotallperipheralsenablethispolicy,andrathermanycentrals(e.g.,\nAndroidmobiles,iPhoneandWindowstablets)haveenabledthe\ninitiatorfilterpolicy,whichwillinstantlyrespondtothe“known”\nperipherals (by storing the peripheral’s IRK) once they are in their\nrange.Therefore,wedesignanotheractiveattackbyusingspoofed\npacketsgeneratedfromamaliciousperipheral,whichbroadcasts\nthe advertising packets to all nearby centrals, and only the central\nenabled the initiator filter policy will respond, allowing an attacker\ntoinstantlyknowacentral’slocation.Similartoactive BATattacks\n3187CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang LinÆÆ\nÆÆ\nÆ\nÆÆÆ\nÆÆ\nÆ\nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆ\nÆ\nÆ\nÆÆ\nÆ\nCentral\nSCAN_REQ (Addr c  Æ Addr p ) \nSCAN_RSP  (with Addr p)\nMalicious Peripheral\n t2 +ΔAddr p = MAC p\nt1 Addr c = MAC c\nt1 \nAddr m =MAC p\nt1 \nSCAN_REQ  (Addr m  Æ Addr p) \nSCAN_RSP  (with Addr p)\nt1\nt\nTime\nt2\nAllowlisted Peripheral\nCONNECT_REQ (Addr c Æ Addr p ) \nAddr p = MAC p\nt2 Addr c = MAC c\nt2\nCONNECT_REQ  (Addr c Æ Addr m) \nPassive \nAttack\nActive \nAttackSCAN_REQ (Addr c  Æ Addr p ) \nSCAN_RSP (with Addr p)\nCONNECT_REQ  (Addr c Æ Addr p ) \nFigure5:Workflowof BATattacksfrommaliciousperipherals\nfrommaliciouscentral,thisattackalsodoesnotneeduninterrupted\nobservationof Bluetooth traffic.\nMorespecifically,asillustratedin Figure5,assumeanattacker\nhasobservedthatacentralwith 𝑀𝐴𝐶𝑐\n𝑡1initiatedaconnectionwith\na peripheral with 𝑀𝐴𝐶𝑝\n𝑡1at𝑡1.A t𝑡2, the central changed its ad-\ndress to𝑀𝐴𝐶𝑐\n𝑡2and theperipheral changed itsaddressto 𝑀𝐴𝐶𝑝\n𝑡2.\nTo associate whether the address 𝑀𝐴𝐶𝑐\n𝑡1and𝑀𝐴𝐶𝑐\n𝑡2belong to the\nsamecentral,at 𝑡2+Δ,theattackercansimplycreateamalicious\nperipheraltobroadcastitspresencewiththeharvested 𝑀𝐴𝐶𝑝\n𝑡1or\n𝑀𝐴𝐶𝑝\n𝑡2. If the victim central has enabled the initiator filter policy,i t\nwillautomaticallyinitiate CONNECT_REQ tothemaliciousperipheral.\nConsequently, the attacker is able to associate 𝑀𝐴𝐶𝑐\n𝑡1with𝑀𝐴𝐶𝑐\n𝑡2and identifythe targeted central.\nAttack Example IV: Tracking a Victim’s Real-time Loca-\ntion w/o Tunneling. Building a tunnel might be expensive.\nThere is no need to do so if attackers use malicious peripherals\nto associate centrals with the initiator filter policy. Still assume\nthat Alice uses her phone configured the initiator filter policy\ntoautomaticallycommunicatewithherBluetoothkeyboard 𝑝\ninherworkspace,andat 𝑡1theattackerisabletoobserveoneof\nitsMACaddresses 𝑀𝐴𝐶𝑝\n𝑡1.Thenlaterat 𝑡2whenAliceisaway\nfrom her workspace, the attacker directly uses beacon-alike\nsnifferstoadvertise 𝑀𝐴𝐶𝑝\n𝑡1tonearbycentrals,andifacentral\ninstantly connects the sniffer with a CONNECT_REQ , then the\nattackerknows Alice’s real-time location.\n6 COUNTERMEASURE\nInthissection,wepresentacountermeasurenamed SecuringAddress\nforBLE(SABLE)todefendagainstour BATattacks.Sincetheat-\ntacks can be launched passively or actively, we need the following\ntwocorrespondingdefensesdescribedin§6.1 and§6.2,respectively.\n6.1 DefendingAgainst Passive BATAttacks\nOverview. Thepassiveattacksaremadepossibleduetothecentral\nandperipheralindependentlyrandomizingtheiraddresses.Assuch,\nto defend against the passive attacks, we propose to (1) make MAC\nrandomization at both sides synchronized, and (2) make the lengthoftheintervalrandom;otherwise,arepeatabletimeinterval(e.g.,\nevery 15 minutes) allows attackers to associate the randomized\nMAC addresses across intervals.\n(I) Making Randomization Synchronized. We first discuss how\nthe two devices change their addresses and when it is the time for\nthem toperform the addressrandomization. Since thecentral and\nthe peripheral may not always be close to each other (e.g., the user\ncouldtakehercentralaway,andviceversa,oroneofthemisturned\noff), and if they are not close to each other, the two devices cannot\ncommunicate to decide how they could change their addresses.\nTherefore, we have the following two scenarios to address:\n•(a)Twodevicesareclosetoeachother. Inthiscase,wecannot\nlet the peripheral and the central independently start their own\nrandomization.Instead,wenoticethattheallowlistingalways\nstarts from the peripheral when advertising its presence, and\nthen the central responds. Therefore, we can take advantage of\nthis causality for the synchronization and let the randomization\nstartrightbeforetheperipheralstartstosendthe ADV_INDatthe\nperipheralside,andthecentralstartsrightafterreceivingthecor-responding\nADV_IND,asillustratedin Figure6.Assuch,attackers\nwill only observe an always synchronized randomization across\nanunpredictableinterval,andtheycannotassociatetheMAC\naddresses acrossthe randomizationtimeintervals anymore.\n•(b) Two devices are far away. In this case, we can let the cen-\ntralandperipheralindependentlystarttheirownrandomization,since the attacker can no longer associate the addresses through\nobserving devices’ SCAN_REQ andSCAN_RSP. Assume a cen-\ntral and a peripheral have passed 𝑁times synchronized address\nrandomization,andnowtheyareintheir( 𝑁+1)-thsynchronized\naddress randomization. During this interval (e.g., 15 minutes),\nthecentralistakenawaybytheuser,andtheyarenolongerclose\ntoeachother(weusethecasewherethecentralisawayfrom\ntheperipheralasanexample,sincetheothercaseisessentially\nthe same). As a result, the peripheral will not be able to receive\nanySCAN_REQ from its allowed central. When it is the time to\nchange its address, the peripheral will fetch its own time 𝑇𝑝and\ngenerate a random address 𝑟𝑝𝑎 𝑝. Since the central is not nearby,\nthelifetimeofsuchagenerated 𝑟𝑝𝑎 𝑝canbearandomtimeperiod\nwithoutnotifyingthecentralforsynchronization.TheperipheralwillcontinuetogeneratenewRPAsusingitsfreshesttimestamps,\nandeachofthoseRPAswillhavearandomlifespan.Whenthe\ncentralisback,theperipheralwillresumeitsstatebyre-entering\nits(𝑁+2)-thaddressrandomization.Specifically,sincethepe-\nripheralkeepsbroadcasting,andwheneverthecentralisclose\ntoit, thecentralcanrecognize itbycorrectlyresolving itsRPA.\nThen, the central sends a SCAN_REQ, which contains its latest\nRPA generated from the freshest timestamp, to inform the pe-\nripheral that it is back. When the peripheral receives the RPA, it\nenters the ( 𝑁+2)-th synchronized address randomization, and\nthen the central also enters the ( 𝑁+2)-th synchronized address\nrandomizationwhenitreceivesthe ADV_INDfromtheperipheral.\nThe following procedures are the same as that in scenario (a),\nwhich we will not present in further detail for brevity.\n(II)MakingRandomizationTimeIntervalConsistentandUn-\npredictable. Our randomization time interval needs to be a secret\n3188Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nAddr p = MAC p\ntp2 tp2\nAddr c = MAC c\ntc2 Addr c = MAC c\ntc1 Addr p = MAC p\ntp1\n AAÆ\nÆÆÆ\nSCAN_REQ  (Addr cÆ Addr p )\nSCAN_RSP (with Addr p )\nADV_IND  (with Addr p )\n AAA\nAAA\nADV_IND (with Addr p )\nAllowlisted Central\nTr (tc)\nSCAN\nSCAN\n REQ\nREQ\n (\n(\nAdd\nAdd\n(\n(\n(\n r\nr\nd\nd\nd\nc\nÆ\nÆ\nÆ\nÆ\nÆ\nÆ\nÆ\nAdd\nAdd\nr\nr\nd\nd\nd\np\nr\n)\n)\nADV\n_\nIND\n (\nwith \n Add\nr\nd\nd\np \nr\n)\nTr (tp)Time\nADV\n_\nIND\n (\nwith \n Add\nr\nd\nd\np \nr\n)\nTime\n tc1 tp1\ntc2\nPeripheral\nFigure 6: Status changing in the passive defense.\nandunpredicatabletoattackers.Toachievethat,thetwodevices\ncanintroduceanewsecretvalueorreuseexistingones(e.g.,IRK)to\nderivetherandomizedintervals.Thesecretalsoneedstobeupdateddynamicallyonbothsidestoensurethattherandomizationtimein-tervalscanalsobechangedsimultaneously.Assuch,weproposetousethehashofanauto-incrementedsecrettoderivetherandomiza-tiontimeinterval,sinceeverytimethevalueofsuchderivedsecret\nchanges,the derived randomization time interval changes as well.\nThedevicescanuseanexistingsecret 𝑆(e.g.,theLTK,ortheIRK)\nwithan automaticincrementto derivetherandom timeintervals.\nAssume there is an 𝑆0, which can be the IRK, and every time we\nupdatetheinterval 𝑆𝑗,weautomaticallyincreaseitby 𝑘(whichcan\nbe one or any other predefined number) from previous 𝑆𝑖.\n𝑆𝑗=𝑆𝑖+𝑘\nwhere𝑆0isassumedtobetheIRKforsimplicity.Then,wecanderive\nthe length of the randomization time interval at the 𝑖-thinterval\n𝑇𝑟(𝑖)=𝐻(𝑆𝑖)mod𝑇𝑚𝑎𝑥\nwhere𝑇𝑚𝑎𝑥is set to be 15 minutes, and 𝐻(𝑆𝑖)is the hash of 𝑆𝑖.A s\nsuch, at any given time interval 𝑖, both central and peripheral will\nhaveapre-determinedrandominterval 𝑇𝑟(𝑖)unknowntoattackers\nonce𝑆0, the initial secret, is exchanged.\nAlso, note that there has to be a unique secret 𝑆for each paired\ncentral and peripheral. But one central (e.g., a smartphone) can\nbepaired withmultipleperipherals.Therefore, therandomization\ntimeintervalandIRKmustbe 𝑆-specific.Thatis,acentralneedsto\nuse a peripheral-specific RPA-type MAC address correspondingly\ntoconnectitspairedperipherals.Finally,twopaireddevicesmay\nbeoutofsynchronization,e.g.,itissupposedtobe 𝑖-thinterval,but\nforsomereasons(e.g.,oneofthemlostitsbattery)theperipheral\nor thecentral maystill bein theprevious ( 𝑖-1)-thinterval or even\nmore. If this occurs, the devices have to correct the errors based ontheobservedintervals.Inparticular,whenacentralnoticesthatthe\ntwodevicesgetoutofsynchronizationbyobservingwhetherthe\nperipheral’s interval equals to its own currently used interval, the\ncentral starts the error handling process: the central first calculatesa few intervals (e.g., (\n𝑖-1)-th interval) that are close to the currently\nused interval (assume it is the 𝑖-th interval) based on the algorithm\nof how𝑇𝑟(𝑖)is derived, e.g., 𝑇𝑟(𝑖−1)=𝐻(𝑆𝑖−1)mod𝑇𝑚𝑎𝑥,𝑇𝑟(𝑖−\n2)=𝐻(𝑆𝑖−2)mod𝑇𝑚𝑎𝑥, and compares those calculatedintervals\ntocheckifanyofthemequalstotheperipheral’sinterval.Ifso,thecentralupdatesits\n𝑖(thecurrentinterval)accordingly,andtheerror\nis corrected (the central and the peripheral now have the same 𝑖).6.2 DefendingAgainst Active BATAttacks\nOverview. Fundamentally,ouractive BATattackworksbecause\nthe current RPA-type MAC address generation suffers from the\nreplayattack.Therearemultiplecountermeasurestodefeatareplay\nattack,e.g.,usingasequencenumber,oratimestamp,orstorage-\nbased(i.e.,savingalltheusedrandomnumbersontothedevices).\nHowever, not all of them are practical. For example, the storage-\nbased solution may cost huge amount of storage resource, e.g., up\nto365∗24∗4∗48=1,681,920MByearlyassumeaddressischanged\nevery 15 minutes (note that each address is 48 bits).\nAnother well-known defense against replay attack is to add ran-\ndom sequence numbers. Theoretically, we can add a synchronized,\nauto-incremented sequence number, together with the randomnumber prand, to generate a one-time only RPA-type MAC ad-\ndress. However, this defense will introduce additional storage and\ncommunicationoverhead,aswellasadditionalsequencenumber\nmaintenance efforts. For example, the central and the peripheral\nmust update their negotiated sequence number simultaneously to\nensuretheykeepthesamesequencenumber.Wethereforepropose\nto use the timestamps together with the random number prandto\ngenerate a one-time only RPA-type MAC address, which can only\nbe used within a given time window depending on the configu-ration. Note that a timestamp essentially can be considered as a\nsequence number, and it increases automatically as time passes by.\nHowever,wedidnotusethetimestampdirectlysincethiswill\nresult in the collision of the Bluetooth MAC address. Recall thatthe Bluetooth MAC address is 48 bits, and if we include a 24-bittimestamp in the MAC address, we only have 24 bits to ensure\nthe randomnessof the MACaddresses. Thiscan only resultin224\n(16,777,216) unique MAC addresses, which is much less than the\ncurrent number of Bluetooth devices (e.g., annual Bluetooth device\nshipments is 4.7 billion in 2021 [ 30]). Nevertheless, given that a\nspecificareamaynothavetoomanydevices,usingthetimestamps\ndirectly could still be a viable mitigation approach.\nDetailed Design. Our active defense is designed by piggybacking\nthe existing protocol without adding any extra field in the protocol\nbut only modifying the central and peripheral to process the times-\ntamp.Intotal,thereare4stepsinvolvedinournewdesign.Note\nthat in the following description, we assume the peripheral has\nenabledallowlist(sincethedefenseworkflowforthecentralwith\nallowlist is similar, we will not present it for brevity). Our defense\nalsoworks when both peripheral and central enable the allowlist.\n•StepKey Distribution. Assume that a peripheral 𝑝and a\ncentral𝑐have passed through the advertising stage, and now\ntheyareenteringthepairingstage.Whenthecentraldistributes\nitsIRK𝑖𝑟𝑘𝑐,italsodistributesthecurrenttimestamp 𝑇0𝑐ofthe\ncentral (i.e., 𝑇0𝑐=getCurrentTime( 𝑐)where getCurrentTime\nreturns the number of seconds since UNIX Epoc for 𝑐).\n•StepAllowlistingConfiguration.Theperipheral 𝑝receives\n𝑖𝑟𝑘𝑐,𝑇0𝑐,andgetsitscurrenttime 𝑇0𝑝viagetCurrentTime( 𝑝)at\n𝑝.Then,itsavesboth 𝑇0𝑝andthereceived 𝑖𝑟𝑘𝑐,and𝑇0𝑐forfuture\nreferencewhenresolvingtheRPA.Now 𝑝finishesconfiguring\nits allowlist, with which 𝑝will only respond to SCAN_REQ or\nCONNECT_REQ from this paired and allowlisted 𝑐.\n3189CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\n•StepRPA Generation. Later, when the central 𝑐receives\nanadvertisingpacketfrom 𝑝,itusesits 𝑖𝑟𝑘𝑐,arandomnumber\nprand24(withitstwoMSBbitstobe01todenoteRPA-typeMAC\naddress), andthe current time 𝑇𝑐to generate its current\n𝑟𝑝𝑎𝑐=(prand24||𝐻24(prand24||𝑇𝑐||𝑖𝑟𝑘𝑐))\nAfterthat, 𝑐cansendthisnewlygenerated 𝑟𝑝𝑎𝑐asusualinits\nSCAN_REQ orCONNECT_REQ to𝑝.Pleasenotethatthis timestamp\n𝑇𝑐should be used in all subsequent sessions within a random\ninterval (e.g., 15 minutes) to avoid the central changing its ad-\ndresses too often.\n•StepRPA Resolution. When 𝑝receives a SCAN_REQ with an\n𝑟𝑝𝑎𝑐,itresolvesthis 𝑟𝑝𝑎𝑐usingitsstored 𝑖𝑟𝑘𝑐asfollows.First,\nwefollowtheinitialRPAresolutionbysplitting 𝑟𝑝𝑎𝑐intotwo\nparts: the random number prand24andhash24. Next, we get 𝑇/prime𝑐\nfrom calculation:\n𝑇/prime\n𝑐=getCurrentTime (p)−(𝑇0\n𝑝−𝑇0\n𝑐)\nAfterfeedingthehashfunction 𝐻withthreeinputs 𝑖𝑟𝑘𝑐,prand24\nand𝑇𝑐to compute the hashed value:\nhash24/prime=𝐻24(prand24||𝑇/prime\n𝑐||𝑖𝑟𝑘𝑐))\nIfhash24equals to hash/prime\n24, this𝑟𝑝𝑎𝑐is resolved. If not, there\ncould be two possibilities. (i) The time on the central and the\nperipheral gets out of synchronization due to unknown reasons\n(e.g., clock skews). In that case, the peripheral may need to enu-\nmerateafewpossibletimestampswithinathreshold(e.g.,the\nthreshold could be oneif the peripheral attempts to try thefor-\nmer timestamp and the next timestamp) to correct the errors\nand update 𝑇𝑐if resolved. (ii) The address is a replayed one and\ntheperipheralshouldrejectit.Inthatcase,thetimestamphas\nsignificant differences when compared with the saved 𝑇/prime𝑐or the\ncurrent time (e.g., the difference is beyond a threshold).\n7 EVALUATION\nWehaveimplementedbothourattacksanddefensesfortheeval-\nuation. To implement our passive BATattack, we used Adafruit\nLE sniffer [ 31] to collect BLE advertising packets (i.e., ADV_IND,\nSCAN_REQ ,SCAN_RSP andCONNECT_REQ ).Toimplementour active\nBATattack, we customized Android 9.0 through the Android Open\nSourceProject(AOSP)[ 10]toimplementboththemaliciouscentral\nandthemaliciousperipheral.Toimplementourdefense,weused\nGoogle Pixel 2 asacentral,anda Nordic NRF52 developmentboard\nasaperipheralfortestingour SABLE.Intherestofthissection,we\npresent our evaluation results.\n7.1 ExperimentSetup\nDuetoethicsconcerns,wecanonlylaunchour BATattacksagainst\nourowndevicesconfiguredwithallowlist.Intuitively,keyboards,\nmouses, earbuds, and smart watches usually support a single user,\nand they tend to have an allowlist. We therefore first purchased\n43Bluetoothperipheralssuchaskeyboards,earbuds,andmouses,\nandamongthem,24ofthemhavetheallowlistenabled.Other19\nperipherals,whichdonothaveallowlist,areoutofourfocus.For\nthe central devices such as smartphones, fortunately they all have\nthe allowlist enabled, and therefore we used all of our own Blue-\ntooth centrals (6 smartphones, 3 laptops, and 2 tablets). We alsoPeripherals& Development Boards\nAllowlistPassive\nAttacksActive Attacks\nBrand & Model Device TypeMAC\nAddrPower\nSavingFrom\nMalicious\nCentralFrom\nMalicious\nPeripheral\nEnabled\nby PUsed\nby CTC TP TC TP TC TP\nDRACONIC /check /check Keyboard SRA /check /check/check/check/check/check/check\nJellyComb /check /check Keyboard SRA /check /check/check/check/check/check/check\niClever /check /check Keyboard SRA /check /check/check/check/check/check/check\nMicrosoft(V1) /check /check Keyboard SRA /check /check/check/check/check/check/check\nMicrosoft(V2) /check /check Keyboard SRA /check /check/check/check/check/check/check\nbyteblue /check /check Keyboard SRA /check /check/check/check/check/check/check\nLogitech K780 /check /check Keyboard SRA /check /check/check/check/check/check/check\nLogitech K830 /check /check Keyboard SRA /check /check/check/check/check/check/check\nLogitech K380 /check /check Keyboard SRA /check /check/check/check/check/check/check\nSXWL /check /check Keyboard SRA /check /check/check/check/check/check/check\nSXWL /check /check Mouse SRA /check /check/check/check/check/check/check\nInphic /check /check Mouse SRA /check /check/check/check/check/check/check\nVogek /check /check Mouse SRA /check /check/check/check/check/check/check\nJellyComb (V1) /check /check Mouse SRA /check /check/check/check/check/check/check\nJellyComb (V2) /check /check Mouse SRA /check /check/check/check/check/check/check\nSEENDA /check /check Mouse SRA /check /check/check/check/check/check/check\nMiBand 4C /check \u0017 Wristband PA \u0017/check/check/check/check\u0017/check\ni-Home Alexa \u0017 /check Speaker PA /check \u0017/check /check/check/check/check\nTEZO \u0017 /check Earbuds PA /check \u0017/check /check/check/check/check\nBoltune \u0017 /check Earbuds PA /check \u0017/check /check/check/check/check\nSoundBot \u0017 /check Earbuds PA /check \u0017/check /check/check/check/check\nRiitek \u0017 /check Keyboard PA /check \u0017/check\u0017/check/check/check\nCimetech \u0017 /check Mouse SRA /check \u0017/check\u0017/check/check/check\nErgonomic \u0017 /check Mouse SRA /check \u0017/check\u0017/check/check/check\nTI CC2640R2F /check/check Dev Board RPA - /check /check /check/check/check/check\nNordic NRF52 /check/check Dev Board RPA - /check /check /check/check/check/check\nSilicon Labs 6101D \u0017 /check Dev Board RPA - - - \u0017\u0017 /check/check\nCrypess CY8kCIT \u0017 /check Dev Board RPA - - - \u0017\u0017 /check/check\nCentrals\nAllowlistPassive\nAttacksActive Attacks\nBrand & Model Type & OSMAC\nAddrRandom\nIntervalFrom\nMalicious\nCentralFrom\nMalicious\nPeripheral\nEnabled\nby CUsed\nby PTP TC TP TC TP TC\nGoogle Pixel 4 /check/check Phone (Android 11) RPA 5-15 /check /check /check/check/check/check\nGoogle Pixel 2 /check/check Phone (Android 10) RPA 5-15 /check /check /check/check/check/check\nSamsung S10 /check/check Phone (Android 10) RPA 5-15 /check /check /check/check/check/check\nGoogle Piexl 4 /check/check Phone (Android 10) RPA 5-15 /check /check /check/check/check/check\niPhone 8 /check/check Phone (iOS 13.2) RPA 15 /check /check /check/check/check/check\niPhone 11 /check/check Phone (iOS 13.2) RPA 15 /check /check /check/check/check/check\niPad /check/check Tablet (iOS 13.2) RPA 15 /check /check /check/check/check/check\nDell GD1H4KU /check/check Laptop(Windows 10) PA +∞ /check/check/check /check /check /check\nDell /check/check Laptop(Ubuntu 20.02) PA +∞ /check/check/check /check /check /check\nThinkpad T450s /check/check Laptop(Windows 8) PA +∞ /check/check/check /check /check /check\nSurfacePro /check/check Tablet (Windows 10) PA +∞ /check/check/check /check /check /check\nTable 1: Evaluation results of the tested devices. “TC” means\ntrackingthecentraland“TP”meanstrackingtheperipheral.\n“/check” means vulnerable and “\u0017” means not.\npurchased a Bluetooth development board each from TI, Nordic,\nSilicon Labs, and Cypress, respectively. As reported in Table 1,w e\ntherefore eventually have 39 tested devices in total (11 centrals, 24\nperipherals, 4 development boards).\n7.2 Evaluation of Passive BATAttacks\nTotestourattacksagainstourowncentralsandperipherals,wefirst\nneedtopairthemup.Tothisend,foreachperipheral,weiterateour\ncentrals: if any of them can expose the vulnerability for the periph-eral,westoppairingmorecentralsandmovetothenextperipheral.\nAlso,duringourpairing,ifadeviceneverinvolvesallowlist(includ-\ning by its peer device), we discard it in our evaluation. As reported\ninTable1,thereare17peripheralsconfiguredwiththeallowlist,as\nshowninthe2ndcolumn.Unfortunately,allofthemarevulnerable\ntopassive BATattackstotracktheircorrespondingcentralssince\ntheyusedstaticaddresses,whicharesubjecttotrackingwithout\ndeploying our attacks at all as described in §3.1. We can also no-\nticethattheseperipheralsincludekeyboards,mouses,andsmart\nwristbands.Asexpected,thesedevicesareintendedforexclusive\nuse(asingleuser)andtendtohav etheallowlist.H owever,other\nIoTdevicessuchassmartspeakerstendnottohavetheallowlist\nsince they are household devices (serving more than one user).\n3190Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\n(a)(b)(c) (d)\nFigure 7: Power Consumption of SABLEdefense.\nFigure 8: Performance of SABLEfor active defense\nSince all the peripherals are vulnerable to the simple passive\nattacks described in §3.1, we have not validated the passive at-\ntacks introduced in §4. To really evaluate these attacks, we use\n4 development boards with RPAs, and pair the smartphone with\nthem. Among them, only TI CC2640 and Nordic NRF52 support al-\nlowlist [32,33], and the development boards (as well as the devices\nthatusedthosedevelopmentboards)areconfirmedvulnerableto\nourpassiveattacks.Also,whilethetestedcentralsareallvulnerable\ntoBATattacks, we notice that the randomization interval is varied\nfromtheoperatingsystems.Forexample,Android-11changesits\ninterval toevery 5 to 15minutes, but iOSstays a constant 15min-\nutes. Meanwhile, Windows and Linux laptops use public addresses\nwithout randomization. In addition, as reported in the 6th column\nofTable 1, among the tested peripherals, we notice that only the\nwristbandwill alwaysstayawake.\n7.3 Evaluationof Active BATAttacks\nActive BATAttacksfromMaliciousCentrals. Sincetheactive\nBATattacks from malicious centrals require the victim peripherals\ntohaveallowlist(regardlessofwhetherornottheyhaveusedstatic\naddresses)andconfigure advertisingfilterpolicy,andinourpassive\nattackswehavealreadyidentifiedthatthereare17peripheralscon-figuredwithallowlist(asreportedinthesecondcolumnof Table1),\nallofthemcanbeusedtolaunch BATfrommaliciouscentralsto\ntrackvictim’scentrals.Whenconfiguringthe4developmentboards\nwith RPAs, only TI CC2640 and Nordic NRF52 can be used to track\nboth the central and the peripheral from a malicious central, since\nonly they support the allowlist [32, 33].\nActive BATAttacksfromMaliciousPeripherals. Similarly,since\nthe active BATattacks from malicious peripherals leverage the ini-\ntiator filter policy, which requires the central to add the peripherals\nto its allowlist for auto-connection, for each central we iterate ourperipherals to pair it and then test whether the central will initiate\ntheconnectionrequestswithoutmanuallytriggeringtheconnec-\ntioninthe Settings app.Ifso,theperipheralscanbeusedtolaunch\nBATattacksfrommaliciousperipheralstotracktheircentrals.As\nreported in Table 1, all of the tested devices are subject to tracking\nofperipherals(thelastcolumn),andtrackingofcentralsexceptthe\ntested Wristband since its central does not use allowlist.\n7.4 Evaluation of SABLE\nEffectivenessof SABLE.We launchedboth ourpassive andactive\nattacksagainagainstourpatched Google Pixel 2 andNRF52,and\nconfirmed that the attacks no longer work. In particular, ( 𝑖) in pas-\nsive attacks,where MAC addresses randomizeon both sidesin a\nsynchronizedrandominterval,attackerscannotobservepredictable\npatterns between centrals and peripherals; ( 𝑖𝑖) in active attacks,\nSABLErejectedallreusedpackets,andattackerscouldnotlinkany\nused RPAs to the new ones by replaying (including via tunnelling).\nPowerandPerformanceOverhead. Sinceourdefenseintroduces\nextraoperations,whichwillcertainlyresultinbothpowerconsump-\ntion and performance overhead. To quantify the battery impact on\ncentral devices, we directly monitor it through the battery level.\nTo quantify the battery impact on peripherals, we measured our\ntested NRF52developmentboard,withanAgilent34410AMulti-\nmetertosampletheelectriccurrentof NRF52thatrunswithour\nSABLE(and without SABLE), and calculate the average current\n𝐼𝑎𝑣𝑔,fromwhichtoapproximatethebatterylife,usingthestandard\n𝑇𝑏𝑎𝑡=𝐶𝑏𝑎𝑡/𝐼𝑎𝑣𝑔[34], where 𝐶𝑏𝑎𝑡is the battery capacity.\n•Active Defense. Since our active defense piggybacks the ex-\nisting pairing messages, we measured the approximation of the\nbattery life of our defense and compared it with the vanilla pair-\ningprotocol.Accordingtoourexperiment,theremainingbattery\npercentage decreases linearly, and there is no extra overhead\nobserved, as shown in Figure 7a. Also, the average current of\nNRF52running SABLEpairing process is 54 .3𝜇𝐴, and the av-\nerage current when NRF52running vanilla pairing process is\n52.7𝜇𝐴(an extra 3.04% overhead). This overhead is negligible\nfor a battery lifetime across different battery capacities, as illus-\ntrated in Figure 7b. To measure the performance of our active\ndefense,werunbothourandvanillaRPAgenerationandreso-\nlution 100 timeson both Google Pixel 2 andNRF52, respectively.\nFigure8showsthese results.Wecanobserve thattheaverage\noverhead on NRF52is around 63.58 (94.46-30.88) 𝜇𝑠whereas the\nsmartphoneis around 20.54 (88.49-67.95) 𝜇𝑠.\n3191CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\n•PassiveDefense. Forpassivedefensewithsynchronizedran-\ndom intervals, it does not have any additional overhead if its\n𝑇𝑟(𝑡)is set to be a fixed 15 minutes (as in iOS) since it does\nnothaveanyadditionaloperations.However,if 𝑇𝑟(𝑡)becomes\nsmaller, there will be more frequent address randomizations,\ncausing more overhead. To quantify this power consumption,\nwe set 15 minutes as the baseline, vary 𝑇𝑟(𝑡)from 3 to 15 with a\nstride3. Theoverheadon thecentraldevice isaround1%, even\nif we set 𝑇𝑟(𝑡)=1 (i.e., randomizing at every minute). For the\nperipheral,asshownin Figure7d,only6.75%extrapowercon-\nsumptionisintroducedwhen 𝑇𝑟(𝑡)=1,whichisalsonegligible.\nForitsperformance,asshownin Figure8,wecanseethatittakes\naround88 .49𝜇sand94.46𝜇sforamobileanddevelopmentboard\nto generate an address, respectively (with our active defense).\nTherefore, compared to the address randomization interval (e.g.,\na few minutes), such a tiny amount of time is negligible.\n8 DISCUSSION\nPracticality and Comparison. We have presented one passive\nBATattack and two active BATattacks. Next, we would like to\ncompare the practicality (i.e., the cost, difficulty, and impact) ofeach attack. In particular, the cost is measured by the resourcesspent and also the efforts taken by the attackers; the difficulty is\nmeasured by the condition of the victim central and peripheral\n(e.g., whether the attacks require the two devices to be nearby);\nthe impacts are the possible consequences caused by the attack. As\nsummarized in Table 2, it can be observed that:\n•PassiveAttacks (§4). Sincethese attacksinvolveonly sniffers,\nthey are less costly. Meanwhile, the attacks do not require at-\ntackers to keep probing or building a tunnel. However, such\nattacks need uninterrupted monitoring of the traffic. Otherwise,\ntheattackerwilllosethetarget.Moreover,theattackswillfail\nwhen the central and peripheral are not within the reach.\n•ActiveAttacksfromMaliciousCentrals(§5.1). Whencom-\nparedwiththepassiveattacks,theactive BATattacksfromama-\nlicious central do not have the distance limit and do not require\nuninterruptedmonitoringofthevictim.Moreover,inaddition\ntomonitoringuserbehaviors,attackscanalsobeusedtotrack\navictim’spasttrajectoryorinstantlocation.However,suchat-\ntacks are also subject to limitations: when launching the attacks,\nthe attacker must probe multiple devices with SCAN_REQ or\nSCAN_RSP in order to identify the one of interest. Such oper-\nationscan be costly when there are too many devices nearby.\n•ActiveAttacksfromMaliciousPeripherals(§5.2). Theac-\ntiveBATattacks from malicious peripherals are most impactful,\npractical,andlesscostly.First,similartotheotheractiveattacks,\nthe attackers can launch such attacks without a distance limit\nand uninterrupted monitoring of the victims. Second, instead of\nprobing each device independently, such attacks use ADV_IND,\nwhichisabroadcastmessage.Thatis,oncetheattackerbroad-\ncasts a single ADV_IND with an old MAC address, the victim\ncentralwillexpose itself instantly if it is nearby.\nSecurity Analysis of Our Defenses. In our passive BATdefense,\nwe rely on synchronized random time intervals at both central and\nperipheraltodefeatcrossintervalMACaddresstracking.Intuitively,sincethedefenserequiressynchronizedrandomtimeintervalsto\nwork,andiftheattackercanmanipulateintervalsbyremoving(e.g.,\nthroughjamming)orinjectingpacketsthatarerequiredforboth\nthecentralandperipheraltoexecutethesynchronization,itwill\ndisableourdefense.However,whileitistruethatthemanipulationmayresultinthedenialofservice(DoS)attack,theattackercannotfurthertrackthecentralortheperipheral.Sincethecentralandthe\nperipheralcanbefarawayfromorclosetoeachother(See§6.1),\nwe then have the following two cases to analyze:\n•Twodevicesarefaraway. Inthiscase,thetwodevicesindepen-\ndently perform their address randomization, and SCAN_REQ or\nSCAN_RSP sentfrom thetwodevices willnotbeused toperform\nthesynchronization.Assuch,iftheattackerremovessomeorallofthosepackets,thedeviceswillbehaveasnormal,noimpacton\ntherandomtimeintervals.Meanwhile,sincetheattackerdoes\nnot have the corresponding IRK, he or she cannot create and\nforge a packet with a valid MAC address. The attacker may also\nreplayanusedpacket,butitisbepreventedbyouractivedefense.\n•Two devices are close to each other. In this case, the devices\nperform randomization according to the exchanged SCAN_REQ\nandSCAN_RSP . First, removing some of those packets intention-\nally may result in the failure of the synchronization (e.g., it is\nsupposedtobethe 𝑖-thinterval,buttheperipheralorthecentral\nmay still be in the previous ( 𝑖-1)-th interval). However, an error\ncorrectionmechanismcanmaketherandomtimeintervalstobe\nre-synchronized.Second,forgingorreplayingthepacketswill\nnotworktoo,thereasonsofwhicharesimilartotheprevious\ncase, thereby omitted for brevity.\nIn an extreme case, the attacker may first remove some of the\npacketsfrom the traffic, and thenreplay those “removed” packets,\ninthepurposeofbreakingour BATactivedefense.Suchattackwill\nnotworkaswell.Assumethatat 𝑡0,theattackerfirstremovesall\nthe packets sent from the peripheral, and then saves those packets.\nAt𝑡1(i.e.,𝑡0+𝑇), the attacker sends out the collected packets to\nprobethecentral(s).The“true”centralwillbeabletoresolveit,and\nquickly notice those packets are old ones due to the significant dif-\nferencesbetweenthosepacketsandthecurrenttime(thoughthose\npacketshaveneverbeenobservedbefore),therebystilldefeating\nsuchattacks.Certainly,iftheattackerobtainstheIRKofthecentral\nor the peripheral, our defense will fail since he or she can forge\nthe MAC address based on our proposed randomization algorithm.\nHowever, we consider this to be hard since the transmission of the\nIRKis protected by encryption.\nEthics and Responsible Disclosure. We did take ethics into\nthe highest possible standard when launching our BATattacks.\nFirst, we only performed our attacks against our own devices. Sec-\nond,wehavedisclosedthisvulnerabilitytoBluetoothSIG,Apple,\nGoogle,Microsoft,TexasInstruments(TI),andNordic.Bluetooth\nSIGassignedCVE-2020-35473totrackthislogical-leveldesignflaw,\nGoogle assigned Android-ID 175212130 (and rated our vulnera-bility as the second highest severity among the total five-levels)and rewarded us with a bug bounty, Apple assigned an internal\nvulnerability-ID 755406462, Microsoft assigned an internal case\ntracking-IDMSRC-63104,andTIinformedusthattheyaretracking\nthe Bluetooth SIG’s recommendations for fixing this vulnerability.\n3192Tracking Bluetooth Low Energy Devices via Allowlist-based Side Channel and Its Countermeasure CCS ’22, November 7–11, 2022, Los Angeles, CA, USA.\nThe BATAttacksCost DifficultyImpacts\nInvolved\nMalicious DevicesUninterrupted\nPassively MonitoringKeeping\nActively ProbingTunnelling(Requiring Central and\nPeripheral to be Nearby)\nPassive Attacks (§4) Sniffer /check \u0017\u0017 /check \nActive Attacks from Malicious Centrals (§5.1) Sniffer, Central, Peripheral \u0017 /check/check &\u0017\u0017  ,,\nActive Attacks from Malicious Peripherals (§5.2) Sniffer, Peripheral \u0017\u0017 \u0017 \u0017  ,,\nTable2:SummaryofOurAttacks. means“monitoringtheuser’sbehavior”, means“trackingavictim’spasttrajectory”,\nandmeans “trackinga victim’s real time location”.\n9 RELATED WORK\nBluetoothPrivacy. Overthepast20years,numerousBluetoothde-\nvicetrackingattackshavebeenproposedbycollectingtheadvertis-\ningpackets(e.g., ADV_IND,SCAN_REQ )usingsniffers[ 1–5,13,14,25–\n27,35–37],assummarizedin Table3.Amongthem,earlierefforts\nsuch as BlueTrack [13] and BLEB[14] track the Bluetooth devices\nthat use public addresses. Marco et al. [ 27] track the Bluetooth\nclassic devices that do not use address randomization via the infor-\nmationleaked from the frame encoding.\nHowever, when the devices use randomized MAC addresses,\nalthough intuitively one can associate a disappeared address and a\nnewlyappearedaddresstobreaktheaddressrandomization,one\nlocation can have multiple devices, which can appear or disappear\nsimultaneously (e.g., turning on/off devices, devices moving out/in\ntherangeofsniffers).Assuch,monitoringthedevicessolelywill\nhave high false alerts, and extra efforts are needed for the tracking.\nTothisend,Ludantetal.[ 26]linkedandtrackedtheBLEaddresses\nvia the collection of Bluetooth Classic (BT) Addresses. Our attacks\ninsteaddonotneedtocollectbothBluetoothclassicpackets(which\nare hard to be collected as discussed in [ 27]) and BLE packets, and\nwe only need to collect BLE advertising packets.\nThere are also tracking attacks against specific implementations\nofBluetoothdevices(e.g.,Appledevices[ 36–39]andwearablefit-\nness trackers [ 40]). Some attacks exploit static payloads (e.g., fixed\nmanufacture identifiers [ 2,3], fixed information elements [ 41,42],\nand fixed GATT attribute [ 43])) to track devices. Most of those\nattacks are implementation specific (which usually requires un-\nchanged payload), whereas our BATattacks are based on protocol\nlevel flaws we identified. There are also tracking attacks requiring\nthe attacker to obtain keys (e.g., [ 25,44,45]). Our attacks do not\nmakesuchassumption.Moreover,unlikethetraditionaltracking\nattacks [3,18], where the attacker has to collect many BLE packets\nandanalyzethemonebyonetoidentifythevictim,ourattackfrom\nmaliciousperipherals,forexample,replaysanoldpacketandthe\nvictimwill be exposed instantly.\nBluetoothSecurity. Bluetootharealsosubjecttomultiplesecu-\nrityattackssuchasbruteforceattacksagainstPIN(e.g.,[ 46,47]),\neavesdroppingattacks(e.g.,[ 48–50]),MiTMattacks[ 51–54],and\nvulnerable pairing (e.g., [ 23,55,56]). In addition to these link layer\nattacks,therearealsoeffortstargetedonBluetoothapplications.For\nexample,theBluetooth Misbonding Attacks[21]targetperipherals\nthatdonotenforceapplicationlayerauthenticationand BadBlue-\ntooth[20]exploitstheweaknesswhenthecentraldoesnotauthen-\nticate the peripherals. Compared to these works, we are the first\nto exploit the allowlist in Bluetooth protocol for device tracking.\nPriorattacksinwirelesssensornetworkscouldalsobeapplied\nto Bluetooth. For instance, in our Attack Example III, we haveAttacks Non-Implementation SpecificAgainst RPAw/o Unchanged Payloadsw/o Installing Malwarew/ either BLE or BT Packetsw/o Stealing IRK/Key\nJakobsson et al. [1] \u0017\u0017\u0017 /check/check/check\nBlueTrack [13] \u0017\u0017\u0017 /check/check/check\nBLEB[13] \u0017\u0017\u0017 /check/check/check\nBLE-Guardian [2] \u0017 /check \u0017 /check/check/check\nKorolova et al. [5] \u0017 /check \u0017\u0017 /check/check\nBecker et al. [3] \u0017 /check \u0017 /check/check/check\nMartin et al. [37] \u0017 /check \u0017 /check/check/check\nCelosia et al. [4] \u0017 /check \u0017 /check/check/check\nBLEScope [19] \u0017\u0017\u0017 /check/check/check\nStute et al.(2019) [39] \u0017 /check \u0017 /check/check/check\nMarco et al. [27] \u0017\u0017 /check/check/check/check\nZhang et al. [25] \u0017 /check/check/check/check \u0017\nFirmwXray [35] \u0017\u0017 /check/check/check/check\nGuillaume et al. [36] \u0017 /check \u0017 /check/check/check\nCominelli et al. [27] \u0017\u0017\u0017 /check/check/check\nStute et al.(2021) [38] \u0017 /check \u0017 /check/check/check\nHeinrich et al. [44] \u0017 /check/check/check/check \u0017\nLudant et al. [26] \u0017 /check \u0017 /check \u0017 /check\nBATAttacks /check/check/check/check/check/check\nTable 3: Comparison of our BATattackswith others.\nleveragedtheconceptofthewormholeattacks[ 29]toestablisha\ntunnelbetweenasnifferandthemaliciouscentrallocatednearby\nofthestationaryperipheral.Whilewormholeattackalonecouldbe\nusedtotunnelconnectionsbetweenacentralandaperipheralto\nidentifyadevice,itwouldrequireadditionalinformationsuchasour\nallowslisting side channels when there are multiple devices nearby.\n10 CONCLUSION\nWe have presented BATattacks by exploiting the single-bit of side\nchannel of response and no-response from BLE devices with al-\nlowlist to track their randomized MAC addresses. Our attacks can\nbelaunchedpassively,oractivelyduetothevulnerabilityofcurrent\nRPAgenerationand resolutionalgorithm.Wehave also presented\ndefense SABLE,byadding arandomsequence number whengen-\neratingandresolvingtheRPA-typeMACaddressestodefeatour\nactive BATattacks,andenforcinganintervalunpredictable,central\nand peripheral synchronized RPA generation scheme to counter\npassive attacks. The experimental results show that our defense\nhas negligible impact on both the battery consumption and perfor-\nmanceoverhead for the involved centrals and peripherals.\nACKNOWLEDGEMENTS\nWewouldliketothankShuoChen,SyedRafiulHussain,MotiYung,\nand the anonymous reviewers for their helpful comments on an\nearly draft of this paper. This research was partially supported by\nNSF award 2112471.\nREFERENCES\n[1]M.JakobssonandS.Wetzel,“Securityweaknessesinbluetooth,”in Cryptogra-\nphers’ Track at the RSA Conference. Springer, 2001, pp. 176–191.\n[2] K. Fawaz, K.-H. Kim, and K. G. Shin, “Protecting privacy of ble device users,” in\n25th USENIX Security Symposium (USENIX Security 16), 2016, pp. 1205–1221.\n3193CCS ’22, November 7–11, 2022, Los Angeles, CA, USA. Yue Zhang & Zhiqiang Lin\n[3]J. K. Becker, D. Li, and D. Starobinski, “Tracking anonymized bluetooth devices,”\nProceedings on Privacy Enhancing Technologies (PETS), vol. 2019, no. 3, pp. 50–65,\n2019.\n[4]G. Celosia and M. Cunche, “Saving private addresses: an analysis of privacy\nissues in the bluetooth-low-energy advertising mechanism,” in Proceedings of the\n16thEAIInternationalConference onMobileandUbiquitousSystems:Computing,\nNetworking and Services, 2019, pp. 444–453.\n[5]A.KorolovaandV.Sharma,“Cross-apptrackingvianearbybluetoothlowenergy\ndevices,”in ProceedingsoftheEighthACMConferenceonDataandApplication\nSecurity and Privacy (CODASPY), 2018, pp. 43–52.\n[6]S. Bluetooth, “Bluetooth core specification version 4.2,” Specification of the Blue-\ntooth System, 2014.\n[7]AppleInc.,“AccessoryDesignGuidelinesforAppleDevices),” https://developer.\napple.com/accessories/Accessory-Design-Guidelines.pdf , 2019.\n[8]S. Bluetooth, “Bluetooth core specification version 4.1,” Specification of the Blue-\ntooth System, 2011.\n[9]——, “Bluetooth core specification version 5.2,” Specification of the Bluetooth\nSystem, 2020.\n[10] Google, “Android open source project,” https://source.android.com/.\n[11]Nordic, “Bluetooth programming framework,” https://embeddedcentric.com/no\nrdic-ble-training/.\n[12]Bluetooth-SIG, “Bluetooth core specification version 4.0,” Specification of the\nBluetooth System, 2010.\n[13]M.Haase,M.Handy etal.,“Bluetrack–imperceptibletrackingofbluetoothde-\nvices,” in Ubicomp Poster Proceedings, vol. 2, 2004.\n[14]T. Issoufaly and P. U. Tournoux, “Bleb: Bluetooth low energy botnet for large\nscale individual tracking,” in 2017 1st International Conference on Next Generation\nComputing Applications (NextComp). IEEE, 2017, pp. 115–120.\n[15]Amazon, “Pro wireless controller for nintendo switch bluetooth controllers\ngamepad pc joystick controller for switch controllers with dual vibrations\nand motion sensors,” https://www.amazon.com/Bluetooth-Wireless-NS-Switch-\nJoystick-Controller/dp/B08FMH783R/ .\n[16]Google, “Android 6.0 changes,” https://developer.android.com/about/versions/m\narshmallow/android-6.0-changes#behavior-hardware-id , 2016.\n[17]C. Ellis, H. Wen, Z. Lin, and A. Arora, “Replay (far) away: Exploiting and fix-\ninggoogle/appleexposurenotificationcontacttracing,” ProceedingsonPrivacy\nEnhancing Technologies (PETS), vol. 2022, no. 4, 2022.\n[18]C. Matte, M. Cunche, F. Rousseau, and M. Vanhoef, “Defeating mac address\nrandomization through timing attacks,” in Proceedings of the 9th ACM Conference\non Security & Privacy in Wireless and Mobile Networks, 2016, pp. 15–20.\n[19]C.Zuo,H.Wen,Z.Lin,andY.Zhang,“Automaticfingerprintingofvulnerable\nble iot devices with static uuids from mobile apps,” in Proceedings of the 2019\nACM SIGSAC Conference on Computer and Communications Security, 2019, pp.\n1469–1483.\n[20]F. Xu, W. Diao, Z. Li, J. Chen, and K. Zhang, “Badbluetooth: Breaking android\nsecuritymechanismsviamaliciousbluetoothperipherals,”in Proceedingsofthe\n26th Annual Network and Distributed System Security Symposium (NDSS’19), San\nDiego, CA, 2019.\n[21]M.Naveed,X.Zhou,S.Demetriou,X.Wang,andC.A.Gunter,“Insidejob:Un-\nderstandingandmitigatingthethreatofexternaldevicemis-bindingonandroid,”\nin21stAnnualNetworkandDistributedSystemSecuritySymposium,NDSS2014,\nSan Diego, California, USA, February 23-26, 2014, 2014.\n[22]L. H. NEWMAN, “Sneaky zero-click attacks are a hidden menace,” https:\n//www.wired.com/story/sneaky-zero-click-attacks-hidden-menace/,April2020,\n(Accessed on 12/24/2021).\n[23]D.Antonioli,N.O.Tippenhauer,andK.Rasmussen,“Bias:Bluetoothimperson-\nationattacks,”in ProceedingsoftheIEEESymposiumonSecurityandPrivacy(S&P),\n2020.\n[24]D. Antonioli, N. O. Tippenhauer, and K. B. Rasmussen, “The {KNOB}is broken:\nExploiting low entropy in the encryption key negotiation of bluetooth br/edr,” in\n28th{USENIX}SecuritySymposium( {USENIX}Security19),2019,pp.1047–1061.\n[25]Y. Zhang, J. Weng, R. Dey, Y. Jin, Z. Lin, and X. Fu, “Breaking secure pairing\nofbluetoothlowenergyusingdowngradeattacks,”in 29th{USENIX}Security\nSymposium ( {USENIX}Security 20), 2020, pp. 37–54.\n[26]N.Ludant,T.D.Vo-Huu,S.Narain,andG.Noubir,“Linkingbluetoothle&classic\nand implications for privacy-preserving bluetooth-based protocols,” in 2021 IEEE\nSymposium on Security and Privacy (SP), 2021.\n[27]M. Cominelli, F. Gringoli, P. Patras, M. Lind, and G. Noubir, “Even black cats\ncannot stay hidden in the dark: Full-band de-anonymization of bluetooth classic\ndevices,”in 2020IEEESymposiumonSecurityandPrivacy(SP) . IEEE,2020,pp.\n534–548.\n[28]SENA, “Patch antenna - rp-sma-r/a right-hand thread, 9dbi,” http://www.senane\ntworks.com/pat-g01r.html.\n[29]Y.-C. Hu, A. Perrig, and D. B. Johnson, “Wormhole attacks in wireless networks,”\nIEEE journal on selected areas in communications, vol. 24, no. 2, pp. 370–380, 2006.\n[30]Statistics, “Bluetooth device shipments worldwide from 2015 to 2026,”\nhttps://www.statista.com/statistics/1220933/global-bluetooth-device-shipment-\nforecast/, April 2020, (Accessed on 12/24/2021).[31]Adafruit,“Adafruitsniffer,” https://learn.adafruit.com/introducing-the-adafruit-\nbluefruit-le-sniffer/introduction .\n[32]Ganesh, “The current psoc ez-serial fw does not support rpa for whitelist,”\nhttps://community.cypress.com/thread/51728?start=0&tstart=0 , 2020.\n[33]S. Labs, “Twhitelisting (silcon labs official document),” https://docs.silabs.com/bl\nuetooth/3.0/general/adv-and-scanning/whitelisting, 2020.\n[34]E. Garcia-Espinosa, O. Longoria-Gandara, I. Pegueros-Lepe, and A. Veloz-\nGuerrero, “Power consumption analysis of bluetooth low energy commercial\nproducts and their implications for iot applications,” Electronics, vol. 7, no. 12, p.\n386, 2018.\n[35]H. Wen, Z. Lin, and Y. Zhang, “Firmxray: Detecting bluetooth link layer vul-\nnerabilitiesfrombare-metalfirmware,”in Proceedingsofthe2019ACMSIGSAC\nConferenceon Computer and Communications Security, 2020.\n[36]G.CelosiaandM.Cunche,“Discontinuedprivacy:Personaldataleaksinapple\nbluetooth-low-energycontinuityprotocols,” ProceedingsonPrivacyEnhancing\nTechnologies, vol. 2020, no. 1, pp. 26–46, 2020.\n[37]J.Martin,D.Alpuche,K.Bodeman,L.Brown,E.Fenske,L.Foppe,T.Mayberry,\nE. Rye, B. Sipes, and S. Teplov, “Handoff all your privacy–a review of apple’sbluetooth low energy continuity protocol,” Proceedings on Privacy Enhancing\nTechnologies, vol. 2019, no. 4, pp. 34–53, 2019.\n[38]M.Stute,A.Heinrich,J.Lorenz,andM.Hollick,“Disruptingcontinuityofapple’s\nwirelessecosystemsecurity:Newtracking, {DoS},and{MitM}attackson {iOS}\nand{macOS}through bluetooth low energy, {AWDL}, and{Wi-Fi},” in30th\nUSENIX Security Symposium (USENIX Security 21), 2021, pp. 3917–3934.\n[39]M.Stute,S.Narain,A.Mariotto,A.Heinrich,D.Kreitschmann,G.Noubir,and\nM.Hollick,“Abillionopeninterfacesforeveandmallory: {MitM},{DoS},and\ntrackingattackson {iOS}and{macOS}throughapplewirelessdirectlink,”in\n28th USENIX Security Symposium (USENIX Security 19), 2019, pp. 37–54.\n[40]A. K. Das, P. H. Pathak, C.-N. Chuah, and P. Mohapatra, “Uncovering privacy\nleakage in ble network traffic of wearable fitness trackers,” in Proceedings of\nthe17thInternationalWorkshoponMobileComputingSystemsandApplications.\nACM, 2016, pp. 99–104.\n[41]M. Vanhoef, C. Matte, M. Cunche, L. S. Cardoso, and F. Piessens, “Why mac\naddress randomization is not enough: An analysis of wi-fi network discovery\nmechanisms,” in Proceedings of the 11th ACM on Asia conference on computer and\ncommunications security, 2016, pp. 413–424.\n[42]H. Wen, Q. Zhao, Z. Lin, D. Xuan, and N. Shroff, “A study of the privacy of\ncovid-19contacttracingapps,”in InternationalConferenceonSecurityandPrivacy\nin Communication Networks, 2020.\n[43]G. Celosia and M. Cunche, “Fingerprinting bluetooth-low-energy devices based\non the generic attribute profile,” in Proceedings of the 2nd International ACM\nWorkshop on Security and Privacy for the Internet-of-Things, 2019, pp. 24–31.\n[44]A. Heinrich, M. Stute, T. Kornhuber, and M. Hollick, “Who can devices? secu-\nrityandprivacyofapple’scrowd-sourcedbluetoothlocationtrackingsystem,”\nProceedingsonPrivacyEnhancingTechnologies,vol.2021,no.3,pp.227–245,2021.\n[45]A. Heinrich, M. Stute, and M. Hollick, “Openhaystack: a framework for tracking\npersonalbluetoothdevicesviaapple’smassivefindmynetwork,”in Proceedingsof\nthe14thACMConferenceonSecurityandPrivacyinWirelessandMobileNetworks,\n2021, pp. 374–376.\n[46]A. Becker and I. C. Paar, “Bluetooth security & hacks,” Ruhr-Universität Bochum,\n2007.\n[47]Y. Shaked and A. Wool, “Cracking the bluetooth pin,” in Proceedings of the 3rd\ninternationalconferenceonMobilesystems,applications,andservices. ACM,2005,\npp. 39–50.\n[48]D.SpillandA.Bittau,“Bluesniff:Evemeetsaliceandbluetooth.” WOOT,vol.7,\npp. 1–10, 2007.\n[49]M. Ryan, “Bluetooth: With low energy comes low security,” in Proceedings\nof the 7th USENIX Conference on Offensive Technologies, ser. WOOT’13.\nBerkeley, CA, USA: USENIX Association, 2013, pp. 4–4. [Online]. Available:\nhttp://dl.acm.org/citation.cfm?id=2534748.2534754\n[50]T. Rosa, “Bypassing passkey authentication in bluetooth low energy.” IACR Cryp-\ntology ePrint Archive, vol. 2013, p. 309, 2013.\n[51]D.Kügler,““maninthemiddle”attacksonbluetooth,”in InternationalConference\non Financial Cryptography. Springer, 2003, pp. 149–161.\n[52]K.HaatajaandP.Toivanen,“Twopracticalman-in-the-middleattacksonblue-\ntooth secure simple pairing and countermeasures,” IEEE Transactions on Wireless\nCommunications, vol. 9, no. 1, 2010.\n[53]K. Hypponen and K. M. Haataja, ““nino” man-in-the-middle attack on bluetooth\nsecuresimplepairing,”in 20073rdIEEE/IFIPInternationalConferenceinCentral\nAsia on Internet. IEEE, 2007, pp. 1–5.\n[54]Y.Zhang,J.Weng,Z.Ling,B.Pearson,andX.Fu,“Bless:Ableapplicationsecurity\nscanning framework,” in IEEE INFOCOM 2020-IEEE Conference on Computer\nCommunications. IEEE, 2020, pp. 636–645.\n[55]D.Antonioli,N.O.Tippenhauer,andK.Rasmussen,“Lowentropykeynegotiation\nattacksonbluetoothandbluetoothlowenergy.” IACRCryptol.ePrintArch.,vol.\n2019, p. 933, 2019.\n[56]——,“Keynegotiationdowngradeattacksonbluetoothandbluetoothlowenergy,”\nACM Transactions on Privacy and Security (TOPS) , vol. 23, no. 3, pp. 1–28, 2020.\n3194"}
{"title": "When the Differences in Frequency Domain are Compensated: Understanding and Defeating Modulated Replay Attacks on", "content": "When the Differences in Frequency Domain are Compensated:\nUnderstanding and Defeating Modulated Replay Attacks on\nAutomaticSpeec hRecognition\nShu Wang1, Jiahao Cao1,2,X uH e1, Kun Sun1,Q iL i2\n1Department of Information Sciences and Technology, CSIS, George Mason University\n2Institute for Network Sciences and Cyberspace, Tsinghua University; BNRist\n{swang47,xhe6,ksun3}@gmu.edu,caojh15@mails.tsinghua.edu.cn,qli01@tsinghua.edu.cn\nABSTRACT\nAutomatic speec h recognition (ASR) systems have been widely\ndeployed in modern smart devices to provide convenient and di-\nversevoice-controlledservices.SinceASRsystemsarevulnerable\nto audio replay attacks that can spoof and mislead ASR systems, a\nnumberofdefensesystemshavebeenproposedtoidentifyreplayed\naudiosignalsbasedonthespeakers’uniqueacousticfeaturesinthe\nfrequencydomain.Inthispaper,weuncoveranewtypeofreplay\nattackcalled modulatedreplayattack,whichcanbypasstheexisting\nfrequency domain based defense systems. The basic idea is to com-\npensateforthefrequencydistortionofagivenelectronicspeaker\nusinganinversefilterthatiscustomizedtothespeaker’stransform\ncharacteristics. Our experiments on real smart devices confirm the\nmodulatedreplayattackscansuccessfullyescapetheexistingdetec-tion mechanisms that rely on identifying suspicious features in the\nfrequency domain.To defeatmodulated replay attacks,we design\nandimplementacountermeasurenamed DualGuard.Wediscover\nand formally prove that no matter how the replay audio signalscould be modulated, the replay attacks will either leave ringing\nartifactsin the time domain or cause spectrum distortion in the fre-\nquency domain. Therefore, by jointly checking suspicious features\ninbothfrequencyandtime domains,DualGuardcansuccessfully\ndetect various replay attacks including the modulated replay at-\ntacks. We implement a prototype of DualGuard on a popular voice\ninteractive platform, ReSpeaker Core v2. The experimental results\nshowDualGuardcanachieve98%accuracyondetectingmodulated\nreplay attacks.\nCCS CONCEPTS\n•Security and privacy →Security in hardware ;•Human-\ncentered computing →Human computer interaction (HCI) .\nKEYWORDS\nmodulated replay attack; automatic speech recognition; ringing\nartifacts; frequency distortion\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\non the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\nfee. Request permissions from permissions@acm.org.\nCCS ’20, November 9–13, 2020, Virtual Event, USA\n© 2020 Association for Computing Machinery.\nACM ISBN 978-1-4503-7089-9/20/11...$15.00\nhttps://doi.org/10.1145/3372297.3417254ACM Reference Format:\nShuWang,JiahaoCao,XuHe,KunSun,andQiLi.2020.WhentheDiffer-\nencesinFrequencyDomainareCompensated:UnderstandingandDefeating\nModulatedReplayAttacksonAutomaticSpeechRecognition.In Proceed-\nings of the 2020 ACM SIGSAC Conference on Computer and Communications\nSecurity(CCS’20),November9–13,2020,VirtualEvent,USA. ACM,NewYork,\nNY, USA, 17 pages. https://doi.org/10.1145/3372297.3417254\n1 INTRODUCTION\nAutomatic speech recognition (ASR) has been a ubiquitous tech-\nniquewidelyusedinhuman-computerinteractionsystems,such\nas Google Assistant [ 5], Amazon Alexa [ 4], Apple Siri [ 52], Face-\nbook Portal[ 45], andMicrosoft Cortana[ 14]. Withadvanced ASR\ntechniques,these systemstake voicecommands asinputsand act\nonthemtoprovidediversevoice-controlledservices.Peoplenow\ncandirectlyusevoicetounlockmobilephone[ 20,39],sendprivate\nmessages[ 2],logintomobileapps[ 6],makeonlinepayments[ 48],\nactivate smart home devices [51], and unlock a car door [36].\nAlthough ASR provides many benefits and conveniences, recent\nstudieshavefoundanumberofattacksthatcaneffectivelyspoof\nandmisleadASRsystems[ 8,11,29,31,38,47,49,53,70,71,74,75].\nOneofthemostpowerfulandpracticalattacksistheaudioreplayat-\ntack[8,29,38],whereapre-recordedvoicesamplecollectedfroma\ngenuinevictimisplayedback tospoofASRsystems.Consequently,itcaneasilybypassvoiceauthenticationandinjectvoicecommands\ntoconductmaliciousactivities[ 25].Forexample,amobiledevice\ncan be unlocked by simply replaying a pre-recorded voice com-\nmand of its owner [ 29]. Even worse, the audio replay attack can be\neasilylaunchedbyanyonewithoutspe cificknowledge inspeech\nprocessingorothercomputertechniques.Also,theprevalenceof\nportablerecordingdevices,especiallysmartphones,makesaudio\nreplay attacks one of the most practical threats to ASR systems.\nTodefeataudioreplayattacks,researchershaveproposedanum-\nber of mechanisms to detect abnormal frequency features of audio\nsignals, such as Linear Prediction Cepstral Coefficient (LPCC) [ 33],\nMel Frequency Cepstral Coefficient (MFCC) [ 68], Constant Q Cep-\nstral Coefficients (CQCC) [ 56], and Mel Wavelet Packet Coeffi-\ncients (MWPC) [ 42]. A recent study [ 65] shows that the amplitude-\nfrequencycharacteristicsinahigh-frequencysub-bandwillchangesignificantlyunderthereplayattack,andthustheycanbeleveraged\nto detect the attack. Another study [ 8] discovers that the signal\nenergyinthelow-frequencysub-bandscanalsobeleveragedtodis-\ntinguish if the voice comes from a human or an electronic speaker.\nMoreover,duetothedegradedamplitudecomponentscausedbythe replay noise, the frequency modulation features [\n21,28,55]\ncan be leveraged into detection. Overall, existing countermeasures\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1103are effective on detecting all known replay attacks by checking\nsuspicious features in the frequency domain.\nInthispaper,wepresentanewreplayattacknamed modulatedre-\nplayattack,whichcangeneratereplayaudioswithalmostthesame\nfrequency spectrum as humanvoices tobypass theexisting coun-\ntermeasures.Inspiredbytheloudspeakerequalizationtechniques\ninauditoryresearchthattargetsatimprovingthesoundeffectof\nanaudiosystem[ 13],thecoreideaofmodulatedreplayattackisto\ncompensateforthedifferencesinthefrequencydomainbetween\nreplayaudiosandhumanvoices.Throughameasurementstudyon\nASRsystems,wefindthedifferencesinthefrequencydomainare\ncausedbytheplaybackelectronicspeakers,whichtypicallyhave\na non-flat frequency response with non-regular oscillations in the\npassband.Inreality,anspeakercanhardlyoutputallfrequencies\nwithequalpowerduetoitsmechanicaldesignandthecrossover\nnature if the speaker possesses more than one driver [ 10]. Thus,\nwhen the genuine human audio is replayed, electronic speakers ex-\nertdifferentspectralgainsonthefrequencyspectrumofthereplay\naudio, leading to different distortion degrees. Typically, electronic\nspeakers suppress the low-frequency components and enhance the\nhigh-frequency components of the genuine human audio.\nBy evaluatingthe transfercharacteristic ofelectronic speakers,\nwe are able to customize a pre-processing inverse filter for any\ngivenspeaker.Byapplyingtheinversefilterbeforereplayingthe\nhumanaudio,thespectraleffectscausedbythespeakerdevicescan\nbeoffset.Consequently,theattackercanproducespoofedaudios\nthat are difficult to be distinguished from real human voices in the\nfrequency domain. We conduct experiments to demonstrate the\nfeasibility and effectiveness of the modulated replay attack against\n8existingreplaydetectionmechanismsusing6realspeakerdevices.\nThe experimental results show that the detection accuracy of most\nfrequency-based countermeasure significantly drops from above\n90%toaround10%underourattack,andeventhebestcountermea-\nsure usingMWPC [ 42] dropsfrom above97% toaround 50%.One\nmajorreasonisthatmodulatedreplayattackisanewtypeofattack\nthat leverages loudspeaker frequency response compensation.\nTo defeat the modulated replay attack as well as classical replay\nattacks,weproposeanewdual-domaindefensemethodnamed Du-\nalGuardthat cross-checks suspicious features in both time domain\nand frequency domain, which is another major contribution in this\npaper. The key insight of our defense is that it is inevitable for\nany replayattacks toeither leave ringing artifacts [63] inthe time\ndomain or cause spectrum distortion in the frequency domain, even\nifthereplayaudiosignalshavebeenmodulated.Weformallyprove\nthe correctness and universality of our key insight. In the time\ndomain, ringing artifacts will cause spurious oscillations, whichgenerate a large number of local extreme points in replay audio\nwaveforms.DualGuard extracts andleverages thoselocal extrema\npatterns to train a Support Vector Machine (SVM) classifier that\ndistinguishesmodulatedreplayattacksfrom humanvoices.Inthe\nfrequencydomain,spectrumdistortionwillgeneratedramatically\ndifferent power spectrum distributions compared to human voices.\nAlso, DualGuard applies the area under the CDF curve (AUC) of\npowerspectrumdistributionstofilteroutclassicalreplayattacks.\nTherefore, DualGuard can effectively identify replay audio by per-\nforming the checks in two domains.We implement a prototype of DualGuard on a voice interactive\nplatform, ReSpeaker Core v2 [ 57]. We conduct extensive experi-\nmentstoevaluateitseffectivenessandperformanceondetecting\nreplay attacks. The experimental results show that DualGuard can\nachieveabout98%detectionaccuracyagainstthemodulatedreplay\nattack and over 90% detection accuracy against classical replay\nattacks. Moreover, we show that DualGuard works well under dif-\nferentnoisyenvironments.Particularly,thedetectionaccuracyonly\ndecreases by 3.2% on average even with a bad signal-to-noise ratio\n(SNR)of40dB.DualGuardislightweightandcanbedeployedto\nworkonlineinrealASRsystems.Forexample,ourtestbedplatform\ntakes5.5𝑚𝑠onaveragetoprocessasignalsegmentof32 𝑚𝑠length\nusing 24.2% CPU and 12.05 MB memory.\nIn summary, our paper makes the following contributions:\n•WeproposeanewmodulatedreplayattackagainstASRsystems,\nutilizing a specific software-based inverse filter to offset suspi-cious features in the frequency domain. By compensating the\nelectronicspeaker’snon-flatfrequencyresponseinthepassband,\nmodulated replay attacks can bypass existing replay detection\nmechanisms.\n•WedesignanoveldefensesystemnamedDualGuardtodetectall\nreplayattacksincludingthemodulatedreplay attacksbycheck-\ningsuspiciousfeaturesinbothfrequencydomainandtimedo-\nmain. We formally prove that replay attacks cannot escape from\nbeing detected in both time and frequency domains.\n•Weverifythefeasibilityandeffectivenessofthemodulatedre-\nplay attack through real experiments using multiple speaker\ndevicesoverexistingreplaydetectionmechanisms.Wealsoim-\nplementaprototypeofDualGuardonapopularvoiceplatform\nanddemonstrateitseffectivenessandefficiencyindetectingall\nreplay attacks.\n2 BACKGROUND\nInthissection,weintroducenecessarybackgroundinformationon\naudio signal processing, ASR systems, and replay attacks.\n2.1 Audio Signal Processing\nAstherearesomanytechnicaltermsonvoicesignalprocessing,we\nonly briefly introduce two necessary terms that are tightly related\nto our work.Signal Frequency Spectrum.\nGenerally, a signal is represented\nasatime-domainform 𝑥(𝑡),recordingthesignalamplitudeateach\ntimepoint.Frequencyspectrumisanothersignalrepresentation,\nproviding a way to analyze the signal in the frequency domain.\nFourieranalysis[ 50]candecomposeatime-domainsignalasthe\nsum of multiple sinusoidal signals of different frequencies, i.e.,\n𝑥(𝑡)=/summationtext.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛𝑡+𝜙𝑛).The𝑛-thsinusoidalsignaliscalled\nthe frequency component with a frequency value of 𝑓𝑛. The set\nof{𝐴𝑛}is called the amplitude spectrum that represents the am-\nplitude of each frequency component. {𝜙𝑛}is the phase spectrum\nrecordingthephaseofeachcomponent.Thefrequencyspectrum\nof a signal is the combination of amplitude and phase spectrum.FrequencyResponse.\nFrequency response represents the output\nfrequency and phase spectrum of a system or a device in response\ntoastimulussignal[ 46].Whenastimulussignalthatistypically\na single-frequency sine wave passes through a system, the ratio\noftheoutputtoinputamplitude(i.e.,signalgain)varieswiththe\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1104Recording \nDeviceHuman\nVoiceSignal\nProcessing\nSi l\n Speech\nRecognition\nFigure 1: ASR Systems.\ninput frequency of the stimulus signal. The amplitude response of\nthesystemrepresentsthesignalgainsatallfrequencies.Hence,the\noutputamplitudespectrumofasignalistheproductoftheinput\namplitudespectrumandtheamplituderesponseofthesystem.A\nsystemisahigh-pass(low-pass)filterifthesystemhasahigheram-\nplitude response in the high-frequency (low-frequency) range. The\nphase response of a system represents the phase shifts of different\nfrequency signals passing through the system.\n2.2 ASR Systems and Replay Attacks\nFigure1showsan automaticspeec hrecognition(ASR)system.A\nrecordingdevicesuchasamicrophonecapturestheaudiosignals\nfrom the air and converts the acoustic vibrations into electrical\nsignals. Then, the analog electrical signals are converted to digital\nsignalsforsignalprocessing.Theprocesseddigitalsignalsareused\nforspeechre cognition or speaker identification in the subsequent\nprocessingofthe ASRsystems.Thesedigitalsignalsare commonly\nreferred to as the genuine audio if the signals are directly collected\nfrom the live human speakers.\nASRsystemsarevulnerabletoreplayattacks.Theclassicalreplay\nattackmodelcontainsfourbasiccomponents,i.e.,arecordingde-\nvice, an analog-to-digital (A/D) converter, a digital-to-analog (D/A)\nconverter, and a playback device such as a loudspeaker. Compared\nwiththenormalspeechrecognition stepsintheASRsystems,the\nreplayattackcontainsareplayprocessasshowninFigure2(a).The\nattacker firstly collects the genuine human voice using a recording\ndevice and converts the voice to a digital signal by an A/D con-\nverter. The digital signal can be stored in a disk device as a lossless\ncompressionformatorbespreadthroughtheInternet.Afterthat,\nthe attacker playbacks the digital signal near the targeted ASR sys-\ntem,whichspoofsthesystemtoprovideexpectedservices.Inthe\nplaybackprocess,thestoreddigitalsignalisconvertedtoananalog\nelectric signal by a D/A converter. Then, the electric signal will be\nplayed as an acoustic wave by a playback device.\n3 MODULATED REPLAY ATTACKS\nIn this section, we propose a new attack called modulated replay\nattack.Byanalyzingthereplaymodelandreplaydetectionmeth-\nods, we find the existing defenses rely on the features of amplitude\nspectrum.Basedontheseobservations,weproposeamethodtoesti-matethespeakerresponseandbuildaninversefiltertocompensate\nthe amplitude spectrum of the replay signals. The reconstructed\nreplay signals can bypass the existing defenses.\n3.1 Impacts of Replay Components\nAlthoughclassicalreplayattackscanachieveahighsuccessratein\nspoofingASRsystems,someacousticfeaturescanstillbeutilized\nto distinguishthe replay audio fromthe genuine audio.As showninFigure2(a),themaindifferencebetweenthesetwotypesofaudio\nis the additional replay process that the replay audio goes through.\nWe study the impacts from four components involved in the\nreplayprocess,namely,therecordingdevice,A/Dconverter,D/A\nconverter, and the playback device. We observe that the impactsfrom the first three components are negligible, and the most sig-\nnificant impactson replaysignals comefrom theplayback device.\nFirst,anattackerneedstousearecordingdevicetocollectthevoice\ncommand.Themainfactorsthatinfluencetherecordingprocess\ninclude the non-linearity of modern microphones and the ambient\nnoise. However, the nonlinear frequency range of a microphone is\nmuch higher than the human speechfre quency. When it comes to\nthe ambient noise, it is hard to tell if the noise is introduced during\nthe attacker’s recording process or the ASR recording phase.\nSecond, when the A/D converter transforms the signal into a\ndigital form, it may cause the information loss of the analog signal\ndue to the sampling and quantization operations. However, this\neffectislimitedsincethemodernrecordingdeviceshaveahigher\nsamplingrate(notlessthan44.1kHz)andahigherbitdepth(usually\nhigher than 16-bit resolution) than the old-fashioned recorders.\nThird,thesignalcanbetransformedbackintotheanalogformby\nthe D/A converter, where a low-pass filteris used to eliminate the\nhigh-frequencycomponents causedby sampling.Asthe sampling\nfrequency is at least 10 times larger than the speech fre quency, the\nfilter in the D/A converter has little effect on the audio signals.\nFinally, we find the most significant effects on the replay signal\narecausedbytheplaybackdevice.Becauseoftheshapeandvolume,\nthe acoustic characteristics of loudspeakers are greatly differentfrom those of human vocal organs. Due to the resonance of the\nspeakerenclosure,thevoicefromloudspeakerscontainslow-power\n\"additive\" noise. These resonant frequency components are typ-ically within 20-60 Hz that human cannot produce [\n8]. Another\nimportantfeatureofloudspeakersisthelow-frequencyresponse\ndistortionduetothelimitedsizeof loudspeakers.Withinthe speech\nfrequencyrange,theamplituderesponseofaloudspeakerisahigh-\npass filter with a cut-off frequency typically near 500 Hz [ 59]. As a\nresult, the power of low-frequency components will be attenuated\nrapidly when a voice signal passes through a loudspeaker, which is\nthe \"multiplicative\" characteristic of speakers in human speech fre-\nquencyrange[46].Eventhoughthegenuineaudioandthereplay\naudio have the same fundamental frequency and harmonic fre-\nquencies,thepowerdistributionsoffrequencycomponentsremain\ndifferent. The low-frequency components of replay audio have a\nsmallerpowerproportioncomparedwiththoseofgenuineaudio.\nBecausethedifferentpowerdistributionsleadtodifferenttimbre,\nthe voice signals sound different even with the same loudness and\nfundamental frequency.\n3.2 Attack Overview\nBasedonourobservationthatexistingdefensesutilizetheampli-\ntudespectrumtodetectreplayattacks,thekeyideaofourproposed\nattackis tomodulatethe voicesignal sothatthe replayaudiohas\nthesameamplitudespectrumasthegenuineaudio.Asshownin\nFigure2(b),themostcriticalcomponentisthemodulationprocessor\nbetweentheA/DandD/Aconversion.Themodulationprocessor\ncancompensatefortheamplitudespectrumdistortioncausedby\nthe replay process. By adding the modulation processor, we can\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1105Playback \nDeviceRecording \nDeviceSaved \nAudio\nASR\nSystemsA/D \nConversion\nD/A \nConversion\nHuman\nVoice\nReplay Process\n(a) Classical Replay Attacks\nPlayback \nDeviceRecording \nDeviceSaved\nAudio\nASR\nSystemsA/D\nConversion\nD/A\nConversion\n,QYHUVH\u0003\n)LOWHU\nHuman\nVoice\n0RGXODWHG\u00035HSOD\\\u00033URFHVV\n(b) Modulated Replay Attacks\nFigure 2: Classical Replay Attacks vs. Modulated Replay Attacks.\ndeal with the modulated replay process as an all-pass filter, so that\nthemodulatedreplayaudiowillhaveanequivalentprocessingflow\nas the genuine audio.\nIn the classical replay process, the recording device and the\nA/DandD/Aconversionhavelimitedeffectsonthereplayaudio.\nThus,ourmodulationprocessormainlytargetstheplaybackdevice,\nspecifically, theamplitude response ofit. There are manytypes of\nplayback devices, such as mobile phones, MP3 players, and remote\nIoTdevicesinthevictim’shome.Weacquiretheamplituderesponse\nofaplaybackdevicebymeasuringtheoutputspectruminresponsetodifferentfrequencyinputs.Iftheplaybackdeviceisunderremote\ncontrolthattheamplituderesponsecannotbemeasureddirectly,\nwe can estimate an approximate response from the same or similar\ndevices. After acquiring the amplitude response of the playback\ndevice,wedesignaninversefilterthatisakeycomponentinthe\nmodulationprocessortocompensateforthedistortionofthesignal\nspectrum. After the spectrum modulation, the modulated replay\naudio can bypass existing frequency-based defense.\nInourmodulatedreplayattack,themodulationprocessoronly\ndeals withthe voice signalsin digitalform. Therefore, theinverse\nfilterisdesignedbydigitalsignalprocessing(DSP)techniques.The\nmodulated signals can be stored or spread through the Internet to\nlaunch a remote replay attack.\n3.3 Modulation Processor\nThestructureofthemodulationprocessorisshowninFigure3.The\nrecordedaudioisadigitalsignalcollectedfromthegenuinehuman\nvoice.Theaudioisthentransformedfromthetimedomaintothe\nfrequency domain by fast Fourier transform algorithm. The FFToutputisacomplexfrequencyspectrumthatcanbedividedinto\ntwoparts:(1)theamplitudespectrumthatrecordstheamplitude\nfor each frequency component, and (2) the phase spectrum thatrecords the phase angle for each frequency component. We onlyprocess the amplitude spectrum in the modulation processor fortwo reasons. One reason is that both the ASR systems and the)DVW\u0003)RXULHU\u0003\n7UDQVIRUP6SHFWUXP  \n)LOWHULQJ\n5HFRQVWUXFWLRQ\n6SHDNHU  \n5HVSRQVH  \n(VWLPDWLRQ6SHDNHU\u00033URSHUWLHV\n5HFRUGHG  \n$XGLR0RGXODWHG  \n$XGLR\n$PSOLWXGH  \n6SHFWUXP\n3KDVH\u00036SHFWUXP&RPSHQVDWHG  \n6SHFWUXP,QYHUVH\u0003)LOWHU  \n(VWLPDWLRQ\n,QYHUVH\u0003)LOWHU\n,QYHUVH\u0003)LOWHU\nFigure 3: The modulation processor.\nreplaydetectionsystemsextractsignalfeaturesfromtheamplitude\nspectrum. Another reason is that the human ear is less sensitive to\nthe sound phase compared to the sound amplitude. Therefore, the\nphase spectrum will remain the same in the modulation processor.\nTheinversefilter,estimatedbasedonthespeakerproperties,is\nthekeycomponentinthemodulationprocessor.Specifically,the\ninverse filter is an engine in the spectrum filtering unit, transform-\ning the amplitude spectrum to a compensated spectrum. By the\nspectrum filtering, the inverse filter can offset the distortion effect\ncaused by the playback device. Therefore, the amplitude responses\nof the inverse filter and the loudspeaker are complementary, be-\ncause the combination of these two transfer functions is a constant\nfunction that represents an all-pass filter.\nAfter processing the amplitude spectrum with the inverse filter,\nwe can obtain a compensated spectrum that has a better frequency\ncharacteristic inthe low-frequencyrange. Withboth the compen-\nsated spectrum and the phase spectrum, the inverse fast Fourier\ntransform(iFFT)isutilizedtoconvertthereconstructedsignalfrom\nfrequency domain to time domain. Finally, we can get a modulated\naudiointhetimedomain.Moreover,themodulatedaudiowillbe\nstoredasadigitalformat, whichisreadytobeusedtolaunchthe\nmodulated replay attack.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n11067HVW\u00036LJQDO\n 6SHDNHU 5HFRUGHU\nI\u0003 \u0003I\u0013\u000f\u0003D\u0003 \u0003\u0014))7\u0003VSHFWUXP\nI\u0003 \u0003I\u0013\u000f\u0003D\u0003 \u0003D\u0013\u000bI\u0013\u000fD\u0013\f\nf \n(a) The measurement of single-frequency response.\n'LVFUHWH\u0003GDWD\u000bI\u0013\u000fD\u0013\f\n6SHDNHU\u0003UHVSRQVH )LWWLQJ\u0003FXUYH\u000bI\u0013\u000fD\u0013\f\nI I I\u0003\n(b) The processing of fitting speaker response.\nFigure 4: The method to estimate the speaker response.\n3.4 Inverse Filter Estimation\nTheinversefilterisestimatedthroughthespeakerproperties.There-\nfore, it is necessary to measure the amplitude response of the loud-\nspeaker directly. If it is not possible for direct measurement, the\namplitude response can be estimated by measuring the speakers in\nthe same or similar model.\nWhenmeasuringthespeakerproperties,wesetasingle-frequency\ntest signal as the speaker input and record the output audio, as\nshowninFigure4(a).Throughcheckingtheoutputamplitudespec-\ntrum, we can get the output amplitude of the corresponding fre-\nquency. The amplitude response of the single frequency is the out-\nputamplitudedividedbytheinputamplitude.Throughchanging\nthe input frequency of the test signal, we can obtain the amplitude\nresponse over the entir espeechfrequency range.\nBecausethetestfrequenciesoftheinputsignalsarediscrete,the\namplituderesponseisaseriesofdiscretedatapoints,asshownin\nFigure 4(b). To obtain a continuous response function over the en-\ntirefrequencyrange,wefillinthemissingdatabythecurvefitting.\nCubic spline interpolation [ 24] will be used to construct a continu-\nousandsmoothresponsecurve 𝐻(𝑓)withmultiplepolynomialsof\ndegree 3.\nAs the inverse filter is implemented on the digital signals, we\nneed to convert the continuous response function into a digital\nform.AftertheFourier transform,thesignalspectrumhasafixed\nfrequencyinterval Δ𝑓denotingthefrequencyresolution.Hence,\nwesamplethecontinuousresponsefunctionatthesamefrequency\ninterval and get a finer-grained amplitude response. The digital\namplitude response of the electronic speaker is denoted as 𝐻(𝑘).\nAfter obtaining the speaker amplitude response, we can design\ntheinversefilterbythecomplementaryprinciple.Theamplitude\nresponsesoftheinversefilterandthespeakercancanceleachother,\nminimizing the impact of the replay process. Hence, the inverse\nfilter𝐻−1(𝑘)should satisfy the all-pass condition that 𝐻−1(𝑘)·\n𝐻(𝑘)=𝐶when𝐻(𝑘)≠0.𝐶isapositiveconstantwhichistypically\n1. In addition, if 𝐻(𝑘)=0 for any𝑘,𝐻−1(𝑘)should also be 0.\nAnotherspeakerpropertyisthesub-bass(0-60Hz)energy,which\ncanbegeneratedbyloudspeakers,nothumans.Thesub-bassfea-\ntures are dependent on the speaker models and enclosure struc-ture [\n8]. Although attackers may pick the speakers to minimizethe sub-bass energy, we still need to minimize the possibility of\ndetected by the sub-bass features. Hence, we optimize the inverse\nfilterintwoways.Weset 𝐻−1(𝑘)=0whenthefrequencyiswithin\n0-60Hz,becausewedonotwanttoamplifytheexistingnoisein\nthe sub-bass range. Another way is to enhance the inverse filter re-\nsponse in the speech frequency range so as to decrease the relative\nproportion of the additive sub-bass energy. By these optimizations,\nwecandecreasethemetricofsub-bassenergybalanceunderthe\ndetection threshold.\nBy applying the inverse filter before the playback device, we\ncan compensate the unwanted replay effects that are caused by the\nelectronic speakers.\n3.5 Spectrum Processing\nThespectrumprocessingwillinvolvethreephases:thetime-frequency\ndomain conversion, the amplitude spectrum filtering, and the mod-\nulated signal reconstruction.\n3.5.1 Time-Frequency Domain Conversion. First,weneedto con-\nverttherecordedaudiofromthetimedomainintothefrequency\ndomain, because it is easier to filter the signals in the frequency\ndomain.Fora 𝐿-lengthsignalsegment,wepadthesignalwithzeros\nso that the total signal length would be 𝑁, where𝑁is the smallest\npowerof2greaterthanorequalto 𝐿.Theextendedsignalisdenoted\nas𝑥(𝑛),𝑛=0,1,...,𝑁−1. Then we convert the time-domain signal\n𝑥(𝑛)intothefrequency-domainrepresentation 𝑋(𝑘)throughthe\nfast Fourier transform algorithm.\n𝑋(𝑘)=𝑁−1/summationdisplay.1\n𝑛=0𝑥(𝑛)·𝑒−𝑖2𝜋𝑘𝑛/𝑁,𝑘=0,1,...,𝑁−1 (1)\n𝑋(𝑘)isthefrequencyspectrumoftheoriginalsignalintheform\nof complex numbers. The frequency resolution is defined as the\nfrequency interval Δ𝑓=𝑓𝑠/𝑁, where𝑓𝑠is the sampling rate of the\nrecording audio.\nThenwesplitthecomplexfrequencyspectrumintotwoparts.\nThemagnitudespectrum 𝑋𝑚(𝑘)=|𝑋(𝑘)|,representsthesignalam-\nplitude of different frequency components 𝑘·Δ𝑓,𝑘=0,1,...,𝑁−1.\nThe phase spectrum 𝑋𝑝(𝑘)=∠𝑋(𝑘)in radians, which is inde-\npendent with the amplitude information, represents where the\nfrequency components lie in time.\n3.5.2 Spectrum Filtering. The inverse filter will only be imple-\nmentedintheamplitudespectrum.Thephasespectrumwillremain\nunchanged. The effect of applying a filter is to change the shapeof the original amplitude spectrum. According to the system re-\nsponsetheory,thecompensatedamplitudespectrumistheproduct\nof the input amplitude spectrum and the amplitude response ofthe inverse filter. Hence, after modulating the signal with the in-\nverse filter𝐻−1(𝑘), the compensated spectrum 𝑌𝑚(𝑘)satisfies that\n𝑌𝑚(𝑘)=𝑋𝑚(𝑘)·𝐻−1(𝑘).\nNotethat theamplitude spectrumof thespeakeroutput isalso\ntheproductoftheinputamplitudespectrumandthespeakeram-\nplitude response. Therefore, the amplitude spectrum of the mod-ulated replay audio will be\n𝑆𝑚(𝑘)=𝑌𝑚(𝑘)·𝐻(𝑘). We can find\nthat𝑆𝑚(𝑘)=𝑋𝑚(𝑘)·𝐻−1(𝑘)·𝐻(𝑘)=𝐶·𝑋𝑚(𝑘). Because𝐶is a\nconstant,thepowerdistributionoffrequencycomponentsinthe\nmodulated replay audio will be the same as that in the genuine\naudio,makingitharderforASRsystemstodetectthereplayattack.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n11073.5.3 Modulated Signal Reconstruction. Aftermodifyingtheampli-\ntudespectrumtocompensatefortheenergylossinthefollowing\nplayback phase, we need to reconstruct the signal in the frequency\ndomain. The modulated signal will have the compensated ampli-\ntude spectrum and remain the original phase spectrum. Therefore,\nthecomplexfrequencyspectrumwillbereconstructedbytheampli-\ntude𝑌𝑚(𝑘)and thephase angle 𝑋𝑝(𝑘). Thatmeans thefrequency\nspectrumofthemodulatedsignalshouldbe 𝑌(𝑘)=𝑌𝑚(𝑘)·𝑒𝑖𝑋𝑝(𝑘)\naccordingtotheexponentialformofcomplexnumbers.Afterre-\nconstructing the modulated signal in the frequency domain, the\ncomplex frequency spectrum 𝑌(𝑘)will be converted back into the\ntime domain by the inverse fast Fourier transform algorithm.\n𝑦(𝑛)=1\n𝑁𝑁−1/summationdisplay.1\n𝑘=0𝑌(𝑘)·𝑒𝑖2𝜋𝑘𝑛/𝑁,𝑛=0,1,...,𝑁−1 (2)\nTo ensure that the length of the modulated audio is the same\nas that of the original audio, the last (𝑁−𝐿)data points in 𝑦(𝑛)\nwillbediscarded.Hence,thetotalsignallengthofthemodulated\naudio would be 𝐿. Then, the final modulated audio will be saved as\na digital format to complete the replay attack.\n4 COUNTERMEASURE: DUAL-DOMAIN\nDETECTION\nInthissection,weproposeacountermeasurecalledDualGuardagainstthe modulated replay attack. Due to the similarity of the amplitude\nspectrumbetweenthemodulatedreplaysignalsandthegenuine\nsignals, the defense will be conducted not only in the frequency\ndomain, but also in the time domain.\n4.1 Defense Overview\nIn our scheme, our countermeasure contains two inseparable parts:\nfrequency-domain defense and time-domain defense. A voice com-\nmand must pass both defenses in time and frequency domains\nbefore it can be accepted by ASR systems.\nThe frequency-domain defense is proved to be effective against\nclassical replay attacks. Because of the frequency spectrum dis-\ntortioncausedbythereplayprocess,weusethepowerspectrum\ndistribution(timbre)todistinguishtheclassicalreplayaudio.The\nareaundertheCDFcurve(AUC)ofthepowerspectrumdistribution\nis extracted as the key frequency-domain feature. We find that the\nAUCvalueofthegenuineaudioisstatisticallylargerthanthatof\nthe replay audio. By utilizing the frequency-domain defense, we\nfilter out the threat from the classical replay attacks.\nThemodulatedreplayaudiohasthesameamplitudespectrumas\nthe genuine audio. Hence, we need to detect the modulated replay\naudio in other domains. In the phase domain, there is no usefulinformation in the phase spectrum, which records the starting\npointsofeachfrequencycomponentinthetimeaxis.Butinthetime\ndomain, we discover and formally prove the following theorem.\nTheorem. There are inevitably spurious oscillations (ringing arti-\nfacts) in the modulated replay audio. The amplitude of the ringing\nartifacts is restricted by the signal amplitude spectrum and absolute\nphase shifts.\nThe mathematical proofof the theorem is demonstrated inAp-\npendix A. In the time domain, based on this theorem, there aresmallringingartifactsinthemodulatedreplaysignals.However,-0.06-0.04-0.02 0 0.02 0.04 0.06\n 0  50  100  150  200  250  300  350Amplitude\nSamplesGenuine Audio\nModulated Audio\n(a) Coarse granularity ( 𝑟=10)-0.06-0.04-0.02 0 0.02 0.04 0.06\n 0  50  100  150  200  250  300  350Amplitude\nSamplesGenuine Audio\nModulated Audio\n(b) Fine granularity ( 𝑟=1)\nFigure 5: The local extrema under different granularity.\ninthegenuineaudioandtheclassicalreplayaudio,thewaveform\nis statistically smooth.\nWe define a new metric called local extrema ratio to quantita-\ntivelydescribethestrengthsoftheringingartifacts.Weutilizelocal\nextrema ratios at different granularity as the key time-domain fea-\ntureandfilteroutmodulatedreplayattacksusinganSVMclassifier.\n4.2 Time-domain Defense\nBecauseofthedifficultyindetectingthemodulatedreplayaudio\nvia frequency and phase features, we seek the defenses in the time\ndomain. Byour observationsand mathematicalproof (see Appen-\ndix A), we find there are small ringing artifacts in the time-domain\nsignals when performing the modulated replay attack. Although\nthese time-domain artifacts correspond to the high-frequency com-\nponents, the power of the artifact is too small to be detected in the\nfrequencydomainbecausethemaximumamplitudeisconstraint\nbytheEquation(11).Inthefrequencydomain,theringingartifacts\ncanbeeasilymistakenfortheambientnoise.Hence,wepropose\na time-domain defense method that utilizes the pattern of small\nringing artifacts in the modulated replay audio.\nTheringingartifactspatternisarobustfeaturethatcannotbe\nfurther compensated by a higher-order filter. The ringing artifacts\nare caused by the physical property, but not the modulated process\nitself. When we modulate the recorded audio, there are no ringing\nartifacts in the processed audio. The ringing artifacts only occur\nafterreplayingtheprocessedaudio,thusbecominganinevitable\nfeature in the modulated replay audio. In order to describe the\nringing artifacts in the time-domain signals, we take local extreme\nratioas the metric. We firstly give a definition of local extrema.\nDefinition: Inasignalsegment 𝑦,ifasamplingpoint 𝑦𝑖isthe\nmaximumvalueortheminimumvalueinthe (2𝑟+1)-lengthwindow\n[𝑦𝑖−𝑟,𝑦𝑖+𝑟],𝑦𝑖is a local extrema in the time-domain signal. Note\nthatiftheindexofthewindowelementisoutofbounds,wewill\npad the window with the nearest effective element.\nLocal extrema ratio (LER) is defined as the ratio of the local\nextrema amount to the total signal length. Given an input signalsegment, the local extrema ratio correlates with the window pa-\nrameter𝑟.Whenthewindowsizeissmall,theLERcalculationis\nin fine granularity that reflects the small ringing artifacts in the\ntime-domainsignals.Whenthewindowsizeislarge,LERshowsthe\noverallchangetrendofthesignals.Themodulatedreplaysignals\nand the genuine signals have different patterns in local extrema\nratiowithdifferentgranularity.Wecandetectthemodulatedreplay\nattack via identifying the LER patterns with different parameter\n𝑟∈[1,𝑟𝑚𝑎𝑥].Algorithm1showsthefunctionofobtainingthelocal\nextrema patterns and detecting the modulated replay audio.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1108InFigure5(a),underthecoarsegranularity(largerwindowsize),\nthe numberof localextrema does notdiffer muchbetween modu-\nlated replay audio and genuine audio. However, in Figure 5(b), the\nsituationwouldbedifferentunderthefinegranularity(smallerwin-\ndowsize).Duetotheringingartifacts,smallspuriousoscillations\noccurinmodulatedreplayaudio.Thenumberoflocalextremain\nmodulated replay audio will be significantly larger than that in\ngenuine audio, which becomes a critical feature that helps us de-\ntect the modulated replay attack. A Support Vector Machine (SVM)\nclassifier is trained to distinguish modulated replay audio by deter-\nminingthelocalextremapattern (LEP)withdifferentgranularity.\nThe time-domain attack detection is shown in Algorithm 1. The\naudiowillbecomethecandidateaudioforthefrequency-domain\nchecking if it does not come from the modulated replay attack.\nAlgorithm 1 Time-Domain Modulated Replay Detection\nInput:an audio signal 𝒚,the largest wnd parameter 𝑟𝑚𝑎𝑥\nOutput: whether there is a modulated replay attack\n1:𝑙←𝑙𝑒𝑛𝑔𝑡ℎ(𝒚)\n2:𝑐𝑛𝑡←0\n3:𝑳𝑬𝑷←[]\n4:for𝑟←1t o𝑟𝑚𝑎𝑥do\n5:/∗𝐶𝑎𝑙𝑐𝑢𝑙𝑎𝑡𝑒𝐿𝑜𝑐𝑎𝑙𝐸𝑥𝑡𝑟𝑒𝑚𝑎𝑅𝑎𝑡𝑖𝑜 ∗/\n6:for𝑖←1t o(𝑙−2)do\n7:𝑙𝑜𝑤←𝑚𝑎𝑥(𝑖−𝑟,0)\n8:ℎ𝑖𝑔ℎ←𝑚𝑖𝑛(𝑖+𝑟,𝑙−1)\n9: 𝒘←[𝒚𝑙𝑜𝑤,...,𝒚ℎ𝑖𝑔ℎ]\n10: if𝒘𝑟=Min(𝒘)or𝒘𝑟=Max(𝒘)then\n11: /∗𝐺𝑒𝑡𝑎𝐿𝑜𝑐𝑎𝑙𝐸𝑥𝑡𝑟𝑒𝑚𝑒𝑃𝑜𝑖𝑛𝑡 ∗/\n12: 𝑐𝑛𝑡←𝑐𝑛𝑡+1\n13: 𝑳𝑬𝑷 𝑖=𝑐𝑛𝑡/(𝑙−2)\n14:/∗𝐼𝑑𝑒𝑛𝑡𝑖𝑓𝑦𝑀𝑜𝑑𝑢𝑙𝑎𝑡𝑒𝑑𝑅𝑒𝑝𝑙𝑎𝑦𝐴𝑡𝑡𝑎𝑐𝑘𝑠𝑤𝑖𝑡ℎ 𝑳𝑬𝑷∗/\n15:if𝑆𝑉𝑀_𝐶𝑙𝑎𝑠𝑠𝑖𝑓𝑖𝑒𝑟 (𝑳𝑬𝑷)=1then\n16:output𝑚𝑜𝑑𝑢𝑙𝑎𝑡𝑒𝑑𝑟𝑒𝑝𝑙𝑎𝑦𝑎𝑡𝑡𝑎𝑐𝑘𝑠\n17:else\n18:output𝑐𝑎𝑛𝑑𝑖𝑑𝑎𝑡𝑒𝑎𝑢𝑑𝑖𝑜\n4.3 Frequency-domain Defense\nThefrequency-domaindefenseisusedtocountertheclassicreplay\nattack. It is based on the noticeable different timbre of the voice\nsounded from human and electronic speakers.\nIn the replay model, each component frequency in the genuine\naudio is exactly the same as that in the replay audio, no matter\nthefundamentalfrequencyortheharmonics.Forexample,ifthe\nfundamental frequencyof the genuine audio is500 Hz, thereplay\naudio will also have a fundamental frequency of 500 Hz. However,\neven with the same component frequencies, the genuine human\nvoiceandthereplayvoicesounddifferentinourperception.The\nmainreasonisthepowerdistributionsofthefrequencycomponents,\nnamely the timbre, are different.\nForhuman,ourvoiceissoundedfromthephonatoryorgan.The\ntypical sound frequency for human is within the range from 85 Hz\nto 4 kHz, where the low-frequency components are dominant. For\nelectronicspeakers,thereisanacousticdefectonthelow-frequencycomponentsduetothespeakerstructure,materials,andthelimited 0 0.2 0.4 0.6 0.8 1\n0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0CDF\nFrequency (kHz)Genuine Audio\nReplay Audio\nFigure6:Cumulativedensityfunctionofspectralpowerdis-tribution for genuine and direct replay audios.\nsize.Thepowerofthereplaysignalsdecaysdramaticallyinthelow-\nfrequencyrange,especiallyunder500Hz.Meanwhile,thehuman\nfundamentalfrequencyrangeis64-523Hzformen,and160-1200\nHz for women. Hence, the electronic speakers will attenuate the\npowerinthehumanfundamentalfrequencybecauseofthespeaker\nproperties. With respect to the power distribution, the power ofthe genuine audio is mainly concentrated in the low-frequency\nrange,whilethepowerofthereplayaudioismoredistributedin\nthespeechfre quencyrange.Ourfrequency-domaindefenseutilizes\nthese timbre features to defeat the classic replay attack.\nAlgorithm 2 Frequency-Domain Replay Detection\nInput:an audio signal 𝒚,FFT point numbers 𝑁,\ndecision threshold 𝐴𝑡ℎ\nOutput: whether there is a classical replay attack\n1:/∗𝐶𝑎𝑙𝑐𝑢𝑙𝑎𝑡𝑒𝑁𝑜𝑟𝑚𝑎𝑙𝑖𝑧𝑒𝑑𝑆𝑖𝑔𝑛𝑎𝑙𝑃𝑜𝑤𝑒𝑟𝑆𝑝𝑒𝑐𝑡𝑟𝑢𝑚 ∗/\n2:𝑲←𝐹𝐹𝑇(𝒚,𝑁)\n3:𝑝←/summationtext.1𝑁−1\n𝑖=0𝑲2\n𝑖\n4:for𝑖←0t o𝑁−1do\n5: 𝑫𝑖=𝑲2\n𝑖/𝑝\n6:/∗𝐶𝑎𝑙𝑐𝑢𝑙𝑎𝑡𝑒𝑡ℎ𝑒𝐶𝐷𝐹𝑎𝑛𝑑𝑖𝑡𝑠𝐴𝑈𝐶 ∗/\n7:𝑨0=𝑫0\n8:for𝑖←1t o𝑁−1do\n9: 𝑨𝑖=𝑨𝑖−1+𝑫𝑖\n10:𝐴𝑈𝐶=/summationtext.1𝑁−1\n𝑖=0𝑨𝑖/𝑁\n11:/∗𝐼𝑑𝑒𝑛𝑡𝑖𝑓𝑦𝐶𝑙𝑎𝑠𝑠𝑖𝑐𝑎𝑙𝑅𝑒𝑝𝑙𝑎𝑦𝐴𝑡𝑡𝑎𝑐𝑘𝑠𝑤𝑖𝑡ℎ𝐴𝑈𝐶 ∗/\n12:if𝐴𝑈𝐶 <𝐴𝑡ℎthen\n13:output𝑟𝑒𝑝𝑙𝑎𝑦𝑎𝑡𝑡𝑎𝑐𝑘𝑠\n14:else\n15:output𝑔𝑒𝑛𝑢𝑖𝑛𝑒𝑎𝑢𝑑𝑖𝑜\nTimbre is described by the power distribution of different fre-\nquency components. It is necessary to define a mathematical de-scription for the timbre. When an ASR system captures a voicesignal from the air with a sampling rate of\n𝑓𝑠, we firstly obtain\nthe amplitude spectrum of the signal through 𝑁-point fast Fourier\ntransform. The signal amplitude spectrum is denoted as 𝐾(𝑛),𝑛=\n0,...,𝑁−1, with the frequency resolution Δ𝑓=𝑓𝑠/𝑁. The fre-\nquency value of the 𝑖-th component is 𝑖·Δ𝑓, while the ampli-\ntude is𝐾(𝑖). Hence, the signal power spectrum is 𝐾2(𝑛), and the\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1109power spectral density (PSD) of frequency components is defined\nas𝐷(𝑛)=𝐾2(𝑛)//summationtext.1𝑁−1\n𝑖=0𝐾2(𝑖). Todistinguish the differentpower\ndistributions,wemeasurethecumulativedensityfunction(CDF)\n𝐴(𝑛)for the power spectral density,\n𝐴(𝑛)=𝑛/summationdisplay.1\n𝑖=0𝐷(𝑖)=𝑛/summationdisplay.1\n𝑖=0𝐾2(𝑖)/𝑁−1/summationdisplay.1\n𝑖=0𝐾2(𝑖). (3)\n𝐴(𝑛)is a monotonically increasing function, with a range of\n[0,1].AsshowninFigure6,thepowerspectrumCDFofgenuine\naudiosandreplayaudiosarequitedifferent.Forgenuineaudios,the\npowerisconcentratedinthelow-frequencyrange,sotheCDFrises\nmore quickly. For replay audios, the CDF function grows slowerdue to the more distributed power spectrum. We utilize the CDF\ncharacteristic to distinguish replay audios from genuine audios.\nWe utilize the area under the CDF curve (AUC) to verify and\nfilter out the classic replay audio. AUC is calculated as/summationtext.1\n𝑛𝐴(𝑛)/𝑁.\nIftheAUCvalueislessthanaspecificthreshold 𝐴𝑇𝐻∈(0,1),there\nis a classic replay attack. We show the frequency-domain attack\ndetection in Algorithm 2.\n4.4 Security Analysis\nWe discover and prove that there are inevitably either ringing arti-\nfacts in the time domain or spectrum distortion in the frequency\ndomain, no matter if replay signals are modulated.\nForthefrequency-domaindefense,theprinciplecomesfromthe\nsignal differenceof thepower spectrumdistributions. Itis known\nthathumanspeechisnotasingle-frequencysignal,butasignalwith\nfundamental frequency 𝑓and several harmonics 𝑛𝑓,𝑛≥2. Within\nthehumanvoicefrequencyrange,thespeakerresponsehasagreat\ndifference in the low-frequency band and the high-frequency band,\nwhichmeans 𝐻(𝑓)≠𝐻(𝑛𝑓).Asaresult,thepowerratioofgenuine\naudio𝐴(𝑓)/𝐴(𝑛𝑓)isdifferentfromthatofthecorrespondingreplay\naudio(𝐻(𝑓)·𝐴(𝑓))/(𝐻(𝑛𝑓)·𝐴(𝑛𝑓)).Thedifferentpowerratios\ncause the difference in the power spectrum distributions.\nFor the time-domain defense, we can prove that there are in-\nevitablyspuriousoscillations(ringingartifacts)inthemodulatedreplayaudio.Thecriticalfactoristheinevitablephaseshiftsthat\ncannot be accurately measured (see details in Appendix A). Al-though the amplitude spectrums are the same, the signal phase\nspectrumscanbedifferent.Therelationshipbetweentheamplitudespectrum to the time-domain signals is a one-to-many relationship.\nMoreover, we cannot compensate for the phase shifts due to the\nlimitsoftheaccuracyinmeasurements.Evenasmallphaseerror\ncancauseringingartifactsinthetime-domain.Thatiswhyweneed\nto check the signals in both frequency domain and time domain.\nBesides, the high local extrema ratio in the modulated replay\naudio can result from other aspects, i.e. the measurement error, the\nFFT truncation effect, and the time-domain joint. First, the mea-\nsurement involves exponential computation, wherethe round-off\nerrors can be accumulated so that the amplitude estimation is not\naccurate,finallybringingaboutparasiticvibrationinthemodulated\nreplay signals. Second, the real FFT operation works on a finite-\nlength signal, which is equivalentto adding a window function to\nan infinite-length signal. The window function in the time domain\ncorrespondstoa 𝑠𝑖𝑛𝑐(𝑥)functionconvolvedinthefrequencydo-\nmain,causingthefrequencyspectrumtoexpandandoverlap.Third,\nwhen splicing the reconstructed signals into new audio, there is noguaranteeofthecontinuityatthestartingandendingsplicepoints.\nAdiscontinuoussplicepointcanleadtoringingartifactsduetothe\nGibbs phenomenon [77].\nMoreover, ringing artifacts cannot be further compensated by\na higher-order filter since ringing artifacts only occur after the\nreplay process rather than after the modulation process. Moreover,\nthe iterative filtering scheme can reduce ringing artifacts in image\nrestoration that are mainly caused by overshoot and oscillations in\nthestepresponseofanimagefilter[ 63].However,itisnotsuitable\nforspeech signalsbecausetheringingartifactsareintroducedby\nhardwareproperties.Evenifattackersmightreduceringingarti-factstoacertainextent,thetime-domaindefensecanstilldetect\nmodulated replay audio. This is because our method does not rely\nontheamplitudethresholdofringingartifacts.Althoughtheampli-\ntude of ringing artifacts may decrease, the local extrema cannot be\neliminated.Thetime-domaindefenseuseslocalextremaasfeatures\nso that even small ringing artifacts can be detected.\n5 EVALUATION\nInthissection,weconductexperimentsinarealtestbedtoevaluate\nthe modulated replay attack and our defense.\nFigure 7: The testbed in our experiments.\n5.1 Experiment Setup\nWeuseaTASCAMDR-40digitalrecorderforcollectingthevoice\nsignals.Thesamplingrateofthedigitalrecorderissetto96kHzbydefault.Weconductrealexperimentswithavarietyofcommonelec-tronicdevicesinourlives,includingiPhoneX,iPadPro,MiPhone4,\nGoogle Nexus 5, Bose Soundlink Micro, and Samsung UN65H6203\nSmartTV.Figure7showsthetestbedinourexperiments.Weaimto\ndemonstrate that both our attack and countermeasure scheme can\nbe applied to various speaker devices. To generate modulated re-\nplayaudios,weapplyMATLABtoestimatetheamplituderesponse\nand design the inverse filter for different speakers. Due to space\nconstraints, we put the details in Appendix C.\nASVspoof 2017 [ 29] and ASVspoof 2019 [ 61] are two popular\ndatabasesforreplayattacks.However,wecannotconvertthereplayattacksamplesinthesetwodatabasesintomodulatedreplayattacks,duetothelackofinformationofreplaydevices.Instead,toconduct\na fair comparison between modulated replay audio and classic\nreplay audio, we collect an in-house dataset with 6 replay devices.\nForeachofthesereplaydevices,thedatasetcontains222modulated\nreplay audios as well as 222 corresponding classic replay audios.\nAllaudiosignalsarecollectedinaquietlabenvironment.Weuse\n10-fold cross-validation accuracy as a metric since it can reflect the\nwhole performance of the system. Moreover, we implement the\nprototypeofourdefenseDualGuardinC++languageandruniton\na popular voice interactive platform, i.e., ReSpeakerCore v2.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1110 0 0.2 0.4 0.6 0.8 1\n0 1.0 2.0 3.0 4.0Normalized Amplitude\nFrequency (kHz)\n(a) Genuine Audio Collected from Human\n 0 0.2 0.4 0.6 0.8 1\n0 1.0 2.0 3.0 4.0Normalized Amplitude\nFrequency (kHz)\n(b) Direct Replay Audio\n 0 0.2 0.4 0.6 0.8 1\n0 1.0 2.0 3.0 4.0Normalized Amplitude\nFrequency (kHz)\n(c) Modulated Replay Audio\nFigure 8: Amplitude spectrum of audio signals.\n5.2 Effectiveness of Modulated Replay Attacks\nWe conduct experiments with the modulated replay attack. The\nattack leverages the inverse filter to generate synthetic audio that\nhas a similar frequency spectrum as the genuine audio. The modu-\nlatedsignalsaregeneratedintheMatlabenvironmentandstored\nin a lossless format. They are then transferred to replay devices for\nperforming attacks. Figure 8 shows the amplitude spectrum of the\nsignals during the modulated replay process in our experiments.\nHere, the results are collected using the iPhone device, while we\nhavesimilarresultswithotherdevices.Figure8(a)illustratesthe\ngenuine audio that is captured directly from a live human in aquiet room environment. The energy of genuine audio is mainlyconcentrated in the low-frequency range. Figure 8(b) shows thespectrum of the direct replay audio, which is captured from thedirect playback of the genuine audio. Due to the response prop-erties of the speaker devices, the high-frequency components in\nthe direct replay audio have a higher relative proportion comparedwith those in the genuine audio. The spectrum difference is a vital\nfeature in the various classic replay detection methods.\nFigure8(c)showsthespectrumofthemodulatedreplayaudio\ncollected by the ASR system. We can see that the low-frequency\nenergy is greatly enhanced to cope with the speaker effects. Thus,\nthe spectrum of the modulated replay audio is very similar to that\nof the genuine audio in Figure 8(a). Moreover, we quantify the sim-\nilarity between the modulated replay audio and the genuine audio\nusingtheL2normcomparison[ 43]thathasbeenwidelyusedto\ncomparethespectrumsofaudio.Itisdefinedas /bardbl𝐾1−𝐾2/bardbl2\n2,where\n𝐾1and𝐾2aretwo normalizedspectrum distributionsof audio,and\n/bardbl·/bardbl22isthesquareofEuclideandistance.ThesmallertheL2norm\nis, the more similar the two audios are. We measure the similarity\nvalueson660pairsofaudiosamples,theaveragesimilaritybetween\nthe modulated replay audio and the genuine audio is 1 .768×10−4.\nHowever, the average similarity between the direct replay audio\nandthegenuineaudio 𝑆𝑟𝑔is15.71×10−4onaverage,whichismuch\nlarger than the similarity between the modulated replay audio and\nthe genuine audio. The results demonstrate that the modulated\nreplay audio is much more similar to the genuine audio.\nFurthermore,were-implement8populardetectionmethodsthat\ncan be divided in three categories, namely, Cepstral Coefficients\nFeatures based defense, High-frequency Features based defense,\nandLow-frequencyFeaturesbaseddefense.Weapplythosedefense\nmethods to detect both direct replay attacks and modulated replay\nattackson6electronicdevices,andtheresultsinTable1showthatourmodulatedreplayattackscanbypassallthesecountermeasures.\nBypassingCepstralCoefficientsFeaturesBasedDefense. The\nmost popular method to detect replay attacks is based on cepstral\ncoefficients features extracted from the signal amplitude spectrum.\nThesecepstralcoefficientsfeaturesincludesCQCC[ 56],MFCC[ 68],\nLPCC [33], and MWPC [ 42]. Our experiments show that the ac-\ncuracyofdetectingdirectreplayattackscanalwaysachieveover\n88%accuracy.However,Table1showstheaccuracysignificantly\ndrops to 1.80% ∼58.56% when detecting the modulated replay audio.\nThe results indicate that our modulated attack can bypass existing\ncepstral coefficients based detection methods.\nBypassingHigh-frequencyFeaturesBasedDefense. Asshown\nin Figure 8(a) and Figure 8(b), the high-frequency spectral features\nbetweenthegenuineaudioandthereplayaudioaresignificantly\ndifferent. Therefore, a number of methods [ 27,55,65] detect re-\nplay attacks using high-frequency features, including Sub-band\nEnergy [27], HF-CQCC [ 65], and FM-AM [ 55]. Table 1 shows they\ncan achieve high accuracy on detecting the direct replay attack,\ne.g., 96.43%. However, they fail to detect the modulated attack due\nto frequency compensation. The highest accuracy on detecting the\nmodulated replay attack is only 38.74%.Bypassing Low-frequency Features Based Defense.\nBesides\ndetection based on high-frequency features, a recent study [ 8]p r o -\nvides an effective method, i.e. Sub-bass, to detect replay attacks\nbased on low-frequency features. It defines a metric named energy\nbalance metric, which indicates the energy ratio of the sub-bass\nrange(20-80Hz)tothelow-frequencyrange(20-250Hz).Ourexper-\niments show that it can achieve 99.1% accuracy on detecting direct\nreplay attacks with the metric. However, the accuracy significantly\ndrops to less than 8% when detecting modulated replay attacks.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1111Table 1: The accuracy of different defense methods on detecting direct replay attacks and modulated replay attacks.\nDetection Method†iPhone iPad Mi Phone Google Nexus BOSE Samsung TV\nCQCC [56] 95.95% / 4.50%★95.51% / 6.31% 92.18% / 8.11% 89.93% / 2.25% 91.90% / 7.21% 95.51% / 6.76%\nMFCC [68] 90.99% / 15.51% 93.24% / 18.92% 89.64% / 24.32% 89.19% / 27.03% 91.89% / 29.73% 90.99% / 27.71%\nLPCC [33] 89.19% / 8.11% 87.84% / 9.91% 90.09% / 15.32% 86.03% / 18.92% 87.84% / 11.71% 90.54% / 11.26%\nMWPC [42] 95.05% / 46.85% 92.79% / 36.04% 90.99% / 53.15% 95.05% / 43.24% 100.0% / 50.45% 86.93% / 58.56%\nSub-band Energy [27] 89.61% / 5.41% 89.22% / 4.50% 89.70% / 6.31% 88.61% / 10.81% 84.11% / 0.00% 85.57% / 0.90%\nHF-CQCC [65] 90.91% / 25.23% 90.91% / 22.52% 90.91% / 24.32% 90.08% / 18.02% 93.94% / 38.74% 93.94% / 11.71%\nFM-AM [55] 92.86% / 7.21% 92.86% / 17.12% 89.29% / 4.5% 92.86% / 9.91% 92.86% / 35.14% 96.43% / 12.61%\nSub-bass [8] 99.10% / 7.66% 99.10% / 4.50% 98.20% / 5.80% 98.65% / 4.95% 96.85% / 6.76% 97.30% / 5.40%\nDualGuard 91.00% / 98.88% 90.54% / 98.32% 89.19% / 97.75% 90.45% / 98.22% 90.10% / 97.79% 89.64% / 99.65%\n†The parameters of the different detection methods are listed in Appendix B.\n★The first number is on direct replay attack and the second number is on modulated replay attack.\nInthese8detectionmethodsabove,MWPCperformsbetterthan\nothertechniques.ThisisbecauseMWPCcancapturepartialtem-\nporal information using the mel-scale Wavelet Package Transform\n(WPT) [64], which handles the temporal signals on different scales.\nHF-CQCC can capture the high-frequency difference in signals.\nSuchpartialtemporalinformationandhigh-frequencydifference\nprovide more useful features for the detection of replay attacks.\nThus, MWPC and HF-CQCC perform better than other techniques.\nInaddition,Table1alsoshowstheexperimentalresultsofthemod-\nulatedreplayattackwithsixloudspeakerdevicesrespectively.In\ntheory, whatever frequency response a speaker has, we can always\nfind the corresponding inverse filter to counteract the effect of the\nreplayprocess.Asaresult,themodulatedreplayattackdoesnot\ndependonanyspecifictypeofspeaker.Theexperimentalresultsin\nTable1validateourattackdesign.Foranyspecificdetectionmethod,\nthe modulated replay attack exhibits similar performance when\nleveraging different speaker devices. This property is critical for\nreal-worldreplayattacks,becauseitdemonstratesthemodulated\nreplay attack is independent of the loudspeaker. An attacker can\nutilize any common speaker in our lives to perform the modulated\nreplay attack against ASR systems.\n5.3 Effectiveness of Dual-Domain Detection\nOurdefense,i.e.DualGuard,containstwoparts:time-domaindetec-\ntion and frequency-domaindetection. The time-domain detection\nmainlyaimstoidentifymodulatedreplayattacksandthefrequency-\ndomain detection mainly aims to identify direct replay attacks. We\nshow the experimental results for these two parts, respectively.\nTime-Domain Detection. We conduct experiments to evaluate\ntheaccuracyforDualGuardtodetectmodulatedreplayattacksin\nthetimedomain.Asthelocalextremaratio(LER)isthekeyfeature\nto detect replay attacks in the time domain, we first measure theLER values of both modulated replay audios and genuine audios\nfrom 6 different speaker devices.\nFigure9illustratesthechangeofLERvaluefromfinegranularity\n(with small window size) to coarse granularity (with large window\nsize). We can see that the LER decreases with the increase of the\nwindow size. When the window size is small, the LER value of\nthemodulatedreplayaudioisstatisticallylargerthanthatofthegenuine audio, which is the main difference between these twotypes of audios. As we mentioned in Section 4.2, the relatively\nhigh LER value results from the ringing artifacts in the modulated\nreplayaudio.Theresultsdemonstratethefeasibilitytodetectthe\nmodulated replay attack in the time domain with the LER patterns.\n 0 0.2 0.4 0.6 0.8 1\n 0  2  4  6  8  10  12  14  16  18  20Local Extrema Ratio\nWindow SizeGenuine Audio\nModulated Replay Audio\nFigure9:20-dimensionallocalextremapatternswithdiffer-ent granularity for genuine and modulated replay audios.\nWeconductexperimentstoevaluatethedetectionaccuracyin\nthe time domain with Algorithm 1. As shown in Figure 9, thereare no significant differences for the LERs of the genuine audio\nand the modulated replay audio when the window size reaches 20.\nThus, we choose a 20-dimensional tuple {LER1, LER2, ..., LER 20}in\nour algorithm as the feature to detect the modulated replay attack.\nHere, LER 𝑟denotes the LER value with the window size 𝑟. The\ndetection accuracy of DualGuard on modulated replay attacks is\nshown in Table 1. We can see that DualGuard can accurately iden-\ntify modulated replay attacks in the time domain. The detectionaccuracy for modulated replay attacks always exceeds 97% with\ndifferentspeakers.Wealsocalculatethefalsepositiverateofour\nmethod in detecting modulated replay attacks. It always maintains\nless than 8% false positive rate. The results demonstrate the gen-\neralizationabilityofDualGuardwithdifferentspeakers.Actually,\nthe generalization is due to the robust artifact properties in the\ntime-domainsignals(seeAppendixA).Ourtime-domaindefense\nisindependentofspeakers. Ourmaincontributionoftime-domain\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1112 0 5 10 15 20 25 30 35\n 0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1Proportion (%)\nArea Under CDF curve (AUC)Genuine Audio\nReplay Audio\nFigure 10: The AUC distribution of genuine audios and re-\nplay audios with the classification decision threshold.\ndefense is on the key feature extraction. For the experiments on\ncomparing different classifiers, we refer the readers to Appendix D.\nIn our defense, we choose SVM due to its high performance and\neasy deployment.\nFrequency-DomainDetection. Weconductexperimentstoeval-\nuatetheaccuracyforDualGuardtodetectdirectreplayattacksin\nthe frequency domain. To decide the decision threshold of Algo-\nrithm 2, we first obtain the Area Under CDF curve (AUC) from the\namplitude spectrum of audios. Figure 10 shows the AUC distribu-\ntions for both genuine audios and direct replay audios. We can see\nthat the AUC values of genuine audios are concentrated and close\nto 1, which indicates that the low-frequency energy is dominant.\nHowever,theAUCvaluesofdirectreplayaudiosaredistributedand\nsmall,whichisconsistentwiththedistributedspectrumofreplay\naudios. As shown in Figure 10, the best decision threshold is 0.817\nsince it can minimize the classification errors between genuine\naudios and replay audios. Table 1 shows the detection accuracyof DualGuard on direct replay attacks using Algorithm 2 with a\ndecisionthresholdof0.817.Theaccuracywithdifferentspeakers\nalways exceeds 89%. We also calculate the false positive rate of our\nmethod in detecting direct replay attacks. It always maintains less\nthan5%falsepositiverate. Moreover,weconductexperimentswith\nthe ASVspoof 2017 and 2019 datasets to show that DualGuard can\neffectivelydetectclassicreplayattacks.OurexperimentalresultsshowthatDualGuardcanachieve87.13%and83.80%accuracyin\nthese two datasets, respectively.\nMoreover, we train another model only with frequency features\nfrom a mix of genuine audios, direct replay audios, and modulated\nreplay audios in order to demonstrate the necessity to detect all\nreplay attacks in two domains. Our experimental results show that\ntheaccuracycanonlyreach63.36%.Itisduetothegreatspectral\nsimilarityofgenuineaudiosandmodulatedreplayaudiosinthefre-\nquency domain. Therefore, the dual-domain detection is necessary\nto accurately detect both two types of replay attacks.\n5.4 Robustness of Dual-Domain Detection\nWeconductexperimentstoshowtherobustnessofourdual-domain\ndetectionunderdifferentsamplingrates,differentrecordingdevices,\ndifferent speaker devices, and different noisy environments.\nImpact from Genuine Audio Sampling Rate. Weevaluatethe\nimpactofthesamplingrateforrecordingtheinitialhumanvoice 76 78 80 82 84 86 88 90 92\niPhone iPad Mi Phone Nexus BOSE TVDetection Accuracy (%)\n96 kHz 48 kHz 44.1 kHz \n(a) accuracy vs. sampling rate. 76 78 80 82 84 86 88 90 92\niPhone iPad Mi Phone Nexus BOSE TVDetection Accuracy (%)\nQuiet Env. SNR = 60 dB SNR = 40 dB\n(b) accuracy vs. noise level.\nFigure11:Detectionaccuracyofdifferentrecordingdevices\nwith different factors.\nby attackers. We first use TASCAM DR-40 digital recorder with\nfs = 96 kHz to capture initial human voice. We also use iPhone\nX with fs = 48 kHz to capture human voice. For both sampling\nrates, the average detection accuracy of DualGuard on modulated\nreplayattack is98.05%.That isbecausethe samplingrateused by\nattackers only changes the spectral resolution in the modulation\nprocess.However,thewaveformofmodulatedreplayaudioswill\nnotbechangedsinceD/Aconverterwillconvertmodulatedsignals\ninto analog form before the replay process.\nImpact from ASR Sampling Rate. Weconductexperimentson\ndifferent recording devices with different sampling rates. In our\nexperiments, there are three settings of sampling rates for our\nrecordingdevices:(S1)TASCAMDR-40with96kHz,(S2)TASCAM\nDR-40with48kHz,and(S3)amobilephone(Xiaomi4)with44.1\nkHz.Figure11(a)showstheexperimentalresults.Wecanseethe\ndetection accuracy usually increases with the increase of sampling\nrates.Wefindthatalthoughchangingthesamplingratehaslittle\neffectonthefrequency-domaindetection,itsignificantlyaffectsthe\ntime-domain detectiondue to thechange of the sampling interval.\nNotethatthesmallersamplingintervalmeansthefinerdetection\ngranularityoflocalextremaratios,whichincreasesthedetection\naccuracy. Moreover, in Figure 11(a), our experiments show thatDualGuard still achieves around 85% detection accuracy in the\nworstcasewherethesamplingrateis44.1kHz.Wenotethat44.1\nkHzistheminimumsamplingrateofcommonelectronicdevicesin\nour lives [ 23]. Therefore, DualGuard can achieve a good detection\naccuracy with different sampling rates in common devices.\nImpact from Different Recording Devices. In Figure 11(a), the\ndetection accuracy does not significantly change when we use\ndifferent recorders with the same sampling rate. The detectionaccuracy changes less than 2% with different recording devices\nwhen the sampling rate is 48 kHz or 44.1 kHz. The results show\nDualGuardcanbeappliedtodifferentrecordingdevicesinourlives.\nImpactfromDifferentNoisyEnvironments. Totestthedetec-\ntion accuracy under different noisy environments, we introducenoise factors in our experiments. We test our detection method\nunder three scenarios: (1) in a quiet environment, (2) in a noisy en-\nvironmentwiththesignal-to-noiseratio(SNR)of60dB,and(3)ina\nnoisyenvironmentwiththeSNRof40dB.Theadditivenoisesignal\nisproducedbyaloudspeakerthatplaysapre-preparedGaussian\nwhitenoisesignal,simulatingthenoiseintherealworld.Thenoise\nis mixed with the test signals with specific SNR. Figure 11(b) illus-\ntratesthedetectionaccuracyinvariousnoiseconditions.Wecan\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1113see that the impact of noise is limited. Particularly, the detection\naccuracyremainsunchangedwhentheSNRis60dB.WhentheSNR\ndropsto40dB,thedetectionaccuracydecreasesby3.2%onaverage.\nActually,theimpactofnoiseismainlyreflectedinthetime-domain\ndefense. General noise has little effect on the frequency-domain\ndefense part. With the increase of noise power, the burr amplitude\ninthenoisewillalsoincrease.Asaresult,noisecanresultinthe\nimprecise detection of the local extrema pattern in the test signals.\nHowever, our experimental results indicate that DualGuard still\nworks well at the general ambient noise level.\n5.5 Overhead of Dual-Domain Detection\nWeimplementDualGuardwithC++language,andbuildasystem\nprototypeinReSpeakerCorev2,whichisapopularvoiceinterac-\ntiveplatformwithquad-coreARMCortex-A7of1.5GHzand1GB\nRAM on-board. Our experimental results show that the embedded\nprogram takes 5.5 𝑚𝑠on average to process a signal segment of 32\n𝑚𝑠length with the CPU usage of 24.2%. The largest memory usage\nof the program is 12.05 MB. The results demonstrate the feasibility\nof applying our dual-domain detection system in the real world.\n6 RELATED WORK\nInthissection,wereviewrelatedresearchonattackstargetingASRsystems, techniques on loudspeaker frequency response compensa-\ntion, and defense systems against replay attacks, respectively.\nAttacks on Speaker Dependent ASRs. A speaker dependent\nASRsystemisdesignedtoonlyacceptvoicecommandsfromspe-\ncificusers[ 66].Itverifiesthespeaker’sidentitybymatchingthein-\ndividual characteristics of human voice. There are four main spoof-\ning attacks against the speaker dependent ASRs. First, an attacker\ncan physically approach a victim’s system and alter its voice to im-\npersonate the victim [ 22]. Second, the attacker can launch a simple\nreplayattackbyplayingbackapre-recordedspeechofthevictim\nto the ASR systems [ 60,62]. Third, speech synthesis attacks gener-\nateartificialspeechtospoof theASRsystems[ 12,15,34].Fourth,\nspeechconv ersion attacks aim to achiev easpeech-to-speechcon-\nversion, so that the generated speech has the same timbre and\nprosody with the victim speech[30, 67].\nAttacksonSpeakerIndependentASRs. Aspeakerindependent\nsystemisdesignedtoacceptcommandsfromanypersonwithout\nidentity verification. Comparing to the speaker dependent system,\nitismorevulnerabletoattacks[ 3,17,26,44].Recently,researchers\nfound more surreptitious attacks that humans cannot easily per-\nceiveorinterpret.Dolphinattackishardtobenoticedsincethema-liciousaudioismodulatedintotheultrasonicrange[\n47,53,71].The\nvoicecommandscanalsobemodulatedintolaserlighttolaunchau-\ndioinjectionattack[ 54].Also,themaliciousaudiocanbeperturbed\nintoanunintelligibleformineithertimedomainorfrequencydo-\nmain[1].ToattackthemachinelearningmoduleinASRs,recent\nresearch shows attackers can produce noise-like [ 11,32,58,76]\nor song-like [ 70] voice commands that cannot be interpreted by\nhuman. Psychoacoustic model can also be applied to generate the\nadversarialaudiobelowthehumanperceptionthreshold[ 49].By\nfooling the natural language processing (NLP) module after ASRs,\nskillsquattingattacksmisleadthesystemtolaunchmaliciousap-\nplications [18, 31, 40, 74, 75].LoudspeakerFrequencyResponseCompensation. Inthefield\nofroomacoustics,loudspeakerfrequencyresponsecompensationisatechniqueusedtoimprovethesoundreproduction[\n13].Thebasic\nmethod is to design an intelligent filter to flatten the frequencyresponse of the loudspeakers [\n10]. The frequency response com-\npensation can also be achieved by advanced filter with a genericHammerstein loudspeaker model [\n16]. For a multichannel loud-\nspeakersystem,theminimaxapproximationmethodisproposedto\nflattenthespectralresponsearoundthecrossoverfrequency[ 37].\nAlso,apolynomialbasedMIMOformulationisproposedtosolve\nthe multi-speaker compensation problem [9].\nDefensesagainstReplayAttacks. InASVspoofingChallenge[ 29],\nseveral replay detection methods are proposed by exploiting the\nfrequency-basedfeatures,suchasLinearPredictionCepstralCoeffi-\ncient(LPCC)[ 42],MelFrequencyCepstralCoefficient(MFCC)[ 68],\nConstantQCepstralCoefficients(CQCC)[ 56],HighFrequencyCep-\nstral Coefficients (HFCC) [ 41] and Modified Group Delay Cepstral\nCoefficient(MGDCC)[ 35].Besides,thehigh-frequencysub-band\nfeaturescanbeusedtodetectlivehumanvoicebythelinearpredic-\ntion (LP) analysis [ 65]. The sub-bass (low-frequency range) energy\nis also an effective feature to detect the replay signals, though\nthismethodcanbebypassedbyalteringthespeakerenclosureor\nmodulatingthesignalswithourinversefilter[ 8].Thefrequency\nmodulation features [ 21,28,55] can also be leveraged due to the\ndegraded amplitude components of replay noise.\nResearchersproposetodetectreplayattacksusingphysicalprop-\nerties. Gong et al. detect the body-surface vibration via a wearable\ndevice to guarantee the voice comes from a real user [ 19]. 2MA [7]\nverifiesthevoicecommandsbysoundlocalizationusingtwomicro-\nphones.Yanetal.proposeaspoofingdetectionmethodbasedon\nthevoiceprintdifferencebetweentheauthenticuserandloudspeak-\ners [69]. All these methods require special equipment or specific\nscenarios. VoiceLive [ 73] detects live human voice by capturing\nthetime-difference-of-arrival(TDoA)dynamicofphonemesound\nlocations.VoiceGesture[ 72]reusessmartphonesasaDopplerradar\nandverifiesthevoicebycapturingthearticulatorygestureofthe\nuser when speaking a passphrase. However, these two methods\nworkwellonlywhenthereisashortdistancebetweentherecorder\nand the user’s mouth.\n7 CONCLUSION\nInthispaper,weproposeanewmodulatedreplayattackagainst\nASRsystems.Thisattackcanbypassalltheexistingreplaydetection\nmethodsthatutilizedifferentfrequencydomainfeaturesbetween\nelectronic speakers and humans. We design an inverse filter to\nhelpcompensatefrequencydistortionsothatthemodulatedreplay\nsignalshavealmostthesamefrequencyfeaturesashumanvoices.\nTo defeatthisnew attack,wepropose adual-domain defensethat\nchecksaudiosignal’sfeaturesinbothfrequencydomainandtime\ndomain.Experimentsshowourdefensecaneffectivelydefeatthe\nmodulated replay attacks and classical replay attacks.\nACKNOWLEDGMENTS\nThisworkispartiallysupportedbytheU.S.AROgrantW911NF-\n17-1-0447, U.S. ONR grants N00014-18-2893 and N00014-16-1-3214,\nand the NSFC grants U1736209 and 61572278. Jiahao Cao and Qi Li\nare the corresponding authors of this paper.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1114REFERENCES\n[1]Hadi Abdullah, Washington Garcia, Christian Peeters, Patrick Traynor, Kevin\nR. B. Butler, and Joseph Wilson. 2019. Practical Hidden Voice Attacks against\nSpeechandSp eaker Recognition Systems. In Proceedings of the 2019 The Network\nand Distributed System Security Symposium (NDSS ’19).\n[2]E.AlepisandC.Patsakis.2017. MonkeySays,MonkeyDoes:SecurityandPrivacy\non Voice Assistants. IEEE Access 5 (2017), 17841–17851. https://doi.org/10.1109/\nACCESS.2017.2747626\n[3]E.AlepisandC.Patsakis.2017. MonkeySays,MonkeyDoes:SecurityandPrivacy\non Voice Assistants. IEEE Access 5 (2017), 17841–17851. https://doi.org/10.1109/\nACCESS.2017.2747626\n[4]AmazonAlexa.2018. Wikipedia,TheFreeEncyclopedia. https://en.wikipedia.\norg/wiki/Amazon_Alexa, [accessed December 2018].\n[5]Google Assistant. 2019. Google. https://assistant.google.com/, [accessed Decem-\nber 2019].\n[6]TheOfficalWeChatBlog.2019. Voiceprint:TheNewWeChatPassword. https:\n//www.techinasia.com/baidu-lenovo-voice-recognition-android-unlock, [Ac-\ncessed September, 2019].\n[7]LoganBlue,HadiAbdullah,LuisVargas,andPatrickTraynor.2018. 2MA:Ver-\nifying Voice Commands via Two Microphone Authentication. In Proceedings\nof the 2018 on Asia Conference on Computer and Communications Security (In-\ncheon, Republic of Korea) (ASIACCS ’18). ACM, New York, NY, USA, 89–100.\nhttps://doi.org/10.1145/3196494.3196545\n[8]Logan Blue, Luis Vargas, and Patrick Traynor. 2018. Hello, Is It Me You’Re\nLookingFor?:DifferentiatingBetweenHumanandElectronicSpeakersforVoiceInterfaceSecurity.In Proceedingsofthe11thACMConferenceonSecurity&Privacy\nin Wireless and Mobile Networks (Stockholm, Sweden) (WiSec ’18). ACM, New\nYork, NY, USA, 123–133. https://doi.org/10.1145/3212480.3212505\n[9]L. Brännmark, A. Bahne, and A. Ahlén. 2013. Compensation of Loud-\nspeaker–RoomResponsesinaRobustMIMOControlFramework. IEEETrans-\nactionsonAudio,Speech,andLanguageProcessing 21,6(June2013),1201–1216.\nhttps://doi.org/10.1109/TASL.2013.2245650\n[10]A.Carini,S.Cecchi,F.Piazza,I.Omiciuolo,andG.L.Sicuranza.2012. Multiple\nPositionRoom ResponseEqualizationin FrequencyDomain. IEEETransactions\non Audio, Speech, and Language Processing 20, 1 (Jan 2012), 122–135. https:\n//doi.org/10.1109/TASL.2011.2158420\n[11]NicholasCarlini, PratyushMishra,Tavish Vaidya,YuankaiZhang, MicahSherr,\nClayShields,DavidWagner,andWenchaoZhou.2016. HiddenVoiceCommands.\nIn25thUSENIXSecuritySymposium(USENIXSecurity16).USENIXAssociation,\nAustin, TX, 513–530. https://www.usenix.org/conference/usenixsecurity16/\ntechnical-sessions/presentation/carlini\n[12] N. CarliniandD. Wagner.2018. AudioAdversarialExamples: TargetedAttacks\non Speech-to-Text. In 2018 IEEE Security and Privacy Workshops (SPW). 1–7.\n[13]StefaniaCecchi,AlbertoCarini,andSaschaSpors.2018. RoomResponseEqualiza-tion—A Review. Applied Sciences 8, 1 (2018). https://doi.org/10.3390/app8010016\n[14]Microsoft Cortana.2019. Microsoft. https://www.microsoft.com/en-us/cortana,\n[accessed December 2019].\n[15]P. L. De Leon, M. Pucher, J. Yamagishi, I. Hernaez, and I. Saratxaga. 2012. Evalu-\nationofSpeakerVerificationSecurityandDetectionofHMM-BasedSynthetic\nSpeech.IEEETransactionsonAudio,Speech,andLanguageProcessing 20,8 (Oct\n2012), 2280–2290. https://doi.org/10.1109/TASL.2012.2201472\n[16]B. Defraene, T. van Waterschoot, M. Diehl, and M. Moonen. 2013. Embedded-optimization-based loudspeaker compensation using a generic Hammerstein\nloudspeakermodel.In 21stEuropeanSignalProcessingConference(EUSIPCO2013).\n1–5.\n[17]Wenrui Diao, Xiangyu Liu, Zhe Zhou, and Kehuan Zhang. 2014. Your Voice\nAssistantisMine:HowtoAbuseSpeakerstoStealInformationandControlYour\nPhone.CoRRabs/1407.4923 (2014). arXiv:1407.4923 http://arxiv.org/abs/1407.\n4923\n[18]Yuan Gong and Christian Poellabauer. 2017. Crafting Adversarial Exam-ples For Speech Paralinguistics Applications. CoRRabs/1711.03280 (2017).\narXiv:1711.03280 http://arxiv.org/abs/1711.03280\n[19]Y. Gong and C. Poellabauer. 2018. Protecting Voice Controlled Systems Using\nSoundSourceIdentificationBasedonAcousticCues.In 201827thInternational\nConference on Computer Communication and Networks (ICCCN). 1–9. https:\n//doi.org/10.1109/ICCCN.2018.8487334\n[20]Google. 2019. Let \"Ok Google\" and \"Hey Google\" unlock your phoneor tablet. https://support.google.com/assistant/answer/7394306?co=GENIE.\nPlatform%3DAndroid&hl=en. Accessed September, 2019.\n[21]TharshiniGunendradasan,BuddhiWickramasinghe,NgocPhuLe,Eliathamby\nAmbikairajah, and Julien Epps. 2018. Detection of Replay-Spoofing Attacks\nUsing Frequency Modulation Features. In Proc. Inters peech2018. 636–640. https:\n//doi.org/10.21437/Interspeech.2018-1473\n[22]RosaGonzálezHautamäki,TomiKinnunen,VilleHautamäki,TimoLeino,and\nAnne-Maria Laukkanen. 2013. I-vectors meet imitators: on vulnerability of\nspeaker verification systems against voice mimicry. In INTERSPEECH.[23]44100 Hz. 2019. Wikipedia, The Free Encyclopedia. https://en.wikipedia.org/\nwiki/44,100_Hz. [accessed November 2019].\n[24]Spline interpolation. 2019. Wikipedia, The Free Encyclopedia. https://en.\nwikipedia.org/wiki/Spline_interpolation, [accessed April 2019].\n[25]Anil K Jain, Ruud Bolle, and Sharath Pankanti. 2006. Biometrics: personal identifi-\ncation in networked society. Vol. 479. Springer Science & Business Media.\n[26]Yeongjin Jang, Chengyu Song, Simon P. Chung, Tielei Wang, and Wenke Lee.\n2014. A11YAttacks:ExploitingAccessibilityinOperatingSystems.In Proceedings\nofthe2014ACMSIGSACConferenceonComputerandCommunicationsSecurity\n(Scottsdale, Arizona, USA) (CCS ’14). ACM, New York, NY, USA, 103–115. https:\n//doi.org/10.1145/2660267.2660295\n[27]M.R.KambleandH.A.Patil.2017. Novelenergyseparationbasedinstantaneous\nfrequency features for sp oof speech detection. In 2017 25th European Signal\nProcessingConference(EUSIPCO).106–110. https://doi.org/10.23919/EUSIPCO.\n2017.8081178\n[28]M. R. Kamble and H. A. Patil. 2018. Novel Amplitude Weighted FrequencyModulation Features for Replay Spoof Detection. In 2018 11th International\nSymposium on Chinese Spoken Language Processing (ISCSLP). 185–189. https:\n//doi.org/10.1109/ISCSLP.2018.8706673\n[29]TomiKinnunen,MdSahidullah,HéctorDelgado,MassimilianoTodisco,NicholasEvans,JunichiYamagishi,andKongAikLee.2017. TheASVspoof2017challenge:\nAssessingthe limitsof replayspoofing attackdetection. In INTERSPEECH2017,\nAnnualConferenceoftheInternationalSpeechCommunicationAssociation,August\n20-24,2017,Stockholm,Sweden.Stockholm,SWEDEN. http://www.eurecom.fr/\npublication/5235\n[30]T. Kinnunen, Z. Wu, K. A. Lee, F. Sedlak, E. S. Chng, and H. Li. 2012. Vulnera-\nbility of speaker verification systems against voice conversion spoofing attacks:\nThe case of telephone speech. In 2012 IEEE International Conference on Acous-\ntics,Speech andSignalProcessing(ICASSP).4401–4404. https://doi.org/10.1109/\nICASSP.2012.6288895\n[31]Deepak Kumar, Riccardo Paccagnella, Paul Murley, Eric Hennenfent, Joshua\nMason,AdamBates,andMichaelBailey.2018. SkillSquattingAttacksonAmazon\nAlexa. In Proceedings of the 27th USENIX Conference on Security Symposium\n(Baltimore, MD, USA) (SEC’18). USENIX Association, Berkeley, CA, USA, 33–47.\nhttp://dl.acm.org/citation.cfm?id=3277203.3277207\n[32]HyunKwon,HyunsooYoon,andKi-WoongPark.2019. POSTER:DetectingAudio\nAdversarial Example Through Audio Modification. In Proceedings of the 2019\nACM SIGSAC Conference on Computer and Communications Security (London,\nUnited Kingdom) (CCS ’19). ACM, NewYork,NY, USA, 2521–2523. https://doi.\norg/10.1145/3319535.3363246\n[33]Galina Lavrentyeva, Sergey Novoselov, Egor Malykh, Alexander Kozlov, Oleg\nKudashev,and VadimShchemelinin.2017. Audio ReplayAttack Detectionwith\nDeep Learning Frameworks. In Proc. Inters peech2017. 82–86. https://doi.org/10.\n21437/Interspeech.2017-360\n[34]PhillipL.DeLeon,BryanStewart, andJunichiYamagishi.2012. SyntheticSpeech\nDiscriminationusingPitchPatternStatisticsDerivedfromImageAnalysis.In\nINTERSPEECH.\n[35]DongboLi,LongbiaoWang,JianwuDang,MengLiu,ZeyanOo,SeiichiNakagawa,\nHaotian Guan, and Xiangang Li. 2018. Multiple Phase Information Combination\nfor Replay Attacks Detection. In INTERSPEECH.\n[36]Johnny Lieu. 2019. Volkswagen drivers can unlock their cars with Siri. https:\n//mashable.com/article/volkswagen-siri-shortcuts-unlock/. AccessedSeptember,\n2019.\n[37]C. S. Lin and Y. H. Chen. 2012. Phase compensation for multichannel low-\nfrequency responseusing minimax approximation. In 2012 InternationalConfer-\nence on Audio, Language and Image Processing. 182–188. https://doi.org/10.1109/\nICALIP.2012.6376608\n[38]K. M. Malik, H. Malik, and R. Baumann. 2019. Towards Vulnerability Analysis of\nVoice-DrivenInterfacesandCountermeasuresforReplayAttacks.In 2019IEEE\nConferenceonMultimediaInformationProcessingandRetrieval(MIPR).523–528.\nhttps://doi.org/10.1109/MIPR.2019.00106\n[39]StevenMillward.2019. OpenSesame:BaiduHelpsLenovoUseVoiceRecognition\ntoUnlockAndroidPhones. https://www.techinasia.com/baidu-lenovo-voice-\nrecognition-android-unlock, [Accessed September, 2019].\n[40]Richard Mitev, Markus Miettinen, and Ahmad-Reza Sadeghi. 2019. Alexa Lied to\nMe: Skill-based Man-in-the-Middle Attacks on Virtual Assistants. In Proceedings\nof the 2019 ACM Asia Conference on Computer and Communications Security\n(Auckland, New Zealand) (Asia CCS ’19). ACM, New York, NY, USA, 465–478.\nhttps://doi.org/10.1145/3321705.3329842\n[41]Parav Nagarsheth, Elie Khoury, Kailash Patil, and Matt Garland. 2017. Replay\nAttack Detection Using DNN for Channel Discrimination. In INTERSPEECH.\n[42]S. Novoselov, A. Kozlov, G. Lavrentyeva, K. Simonchik, and V. Shchemelinin.\n2016. STC anti-spoofing systems for the ASVspoof 2015 challenge. In 2016 IEEE\nInternational Conference on Acoustics, Speech and Signal Processing (ICASSP).\n5475–5479. https://doi.org/10.1109/ICASSP.2016.7472724\n[43]openstax. 2019. Comparison of Spectrums of Voice Signals Using the L2Norm. https://cnx.org/contents/gm57qegZ@1/Comparison-of-Spectrums-of-\nVoice-Signals-Using-the-L2-Norm. Accessed January, 2020.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1115[44]GiuseppePetracca,YuqiongSun,TrentJaeger,andAhmadAtamli.2015. AuDroid:\nPreventingAttacksonAudioChannelsinMobileDevices.In Proceedingsofthe\n31stAnnualComputerSecurityApplicationsConference (LosAngeles,CA,USA)\n(ACSAC 2015). ACM, New York, NY, USA, 181–190. https://doi.org/10.1145/\n2818000.2818005\n[45]Facebook Portal. 2019. Facebook. https://portal.facebook.com/, [accessed\nDecember 2019].\n[46]Frequency Response. 2019. Wikipedia, The Free Encyclopedia. https://en.\nwikipedia.org/wiki/Frequency_response, [accessed December 2019].\n[47]NirupamRoy,ShengShen,HaithamHassanieh,andRomitRoyChoudhury.2018.\nInaudibleVoiceCommands:TheLong-RangeAttackandDefense.In 15thUSENIX\nSymposium on Networked Systems Design and Implementation (NSDI 18) . USENIX\nAssociation, Renton, WA, 547–560. https://www.usenix.org/conference/nsdi18/\npresentation/roy\n[48]Say-Tec. 2019. Use Say-Tec (formerly SayPay) to make payment approvals.\nhttps://www.say-tec.com/.\n[49]Lea Schönherr, Katharina Kohls, Steffen Zeiler, Thorsten Holz, and Dorothea\nKolossa.2018. AdversarialAttacksAgainst AutomaticSpeec hRecognitionSys-\ntems via Psychoacoustic Hiding. CoRRabs/1808.05665 (2018).\n[50]Fourier series. 2019. Wikipedia, The Free Encyclopedia. https://en.wikipedia.\norg/wiki/Fourier_series, [accessed April 2019].\n[51]American Home Shield. 2019. Top 10: Best “Smart Home” Voice-Control De-\nvices. https://www.ahs.com/home-matters/tech/smart-home-voice-control-\ndevices. Accessed September, 2019.\n[52]AppleSiri.2019. Apple. https://www.apple.com/siri/,[accessedNovember2019].\n[53]Liwei Song and Prateek Mittal. 2017. Inaudible Voice Commands. CoRR\nabs/1708.07238 (2017). arXiv:1708.07238 http://arxiv.org/abs/1708.07238\n[54]Takeshi Sugawara, Benjamin Cyr, Sara Rampazzi, Daniel Genkin, and Kevin\nFu. 2019. Light Commands: Laser-Based Audio Injection on Voice-Controllable\nSystems. https://lightcommands.com/20191104-Light-Commands.pdf,[accessed\nNovember 2019].\n[55]Gajan Suthokumar, Vidhyasaharan Sethu, Chamith Wijenayake, and Eliathamby\nAmbikairajah.2018. ModulationDynamic Featuresfor theDetectionof Replay\nAttacks. 691–695. https://doi.org/10.21437/Interspeech.2018-1846\n[56]MassimilianoTodisco,HéctorDelgado,andNicholasEvans.2017. ConstantQ\ncepstral coefficients: A spoofing countermeasure for automatic speaker verifica-\ntion.Computer Speec h Language 45 (2017), 516 – 535. https://doi.org/10.1016/j.\ncsl.2017.01.001\n[57]ReSpeakerCorev2.0. 2019.Seeed Studio. http://wiki.seeedstudio.com/ReSpeaker_\nCore_v2.0/, [accessed December 2019].\n[58]Tavish Vaidya, Yuankai Zhang, Micah Sherr, and Clay Shields. 2015. Cocaine\nNoodles: Exploiting the Gap betwee n Human and Machine SpeechR ecognition.\nIn9th USENIX Workshop on Offensive Technologies (WOOT 15) . USENIX Associa-\ntion, Washington, D.C. https://www.usenix.org/conference/woot15/workshop-\nprogram/presentation/vaidya\n[59]JesúsVillalbaandEduardoLleida.2011. DetectingReplayAttacksfromFar-Field\nRecordingsonSpeakerVerificationSystems.In BiometricsandIDManagement,\nClaus Vielhauer, Jana Dittmann, Andrzej Drygajlo, Niels Christian Juul, and\nMichael C. Fairhurst (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 274–\n285.\n[60]J. Villalba and E. Lleida. 2011. Preventing replay attacks on speaker verification\nsystems.In 2011CarnahanConferenceonSecurityTechnology.1–8. https://doi.\norg/10.1109/CCST.2011.6095943\n[61]Xin Wang, Junichi Yamagishi, Massimiliano Todisco, Hector Delgado, An-\ndreasNautsch,NicholasEvans,MdSahidullah,VilleVestman,TomiKinnunen,\nKong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu\nTsao,Hsin-MinWang, SebastienLe Maguer, MarkusBecker, FergusHenderson,\nRob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi\nKaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda,\nKouTanaka,HirokazuKameoka,IngmarSteiner,DrissMatrouf,Jean-Francois\nBonastre,AvashnaGovender,SrikanthRonanki,Jing-XuanZhang,andZhen-Hua\nLing. 2019. ASVspoof 2019: a large-scale public database of synthetic, converted\nandreplayedspeech. arXiv:1911.01601[eess.AS]\n[62]Z. Wang,G. Wei, and Q.He. 2011. Channel pattern noise based playback attack\ndetection algorithm for speakerrecognition. In 2011 International Conferenceon\nMachineLearningandCybernetics ,Vol.4.1708–1713. https://doi.org/10.1109/\nICMLC.2011.6016982\n[63]Wikipedia. 2019. Ringing artifacts. https://en.wikipedia.org/wiki/Ringing_\nartifacts. Accessed September, 2019.\n[64]Wikipedia. 2020. Wavelet packet decomposition. https://en.wikipedia.org/wiki/\nWavelet_packet_decomposition. Accessed April, 2020.\n[65]Marcin Witkowski, Stanislaw Kacprzak, Piotr Zelasko, Konrad Kowalczyk, and\nJakubGalka.2017. AudioReplayAttackDetectionUsingHigh-FrequencyFea-\ntures.. In INTERSPEECH 2017.\n[66]Zhizheng Wu, Nicholas Evans, Tomi Kinnunen, Junichi Yamagishi, Federico\nAlegre, and Haizhou Li. 2015. Spoofing and countermeasures for speaker\nverification: A survey. Speech Communication 66 (2015), 130 – 153. https:\n//doi.org/10.1016/j.specom.2014.10.005[67]Z. Wu and H. Li. 2013. Voice conversion and spoofing attack on speaker verifica-tionsystems.In 2013Asia-PacificSignalandInformationProcessingAssociationAn-\nnual Summit and Conference. 1–9. https://doi.org/10.1109/APSIPA.2013.6694344\n[68]ZhifengXie,WeibinZhang,ZhuxinChen,andXiangminXu.2019. AComparison\nof Features for Replay Attack Detection. Journal of Physics: Conference Series\n1229 (may 2019), 012079. https://doi.org/10.1088/1742-6596/1229/1/012079\n[69]ChenYan,YanLong,XiaoyuJi,andWenyuanXu.2019.TheCatcherintheField:AFieldprintBasedSpoofingDetectionforText-IndependentSpeakerVerification.InProceedingsofthe2019ACMSIGSACConferenceonComputerandCommunications\nSecurity(London, United Kingdom) (CCS ’19). ACM, New York, NY, USA, 1215–\n1229. https://doi.org/10.1145/3319535.3354248\n[70]XuejingYuan,YuxuanChen,YueZhao,YunhuiLong,XiaokangLiu,KaiChen,\nShengzhiZhang,HeqingHuang,XiaoFengWang,andCarlA.Gunter.2018. Com-manderSong:ASystematicApproachforPracticalAdversarialVoiceRecognition.\nIn27thUSENIXSecuritySymposium(USENIXSecurity18).USENIXAssociation,\nBaltimore,MD,49–64. https://www.usenix.org/conference/usenixsecurity18/\npresentation/yuan-xuejing\n[71]Guoming Zhang, Chen Yan, Xiaoyu Ji, Tianchen Zhang, Taimin Zhang, and\nWenyuanXu.2017. DolphinAttack:InaudibleVoiceCommands.In Proceedings\nofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity\n(Dallas, Texas, USA) (CCS ’17). 103–117.\n[72]LinghanZhang,ShengTan,andJieYang.2017. HearingYourVoiceisNotEnough:\nAn Articulatory Gesture BasedLiveness Detection for Voice Authentication. In\nProceedingsofthe2017ACMSIGSACConferenceonComputerandCommunicationsSecurity(Dallas, Texas, USA) (CCS ’17). ACM, New York, NY, USA, 57–71. https:\n//doi.org/10.1145/3133956.3133962\n[73]Linghan Zhang, Sheng Tan, Jie Yang, and Yingying Chen. 2016. VoiceLive: APhoneme Localization Based Liveness Detection for Voice Authentication on\nSmartphones.In Proceedingsofthe2016ACMSIGSACConferenceonComputer\nand Communications Security (Vienna, Austria) (CCS ’16). ACM, New York, NY,\nUSA, 1080–1091. https://doi.org/10.1145/2976749.2978296\n[74]Nan Zhang, Xianghang Mi, Xuan Feng, XiaoFeng Wang, Yuan Tian, and Feng\nQian.2019. DangerousSkills:UnderstandingandMitigatingSecurityRisksof\nVoice-ControlledThird-Party Functionson Virtual PersonalAssistant Systems.\nInIEEE SP 2019.\n[75]YangyongZhang,AbnerMendoza,GuangliangYang,LeiXu,PhakpoomChinprut-\nthiwong, and Guofei Gu. 2019. Life after SpeechRecognition: Fuzzing Semantic\nMisinterpretationforVoiceAssistantApplications.In Proceedingsofthe2019The\nNetworkandDistributedSystemSecuritySymposium(NDSS’19) .InternetSociety.\n[76]M.Zhou,Z.Qin,X.Lin,S.Hu,Q.Wang,andK.Ren.2019. HiddenVoiceCom-\nmands:AttacksandDefensesontheVCSofAutonomousDrivingCars. IEEEWire-\nless Communications (2019), 1–6. https://doi.org/10.1109/MWC.2019.1800477\n[77]H.Zhu,M.Ding,andY.Li.2011. GibbsphenomenonforfractionalFourierseries.\nIET Signal Processing 5, 8 (December 2011), 728–738. https://doi.org/10.1049/iet-\nspr.2010.0348\nA MATHEMATICAL PROOF OF RINGING\nARTIFACTS IN MODULATED REPLAY\nAUDIO\nTheoremA.1. UncertaintyPrinciple:Itishardtoaccuratelyde-\ntermine the entire frequency response of a loudspeaker.\nProof.Thefrequencyresponseofaloudspeakercontainsampli-\ntude response and phase response. The measurement of amplitude\nresponseisdemonstrated inSection3.4.However,itisdifficultto\naccurately measure the phase response.\nFor an electronic circuit system, the phase response can be mea-\nsuredbyobservingtheelectricsignals 𝑥𝑜𝑢𝑡(𝑡)and𝑥𝑖𝑛(𝑡)withan\noscilloscope. But in a loudspeaker system, we cannot measure the\nphaseresponsedirectlybecausetheoutputsignal 𝑥𝑜𝑢𝑡(𝑡)isasound\nwave.Otherequipment(suchasareceiverthatconvertssoundwave\nto electronic signal) is required to complete the measurement. But\nthemeasuringsystemcanintroduceotherphasedifferences.There\nare mainly three influence factors:\n(1) Time of flight. The propagation time will add phase differ-\nences. It is important to know the accurate delay time 𝑡=𝐿/𝑣0,\nwhere𝐿is the direct distance between the speaker and the sensor.\nThesoundspeed 𝑣0≈344m/s (@20◦C).\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1116(2)Time incoherence. Most of the available loudspeakers are not\ntime coherent,which will exhibitphase error in themeasurement.\n(3)Phase response of receiving sensor. The phase response of\nreceivingsensoristypicallyunknown,whichwillalsointroduce\nphase shifts.\nAsaresult,theaccuracyofphaseresponsemeasurementcannot\nbeguaranteed.Thatmeanstheentirefrequencyresponsecannot\nbeaccurate.Alsowecanprovethatevensmallmeasurementerrors\nfor phase response can cause ringing artifacts (see Theorem 3).\n/square\nTheorem A.2. Compared to the genuine signal 𝑥(𝑡), there are\nphaseshiftsforeachfrequencycomponentinthemodulatedreplay\nsignal𝑥𝑚𝑟(𝑡).\nProof.In the modulated replay attack, the inverse filter only\nneeds to compensate the amplitude spectrum because the features\n(e.g.CQCC,MFCC,LPCC)intheexistingdefensesonlyderivesfrom\nthe amplitude spectrum. However, a loudspeaker has a non-zero\nphase response in the real world, though it cannot be accurately\nmeasured (see Theorem A.1).\nSupposethegenuineaudiox(t)isadigitalsignal.Throughthe\nfastFouriertransform,x(t)wouldbedecomposedas 𝑁frequency\ncomponentswiththefrequencyset {𝑓1,𝑓2,...,𝑓 𝑁}.Thefrequency\nspectrumof𝑥(𝑡)isdenotedas {𝐴𝑛,𝜑𝑛},where{𝐴𝑛}istheampli-\ntude spectrum while {𝜑𝑛}is the phase spectrum. So, 𝑥(𝑡)can be\nrepresented as\n𝑥(𝑡)=/summationdisplay.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛). (4)\nAssumethatthefrequencyresponseoftheloudspeakeris 𝐻=\n{𝐺𝑛,𝜓𝑛},where{𝐺𝑛}isthe amplituderesponse while {𝜓𝑛}isthe\nphase response. By measuring the input and output test signals,\nattackercanachievetheestimatedfrequencyresponse ˆ𝐻={ˆ𝐺𝑛,0}.\nThe inverse filter is then designed based on ˆ𝐻, denoted as 𝐼=\nˆ𝐻−1={ˆ𝐺𝑛−1,0}.Asaresult,thegeneratedmodulatedaudiowould\nbe\n𝑥𝑚(𝑡)=/summationdisplay.1\n𝑛(𝐴𝑛/ˆ𝐺𝑛)·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛). (5)\nIf the loudspeaker is ideal that does not have phase shift effects.\nAndtheamplitudeestimationisenoughaccurate.Theestimated\nreplay output of the modulated audio would be\nˆ𝑥𝑚𝑟(𝑡)=/summationdisplay.1\n𝑛(𝐴𝑛·𝐺𝑛/ˆ𝐺𝑛)·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛)\n≈/summationdisplay.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛)=𝑥(𝑡),(6)\nwhich is approximately equal to the genuine audio.\nHowever, if the modulated audio 𝑥𝑚(𝑡)passes through the real\nloudspeaker system 𝐻, the real modulated replay 𝑥𝑚𝑟(𝑡)audio\nwould be\n𝑥𝑚𝑟(𝑡)=/summationdisplay.1\n𝑛(𝐴𝑛·𝐺𝑛/ˆ𝐺𝑛)·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛+𝜓𝑛)\n≈/summationdisplay.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛𝑡+𝜑𝑛+𝜓𝑛)≠𝑥(𝑡).(7)Because𝑥𝑚𝑟(𝑡)hasalmostthesameamplitudespectrumwith\nthe genuine audio 𝑥(𝑡), it can bypass the existing defense systems.\nHowever, compared to the genuine signal 𝑥(𝑡), there are phase\nshiftsforeachfrequencycomponentinthemodulatedreplaysignal\n𝑥𝑚𝑟(𝑡).\n/square\nTheoremA.3. Thephaseshiftswillcausethespuriousoscillations\n(ringing artifacts) in the original audio.\nProof.Supposethereisasmallphaseshiftd 𝜑inthe𝑁-thfre-\nquencycomponentofthesignal 𝑥(𝑡),whileotherfrequencycom-\nponents remain unchanged. The new signal would be\n𝑥/prime(𝑡)=/summationdisplay.1\n𝑛≠𝑁𝐴𝑛·sin(2𝜋𝑓𝑛+𝜑𝑛)+𝐴𝑁·sin(2𝜋𝑓𝑁+𝜑𝑁+d𝜑)\n=/summationdisplay.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛+𝜑𝑛)+𝐴𝑁·sin(2𝜋𝑓𝑁+𝜑𝑁+d𝜑)\n−𝐴𝑁·sin(2𝜋𝑓𝑁+𝜑𝑁)\n=𝑥(𝑡)+2·𝐴𝑁·sin(d𝜑\n2)·cos(2𝜋𝑓𝑁+𝜑𝑁+d𝜑\n2)\n=𝑥(𝑡)+𝐶·cos(2𝜋𝑓𝑁+𝜑𝑁+d𝜑\n2)\n=𝑥(𝑡)+𝑜𝑁(𝑡).\n(8)\nBecause d𝜑is a very small shift value, 𝐶is a small constant that\nsatisfies|𝐶|<|𝐴𝑛·d𝜑|.\n𝑥(𝑡)is an audio signal that is statistically smooth in the time do-\nmain. Hence, the newsignal 𝑥/prime(𝑡)contains small ringing artifacts\nbecause of the additional oscillations signal 𝑜𝑁(𝑡)with the fre-\nquencyof𝑓𝑁.Themaximumamplitudeofthespuriousoscillations\nis limited by |𝐶|value.\nAssumethatthephaseshiftsofaloudspeakersystemaredenoted\nas𝜓={𝜓𝑛}forallfrequencycomponents.Themodulatedreplay\nsignal would be\n𝑥𝑚𝑟(𝑡)=/summationdisplay.1\n𝑛𝐴𝑛·sin(2𝜋𝑓𝑛+𝜑𝑛+𝜓𝑛)\n=𝑥(𝑡)+2·/summationdisplay.1\n𝑛𝐴𝑛·sin(𝜓𝑛\n2)·cos(2𝜋𝑓𝑛+𝜑𝑛+𝜓𝑛\n2)\n=𝑥(𝑡)+/summationdisplay.1\n𝑛𝐶𝑛·cos(2𝜋𝑓𝑛+𝜑𝑛+𝜓𝑛\n2)\n=𝑥(𝑡)+𝑜(𝑡).(9)\nThe total spurious oscillations 𝑜(𝑡)can be presented as\n𝑜(𝑡)=2·/summationdisplay.1\n𝑛𝐴𝑛·sin(𝜓𝑛\n2)·cos(2𝜋𝑓𝑛+𝜑𝑛+𝜓𝑛\n2).(10)\nThemaximum amplitude 𝐴𝑜ofthe spuriousoscillations iscon-\nstraint by the following condition.\n𝐴𝑜=/summationdisplay.1\n𝑛|𝐶𝑛|</summationdisplay.1\n𝑛𝐴𝑛·|𝜓𝑖| (11)\nAs a result, the phase shifts of the loudspeakers will lead to the\nringing artifacts in the modulated replay audio.\n/square\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1117B PARAMETERS IN DETECTION METHODS\nWelisttheparametersofdifferentreplaydetectionmethodshere\nfor better understanding the modulated replay attack.\n(1) Constant Q Cepstral Coefficients (CQCC) based method.\nThe Constant-Q Transform (CQT) is applied with a maximum fre-\nquency of𝐹𝑚𝑎𝑥=𝑓𝑠/2=48𝑘𝐻𝑧. The minimum frequency is set\nto𝐹𝑚𝑖𝑛=𝐹𝑚𝑎𝑥/212=11.7𝐻𝑧(12 is the number of octaves). The\nvalue of bins per octave is set to 96. Re-sampling is applied with a\nsampling period of 𝑑=16. The dimension of the CQCC features is\n19. Experiments were performed with all possible combinations of\nstatic and dynamic coefficients.\n(2)MelFrequencyCepstralCoefficents(MFCC)basedmethod.\nThe window length is set to 3072 samples (32 ms), and the window\nshift is 1536 samples (16 ms). Thus, the frequency bins would be\n4096 samples. When we create the triangular mel-scale filterbanks,\nthe number of filterbanks is 26. The length of each filter is set to\n2049. The sampling rate in experiments is 96 kHz.\n(3)LinearPredictiveCepstralCoefficients(LPCC)basedmethod.\nIntheLPCCfeature,theframelengthissetto1280andtheoffsetis\n0. The threshold of the silence power is 10−4. The prediction order\nin the LPC coefficients is set to 14.\n(4) Mel Wavelet Packet Coefficients (MWPC) based method.\nMWPCfeatureisbasedonwaveletpackettransform,adaptedtothe\nmel scale. Instead of using the energy of the frequency sub-bands,\nMWPC use Teager Keiser Energy (TKE) Operator as the following\nequation, Ψ(𝑠(𝑡))=𝑠(𝑡)2−𝑠(𝑡−1)𝑠(𝑡+1).ThedimensionofMWPC\nfeatures is 12, derived from the principle component analysis.\n(5)High-frequencysub-bandpowerbasedmethod. Highfre-\nquency energy ratio is measured between (2-4) kHz and (0-2) kHz.\n(6) High-frequency CQCC based method. Similar to CQCC-\nbased methods. But it concerns the high-frequency (2-4kHz) band.\n(7) FM-AM based method. This method aim to detect the fre-\nquency modulation (FM) and amplitude modulation (AM) features\nin replay audio. Here, the feature vector consists of the modula-\ntioncentroidfrequency(MCF)andmodulationstaticenergy(MSE).\nWhicharebothextractedfrommodulationspectrum.TheGaussian\nmixture model (GMM) is employed as the back-end classifier.\n(8) Sub-bass Frequency based method. Energybalancemetric\nindicatestheenergyratioofthesub-bassrange(20-80Hz)tothe\nlow-frequency range (20-250 Hz). The threshold is set to 0.228\naccording to the study [8].\nC INVERSE FILTER IMPLEMENTATION\nThespeakerresponseestimationprocesscontainstwosteps:dis-\ncrete amplitude response measurement and continuous amplitude\nresponse fitting. In the discrete amplitude response measurement,\nwemeasurethespeakerinput/outputresponsecoefficientbytest-\ning 68 discrete typical frequency values. The discrete frequency\nvalues are within four audio frequency ranges: bass (from 60 Hz to\n225 Hz with a spacing of 15 Hz), low midrange (from 250 Hz to 500\nHzwithaspacingof50Hz),midrange(from550Hzto2kHzwithaspacingof50Hz),anduppermidrange(from2.1kHzto4kHzwith\na spacing of 100 Hz). The input test signals are single-frequency 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(a) iPhone X 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(b) iPad Pro\n 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(c) Mi Phone 4 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(d) Google Nexus 5\n 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(e) Bose Soundlink Micro 0  0.2 0.4 0.6 0.8 1.0\n0 1 2 3 4 0 1 2 3 4 5Frequency Response\nGain\nFrequency (kHz)Speaker\nInverse Filter\n(f) Samsung Smart TV\nFigure 12: The amplitude response curves of differentspeaker devices and their corresponding inverse filters.\nsignalswiththesameamplitudeof1,whicharegeneratedbyusing\nthewavwrite tool and stored in a lossless format. The test audio is\nthentransferredtoreplaydevicesandplayedatmediumvolume\non loudspeakers, since the response function is not directly related\nto the input amplitude according to our experiments. After thespectrumanalysis,wecangetaroughresponsepolygonalcurve\nacross 68 discrete points.\nIn the finer-grained amplitude response fitting, we need to first\ncalculatethespectralresolutionofthemodulatedsignal Δ𝑓=𝑓𝑠/𝑁,\nwhere𝑓𝑠is the signal sampling rate. 𝑁is the FFT point number\nwhich is the minimum power of 2 that is greater than or equal\ntothe signallength 𝐿,denoted as𝑁=2⌈log2𝐿⌉.The finer-grained\namplituderesponsecurvecanbeachievedbythecubicsplinefitting.\nAnd the estimated response used in the inverse filter generation is\nsampledwiththesignalspectralresolution Δ𝑓.Theinversefilter\nisdesignedbyusingthefiner-grainedspeakerresponse 𝐻(𝑘).In\norder to avoid divide-by-zero error in our experiments, the inverse\nfiltertransferfunctioniscalculatedas1 /(𝐻(𝑘)+𝑒𝑝𝑠),where𝑒𝑝𝑠\nis a small value from 0.001 to 0.002.\nFigure 12 shows the amplitude response curves of different\nspeaker devices and their inverse filters. For mobile devices, the\nresponsecurvesarehigh-passfiltersduetothelimitedsizeofspeak-ers.Therefore,theinversefiltersshouldbelow-passfilters.ForBose\nSoundlink Micro which has a tweeter and a woofer, there are obvi-\nous two-stage enhancements in the amplitude response. However,\nthetransferfunctionstillcannotbeconsideredasapass-through\nfilter.ThefrequencyresponseofSamsungSmartTVfluctuateswith\nfrequency due to its two speakers that create stereo audio. We can\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1118 50 55 60 65 70 75 80 85 90 95 100\nSVM DecisonTree    NaiveBayes GMM KStarDetection Accuracy (%)\nFigure 13: Performance of different classifiers in the time-\ndomain defense.\nusedesignedinversefilterstocompensatethespeakeramplitude\nresponse, mitigating the decay of frequency components.D CLASSIFIERS IN TIME-DOMAIN DEFENSE\nInthetime-domaindefense,thelocalextremeratio(LER)isaro-bust feature that can describe the ringing artifacts in modulatedreplay audios. Therefore, the classifier selection has little impact\non the defense performance. To verify this hypothesis, we conduct\nexperiments to evaluate the effects of different classifiers on the\nfeature classification.\nWeclassifytheLERfeaturesusingfivecommonclassifiers,in-\ncluding Support Vector Machine (SVM), Decision Tree (DT), Naive\nBayes(NB),GaussianMixtureModel(GMM),andK-Star.The10-\nfoldcross-validation accuracyisusedastheevaluation standard.\nThe performance of different classifiers is shown in Figure 13. We\ncanseethatSVM,DecisionTree,andKStarachievebetterperfor-\nmancethanotherclassifiers.GaussianMixtureModelobtainsthe\nworst accuracy since the data distribution of LER features does\nnot subject to the normal distribution. Above all, we choose theSVM model in our system due to its easy deployment and high\nperformance.\nSession 4B: Physical Attacks\n \nCCS '20, November 9–13, 2020, Virtual Event, USA\n1119"}
{"title": "You Make Me Tremble: A First Look at Attacks Against Structural Contr", "content": "You Make Me Tremble: A First Look at Attacks Against\nStructural Contr\nol Systems\nAbel Zambrano∗Alejandro Palacio-Betancur+Luis Burbano†Andres Felipe Niño∗\nLuis Felipe Giraldo∗Mariantonieta Gutierrez Soto+Jairo Giraldo‡Alvaro A. Cardenas†\n∗Universidad de Los Andes+The Pennsylvania State University\n‡University of Utah†University of California, Santa Cruz\nABSTRACT\nThispapertakesafirstlookatthepotentialconsequencesofcyber-\nattacksagainststructuralcontrolsystems.Wedesignalgorithms\nandimplementtheminatestbedandonwell-knownbenchmark\nmodels for buildings and bridges. Our results show that attacks\ntostructuresequippedwithsemi-activeandactivevibrationcon-\ntrol systems can let the attacker oscillate the building or bridge\nat the resonance frequency, effectively generating threats to the\nstructureandthepeopleusingit.Wealsoimplementandtestthe\neffectiveness of attack-detection systems.\nCCS CONCEPTS\n·Computer systems organization →Embedded and cyber-\nphysical systems; · Applied computing →Engineering .\nKEYWORDS\nStructuralcontrol,attacks,smartstructures,security,building,bridges\nACM Reference Format:\nAbelZambrano,AlejandroPalacio-Betancur,LuisBurbano,AndresFelipe\nNiño, Luis Felipe Giraldo, Mariantonieta Gutierrez Soto, Jairo Giraldo, &\nAlvaroA.Cardenas.2021.YouMakeMeTremble:AFirstLookatAttacks\nAgainstStructural ControlSystems. In Proceedings ofthe 2021ACMSIGSAC\nConferenceonComputerandCommunicationsSecurity(CCS’21),Nov.15ś\n19, 2021, Virtual Event, Republic of Korea. ACM, NY, NY, USA, 18 pages.\nhttps://doi.org/10.1145/3460120.3485386\n1 INTRODUCTION\nSince 1980, 258 weather and climate-related natural hazards in the\nUnitedStates(US)haveresultedin$1.75trillioncumulativecosts\nof damage to cities [ 80]. To reduce these costs, civil infrastructures\nare being equipped with various sensors for health monitoring and\nstructural control [ 65]. Sensors can measure physical quantities\nrelatedtothebuildingmotion,suchasstrain,acceleration,velocity,\ndisplacement, pressure, temperature, and ground motion [ 21,102].\nStructures equipped with control devices can adapt in real-time to\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthe firstpage.Copyrights forcomponentsof thisworkowned byothersthan the\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or\nrepublish,topostonserversortoredistributetolists,requirespriorspecificpermission\nand/or a fee. Request permissions from permissions@acm.org.\nCCS ’21, November 15ś19, 2021, Virtual Event, Republic of Korea\n© 2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-8454-4/21/11...$15.00\nhttps://doi.org/10.1145/3460120.3485386counteract extreme dynamic loads such as earthquakes or wind\nstorms.\nAmong525buildingsof250metersorgreaterheightworldwide,\n18%(97)areequippedwithdynamicmodificationdevices[ 56].This\nstatistic increases to 39% if we consider buildings constructed in\nthelastdecade.Withoutconsideringtheirheight,inJapanalone,\nmorethan50buildingshaveActiveMassDampers(AMD)tocontrol\nbuildingvibrations[ 102],andmorethan30high-risebuildingshave\nbeen instrumented with semi-active variable oil dampers [35, 50].\nStructuralvibrationcontrolsystemsareparticularlyusefulfor\ntall buildings, often affected by wind-induced vibrations. Wind-\ninducedvibrationsintallbuildingshaveproventocause building\nmotion sickness to the occupants during normal operations [ 57,58]\nandsupplementaldampingcanmitigatethesevibrations.Life-cycle\ncost analysis about the investment in control devices, including\nsemi-active friction devices, has shown that structural control pro-\nvides significant economic benefits on tall buildings subjected to\nwind loading [29, 64], among other natural hazards.\nWhilestructuralcontrolprovidesmanybenefits,asfarasweare\naware, these systems have not been studied from a security per-\nspective. As the popularity of structural control increases, we need\ntostartassessingandimprovingthesecurityposture.Thispaper\npresentsthefirststudyofattacksagainstcontrolsystemsincivil\nengineeringstructures.Weconsidertwotypesofattacks:Denialof\nService (DoS) attacks, where the attacker disables the activation of\nspecificactuators,andFalseDataInjection(FDI)attacks,wherethe\nattacker forces the actuators to follow an attack command.\nOur contributions include the following: (1) we are the first\nresearch paperto studythe impact ofattacks tostructural control\nsystems, (2) we provide the first algorithm for optimal DoS attacks\ntryingtomaximizetheimpactofexternalvibrations,(3)Weidentify\nmetrics, testbeds, and benchmark models of buildings and bridges\ntoevaluatetheeffectivenessofourmethods,(4)Wedesignandtest\nthe first effective attack-detection method in structural control, (5)\nWe make all our algorithms and models open to the community\nhttps://github.com/BuildingResearch/security.\n2 RELATED WORK\nAttackstoCPS AttackstoCyber-PhysicalSystems(CPS)canhap-\npen in a variety of components, including sensors, controllers, and\nactuators: (1) an attacker can inject false data into the system by\nfakingsensordata(e.g.,ifthesensordataisunauthenticatedorif\nthe attacker has the key material for the sensors) and cause the\ncontrol logic of the system to act on malicious data [ 59]. (2) The at-\ntackercandelayorevencompletelyblocktheinformationfromthe\nsensors to the controller, causing it to operate with stale data [54].\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1320\n(3) The attacker may be able to compromise the controller and\nsendincorrectcontrolsignalstotheactuators[ 63].(4)Theattacker\ncan delay or block any control command, thus causing a denial\nofcontroltothesystem[ 4].(5)Theattackercancompromisethe\nactuators and execute a control action that is different to what\nthecontrollerintended[ 88].And,(6)theattackermaybeableto\nphysically attack the system (e.g.. physically destroying part of the\ninfrastructure and combine this with a cyber attack) [5].\nAlltheseattackscanbeclassifiedaseithera False Data Injec-\ntionFDI or aDenial of Service DoS attack. FDI [ 49,59] and DoS\nattacks [4] have been discussed in the context of cyber-physical\nsystemssince2009. Ina Denial-of-Service (DoS) attack[4],the\nadversarypreventsthecontrollerfromreceivingsensormeasure-\nments, or the physical system from receiving a proper actuation\ncommand. To launch a denial of service, the adversary can jam the\ncommunicationchannels,compromisedevicesandpreventthem\nfromsendingdata,attacktheroutingprotocols,oreventurnoffthe\nlights(withoutelectricity,controlsystemswon’t work).Similarly\nphysical side channel attacks can inject false signals into a system,\nthey can also be used to cause DoS attacks [ 71]. Attackers in close\nproximity of a target device can also damage them physically.\nIn aFalse Data Injection (FDI) attack [49,59], the adversary\nsendsfalseinformationwhereamaliciousvalue(attimet) 𝑎(𝑡)will\nbe different than the non-attacked value 𝑢(𝑡)(𝑎(𝑡)≠𝑢(𝑡)). The\nadversarycanlaunchtheseattacksbyobtainingthe secretkey of\nsome sensors, controllers, or actuators (if the communications are\nauthenticated).Severalcontrolsystemsareair-gaped,andassumea\ntrustedenvironmentonceadeviceisinsidethisair-gapednetwork,\nso a malicious insider doesn’t need to worry about authentication.\nCPScanbecompromisedevenwithoutacomputer-basedexploit\nin what has been referred to as transduction attacks [34]. By tar-\ngeting the way sensors capture real-world data, the attacker can\ninject a false sensor reading or even a false actuation action, by\nmanipulating the physical environment around the sensor [ 34,36].\nForexampleattackerscanusespeakerstoaffectthegyroscopeofa\ndrone[82],exploitunintentionalreceivingantennasinthewires\nconnectingsensorstocontrollers[ 76],oruseintentionalelectro-\nmagneticinterferencetocauseaservo(anactuator)tofollowthe\nattacker’s commands [76].\nPopularexamplesofFDIattacksincludescalingattacks 𝑎(𝑡)=\n𝛼𝑢(𝑡)[86],biasattacks 𝑎(𝑡)=𝑢(𝑡)+𝑏[13,16],delayattacks 𝑎(𝑡)=\n𝑢(𝑡−𝑑)[86], and random attacks (where 𝑎(𝑡)is a random value\nat each time) [ 26,98]. These attacks were successfully applied to\npower systems [ 86], a power plant boiler [ 98], water plants [ 13],\nrobotic vehicles [ 16], and autonomous vehicles [ 26]. These simple\nattacks,however,donotsucceedwhentargetingastructuralcontrol\nsystem.\nOnecriticaldifferencebetweenstructuralcontrolsystemsand\nmostothercyber-physicalsystemsisthatattacksagainststructural\ncontrol are not obvious. In a power grid, you know that opening\ncircuit breakers will disconnect systems. In a vehicle, you know\nthatyoucancrashanothervehiclebyacceleratingtotopspeed.Ina\nwater system, you know that if you inject liquid into a tank and do\nnotletitout,itwillcauseanoverflow,etc.Incontrast,instructural\ncontrol systems it is not obvious how to attack the system in a\nway that itcauses any significant effect. In particular,because each\nactuator’senergyissmallcomparedtothewholestructure,mostrandom attacks or heuristics will not have any significant effect.\nAnattackagainststructuralcontrolsystemsneedstobestrategic\ninthewayfrequencies,magnitudes,andphasesareinjectedateach\nof the compromised endpoints.\nTotargetstructuralcontrolsystems,weneedtofocusonanalyz-\ningtheresponseofthestructuretovarioustypesofvibrations.This\nis called frequency analysis. This paper is related to previous work\nthat exploits when physical systems are sensitive to oscillations\nat specific frequencies. For example, an external acoustic signal\ntunedataspecificfrequencycandeterioratetheaccuracyofMicro-\nElectro-MechanicalSystems(MEMS)gyroscopes[ 89].Thepower\ngrid might also be vulnerable to small oscillations being amplified\nbythesystem[ 46,100].OurproposedFDIattacksareclosesttothe\nwork of Dadras et al. [ 22], where the authors study how malicious\nvehicles in a platoon can make small oscillations in their speed, be\namplified by their neighbors, making the system unstable.\nOur FDI attacks extend previous work by designing a new algo-\nrithm thatfinds a (local)optimal amplitude, phase,and frequency\nof attacks (rather than just finding a parameter of a predefined\ncontrol).Inaddition,workonDoSattacksis(asfarasweareaware)\ncompletely novel. To design our DoS attacks we need to evalu-\nate the potential frequency response of the structure to a future\nunknown perturbation. We are not aware of anything similar in\npreviousworkonCPSattacks.Ourfinalnoveltywhencompared\ntopreviouswork,istheuse-caseofstructuralcontrol,whichhasn’t\nbeen previously explored.\nBuilding Automation Security In terms of applications, our\nstudy is related to the security of Building Automation Systems\n(BAS)[18,70].BAScanmonitorandcontrolHeating,Ventilation,\nandAirConditioning(HVAC),lighting,energyconsumptionand\nphysical security (cameras, key cards, etc.). Previous research fo-\ncused on proposing new security for the Building Automation and\nControlNetwork(BACnet)protocol[ 11,31,32],aswellasforim-\nproving the security of endpoint devices in BAS [95, 96].\nDespite these research efforts, ethical hackers as well as attack-\ners, have found several ways to attack these systems. For example,\nethical hackers took control of the building control system of a\nGoogle office in Australia [ 104], a ransomware gang attacked a\nhotel in Austria four times, disabling their electronic keys [ 8], a\nDDoS attack cut heat to apartments in Finland [ 62], and vulner-\nabilities found in one of the most popular software frameworks\nto create building automation controls (the Niagara framework)\nhadvulnerabilitiesthatcouldhaveallowedattackersfromtaking\nremotecontroltoaccesssystems,elevators,HVACsystems,alarms,\nandothercriticaloperations[ 105].Theinterestofattackersinstruc-\nturalcontrol(whereveravailable)isthelogicalnextstepandthis\npaper is the first proposal for understanding the potential impacts\nof sophisticated structural control attacks, as well the first study to\npropose new countermeasures.\n3 STRUCTURAL CONTROL\nVibrationcontrolofstructurescanadaptinreal-timetominimize\nthe movements of a building, bridge, or wind turbine during ex-\ntreme events [ 44]. Structural control systems have three major\ncomponents:(i)sensorstocapturethestateoftheenvironment,(ii)\na computer to process the information from the sensors and make\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1321Figure 1: Top: (a)-(c) The Bandaijima 31-story building in\nNiigata, Japan,\nequipped with 72 hydraulic oil dampers\n(HiDAX-s) by Kajima Corporation. Bottom: (d)-(f) The\nDanube City Tower in Vienna, Austria, instrumented with\ntwo semi-active vibration absorbers based on Maurer MR\ndampers and two independent real-time controllers (Cour-\ntesy of Felix Weber [99]).\ndecisionsbasedontheinformation,and(iii)actuatorstoperform\nthe actions determined by the computer system [20].\nStandardsensorsforstructuralmonitoringincludeLinearvari-\nable differential transformers (LVDTs), velocity transducers, ac-\ncelerometers, and load cells, which measure displacement, velocity,\nacceleration, and force, respectively. These sensors can work as\nlinearproportionaldevicesinthefrequencyrangeof0.1ś100Hz,\ncovering the frequency band of structural vibration under seismic\nor wind excitation.\nActuators are the set of physical devices that execute the in-\nstructions from the controller [ 20]. There are four main types of\nstructuralcontrolactuators:passive,semi-active,active,andhybrid\n(which combine active and passive actuators). Passive actuators\ndissipate the power of external perturbations and do not receive\nany control [ 30]. Passive control devices include linear viscous\ndampers, friction dampers, tuned mass dampers, and tuned liquid\ncolumn dampers [ 42,48]. Active and semi-active systems have\nan external energy source to activate hydraulic, electromechani-\ncal,orelectromagneticsystems.Activecontrolactuatorsinclude\nHiDAX-s, linear pistons, and mass dampers. Semi-active control\nactuators include magneto-rheological (MR) dampers [ 17] and fric-\ntion dampers [ 23,24,39]. Active and semi-active dampers improve\nenergy dissipation capacity, and create a safer structure when com-\nparedto passivedevices[ 1,55,102].Examples ofactiveandsemi-\nactivedamperscanbefoundonbridgesandbuildingsworldwide,\nas shown in Fig. 1 and Fig. 2.\nInthispaperwefocusonthefollowingthreeactuators:Magneto-\nRheological MR Dampers , Active Mass Dampers AMDs, and Ac-\ntive Tuned Mass Dampers ATMDs. An MR damper has a fluid\nFigure 2: Top: Perspective view of a highway bridge\nequipp\ned with dampers in Orange County, California, and\nclose-up to the installed dampers (Source: Google Street\nView 33°51’27.5\"N 117°58’46.9\"W). Bottom: Highway bridge\nin Oklahoma, US, instrumented with semi-active variable\nfriction control devices (Source: DoT [69]).\ncontrolled by a magnetic field. By varying the power of an electro-\nmagnet,wecancontrolthedampingcharacteristicsoftheshock\nabsorber. Active mass damping approaches consist of applying a\ndynamicmodificationsysteminafewlocationsinthestructure.An\nAMD controls the movement of a mass to counteract vibrations in\nthestructure.AnATMDconsistsofanactuatorplacedbetweenthe\nstructure and a tuned mass damper, a system composed of a mass,\nspring,anddamper(adequatelytuned)attachedtoastructureto\nreduce its dynamic response.\nIn our simulations we use bridge and building benchmarks pro-\nposed by the Committee on Structural Control of the American\nSociety of Civil Engineers (ASCE) [27, 67, 78].\n3.1 Vulnerabilities and Adversary Model\nStructuralcontrolsystemsintegratevariousoperationaltechnolo-\ngies such as Industrial PCs (Regular Windows PCs that pass safety\nstandards because of their enclosures), Ethernet networks (e.g.,\nEtherCAT)orinlegacyimplementationsseriallines(e.g.,RS422),\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1322Figure 3: Operational Technology for structural control of\ntheGuangzhou\nTVTower(adaptedfromadiagramin[66]).\nFigure 4: Operational technology for structural control of\nthe W\nalnut Bridge (adapted from a diagram in [68]).\nembedded computers near sensors and actuators to capture and\nconvert physical signalsto computer information [ 10,61,81,101].\nFig.3illustrateshowcomputersandnetworksareintegratedinthe\ncontroloftheGuangzhoutower,Fig.4showsthetechnologyinthe\nWalnutCreekBridge,andFig.5illustrateshowanAMDactuator\nis instrumented within the Kyobashi Seiwa Building.\nAs we can see, these systems use computers and networks that\ncan be attacked with methods that worked for similar technolo-\ngies[6,15,40,52,79,106].Ingeneral,thesenetworksareair-gapped\nand assume a trusted insider setting, but as the Stuxnet attack\nshowed,air-gappednetworksarenotimmunetoattacks(especially\nnot against state-sponsored attacks). A malicious insider, an un-\ntrustedcontractor,asupply-chainattack,ormalwareonadevice\nFigure 5: AMD instrumentation (adapted from [60]).\ncrossing the air-gapped network (such as USB drives) can defeat\nthis isolation.\nAttacks Passive Semi-active Active Hybrid\nDoS Y X X X\nFDI X\nX X\nTable 1: Possible Attacks for Each Type of Actuator. Y de-\nnotes physical\nattacks. X denotes that the attack can be\nlaunched through a cyber-attack.\nOnceinsidethesystem,theattackercanlaunchavarietyofDoS\norFDIattacks.DoSattackscanbelaunchedbyblocking(ornoteven\nsending) the control signal toactive or semi-active actuators. DoS\nattackscanalsooccurbyshuttingdowntheelectricpowertothe\nbuilding:withoutpower,activeandsemi-activeactuatorscannot\nbe controlled. Finally, an insider can launch DoS attacks against\npassive actuators (the attacker can physically destroy the damper).\nFDI attacks canbe launched by an attackerthat compromised the\nindustrial PC. The industrial PC can then send malicious control\nsignalstotheactiveorsemi-activeactuators.Amalicioussupply\nchain attack providing a compromised microcontroller can also\nbe used to launch FDI attacks. Table 1 shows a summary of this\ndiscussion.\nInthispaper,weassumeanattackerthatcandisruptthecom-\nmunicationlinktotheactuators(DoSattack),andanotheronewho\nhaspartial(ortotal)accesstothecontrolsystemandcansendfalse\ncontrol commands to the actuators (FDI attack). We also assume\ntheattackerhassomeknowledgeabouttheoperationanddesign\nof the structural control system.\n3.2 Damage Metrics\nTo understand the impact of attacks, we need to look at how struc-\nturalengineersevaluateriskstobuildingsandbridges.Thestandard\nASCE7-16[ 51]isanintegralpartofbuildingcodesintheUSand\nis adopted by the International Building Code, the International\nExisting Building Code, the International Residential Code, and\nthe NFPA 5000 Building Construction and Safety Code. In ASCE\n7-16, the primary metric to evaluate the effects of wind and seis-\nmic events is the Inter-Story Drift (ISD) (lateral deflection of a\nbuilding)asdriftsdamagecladding,nonstructuralwalls,andpar-\ntitions [87]. The allowable drift limits placed by ASCE 7-16 are\nfunctions of the risk category and type of seismic forces. ASCE\n7-16 Section 12.12 states the allowable drift for any floor in most\nstructures is 0 .020ℎ𝑠𝑥, 0.015ℎ𝑠𝑥, 0.010ℎ𝑠𝑥, for Risk Category I or II,\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1323Figure 6: ISD vs. damage. Top: Steel. Bottom: Concrete.\nIII,andIV,respectively,where ℎ𝑠𝑥isthestoryheightbelowlevel\nx. The Risk Category is based on the risk to human life, health,\nand welfare associated with structural damage or by the nature\nof their occupancy or use. For example, buildings designated as\nessential facilities such as hospitals have a Risk Category IV and\nwillrequireadriftlimitof1%oftheheightofallfloors.Buildings\nthatcreateasubstantialrisktohumanlifehaveaRiskCategoryIII,\nandbuildingsthatposealowrisktohumanlifeareRiskCategoryI.\nSimilarly,theNationalBuildingCodeofCanadalimitsISDto1%of\ntheheightofthefloorsforpost-disasterbuildingsthatmustremain\nin operation immediately after an earthquake [33].\nFig.6illustratestheISD-damagerelationshipforconcreteand\nsteelbuildings,adaptedfromtheNEHRPGuidelinesfortheSeismic\nRehabilitation of Buildings [ 77]. If a building has an ISD above\nits elastic range, a few places start presenting some permanent\ndistortion; however they are repairable by replacing the affected\ncomponents.AmoresevereISDcancreatevisibledeformationin\nbeams and columns. Damage in concrete structures is evident with\nthepropagationofcracksinsteadofdistortionofcomponents.Ifthe\ndisplacementsinthestructurearehigher,thereisextensivecracking\nandseveredamageinthestructurethatcanbringthestructurenear\ncollapse [ 77]. We can see that a 1% ISD is at the boundary between\nreparable andirreparable damages.We highlight thisvalue inour\nsimulations to show when attacks can cause significant damages.\nSincebridgesdonothaveseveralstories,weneedtouseadif-\nferent metric. The most common metrics for predicting bridge\ndamages are the lateral displacement and the lateral force [ 41]. We\nwill use them to analyze the impact of attacks on bridges.\n4 DESIGNING OPTIMAL ATTACKS\nBuildings, bridges, and soil/rock formations have several vibration\nfrequencies at which they tend to oscillate more strongly, as il-\nlustrated in Fig. 7. When these peaks are large enough, they are\ncalled resonant frequencies. An attacker trying to damage an in-\nfrastructurecanlaunchDoSorFDIattackstochangethefrequency\nresponseofthebuildingandmaximizethemagnitudeandthenum-\nber of amplifying frequencies. In addition, if a building vibrates at\nthe same frequency as the input seismic wave, the vibrations may\ndouble in amplitude, causing devastating consequences [3].\nLaunching attacks to drive a building or a bridge to oscillate\nat a resonant frequency is not obvious. This section studies the\nrisk that sophisticated attackers may pose when they design a\nstrategicattack.Weassumethattheadversaryhasgained(fullor\nFigure 7: Frequency response associated with the vibration\nmodes\nof the 20-story benchmark steel building.\npartial)accesstothebuilding’scontrolsystem.WeconsiderDoS\nattacks(interruptingcommunicationstoactuators)andFDIattacks\n(sendingfalsecommandstoactuators)anddemonstratetheireffects\non real and simulated scenarios based on well-known benchmarks\nfromstructuralengineeringsocieties.Wefirstdefineadynamical\nsystem modelthat characterizesthe controlled structureand later\npropose strategies to design attacks that maximize their impact\nover the building.\n4.1 Mathematical Description of a Structure\nThedesignofactiveandsemi-activevibrationcontrollersuseswell-\nknown equations of motion for a building or bridge (see Appendix\nA) that describe how the lumped masses, stiffness, and damping\nproperties of the elements of a structure interact to change their\nposition, velocity, and acceleration [ 43]. The model has three main\nvariables: i) the structure’s state variables x, which typically in-\ncludedisplacementsandtheirvelocitiesatdifferentpointsinthe\nstructure;ii) theforcesthatare exertedbytheactuators tryingto\nstabilize the structure u; and iii) forces that are exerted by external\ndisturbances such as earthquakes and wind w. If we denote the\nvariationsofthe structure’sstatevariables by x(thederivativeof x\nwith respect to time), the mathematical model of the structure is\n/dotaccx=Ax+Bu+Ew\nz=Fx(1)\nwhereA,B,andEarematrixelementsthatareusedtorepresentthe\ncombinedactionofvariables x,u,andw.Thematrix Fisamaskthat\nselectsonlythosestatevariablesthatwewanttoattack.Therefore, z\ncontainssuchvariables.Apopularvibrationcontrolsystemconsists\nof a feedback control strategy represented by u=−Rx, whereRis\na matrix gain [ 107]. Structural engineers design this control matrix\nto reduce the displacement of the structure caused by external\ndisturbances.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n13244.2 Denial of Service (DoS) Attack\nA DoS attack is opportunistic, and therefore it will only be damag-\ning if it is launched during an occurring natural event (earthquake\nor high winds). Since attackers cannot predict the type of vibra-\ntions this natural hazard will create in the structure, they need\ntomaximizethedamageoverthemaximumnumberofpotential\nperturbations. Tocapture thiscriterion,westudythe 𝐻2normof\na system [ 107], which can be seen as the power of the response\nof the dynamical system to external disturbances for a wide range\nof frequencies. A large 𝐻2norm indicates that the response of the\nstructuretoexternaldisturbanceswillbelargeaswellforawide\nrange of frequencies. If the DoS attack is designed in a way to\nmaximize the 𝐻2norm, then it has a high chance of damaging the\nsystem.\nThe𝐻2norm of Eq. (1) is defined as:\n||H𝑧𝑤||2=/parenleftbigg1\n2𝜋∫+∞\n−∞Trace/parenleftbigH𝑧𝑤(𝑗𝜔)H∗\n𝑧𝑤(𝑗𝜔)/parenrightbig𝑑𝜔/parenrightbigg1/2\n.\nNow,letx𝑠bea𝑛-dimensionalbinaryvectorthatindicateswhat\nactuatorstheadversarywilldisconnect:entry 𝑖is1ifthe 𝑖-thisnot\nattacked,and0otherwise.The 𝐻2normofthecontrolledsystem\nwith the feedback matrix gain Ris defined as ℎ2(xs)=||H𝑧𝑤||2,\nwhereH𝑧𝑤(𝑗𝜔)=F(𝑗𝜔I−A𝑐𝑙)−1E,A𝑐𝑙=A+BR𝑛𝑒𝑤,andR𝑛𝑒𝑤=\ndiag(1−x𝑠)R. Then, the actuators to be affected by the DoS attack\ncan be chosen by the following optimization process:\nmaximize\nx𝑠∈Z𝑛ℎ2(xs) (2)\nsubject to:𝑛/summationdisplay.1\n𝑖=1𝑥𝑖\n𝑠=𝑘\n𝑥𝑖\n𝑠∈ {0,1} ∀𝑖=1,...,𝑛.\n4.3 False Data Injection (FDI) Attack\nAnadversarylaunchinganFDIattackonthecontrolsystemchanges\nthesystem’sfrequencyresponse(e.g.,itchangesthecurveinFig.7).\nTherefore we need a process based on two steps: i) finding those 𝑘\nactuators such that, if their control is blocked, then the response\nof thesystem controlled bythe remaining 𝑛−𝑘actuators ismaxi-\nmized at a particular frequency of the force exerted by the blocked\nactuators; and ii) designing the control signals at the frequency\nwith the maximum response of the system to be injected to the\nattacked actuator.\nIncontrasttoDoSattacks,anFDIattackwillattempttomaxi-\nmizethefrequencyresponseofanindividualfrequencyofattack.\nThereforeinthiscaseweusethe 𝐻∞normofasystem[ 107],which\nisthemaximumgainofthesystemforagivencontrolinputata\nspecificfrequency.Thisnormcanbeseenasthemaximumresponse\nofthesystemforagivensetofinputsthatoscillateataspecificfre-\nquency. The 𝐻∞norm is computed using the representation of the\nstructureinEq. (1)andthecontrolpolicythatdefinesthestabilizing\nforcesuas follows. Let H𝑧𝑢(𝑗𝜔)be the transfer function matrix of\nthe structure,representing theresponse ofthe stablesystem with\noutputszfor the input control signals u. These input signals are\nthe ones that inject energy into the system to try to control the\nvibrations of the structure. Let ¯𝜎𝐻(𝜔)be the largest singular value\nofmatrix H𝑧𝑢(𝑗𝜔).Then,the 𝐻∞normofasystemwithtransferfunctionH𝑧𝑢(𝑗𝜔)is\n||H𝑧𝑢||∞=sup\n𝜔¯𝜎𝐻(𝜔)=sup\n||u||2≠0||z||2\n||u||2. (3)\nLetx𝑠be a𝑛-dimensional binary vector that indicates what\nactuatorsarenotattackedbytheadversary:entry 𝑖is1ifthe 𝑖-th\nis not attacked, and 0 otherwise. The 𝐻∞norm of the controlled\nsystem with the feedback matrix gain Ris defined as ℎ∞(x𝑠)=\n||H𝑧𝑢||∞, whereH𝑧𝑢(𝑗𝜔)=F(𝑗𝜔I−A𝑐𝑙)−1B,A𝑐𝑙=A+BR𝑛𝑒𝑤,\nandR𝑛𝑒𝑤=diag(1−x𝑠)R.Here,H𝑧𝑢isthetransferfunctionmatrix\nthat captures the response of the outputs of the controlled system\nzwith the control inputs u. The attack is designed in two steps:\nStep 1:The adversary determines which actuators will be dis-\nconnectedfromthecentralcontrolsystemsuchthatthepeakofthe\nfrequencyresponseofthesystemismaximized,viathefollowing\noptimization process:\nmaximize\nx𝑠∈Z𝑛ℎ∞(x𝑠) (4)\nsubject to:𝑛/summationdisplay.1\n𝑖=1𝑥𝑖\n𝑠=𝑘\n𝑥𝑖\n𝑠∈ {0,1} ∀𝑖=1,...,𝑛.\nStep 2:The adversary needs to determine the magnitude and\nphaseofthesignalsthatwillbeinjectedintotheactuators.From\nEq.(3),the𝐻∞normcorrespondstothelargestsingularvalueof\nmatrixH𝑧𝑢(𝑗𝜔), that is, ¯𝜎𝐻(𝜔). We know that the input vector\nthatproducesthismaximumgaincorrespondstotheright-singular\nvector associated with the largest singular value ¯𝜎𝐻(𝜔)[38]. This\nright-singular vector contains the amplitude and phases that the\nsinusoidalsignalstobeinjectedintotheactuators.Thisvectoris\nknown as the direction of the input signal. This is a unitary vector,\nmeaning that amplitudes of the sinusoidal signals are such that the\nEuclidean norm of this vector is 1. The magnitude of this vector\ncanbeamplifiedbyanyconstantthatkeepsthesignalsinsidethe\nrange of operation of the actuators.\n5 QUANSER TESTBED\nOur first experiment is conducted using Quanser’s bench-scale\nmodelthatemulatesabuildingequippedwithactivemassdampers\n(AMDs)subjectedtoearthquakeloading,asshowninFig.8.The\nplantisatwo-storybuilding-likestructurewithtwoactivemasses1\nand a shake table that generates an external earthquake-like dis-\nturbance2. Two accelerometers are used to estimate the position\nand velocity of two different points of the structure relative to the\nground.Theframeofthestructureismadeofsteelandhasaflexible\nfacade. The computer program sending commands to the actua-\ntors(AMDs)isaLinearQuadraticRegulator(LQR),analgorithm\ncommonly used to suppress vibrations in tall buildings [ 73]. The\nparameters of the mathematical model of the structure as in Eq. (1)\nand the control parameters of the LQR are given in Appendix B.\nThestatevariablesfromthevector xinEq.(1)are(i)theposition\nofthemovingcartatfloor1 𝑥𝑐1,(ii)thepositionofthemovingcart\nof floor 2 𝑥𝑐2, (iii) displacement at floor 1 𝑥𝑓1, (iv) displacement at\nfloor 2𝑥𝑓2, (v) velocity of cart 1 /dotacc𝑥𝑐1, (vi) velocity of cart 2 /dotacc𝑥𝑓2, (vii)\n1https://www.quanser.com/products/active-mass-damper\n2https://www.quanser.com/products/shake-table-ii/\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1325Figure 8: Experimental setup: Quanser’s shake table with\ntwo-flo\nor plants equipped with two active mass dampers\n(AMDs) and accelerometers to estimate position and veloc-\nity. Variables 𝑥𝑐1and𝑥𝑐2indicate the position of carts 1 and\n2;variables 𝑥𝑓1and𝑥𝑓2indicatethepositionofstories1and\n2, variables 𝑢1and𝑢2are the control signals of carts 1 and\n2, and variable /ddotacc𝑥𝑔indicate the acceleration produced by the\nearthquake-like disturbance produced by the shake table.\nTable 2: 𝐻2norm for different configurations of the system\nin Fig. 8 under DoS attacks.\nAttack configuration 𝐻2norm ( dB)\nUncontrolled -16.26\nControlle\nd -19.53\nDoS on𝑢1 -16.57\nDoS on𝑢2 -19.46\nvelocityoffloor1relativetotheground /dotacc𝑥𝑓1,and(viii)velocityof\nfloor2relativetotheground /dotacc𝑥𝑓2.Thevector zdefinesthevariables\nthat we want to attack, namely the ISD at floors 1 and 2, and their\nvelocities.\n5.1 DoS Attack\nWe used the optimization process in Eq. (2)to design a DoS attack\nonthetwo-storybuilding,basedonthephysicalequationsofthe\ntestbed (seeAppendix B). Inthis process,the 𝐻2norm iscomputed\nfrom the response of the system for external disturbances at fre-\nquenciesrangingfrom0Hzto10Hz,whichisthemaximumallowed\nvibrationfrequencyofthestructure.Inthiscasestudy,theattacker\nevaluates the response of the system for four different scenarios:\nthecontrolledsystem(nodisconnections),disconnectingactuator1\n(𝑢1), disconnecting actuator 2 ( 𝑢2), or disconnecting both actuators.\nFig. 9 shows the frequency response, and Table 2 shows the 𝐻2\nnorm in these scenarios.\nFromFig.9andTable2,wecanseethatanadversarythatcon-\nducts the optimization process in Eq. (2)to deliver a DoS attack on\nthisbuildingwilldisconnectallactuatorsifpossible.Iftheadversary\ncan only disconnect one actuator, it will choose actuator 1.\nToillustratethisresult,wetestedtwoexternaldisturbances.First,\nwe used the Kanai-Tajimi model [ 53,85], which is commonly used100-60-55-50-45-40-35-30-25-20-15-10\nFigure 9: Response of the system in Fig. 8 for different fre-\nquencies when\nthe two actuators are disconnected (uncon-\ntrolled), only actuator 1 ( 𝑢1) is disconnected, only actuator\n2 (𝑢2) is disconnected, and when the control system of the\nbench-scale structure is completely functional (controlled).\n0\n5 10 15 20 25 30 35 40012\nFigure10:Ourexperimentalresultsinthetestbedmatchour\npre\ndiction that disconnecting 𝑢1will cause a larger maxi-\nmum ISD than disconnecting 𝑢2.\ntoartificiallygenerateearthquake-likedisturbances,tocreate200\ntime-series of artificial ground motions with different frequencies\nrangingfrom1Hzto11Hz.Thisrangeoffrequenciesiscommonly\nseen in earthquakes[ 43]. In these experiments, 70 .5% of the time,\ndisconnecting actuator 1 produced a larger ISD than disconnecting\nactuator2,confirmingthepredictionofourtheoryandoptimization\nproblem.\nSecond,wetestedthelaboratorybench-scalemodelbydiscon-\nnectingoneactuatorwhenthedisturbanceisthetimeseriescor-\nresponding tothe recording of thefamous Kobe earthquake that\noccurredinJapanin1995[ 74].Thisrecordingiswidelyusedasa\nreferencetotestvibrationattenuationsystemsduetoitsimpacton\ncivil structures. Fig. 11 shows the response of the system when the\nDoSattackdisconnectsactuator1andwhentheattackdisconnects\nactuator 2. The maximum ISD per story is shown in Fig. 10. The\nbehavior of this real bench-scale model shows that a DoS attack\nthat blocks actuator 1, as it was designed, has a bigger impact than\nthe one that blocks actuator 2 (confirming our prediction again).\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n13260\n5 10 15 20 25 30 35 40-40-2002040\n0\n5 10 15 20 25 30 35 40-40-2002040\nFigure 11: ISD vs. time of the bench-scale structure for two\ndifferent\nDoSattacks(above:blockingactuator1,andbelow:\nblockingactuator2),whentheKobeearthquake-likedistur-\nbance is exerted on the system.\n0 5 10 15-15-10-5051015\n0 5 10 15-15-10-5051015\nFigure12:ISDvs.timeforeachFDIattackonthebench-scale\nstructure\n.\n5.2 FDI Attack\nWenowusethedesignprocessinSection4.3todesignanFDIattack\nfor the testbed based on the model in Appendix B. Fig. 13 shows\nthefrequencyresponseofthebuildingwithrespecttotheaction\nof𝑢1(signalofactuator1)onthesystemandtheresponseofthe\nbuilding with respect to the action of 𝑢2(actuator 2) on the system.From these plots, the highest peak occurs when 𝑢1is manipulated.\nSincetheseresponsesareshown onalogarithmicscale(decibels),\nthedifferencebetweenthesetworesponsesissignificant.Here,the\nhighestpeakoccursat0.68Hz.Usingthisinformation,theadversary\ninjectsacontrolcommandwithafrequencyof0.68Hz.Inthesecond\nstep of the FDI attack design process, the adversary determines the\nmagnitude and phase of the attacks sent to actuators.\n10-1100-65-60-55-50-45-40-35-30-25-20\nX 0.67215\nY -34.2973\nFigure 13: Frequency response of the system with respect\nto𝑢1(actuator 1) and with respect to 𝑢2(actuator 2). Note\nthatthesystem’sresponsewithrespectto 𝑢1hasitshighest\npeakwhenactuator 1ismanipulatedat0.68Hz;theresponse\nof the system with respect to 𝑢2has its highest peak when\nactuator 2is manipulated at 0.70Hz.\n0\n2 4 6 8 10 12 14012\nFigure14:Ourexperimentalresultsconfirmourtheoretical\npre\ndiction that the attack with 𝑢1would cause larger dam-\nages (a larger maximum ISD).\nFor comparison purposes, we also studied the scenario when\nonly actuator 2 is attacked using a signal at a frequency where\nthe maximum peak occurs, that is, 0.70Hz (see Fig. 13). The ISD vs.\ntime in the real plant for both attacks is shown in Fig. 12. Fig. 14\nshowsthemaximumISDforbothattacks.Fromtheseexperimental\nresults,itisclearthatattackingsignal 𝑢1isthebestdecisionthat\nanattackershouldtakebasedonthemodeltogeneratetheworst\ndamage in the structure. This is consistent with the result in Fig.\n13obtainedfromthemathematicalmodelofthebuilding.Fig.15\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1327Figure 15: A video can be seen at https://youtu.be/vM_\nn1t92NJg.\nshowsthemaximumdisplacementoftherealplantwhentheattack\non one of the actuators is deployed.\nToshowthatourdesignedattackusingEq. (4)istheonethatwill\ngeneratethelargestimpactonthestructure,weinjectedsignalson\nactuator1atdifferentfrequenciesbutwiththesameamplitude.We\ninjectedsinusoidalactuationsignalsatfrequencies1.11Hz,1.27Hz,\nand 1.43 Hz for comparison purposes and compared them to our\npredictedoptimalattackat0.68HzFig.16showstheresultsusing\nthese test signals. An anonymized video of this comparison can\nbe seen at https://youtu.be/vM_n1t92NJg. We confirm that these\nhigher-frequencyattacksresultinsmallerISDsthanouroptimal\ndesign.\n0 5 10 15 20 25012\nFigure 16: Maximum ISD for each story of the bench-scale\nstructure\nfor𝑢1at different frequencies. Our predicted opti-\nmal attack oscillates at 0.68Hz.\n6 ATTACKING A BUILDING WITH\nSEMI-ACTIVE DAMPERS\nTostudymorerealisticscenarios,westartusingstandardmodelsof\nlarge scale structures.This case study consists in abenchmark 20-\nstorybuildingshowninFig.17suppliedbytheStructuralEngineer\nAssociationofCalifornia(SAC)[ 84].Thestructurehasmagnetorhe-\nological(MR)fluiddampersateverystorythatworkassemi-active\ncontroldevices,anditismodeledasanin-planelumped-massshear\nstructure.\nThe mass of story 1 is 1 .126×106kg, masses from story 2 to\nstory 19 are 1 .100×106kg, and the mass of story 20 is 1 .170×106\nkg.Theinter-storystiffnessarethefollowing:fromstory1tostory\n5 are 862.07×103kN/m, from story 6 to story 11 are 554 .17×103\nkN/m, from story 12 to story 14 are 453 .51×103kN/m, from story\n15 to story 17 are 291 .23×103kN/m, for story 18 and story 19 are256.46×103kN/m, and for story 20 is equals to 171 .70×103kN/m\nper [97].\nFigure 17: a) Benchmark 20-story high-rise building, b) its\nlayout\nof actuators, and c) a close-up of the MR damper.\nThe state variables of the vector xare the displacement and\nvelocityofeachofthe20storiesofthebuilding.Similarly,sincethe\nadversarywantstomaximizetheISD, zinEquation (1)isdefinedas\navectoroftheISDateachfloor.TheASCE7-16standardstatesthat\nISD ratios above 1% can compromise the integrity of the structure.\nThedynamicbehavioroftheMRdamperisbasedontheBouc-\nWenhystereticmodelinparallelwithadashpotaddedforanonlin-\near \"roll-off\" effect. The force produced by this model is a function\nofthevelocityofthedevice,anevolutionaryvariable,asetofparam-\neters controlling the behavior of the hysteresis, and the command\nvoltage applied to the current driver. The values of the parameters\nused in this study have a capacity of 1000kN [ 103] and scaled to\nhave this capacity with a maximum voltage of 10 V.\nThe control algorithm for this system consists of an LQR al-\ngorithm as the primary controller that determines the command\nforce (𝑓𝑐), and a clipped-optimal controller that defines the in-\nput voltage to the MR dampers ( 𝑣). The latter can be expressed\nas [28]:𝑣=𝑉𝑚𝑎𝑥𝐻((𝑓𝑐−𝑓)𝑓),where𝑓is the force of the MR\ndamper,𝑉𝑚𝑎𝑥isthemaximumvoltage,and 𝐻(.)istheHeaviside\nstep function.\nWe used the optimization process in Equation (2)to design a\nDoS attack on the 20-story building. Fig. 18 shows the 𝐻2norm\nandthemaximumISDratioforallstorieswhentheDoSattackis\ndeployedon 𝑘actuators,from 𝑘=1to𝑘=20,whenthebuildingis\nunder a 0.7 łEl Centrož earthquake [90].\nNote that when you only disconnect 12 actuators you get a\nbetter attack (higher ISD) than when you disconnect all 16 of them.\nFurthermore, the ISD ratio surpasses the safety limit of 1% after\ndisabling only 5 actuators! This information is important, because\nan attacker might not be able to attack every actuator. With the\nproposedalgorithm,anoptimalattackcanbedesignedforwhatever\nnumber of actuators an attacker can affect.\nFig.19showswhichactuatorsaredisabledbythegeneticalgo-\nrithm for each designed attack. It can be seen that the algorithm\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n13280 5 10\n15 20-14-12-10-8-6\n(a)\n0 5 10 15 2000.20.40.60.811.2\n(b)\nFigure\n18: (a)𝐻2norm of the system for each k attacked ac-\ntuators. (b) maximum ISD ratio for all stories when the at-\ntacker has blocked k signals from the designed DoS attack.\nThe horizontal line indicates the 1% safety level, any ISD\nabove that is dangerous for the building.\n0 5 10 15 2001234567891011121314151617181920\nFigure 19: Actuators disabled for every 𝑘.\ntendstodisabletheactuatorslocatedinthetopfloors.Thisisin-\ntuitive as actuators in the top floors can compensate better the\nvibrations in the building.\nTo show that our attacks are optimal, we compare our results\nwith random disconnections of actuators. Fig. 20 shows that our\noptimal attack is considerably more effective.\n7 ATTACKING A BUILDING WITH ACTIVE\nDAMPERS\nWe use the same 20-story benchmark building but the control sys-\ntem is replaced by two different mass damper systems as shown in\nFig.21.ThefirstoneisanActiveMassDamper(AMD)wherean\nauxiliarymassisconnectedtothestructurethroughanactuator,0\n0.2 0.4 0.6 0.8 1 1.201234567891011121314151617181920\n01234567891011121314151617181920\nFigure20:Comparisonbetweentheoptimalattackandother\ndifferent\nselections for k=5, with the actuators disabled in\neach attack.\nand the second is an Active Tuned Mass Damper (ATMD) where\nthemassisconnectedtothestructurethroughanactuator,aspring,\nandadampingdevice[ 73].ThelatterisknownasHybridcontrol\nbecauseitisacombinationofanactivecomponent(actuator)and\napassivecomponent(springanddamping)thatincreasethereli-\nability of the system if there is a malfunction of the actuator, an\nenergy outage, or, in this case, a cyberattack.\nFigure 21: a) Benchmark 20-story high-rise building with a\nmass damp\ner, b) AMD model, c) and ATMD model.\nThe state variables of the vector xfor this case are the displace-\nment and velocity of each of the 20 stories, as well as the displace-\nment and velocity of the auxiliary mass. Similar to the previous\ncasestudy,theoutputvector zinEq.(1)isavectoroftheISDfor\neach floor.\nFirstthe AMD isconsidered witha massratio of2% ofthe first\nmodalmass,correspondingto332tons,anactuatorwithmaximum\ncapacity of 2MN, a maximum stroke of 50 cm, and an LQR control\nalgorithm[ 47].TheLQRisdesignedwiththeidentitymatrixand\na control force weight as 𝑅=10−14. The ATMD is considered\nwith the same mass ratio, actuator and LQR controller as the AMD,\nand the optimal tuning of the spring and damping is evaluated\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1329usingthe Sadekcriterion [ 75].Since themovement ofthemass is\nlimitedbythestrokeoftheactuator,thisstateisboundedduring\nthe simulation by generating a stopping force [19].\nOurstudyshowsthati)aDoSattacktothesingleactuatorcan\ncompromise the integrity of the structure, and additionally, the\nattacks are more successful on the AMD than the ATMD thanks\nto the additional reduction of vibrations provided by the passive\ncomponent of the ATMD; and ii) FDI attacks that are able to inject\nenergy to the system causing similar or worse damages than those\ncausedbynaturalhazards.ContrarilytotheDoSresults,theFDI\nis more effective on the ATMD than the AMD because the passive\ncomponent assists the oscillation of the attacking signal.\n7.1 DoS Attack\n0\n0.2 0.4 0.6 0.8 1 1.2 1.401234567891011121314151617181920\nFigure 22: Maximum ISD ratio per floor for the AMD and\nATMD\nsystems controlled and under a DoS attack\nThe system was subjected to a Kobe earthquake disturbance,\nwithascalingfactorof0.4.InFig.22,themaximumISDperfloor\ncan be seen when the Kobe disturbance was applied to the ATMD\nand AMD systems, both controlled and attacked. Note that the\nDoS attackgenerates higherISD ratiosfor theAMD system.This\ncanbeexplainedbythepassivedynamicsinvolvedintheATMD\nmodel. When the AMD actuator is disconnected, the system is\nessentially left as if no preventive measure was installed. On the\ncontrary, when the ATMD actuator is disconnected, there still is\napassive componentmitigating theeffectof thedisturbanceby a\nsmallmargin.However,theDoSattackishighlyeffectiveinboth\ncases,wherefloors15and18surpassde1%limitevenwhenthey\nwere within safe ranges on the controlled system\nAmoredetailedeffectoftheDoSattackcanbeseeninFig.23.\nEven though the maximum ISD ratio of the roof is higher than 1%\nfor the four simulated systems, it is still considerably higher when\nthe DoS attack is performed. It is also notable how other ISD ratio\nvaluesaremitigatedinotherinstantsofthetimeresponsebythe\ncontrol system, which reduce the oscillations performed by the\nsystem, diminishing the overall damage to the structure during the\nearthquake.AllofthisprovestheeffectivenessoftheDoSattack,0\n5 10 15 20 25 30 35 40-1.5-1-0.500.511.5\n(a)\n0\n5 10 15 20 25 30 35 40-1.5-1-0.500.511.5\n(b)\nFigure\n23:(a)TimeresponseoftheISDratiofortherooffor\nthe AMD system. (b) Time response of the ISD ratio for the\nroof for the ATMD system.\nand while it may be slightly more effective in the AMD system,\ndisabling the actuator causes high damage in both systems.\n7.2 FDI Attack\nThe FDIattack was designed by usingthe two stepprocess from\nsection 4.3. We obtained the frequency response in Fig. 24 from\nthe singular value decomposition of the systems. The specified 𝐻∞\nnormisthemaximumvalueseenintheplot.Thefrequenciesfor\nboth systems are very similar: 𝐻𝜔𝐹𝐷𝐼=0.2847Hz for the AMD\nand𝐻𝜔𝐹𝐷𝐼=0.2787HzfortheATMD.Despitethissimilarity,we\ncan predict that the FDI attack will be more effective on the ATMD\nsystem, since the 𝐻∞norm is higher for this case.\nFigures 25 and 26 present the Maximum ISD ratios per floor and\ntheISDratiooftheroofduringtheattackfortheinjectedsignal.As\npredicted by the SVD analysis, the attack has a significantly higher\nimpact for the ATMD system, where the ISD ratios are over 1% for\neveryfloor,andashighas3%ontheroof.Thismeansthatacritical\ndamageisachievedfor theentirebuildingstructure. As fortheFDI\nattack on the AMD system, it has less significant effects. In spite\nofthis,permanentdamageisachievedonthestructureonfloors\n15and20,whichshowsthatthisattackstillcanhavedevastating\nconsequences on both systems.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n133010-210-1100101-220-200-180-160-140-120-100\nFigure 24: SVD for the AMD and ATMD models with the ac-\ntuator for\nce as input.\n0\n0.5 1 1.5 2 2.5 3 3.501234567891011121314151617181920\nFigure 25: Maximum ISD per floor for the FDI attack.\n0 50 100 150-4-2024\nFigure26:TimeresponseoftheroofISDratioduringtheFDI\nattack.\nFig. 26 reveals that the system has repeated oscillations over\nthemaximumISDratio.Thismeansthateveryadditionaloscilla-\ntion will be even more damaging. While ISD ratios above 1% are\nachievedforonlyafewinstantsduringanearthquake(evenwhena\nDoS attack is performed), values above 1% are achieved repeatedly\nduringtheFDIattack.Furthermore,thisattackrequiresnoexternal\ndisturbance to generate damage to the structures. Consequently,\nforactivedampers,anFDIattackposesagreaterdangerthanaDoS\nattack.0 5 10 15 20161820\n(a)\n0\n5 10 15 2001020\n(b)\nFigure\n27: (a)𝐻2norm of the system for each k attacked ac-\ntuators. (b) maximum displacement at mid-span when the\nattackerhasblockedksignalsfromthedesignedDoSattack.\nThehorizontallineindicatesthe2%safetylevel,anyhigher\ndisplacement is dangerous for the bridge.\n8 CASE STUDY: ATTACKING A BRIDGE\nWITH SEMI-ACTIVE DAMPERS\nOur final case study investigates the effect of DoS attacks on a\nbenchmarkmodelfromtheASCEcommunity[ 2]tostudythestruc-\ntural performance of a bridge with semi-active dampers subjected\ntohistoricalearthquakes.Researchershaveusedthisbenchmark\nproblem to test the performance of control algorithms in reducing\nvibrationsandmitigatedamagecausedbyseismicevents[ 12,45,94].\nThe bridge is equipped with 20 MR fluid dampers with a maximum\ncapacity of 1MN, nonlinear isolation bearings, and a sensor net-\nworkcapturingaccelerationanddisplacementattheabutmentsand\nbent columns. Fig. 4 shows a plan view of this smart bridge. The\ncontrolalgorithmconsistsofanLQRalgorithmastheprimarycon-\ntrollerthatdeterminesthecommandforceandaclipped-optimal\ncontroller that defines the input voltages to the MR dampers.\nSince bridges do not have different floors, we cannot use ISD\nto measure the impact of attacks. Instead, we use the maximum\ndisplacementatmid-spantoevaluatesafety[ 2].Inparticular,we\nstudy the maximum displacement at mid-span for DoS during the\nKobe earthquake [ 74]. We want to see if the attack exceeds the\nmaximumsafedisplacementof2%oftheheightofthebridgewhere\npotentialspalling,anon-reparabledamageonthecolumnsofthe\nbridge, starts to appear [93]\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1331WeusetheoptimizationprocessinEq. (2)againtodesignaDoS\nattack on the highway bridge, based on the linear mathematical\nmodelfrom[ 2].Fig.27showsthe 𝐻2normofthesystemandthe\nmaximumdisplacementatmid-spanfortheDoSattackonthemost\ndamaging 𝑘actuators, from 𝑘=1 to𝑘=20.\n(a)\n(b)\nFigure\n28:(a)Layoutoftheactuatorsonthebridge.(b)Actua-\ntorsdisabledforeverydesignedattackwithkrangingfrom\n1 to 20.\nNotice that only 5 disabled actuators are required to surpass the\nmaximum safe displacement for this bridge. This information is\nimportant,because anattacker might notbe ableto attackevery\nactuator. Fig. 28 shows the histogram of the number of times each\nactuator is disabled for the 20 DoS attacks. This shows that the\nmid-spandisplacementisheavilydependantonthehorizontalac-\ntuators, more specifically actuators 17 and 19 located in the bent\ncolumnofthebridge.Thisisanotherintuitiveresult,becausethe\ndisplacements in the horizontal direction are usually double the\nmagnitude of the vertical direction on this particular bridge model\nand the design of the attacks identified this characteristic through\nthe𝐻2norm.Also,theactuatorsinthebentcolumnarethemost\ncrucial because they support the mid-span of the bridge.\nWe again show that our attacks are optimal, with a comparison\nto other attacks that deactivate k=6 actuators at random, as shown\nin Fig. 29.\n9 CONCLUSIONS\nA structural control system is designed to reduce vibrations and\ntolerateuncertaintiescausedbyvariationsinthestructure,dynamic\nloads,ordisturbancesinthemeasurementsandactuationsignals0 10 20 30 40-10010\n01234567891011121314151617181920\nFigure29:Comparisonofresponseintimebetweenthecon-\ntrolle\nd bridge structure, the optimal attack, and a random\nselection for k=6.\n[7,25,83]. However, to our knowledge, there are no studies that\ndesign and evaluate structural control systems in scenarios where\nthe structure is subject to attacks. In this paper, we showed that\nsimple disconnections of some of the actuators, or the injection of\nsignals on the actuators at specific frequencies, magnitudes, and\nphases, maycause criticaldamage tothe structure. Thisfirst look\nat attacks against structural control systems is a crucial step to\ndefinecriteriaforthedesignandevaluationofstructuralcontrol\nsystemsthatconsidernotonly robustness initscommonuse,but\nalsoresilience to attacks.\nAspartofourcontributionstothisnewareaofinquiry,we(1)\nProposeasetofbenchmarkstoevaluatethesecurityofstructural\ncontrolsystems.Notonlydidwefindandarguefortheuseofhigh-\nfidelityindustry-approvedsimulationsofbuildingsandbridges,but\nwe also propose a set of standard earthquake models to consider in\nthese studies. (2) Propose a set of metrics to measure the impact of\nattacks on buildings (ISD) and on bridges (maximum displacement\nandaccelerationatmid-span).(3)Designtwotypesofattacks(DoS\nand FDI) and show how their effects are better than other heuristic\nattacks (e.g., in the Quanser testbed, we showed how our proposed\nattack is better than others). (4) We start the discussion on unique\ndefenses for these types of attacks. Based on our previous work\non physics-based attack detection [ 9,37,72,91], in Appendix C\nwe design and test a new model-based attack detection tool that\ncan identify both DoS and FDI attacks on actuators (or sensors).\nTodetectattacksfromthecontrolleritself,weneedanadditional\nmodel of the control system.\nThispaper isthefirst typeof researchinthis direction,andwe\nhopeitcanmotivatemoreworkinthissafety-criticalsystem.Future\nworkincludesstudyingmitigationstrategiessuchasredesigning\nthesystemwhenitisfoundvulnerabletoourattacksandproposing\nattack-resilient-control algorithms.\nACKNOWLEDGEMENTS\nThis material is based on research sponsored by NSF CNS-1929410,\n1929406, 1931573, and by the Air Force Research Laboratory un-\nder agreement number FA8750-19-2-0010. The U.S. Government is\nauthorized to reproduce and distribute reprints for Governmental\npurposes notwithstanding any copyright notation thereon.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1332REFERENCES\n[1]AhmadAbdelrazaq.2012. Validatingthestructuralbehaviorandresponseof\nBurjKhalifa:Synopsisofthefullscalestructuralhealthmonitoringprograms.\nInternational Journal of High-Rise Buildings 1, 1 (2012), 37ś51.\n[2]Anil Agrawal, Ping Tan, Satish Nagarajaiah, and Jian Zhang. 2009. Benchmark\nstructural control problem for a seismically excited highway bridgeÐPart I:\nPhaseIproblemdefinition. StructuralControlandHealthMonitoring:TheOfficial\nJournaloftheInternationalAssociationforStructuralControlandMonitoringand\nof the European Association for the Control of Structures 16, 5 (2009), 509ś529.\n[3] David Alexander. 2018. Natural disasters. Routledge.\n[4]Saurabh Amin,Alvaro ACárdenas, andS Shankar Sastry.2009. Safeand secure\nnetworked control systems under denial-of-service attacks. In International\nWorkshop on Hybrid Systems: Computation and Control. Springer, 31ś45.\n[5]SaurabhAmin,XavierLitrico,ShankarSastry,andAlexandreMBayen.2013.\nCyber security of water SCADA systemsśpart I: analysis and experimentation\nof stealthy deception attacks. Control Systems Technology, IEEE Transactions on\n21, 5 (2013), 1963ś1970.\n[6]AP. 2017. Revenge Hacker: 34 Months, Must Repay Georgia-Pacific\n$1M. https://www.usnews.com/news/louisiana/articles/2017-02-16/revenge-\nhacker-34-months-must-repay-georgia-pacific-1m.\n[7]GaryJBalasandJohnCDoyle.1994. Robustnessandperformancetrade-offs\nin control design for flexible structures. IEEE Transactions on control systems\ntechnology 2, 4 (1994), 352ś361.\n[8]MattBurgess.2017. Couldhackersreallytakeoverahotel?WIREDexplains.\nWIRED(2017).\n[9]Alvaro A Cárdenas, Saurabh Amin, Zong-Syun Lin, Yu-Lun Huang, Chi-Yen\nHuang, and Shankar Sastry. 2011. Attacks against process control systems: risk\nassessment, detection, and response. In Proceedings of the 6th ACM symposium\non information, computer and communications security. 355ś366.\n[10]S.CasciatiandZ.Chen.2012. Anactivemassdampersystemforstructuralcon-\ntrol using real-time wireless sensors. Structural Control and Health Monitoring\n19, 8 (2012), 758ś767.\n[11]MarcoCaselli,EmmanueleZambon,JohannaAmann,RobinSommer,andFrank\nKargl. 2016. Specification mining for intrusion detectionin networked control\nsystems.In 25th{USENIX}SecuritySymposium( {USENIX}Security16).791ś\n806.\n[12]Young-JinChaandAnilKAgrawal.2013. Decentralizedoutputfeedbackpolyno-\nmialcontrolofseismicallyexcitedstructuresusinggeneticalgorithm. Structural\nControl and Health Monitoring 20, 3 (2013), 241ś258.\n[13] Yuqi Chen, Christopher M Poskitt, and Jun Sun. 2018. Learning from mutants:\nUsingcodemutationtolearnandmonitorinvariantsofacyber-physicalsystem.\nIn2018 IEEE Symposium on Security and Privacy (SP). IEEE, 648ś660.\n[14]Franklin Y Cheng, Hongping Jiang, and Kangyu Lou. 2008. Smart structures:\ninnovative systems for seismic response control. CRC press.\n[15]AntonCherepanov.2017. Win32/Industroyer,Anewthreatforindustrialcontrol\nsystems. White Paper. ESET (2017).\n[16]HongjunChoi,Wen-ChuanLee,YousraAafer,FanFei,ZhanTu,XiangyuZhang,\nDongyan Xu, and Xinyan Deng. 2018. Detecting Attacks Against Robotic\nVehicles:AControlInvariantApproach.In Proceedingsofthe2018ACMSIGSAC\nConferenceonComputerandCommunicationsSecurity (Toronto,Canada) (CCS\n’18). ACM, New York, NY, USA, 801ś816.\n[17]Richard Christenson, Yi Zhong Lin, Andrew Emmons, and Brent Bass. 2008.\nLarge-scaleexperimentalverificationofsemiactivecontrolthroughreal-time\nhybrid simulation. Journal of Structural Engineering 134, 4 (2008), 522ś534.\n[18]Pierre Ciholas, Aidan Lennie, Parvin Sadigova, and Jose M Such. 2019. The\nsecurity of smart buildings: a systematic literature review. arXiv preprint\narXiv:1901.05837 (2019).\n[19]Cong Cong. 2019. Using active tuned mass dampers with constrained stroke to\nsimultaneously control vibrations in wind turbine blades and tower. Advances\nin Structural Engineering 22, 7 (2019), 1544ś1553.\n[20]Jerome Connor and Simon Laflamme. 2014. Applications of Active Control.\nSpringerInternationalPublishing,Cham,347ś386. https://doi.org/10.1007/978-\n3-319-06281-5_7\n[21]Jerome Connor and Simon Laflamme. 2014. Structural motion engineering.\nSpringer.\n[22]SoodehDadras,RyanMGerdes,andRajnikantSharma.2015. Vehicularplatoon-\ninginanadversarialenvironment.In Proceedingsofthe10thACMSymposium\non Information, Computer and Communications Security. ACM, 167ś178.\n[23]Austin Downey, Liang Cao, Simon Laflamme, Douglas Taylor, and James Ricles.\n2016. High capacity variable friction damper based on band brake technol-\nogy.EngineeringStructures 113(apr2016),287ś298. https://doi.org/10.1016/j.\nengstruct.2016.01.035\n[24]Austin Downey, Connor Theisen, Heather Murphy, Nicholas Anastasi, and\nSimonLaflamme.2019. Cam-basedpassivevariablefrictiondeviceforstructural\ncontrol.EngineeringStructures 188(jun2019),430ś439. https://doi.org/10.1016/\nj.engstruct.2019.03.032[25]JohnDoyleandGunterStein.1981. Multivariablefeedbackdesign:Concepts\nforaclassical/modernsynthesis. IEEEtransactionsonAutomaticControl 26,1\n(1981), 4ś16.\n[26]RajGautamDutta,FengYu,TengZhang,YaodanHu,andYierJin.2018. Security\nfor safety: a path toward building trusted autonomous vehicles. In Proceedings\nof the International Conference on Computer-Aided Design. ACM, 92.\n[27]Shirley J Dyke, Juan Martin Caicedo, Gursoy Turan, Lawrence A Bergman, and\nStevenHague.2003. PhaseIbenchmarkcontrolproblemforseismicresponseof\ncable-stayed bridges. Journal of Structural Engineering 129, 7 (2003), 857ś872.\n[28]Shirley J Dyke, BF Spencer Jr, MK Sain, and JD Carlson. 1996. Modeling and\ncontrolofmagnetorheologicaldampersforseismicresponsereduction. Smart\nmaterials and structures 5, 5 (1996), 565.\n[29]OmarEl-Khoury,AbdollahShafieezadeh,andEhsanFereshtehnejad.2018. A\nrisk-based life cycle cost strategy for optimal design and evaluation of control\nmethodsfornonlinearstructures. EarthquakeEngineering&StructuralDynamics\n47, 11 (2018), 2297ś2314.\n[30]JosuéEnríquez-Zárate,HugoFranciscoAbundis-Fong,RamiroVelázquez,and\nSebastián Gutiérrez. 2019. Passive vibration control in a civil structure: Experi-\nmentalresults. MeasurementandControl 52,7-8(2019),938ś946. https://doi.\norg/10.1177/0020294019847715 arXiv:https://doi.org/10.1177/0020294019847715\n[31]Herson Esquivel-Vargas, Marco Caselli, and Andreas Peter. 2017. Automatic\ndeploymentofspecification-basedintrusiondetectionintheBACnetprotocol.\nInProceedings of the 2017 Workshop on Cyber-Physical Systems Security and\nPrivaCy. 25ś36.\n[32]Davide Fauri, Michail Kapsalakis, Daniel Ricardo dos Santos, Elisa Costante,\nJerry den Hartog, and Sandro Etalle. 2018. Leveraging semantics for actionable\nintrusion detection in building automation systems. In International Conference\non Critical Information Infrastructures Security. Springer, 113ś125.\n[33]AndréFiliatrault.2013. Elementsofearthquakeengineeringandstructuraldy-\nnamics. Presses inter Polytechnique.\n[34]Kevin Fu and Wenyuan Xu. 2018. Risks of trusting the physics of sensors.\nCommun. ACM 61, 2 (2018), 20ś23.\n[35]R Fukuda and H Kurino. 2017. Highly efficient semi-active oil damper for\nstructuralcontrolwithenergyrecoverysystem.In Proceedingsofthe16thWorld\nConference on Earthquake Engineering.\n[36]Ilias Giechaskiel and Kasper Bonne Rasmussen. 2019. Sok: Taxonomy and\nchallenges of out-of-band signal injection attacks and defenses. arXiv preprint\narXiv:1901.06935 (2019).\n[37]Jairo Giraldo, David Urbina, Alvaro Cardenas, Junia Valente, Mustafa Faisal,\nJustinRuths,NilsOleTippenhauer,HenrikSandberg,andRichardCandell.2018.\nA survey of physics-based attack detection in cyber-physical systems. ACM\nComputing Surveys (CSUR) 51, 4 (2018), 1ś36.\n[38]Gene H Golub and Christian Reinsch. 1971. Singular value decomposition and\nleast squares solutions. In Linear Algebra. Springer, 134ś151.\n[39]Yongqiang Gong, Liang Cao, Simon Laflamme, Spencer Quiel, James Ricles, and\nDouglas Taylor. 2018. Characterization of a novel variable friction connection\nforsemiactivecladdingsystem. StructuralControlandHealthMonitoring 25,6\n(2018), e2157.\n[40]Andy Greenberg. 2020. Sandworm: A New Era of Cyberwar and the Hunt for the\nKremlin’s Most Dangerous Hackers. Anchor.\n[41]Michael A Grubb, Kenneth E Wilson, Christopher D White, William N Nickas,\net al.2015.Load and resistance factor design (lrfd) for highway bridge\nsuperstructures-reference manual. Technical Report. National Highway Institute\n(US).\n[42]Mariantonieta Gutierrez Soto and Hojjat Adeli. 2013. Tuned mass dampers.\nArchives of Computational Methods in Engineering 20, 4 (2013), 419ś431.\n[43]Mariantonieta Gutierrez Soto and Hojjat Adeli. 2017. Multi-agent replicator\ncontroller for sustainable vibration control of smart structures. Journal of\nVibroengineering 19 (2017), 4300ś4322.\n[44]MariantonietaGutierrezSotoandHojjatAdeli.2017. Recentadvancesincontrol\nalgorithms for smart structures and machines. Expert Systems 34, 2 (2017),\ne12205.\n[45]Mariantonieta Gutierrez Soto and Hojjat Adeli. 2019. Semi-active vibration\ncontrol of smart isolated highway bridge structures using replicator dynamics.\nEngineering Structures 186 (2019), 536ś552.\n[46]Eman Hammad, Ahmed M. Khalil, Abdallah Farraj, Deepa Kundur, and Reza\nIravani.2015. Tuningoutofphase:Resonanceattacks.In 2015IEEEInternational\nConferenceonSmartGridCommunications(SmartGridComm).491ś496. https:\n//doi.org/10.1109/SmartGridComm.2015.7436348\n[47] MasahikoHigashino,SatoruAizawa,MasashiYamamoto,andKotaroToyama.\n1998. Applicationofactivemassdamper(AMD)system,andearthquakeand\nwindobservationresults.In Proceedingsofthe2ndWorldConferenceonStructural\nControl, Vol. 1. 783ś794.\n[48]GWeaHousner,LawrenceABergman,TKfCaughey,AnastassiosGChassiakos,\nRichardOClaus,SamiFMasri,RobertESkelton,TTSoong,BFSpencer,and\nJames TP Yao. 1997. Structural control: past, present, and future. Journal of\nengineering mechanics 123, 9 (1997), 897ś971.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1333[49]Yu-Lun Huang, Alvaro A Cárdenas, Saurabh Amin, Zong-Syun Lin, Hsin-Yi\nTsai, and Shankar Sastry. 2009. Understanding the physical and economic\nconsequences of attacks on control systems. International Journal of Critical\nInfrastructure Protection 2, 3 (2009), 73ś83.\n[50]YoshikiIkeda,MasashiYamamoto,TakeshiFuruhashi,andHaruhikoKurino.\n2019.RecentresearchanddevelopmentofstructuralcontrolinJapan. JAPANAR-\nCHITECTURALREVIEW 2,3(2019),219ś225. https://doi.org/10.1002/2475-8876.\n12081 arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/2475-8876.12081\n[51]Structural Engineering Institute. 2016. Minimum design loads for buildings and\nother structures. American Society of Civil Engineers.\n[52]BlakeJohnson,DanCaban,MarinaKrotofil,DanScali,NathanBrubaker,and\nChristopherGlyer.2017. AttackersDeployNewICSAttackFramework\"TRI-\nTON\" and Cause Operational Disruption to Critical Infrastructure. Threat\nResearch Blog (2017).\n[53]Kiyoshi Kanai. 1957. Semi-empirical formula for the seismic characteristics of\nthe ground. Bulletin of the Earthquake Research Institute, University of Tokyo 35,\n2 (1957), 309ś325.\n[54]Marina Krotofil, Alvaro Cardenas, Jason Larsen, and Dieter Gollmann. 2014.\nVulnerabilitiesofcyber-physicalsystemstostaledata?Determiningtheoptimal\ntimetolaunchattacks. Internationaljournalofcriticalinfrastructureprotection\n7, 4 (2014), 213ś232.\n[55]HaruhikoKurino,JunTagami,KanShimizu,andTakujiKobori.2003. Switching\noildamperwithbuilt-incontrollerforstructuralcontrol. JournalofStructural\nEngineering 129, 7 (2003), 895ś904.\n[56]AlbertoLago,HadiMoghadasiFaridani,andDarioTrabucco.2018. Damping\nTechnologies for Tall Buildings. CTBUH Journal 3 (2018).\n[57]S. Lamb and K.C.S. Kwok. 2019. The effects of motion sickness and sopite\nsyndromeonofficeworkersinan18-monthfieldstudyoftallbuildings. Journal\nof Wind Engineeringand Industrial Aerodynamics 186 (2019),105 ś 122. https:\n//doi.org/10.1016/j.jweia.2019.01.004\n[58]S. Lamb, K.C.S. Kwok, and D. Walton. 2013. Occupant comfort in wind-excited\ntallbuildings:Motionsickness,compensatorybehavioursandcomplaint. Journal\nof Wind Engineering and Industrial Aerodynamics 119 (2013), 1 ś 12. https:\n//doi.org/10.1016/j.jweia.2013.05.004\n[59]Yao Liu, Peng Ning, and Michael K Reiter. 2009. False data injection attacks\nagainst state estimation in electric power grids. In Proceedings of the conference\non Computer and communications security (CCS). ACM, 21ś32.\n[60]Jerome Peter Lynch. 1998. Active structural control research at Kajima Corpo-\nration.The National Science Foundation’sSummer Institute in Japan Program,\nResearch Project 17 (1998), 11.\n[61]J.P.Lynch,Y.Wang,R.A.Swartz,K.C.Lu,andC.HLoh.2008. Implementa-\ntion of a closed-loop structural control system using wireless sensor networks.\nStructural Control and Health Monitoring 15, 4 (2008), 518ś539.\n[62]Lee Mathews. 2016. Hackers use DDoS attack to cut heat to apartments. Forbes\n(2016).\n[63]StephenMcLaughlin.2013. CPS:StatefulPolicyEnforcementforControlSystem\nDevice Usage. In Proceedings of the 29th Annual Computer Security Applications\nConference (NewOrleans,Louisiana,USA) (ACSAC’13).ACM,NewYork,NY,\nUSA, 109ś118.\n[64]Laura Micheli, Alice Alipour, Simon Laflamme, and Partha Sarkar. 2019.\nPerformance-based design with life-cycle cost assessment for damping sys-\ntemsintegratedinwindexcitedtallbuildings. EngineeringStructures 195(2019),\n438ś451.\n[65]Satomi Nakanishi and K. Taira. 2010. Study on cost reduction by seismic\nisolationbearingandvibrationcontroldeviceforthebridge.In Proceedingsof\nthe IABSE-JSCE Joint Conference on Advances in Bridge Engineering-II.\n[66]Y. Q. Ni and H. F. Zhou. 2010. Guangzhou new TV tower: Integrated structural\nhealth monitoring and vibration control. In Structures Congress 2010. https:\n//doi.org/10.1061/41130(369)283\n[67]YOhtori,REChristenson,BFSpencerJr,andSJDyke.2004. Benchmarkcontrol\nproblems for seismically excited nonlinear buildings. Journal of engineering\nmechanics 130, 4 (2004), 366ś385.\n[68]WilliamNPatten.1997. Semiactivevibrationabsorbers(SAVA)attheI-35Walnut\nCreek bridge (FHWA-OK-97-08) 2125. Technical Report.\n[69]William Neff Patten, Jinghui Sun, and Gang Song. 1998. Prototype Testing\nof Intelligent Stiffener for Bridges at I-35 Walnut Creek Bridge. Transporta-\ntionResearchRecord 1624,1(1998),160ś165. https://doi.org/10.3141/1624-19\narXiv:https://doi.org/10.3141/1624-19\n[70]Matthew Peacock, Michael N Johnstone, and Craig Valli. 2017. An exploration\nof some security issues within the BACnet protocol. In International Conference\non Information Systems Security and Privacy. Springer, 252ś272.\n[71]Jonathan Petit, Bas Stottelaar, Michael Feiri, and Frank Kargl. 2015. Remote\nattacksonautomatedvehiclessensors:Experimentsoncameraandlidar. (2015).\n[72]RaulQuinonez,JairoGiraldo,LuisSalazar,ErickBauman,AlvaroCardenas,and\nZhiqiang Lin. 2020. {SAVIOR}: Securing Autonomous Vehicles with Robust\nPhysical Invariants. In 29th{USENIX}Security Symposium ( {USENIX}Security\n20). 895ś912.[73]Francesco Ricciardelli, A David Pizzimenti, and Massimiliano Mattei. 2003.\nPassiveandactivemassdampercontroloftheresponseoftallbuildingstowind\ngustiness. Engineering structures 25, 9 (2003), 1199ś1209.\n[74]Andreas Rietbrock.2001. Pwave attenuation structurein the faultarea of the\n1995 Kobe earthquake. Journal of Geophysical Research: Solid Earth 106, B3\n(2001), 4141ś4154.\n[75]Fahim Sadek, Bijan Mohraz, Andrew W Taylor, and Riley M Chung. 1997. A\nmethod of estimating the parameters of tuned mass dampers for seismic appli-\ncations.Earthquake Engineering & Structural Dynamics 26, 6 (1997), 617ś635.\n[76]Jayaprakash Selvaraj, Gökçen Y Dayanıklı, Neelam Prabhu Gaunkar, David\nWare,RyanMGerdes,ManiMina,etal .2018. Electromagneticinductionattacks\nagainst embedded systems. In Proceedings of the 2018 on Asia Conference on\nComputer and Communications Security. ACM, 499ś510.\n[77]CHARLESTON SEMINAR. 1997. NEHRP Guidelines for the Seismic Rehabilita-\ntion of Buildings (FEMA 273). (1997).\n[78]ChristianESilva,DanielGomez,AminMaghareh,ShirleyJDyke,andBillieF\nSpencerJr.2020. Benchmarkcontrolproblemforreal-timehybridsimulation.\nMechanical Systems and Signal Processing 135 (2020), 106381.\n[79]JillSlayandMichaelMiller.2007. LessonsLearnedfromtheMaroochyWater\nBreach. In Critical Infrastructure Protection, Vol. 253/2007. Springer Boston,\n73ś82.\n[80]AdamSmith.2020. 2010-2019:ALandmarkDecadeofUSBillion-DollarWeather\nand Climate Disasters| NOAA Climate. Gov. Climate. Gov 9 (2020).\n[81]I. Solomon, J. Cunnane, and P. Stevenson. 2000. Large-scale structural monitor-\ningsystems. NondestructiveEvaluationofHighways,Utilities,andPipelinesIV\n3995 (2000), 281ś303.\n[82]Yun Mok Son, Ho Cheol Shin, Dong Kwan Kim, Young Seok Park, Ju Hwan\nNoh,KiBumChoi,JungWooChoi,andYongDaeKim.2015. Rockingdrones\nwith intentional sound noise on gyroscopic sensors. In 24th USENIX Security\nsymposium. USENIX Association.\n[83]BFSpencerJr,MKSain,C-HWon,DCKaspari,andPMSain.1994. Reliability-\nbased measures of structural control robustness. Structural safety 15, 1-2 (1994),\n111ś129.\n[84]B. F. Spencer Jr., R. E. Christenson, and S. J. Dyke. 1998. Next generation\nbenchmark control problem for seismically excited buildings. Second World\nConference on Structural Control (1998), 1135ś1360.\n[85]H Tajimi.1960. A statisticalmethod of determiningthe maximumresponse of\na building structure during an earthquake. 2nd WCEE. Tokyo, Japan (1960).\n[86]Rui Tan, Varun Badrinath Krishna, David KY Yau, and Zbigniew Kalbarczyk.\n2013. Impact of integrity attacks on real-time pricing in smart grids. In Pro-\nceedings of the 2013 ACM SIGSAC conference on Computer & communications\nsecurity. ACM, 439ś450.\n[87]BungaleSTaranath.2016. Structuralanalysisanddesignoftallbuildings:Steel\nand composite construction. CRC press.\n[88]A. Teixeira, I. Shames, H. Sandberg, and K. H. Johansson. 2012. Revealing\nstealthy attacks in control systems. In Communication, Control, and Computing\n(Allerton), 2012 50th Annual Allerton Conference on. 1806ś1813. https://doi.org/\n10.1109/Allerton.2012.6483441\n[89]Yazhou Tu, Zhiqiang Lin, Insup Lee, and Xiali Hei. 2018. Injected and delivered:\nFabricating implicit control over actuation systems by spoofing inertial sensors.\nIn27th{USENIX}Security Symposium ( {USENIX}Security 18). 1545ś1562.\n[90]FEUdwadiaandMDTrifunac.1973.Comparisonofearthquakeandmicrotremor\nground motions in El Centro, California. Bulletin of the Seismological Society of\nAmerica63, 4 (1973), 1227ś1253.\n[91]DavidUrbina,JairoGiraldo,AlvaroA.Cardenas,NilsOleTippenhauer,Junia\nValente, Mustafa Faisal, Justin Ruths, Richard Candell, and Henrik Sandberg.\n2016. LimitingTheImpactofStealthyAttacksonIndustrialControlSystems.In\nProceedingsoftheACMConferenceonComputerandCommunicationsSecurity\n(CCS). https://doi.org/10.1145/2976749.2978388\n[92]DavidIUrbina,JairoAGiraldo,AlvaroACardenas,NilsOleTippenhauer,Junia\nValente, Mustafa Faisal, Justin Ruths, Richard Candell, and Henrik Sandberg.\n2016. Limitingtheimpactofstealthyattacksonindustrialcontrolsystems.In\nProceedings of the 2016 ACM SIGSAC Conference on Computer and Communica-\ntions Security. ACM, 1092ś1105.\n[93]MarcVeletzos,MarioPanagiutou,JoseRestrepo,StephenSahs,etal .2008.Visual\ninspection&capacityassessmentofearthquakedamagedreinforcedconcretebridge\nelements. Technical Report. California. Dept. of Transportation. Division of\nResearch and Innovation.\n[94]NengmouWangandHojjatAdeli.2015. Self-constructingwaveletneuralnet-\nworkalgorithmfornonlinearcontroloflargestructures. EngineeringApplica-\ntions of Artificial Intelligence 41 (2015), 249ś258.\n[95]Xiaolong Wang, Richard Habeeb, Xinming Ou, Siddharth Amaravadi, John\nHatcliff,MasaakiMizuno,MitchellNeilsen,SRajRajagopalan,andSrivatsan\nVaradarajan. 2017. Enhanced security of building automation systems through\nmicrokernel-based controllerplatforms. In 2017 IEEE37th International Confer-\nence on Distributed Computing Systems Workshops (ICDCSW). IEEE, 37ś44.\n[96]XiaolongWang,MasaakiMizuno,MitchNeilsen,XinmingOu,SRajRajagopalan,\nWill G Boldwin, and Bryan Phillips. 2015. Secure rtos architecture for building\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1334automation.In ProceedingsoftheFirstACMWorkshoponCyber-PhysicalSystems-\nSecurity and/or PrivaCy. 79ś90.\n[97]Yang Wang, Jerome P. Lynch, and Kincho H. Law. 2009. Decentralized 𝐻∞\ncontrollerdesignforlarge-scalecivilstructures. EarthquakeEngineeringand\nStructural Dynamics (2009). https://doi.org/10.1002/eqe.862\n[98]Yong Wang, Zhaoyan Xu, Jialong Zhang, Lei Xu, Haopei Wang, and Guofei Gu.\n2014. Srid:Staterelationbasedintrusiondetectionforfalsedatainjectionattacks\nin scada. In European Symposium on Research in Computer Security. Springer,\n401ś418.\n[99]Felix Weber, Hans Distl, Sebastian Fischer, and Christian Braun. 2016. MR\ndamper controlled vibration absorber for enhanced mitigation of harmonic\nvibrations. Actuators 5, 4 (2016), 27.\n[100]YongdongWu,ZhuoWei,JianWeng,XinLi,andRobertH.Deng.2018. Reso-\nnance Attacks on Load Frequency Control of Smart Grids. IEEE Transactions on\nSmart Grid 9, 5 (2018), 4490ś4502. https://doi.org/10.1109/TSG.2017.2661307\n[101]H.B.Xu,C.W.Zhang,H.Li,P.Tan,J.P.Ou,andF.L.Zhou.2014. Windinduced\nvibration characteristics and model updating of Canton Tower structure. Smart\nStructures and Systems 13, 2 (2014), 281ś303.\n[102]Masashi Yamamoto and Takayuki Sone. 2014. Behavior of active mass damper\n(AMD)installedinhigh-risebuildingduring2011earthquakeoffPacificcoastof\nTohokuandverificationofregeneratingsystemofAMDbasedonmonitoring.\nStructural Control and Health Monitoring 21, 4 (2014), 634ś647.\n[103]Fu Yi, ShirleyJ Dyke, Juan M Caicedo, andJ David Carlson. 2001. Experimental\nverification of multiinput seismic control strategies for smart dampers. Journal\nof Engineering Mechanics 127, 11 (2001), 1152ś1164.\n[104]Kim Zetter. 2013. Researchers hack building control system at google australia\noffice.Wired. com, available at https://www. wired. com/2013/05/googles-control-\nsystem-hacked (accessed 9th June, 2017) (2013).\n[105]K Zetter. 2013. Vulnerability lets hackers control building locks, electricity,\nelevators and more. WIRED, Boone, IA, USA, Feb 6 (2013).\n[106]Kim Zetter. 2014. Countdown to Zero Day: Stuxnet and the launch of the world’s\nfirst digital weapon. Broadway books.\n[107]KeminZhou,JohnComstockDoyle,KeithGlover,etal .1996.Robustandoptimal\ncontrol. Vol. 40. Prentice hall New Jersey.\nA STRUCTURE’S EQUATION OF MOTION\nWecanmodeltheframeshowninFig.30aasthesimple,dynami-\ncally equivalent model shown in Fig. 30b. In this model, the lateral\nstiffness of the columns is modeled by the spring (k ), the damping\nis modeled by the shock absorber (c ) and the mass of the floor is\nmodeledbythemass(m ).Figure30cshowsthefreebodydiagramof\nthestructure.Theforcesincludethespringforce 𝑓𝑠(𝑡),thedamping\nforce𝑓𝑑(𝑡), the external dynamic load on the structure 𝑝(𝑡), and\nthe inertial force 𝑓𝑖(𝑡). These forces are defined as:\n𝑓𝑠=𝑘𝑞(𝑡)𝑓𝑑=𝑐/dotacc𝑞(𝑡)𝑓𝑖=𝑚/ddotacc𝑞(𝑡)(5)\nwhere/dotacc𝑞(𝑡)isthefirstderivativeofthedisplacementwithrespectto\ntime(velocity)and /ddotacc𝑞(𝑡)isthesecondderivativeofthedisplacement\nwithrespecttotime(acceleration).Summingtheforcesshownin\nFigs. 30b and c, we obtain the following:\n/summationdisplay.1\n𝐹=𝑚/ddotacc𝑞(𝑡)=𝑝(𝑡) −𝑐/dotacc𝑞(𝑡) −𝑘𝑞(𝑡) (6)\nTranslating this concept to a multiple degree of freedom and\nitsequivalentdynamicmodelisshowninFig.31,with 𝑛-degrees\nof freedom subjected to 𝑚1external excitation and 𝑚2controlling\ndevices, we obtain the following expression:\nMq(𝑡) +Cq(𝑡) +Kq(𝑡)=Tuu(𝑡) +Tpp(t) (7)\nwhereq(𝑡) ∈R𝑛×1isthedisplacementvectorrelativetotheground,\nM,C,K∈R𝑛×𝑛are the mass, damping, and stiffness matrices, re-\nspectively; u(𝑡) ∈R𝑚2×1is the control force vector; Tu∈R𝑛×𝑚2\nandTw∈R𝑛×𝑚1arethecontrolandexcitationlocationmatrices,\nrespectively. In terms of calculating the inter-story drift (ISD), the\ndisplacementisshownFig.31andthecalculatedinter-storydrift\nis determined by Δ2=(𝑞2−𝑞1)with the inter-story drift ratio\ncomputed as, Δ𝑟2=(𝑞2−𝑞1)/ℎ2andΔ𝑟1=𝑞1/ℎ1. In the case ofthebuildingsubjectedtoseismicloading,thespatialloadpattern\nvectorTpis equal to −M/braceleftbig¯I/bracerightbig\n𝑛×1/ddotacc𝑞𝑔(𝑡)where the external excita-\ntion/ddotacc𝑞𝑔(𝑡)isthegroundaccelerationtimehistory.Chenetal.[ 14]\nandConnorandLaflamme[ 21]provideadditionalinformationof\nthe mathematical derivation of buildings equipped with control\ndevices.\nB MODEL OF QUANSER’S BENCH-SCALE\nTESTBED\nThestate variablesthatdefinethe mathematicalrepresentationof\nthe structure according to Equation (1)are chosen to be: (i) the\nposition of the moving cart at story 1 𝑥𝑐1, (ii) the position of the\nmoving cart of floor 2 𝑥𝑐2, (iii) displacement at story 1 𝑥𝑓1, (iv)\ndisplacementatstory2 𝑥𝑓2,(v)velocityofcart1 /dotacc𝑥𝑐1,(vi)velocity\nofcart2/dotacc𝑥𝑓2,(vii)velocityofstory1relativetotheground /dotacc𝑥𝑓1,and\n(viii) velocity of story 2 relative to the ground /dotacc𝑥𝑓2. These are the\nvariablesthatareconsideredtoprovideinformationaboutthestate\nof the structure. The output vector zcorresponds to the inter-story\ndriftsΔ𝑥𝑓1=𝑥𝑓1andΔ𝑥𝑓2=𝑥𝑓2−𝑥𝑓1. The state-space vector of\nthe plant is given by\nx=/bracketleftbig𝑥𝑐1𝑥𝑐2𝑥𝑓1𝑥𝑓2/dotacc𝑥𝑐1/dotacc𝑥𝑐2/dotacc𝑥𝑓1/dotacc𝑥𝑓2/bracketrightbig𝑇.\nTheparametersofthestate-spacerepresentationofthestructure\nin Equation (1) are:\nA=0 0 0 0 1 0 0 0\n0 0 0 0 0 1 0 0\n0 0 0 0 0 0 1 0\n0 0 0 0 0 0 0 1\n0 0 0 87 .61−43.73 30.09 0 0\n0 0 0 87 .60 30 .09−43.73 0 0\n0 0−66.41 66 .41 0 0 0 0\n0 0 66 .41−140.89 2.64 2 .64 0 0,\nB=0 0\n0 0\n0 0\n0 0\n7.2714−5.6968\n−5.6968 7 .2714\n0 0\n−0.4078−0.4078,E=0\n0\n0\n0\n−1\n0\n−1\n0.\nMatrixFis chosen to compute the inter-story drift for each floor:\nF=0 0 1 0 0 0 0 0\n0 0−1 1 0 0 0 0\n0 0 0 0 0 0 0 0\n0 0 0 0 0 0 0 0\nThe feedback control gain used to define the control strategy is\ncomputed using the LQR method and is given by Ras follows:\nR=/bracketleftbigg7.0244−0.8110 42 .2172−80.4384\n0.3627 3 .1414 8 .8323−14.0781\n−0.1108−0.2989−1.1316−11.8019\n0.0319 0 .0874 0 .0148−2.2558/bracketrightbigg\nHere,thecontrolactionisdefinedbythefeedbackgain u=−Rxto\nreduce the effect vibrations on the structure.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1335Figure 30: a) Single degree of freedom structure, b) Mass with spring and damper, c) Free Body Diagram\nFigure 31: Two-degree of freedom structure with an active\nbracing system\nequipped with 2 hydraulic actuators\nC DEFENSES\nWehaveseenthatattacksagainststructuralcontrolsystemscan\npose significant damages. Therefore in this section we start the\ndiscussiononpotentialdefensestoattacksagainststructuralcontrol\nsystems. In particular, we focus on how to detect these attacks.\nTakingadvantageofthephysicalmodelofthesystem,itispossi-\nbletoconstructanindependentreferencemonitorthatusesexisting\nor redundant sensor measurements (e.g., place additional vibration\nsensors in an independent network) to estimate the sensor mea-\nsurements ˆ𝑦andcomputearesidual 𝑟=𝑦𝑎−ˆ𝑦comparinghowthe\nsystem should be behaving with what we measure. This type of\napproach has been widely studied in the literature, [ 37,92] and we\ncan adapt these defenses to civil structures.\nThese detectors can determine if sensors or actuators are under\nattack.Todetecttheattack,themeasurementsobtainedwiththe\nsensorsarecomparedwithourexpectedestimateofthebehavior\nofthesystem.Whenahistoricaldifferencebetweenthosevaluesis\nlarge, we raise an alert.\nItiseasiertokeeptrackofanomaliesindiscretetime[ 37],there-\nforeweuseadiscreteversionoftheLuenbergerobservertoestimate\nthesystemstates.Thestateestimation ˆxandtheoutputestimationˆzare given by,\nˆx[𝑘+1]=A𝑑ˆx[𝑘] +B𝑑u[𝑘] +L(z[𝑘] −F𝑑ˆx[𝑘])\nˆz[𝑘]=F𝑑ˆx[𝑘],\nwhereA𝑑,B𝑑,andF𝑑areadiscreteversionofthesysteminEq. (1),\nLismatrixselectedsuchthattheeigenvaluesof A𝑑−LF𝑑areinside\nthe unit circle, and ˆx[0]is the initial condition of the estimator.\nThedifferencebetweenwhatweexpectandwhatwemeasureis\ncalled a residue r[𝑘]:\n𝑟𝑖[𝑘]=|𝑧𝑖[𝑘] −ˆ𝑧𝑖[𝑘]|,\nwhere𝑧𝑖refers to themeasurementobtained with the 𝑖𝑡ℎsensor,\nandˆ𝑧𝑖refers to the estimation of the 𝑖𝑡ℎoutput.\nWhen the system is under attack, the residues rare large. To\ndetermineifsuchdifferenceislargeenoughtoraiseanalarm,we\nuse the non-parametric cumulative sum (CUSUM). Unlike other\ntests,theCUSUMconsidersnotonlythecurrentresiduebutalsothe\nhistorical behavior of the residues. We select this detector because\nit outperforms other statistics [ 92]. For the CUSUM, we define a\nnew statistic for each sensor 𝑆𝑖[𝑘], which is given by,\n𝑆𝑖[𝑘+1]=max{0,𝑆𝑖[𝑘] +𝑟𝑖[𝑘] −𝑏𝑖},\nwhere𝑆𝑖[0]=0, and𝑏𝑖>0 is selected to prevent that statistic\nincreases without attack. The parameter is tuned such that, in a\nscenario without attack,\nE[𝑟𝑖[𝑘] −𝑏𝑖]<0,\nwhereE[·]is the expected value. An alarm is raised for the 𝑖𝑡ℎ\nsensor when the statistic exceeds a threshold 𝑆𝑖[𝑘]>𝜏𝑖,𝜏𝑖>0.\nCommonly,thestatisticisresettozero 𝑆𝑖[𝑘+1]=0onceanalarm\nisraised.However,forillustrationpurposes,wewillnotresetthe\nCUSUMintheresultsofthissection.Theselectionoftheparameter\n𝜏𝑖is a trade-off between the time taken to detect an attack and the\nfalse alarm rate: a large threshold will give us low false alarms, but\nthen, the time to detect an attack will increase. A block diagram\nthatsummarizestheanomalydetectionstrategyispresentedinFig.\n32.\nWestudytheperformanceofthisdefenseinthe20-storybuilding\nwith an ATMD.\nOne of our unanticipated challenges of using a model-based\nanomalydetectioninstructuralcontrol,isthatthesystemgenerates\nfalsealarmswheneverthereisanearthquake,asseeninFig.33a.\nSo if a DoS attack is launched during an earthquake, it would be\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1336Building\nEstimator\nCUSUM\nSensors\n Actuators\nController\nAlarms\nFigure 32: Model-based anomaly detection.\nimpossible to determine if the alert is the result of an attack or the\nearthquake.\nToaddressthisproblem,weneedtomeasuregroundseismicsig-\nnals.Fortunately,seismicwavescanberecordedwithseismographs\nand their size or intensity can be estimated using the Moment\nmagnitude or the Richter scale. Most structural health monitoring\nsystems include an accelerometer installed in the ground to cap-\nture earthquake signals in real time and trigger the control system.\nThese accelerometers can be digital seismographs or the same type\nof sensors used inside the structure [20].\n0 10 20 300246\nFalse\nalarm\n(a)0 10 20 30 400204060\n(b)\nFigure\n33: Anomaly detection statistic when there is no at-\ntackbutduringanearthquakefora)adetectorthatdoesnot\nconsidertheearthquakeandb)adetectorthatconsidersthe\nearthquake.\nWithearthquakemeasurements,weneedtoselectthediscretiza-\ntion time to ensure that the earthquake is properly sampled. Since\nthe maximum frequency of an earthquake is 10 𝐻𝑧, we select a\nsampling time of 𝑇𝑠=0.01𝑠.With this new system, the estimator receives a noisy version of\ntheearthquakeinsteadoftheactualsignal.Forthisnewdetector,\nthe CUSUM parameters are tuned by generating different earth-\nquakes using the Kanai-Tajimi model for each of the one thousand\nsimulationsusedtotunetheCUSUM.Fig.33bshowstheCUSUM\nfor this new detector during El Centro earthquake.\nWe now consider the performance of this attack-detector when\nfacingaDoSattackduringanearthquake,andanFDIattackwithout\nan earthquake. The results of those scenarios are presented in Figs.\n34aand34b,respectively.OursystemdetectstheDoSattackattime\n4.78𝑠before the ISD ratio reaches 1% (that is, the attack is detected\nbefore they damage the structure). We detect an FDI attack even\nfaster and well before any damage to the system.\nTosumup,model-basedanomalydetectionalgorithmscanbe\nused to detect both, DoS and FDI attacks to structural control sys-\ntems;however,weneedtomeasuretheearthquakeduringaDoS\nattack(inadditiontomeasuringthecontrolandsensorsignalsfrom\nall other floors).\n0 10 20 3000.10.20.30 10 20 30-2-1012ISD (%)\nAttack\ndetectedAttack detectedMaximum safe\n ISD ratio\n(a)0 10 20 3002460 10 20 30-2-1012ISD (%)\nAttack detectedMaximum secure ISD ratio\nAttack\ndetected\n(b)\nFigure\n34:Detectionofthea)DoSandb)FDIattacksusinga\ndetector that considers the disturbances.\nSession 5A: Control System Security\n \nCCS ’21, November 15–19, 2021, Virtual Event, Republic of Korea\n1337"}
